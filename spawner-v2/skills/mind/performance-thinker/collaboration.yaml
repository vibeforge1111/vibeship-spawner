# Performance Thinker Collaboration Patterns
# How performance work integrates with other foundational skills

collaboration:
  # Lead role - Performance Thinker drives these workflows
  leads:
    - workflow: performance-optimization
      description: Identifying and fixing performance bottlenecks
      involves:
        - debugging-master: Finding root cause of slowdowns
        - system-designer: Architecture-level performance decisions
        - refactoring-guide: Code changes for performance
      handoff_points:
        - to: debugging-master
          when: Performance issue requires deep investigation
          context_to_share: Symptoms, profiling data, suspected areas
        - to: system-designer
          when: Architecture change needed for performance
          context_to_share: Current bottlenecks, scale requirements

    - workflow: capacity-planning
      description: Understanding and planning for load requirements
      involves:
        - system-designer: Architecture scaling decisions
        - test-strategist: Load testing design
      handoff_points:
        - to: system-designer
          when: Need to design for scale
          context_to_share: Current metrics, projected growth
        - to: test-strategist
          when: Need load testing strategy
          context_to_share: Performance targets, critical paths

    - workflow: performance-monitoring
      description: Setting up and maintaining performance observability
      involves:
        - incident-responder: Alerting on performance issues
        - debugging-master: Investigating anomalies
      handoff_points:
        - to: incident-responder
          when: Performance degradation detected
          context_to_share: Metrics, thresholds, baseline data

  # Support role - Performance Thinker assists these workflows
  supports:
    - workflow: system-design
      led_by: system-designer
      contribution: Performance implications of design decisions
      when_called: Design review, technology selection

    - workflow: code-review
      led_by: code-quality
      contribution: Identifying performance anti-patterns
      when_called: Reviewing code for performance concerns

    - workflow: debugging
      led_by: debugging-master
      contribution: Performance debugging techniques
      when_called: Investigating slow behavior

    - workflow: incident-response
      led_by: incident-responder
      contribution: Performance-related incident investigation
      when_called: Performance degradation in production

  # Escalation patterns
  escalations:
    - situation: Performance issue requires architecture redesign
      escalate_to: system-designer
      with_context: Bottleneck analysis, scaling requirements
      reason: Beyond code-level optimization

    - situation: Can't identify root cause of slowdown
      escalate_to: debugging-master
      with_context: Symptoms, what's been tried, profiling data
      reason: Need systematic debugging approach

    - situation: Performance fix requires significant refactoring
      escalate_to: refactoring-guide
      with_context: Current code, target architecture, tests needed
      reason: Safe transformation needed

    - situation: Performance vs feature tradeoff decision
      escalate_to: decision-maker
      with_context: Performance cost, business value, alternatives
      reason: Need strategic decision framework

  # Integration contracts
  contracts:
    with_debugging_master:
      performance_thinker_provides:
        - Profiling data and hotspots
        - Performance baselines
        - Reproduction steps for slow behavior
      debugging_master_provides:
        - Root cause analysis
        - Systematic investigation approach
        - Identification of subtle issues
      interface_example: |
        # Performance thinker hands off to debugging master:
        """
        PERFORMANCE ISSUE:

        SYMPTOM: API endpoint p95 jumped from 100ms to 2000ms
        STARTED: After deploy abc123
        PROFILING: Database query taking 1800ms (was 50ms)

        TRIED:
        - Checked EXPLAIN (uses index, same as before)
        - Checked database load (normal)
        - Checked network (normal)

        NEED: Root cause investigation
        """

        # Debugging master investigates and returns:
        """
        ROOT CAUSE: Connection pool exhausted

        EVIDENCE:
        - Pool max: 10 connections
        - Under load: all connections in use
        - Queries waiting for connection

        FIX: Increase pool size or investigate connection leaks
        """

    with_system_designer:
      performance_thinker_provides:
        - Current performance metrics
        - Scaling limits of current design
        - Bottleneck analysis
      system_designer_provides:
        - Architecture patterns for scale
        - Component design for performance
        - Technology recommendations
      interface_example: |
        # Performance thinker identifies limit:
        """
        SCALING LIMIT:

        CURRENT: 500 requests/second before degradation
        TARGET: 5000 requests/second
        BOTTLENECK: Database is single instance, read-heavy workload

        OPTIONS CONSIDERED:
        1. Add read replicas (4x improvement)
        2. Add caching layer (10x for cache hits)
        3. Shard database (unlimited but complex)
        """

        # System designer recommends:
        """
        ARCHITECTURE RECOMMENDATION:

        Phase 1 (immediate): Add read replicas
        - 2 replicas for read scaling
        - Split read/write at application layer
        - Expected: 1500 req/sec

        Phase 2 (3 months): Add Redis cache
        - Cache hot data (user sessions, config)
        - 80% hit rate expected
        - Expected: 5000+ req/sec

        Phase 3 (if needed): Evaluate sharding
        - Only if phases 1-2 insufficient
        """

    with_test_strategist:
      performance_thinker_provides:
        - Performance requirements and SLAs
        - Metrics to track
        - Realistic load patterns
      test_strategist_provides:
        - Load test design
        - Benchmark test suite
        - Performance regression testing
      interface_example: |
        # Performance thinker defines requirements:
        """
        PERFORMANCE REQUIREMENTS:

        API ENDPOINTS:
        - GET /users: < 50ms p95
        - POST /orders: < 200ms p95
        - GET /search: < 500ms p95

        THROUGHPUT:
        - Sustained: 1000 req/sec
        - Peak: 3000 req/sec for 5 minutes

        LOAD PATTERN:
        - Normal: 200 req/sec
        - Peak hours: 800 req/sec
        - Flash sale events: 3000 req/sec
        """

        # Test strategist designs suite:
        """
        LOAD TEST SUITE:

        Benchmark Tests (every PR):
        - Key function benchmarks
        - Regression detection

        Load Tests (nightly):
        - Sustained load: 1000 req/sec, 10 minutes
        - Ramp test: 0 → 2000 req/sec over 5 minutes
        - Soak test (weekly): 500 req/sec, 4 hours

        Spike Tests (weekly):
        - Flash sale simulation: 3000 req/sec, 5 minutes

        ASSERTIONS:
        - p95 < target
        - Error rate < 0.1%
        - No memory growth trend
        """

    with_refactoring_guide:
      performance_thinker_provides:
        - Performance-critical code sections
        - Target performance improvements
        - Profiling data before changes
      refactoring_guide_provides:
        - Safe refactoring plan
        - Test strategy for changes
        - Incremental improvement path
      interface_example: |
        # Performance thinker identifies optimization need:
        """
        OPTIMIZATION OPPORTUNITY:

        TARGET: OrderProcessor.calculateTotal()
        CURRENT: 50ms per call, called 1000x/request
        TOTAL: 50 seconds per request (unacceptable)

        ROOT CAUSE: Fetches pricing data per item (N+1)

        REQUIRED:
        - Batch pricing lookup
        - Expected: 1ms per call → 1 second total
        """

        # Refactoring guide plans changes:
        """
        REFACTORING PLAN:

        1. Add characterization tests for calculateTotal
        2. Extract getPrices() method
        3. Change to batch: getPrices(itemIds)
        4. Update calculateTotal to use batch
        5. Verify tests pass
        6. Benchmark improvement

        SAFETY: Tests catch behavior changes
        ROLLBACK: Each step independently reversible
        """

    with_incident_responder:
      performance_thinker_provides:
        - Performance baselines
        - Alerting thresholds
        - Diagnostic runbooks
      incident_responder_provides:
        - Real-time incident data
        - Impact assessment
        - User-facing symptoms
      interface_example: |
        # Performance thinker defines thresholds:
        """
        PERFORMANCE ALERTS:

        WARNING (investigate):
        - p95 latency > 200ms (baseline: 100ms)
        - Error rate > 0.5%
        - CPU > 70% sustained

        CRITICAL (page on-call):
        - p95 latency > 500ms
        - Error rate > 2%
        - CPU > 90% sustained
        - Memory > 85%
        """

        # Incident responder triggers:
        """
        PERFORMANCE INCIDENT:

        ALERT: p95 latency at 450ms (critical: 500ms)
        STARTED: 10 minutes ago
        IMPACT: 12% of requests slow

        INITIAL FINDINGS:
        - Database CPU elevated
        - No recent deploys
        - Traffic slightly elevated

        NEED: Performance expert investigation
        """

# Prerequisites for using this skill effectively
prerequisites:
  skills: []  # Foundational skill, no prerequisites
  knowledge:
    - Basic programming concepts
    - Understanding of databases
    - Familiarity with web applications
  tools:
    - Profiler for your language
    - Database query analyzer
    - Monitoring/APM tool (optional)

# When to delegate to this skill
delegation_triggers:
  - phrase: "slow"
    confidence: high
  - phrase: "performance"
    confidence: high
  - phrase: "optimize"
    confidence: high
  - phrase: "latency"
    confidence: high
  - phrase: "throughput"
    confidence: high
  - phrase: "profiling"
    confidence: high
  - phrase: "benchmark"
    confidence: high
  - phrase: "cache"
    confidence: medium
  - phrase: "n+1"
    confidence: high
  - phrase: "bottleneck"
    confidence: high
  - phrase: "memory leak"
    confidence: high
  - phrase: "response time"
    confidence: high
  - phrase: "too slow"
    confidence: high
  - phrase: "speed up"
    confidence: high

# Skill maturity indicators
maturity_levels:
  beginner:
    characteristics:
      - Profiles before optimizing
      - Understands Big O basics
      - Knows common anti-patterns (N+1)
    common_mistakes:
      - Premature optimization
      - Optimizing without measuring
      - Micro-benchmarking irrelevant code

  intermediate:
    characteristics:
      - Systematic bottleneck identification
      - Database query optimization
      - Caching with invalidation strategy
    common_mistakes:
      - Over-engineering for scale
      - Cache without clear invalidation
      - Missing end-to-end measurement

  advanced:
    characteristics:
      - Capacity planning
      - Trade-off analysis
      - Knows when NOT to optimize
    common_mistakes:
      - Assuming team understands trade-offs
      - Over-optimizing stable systems
      - Not documenting performance decisions
