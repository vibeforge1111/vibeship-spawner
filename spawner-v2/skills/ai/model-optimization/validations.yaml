validations:

  - id: no-calibration-data
    name: Static Quantization Without Calibration
    severity: error
    type: regex
    pattern:
      - "quantization\\.convert\\((?!.*calibrat)"
      - "prepare\\(.*\\).*convert\\((?!.*for.*in)"
    message: "Static quantization requires calibration data for accurate activation ranges."
    fix_action: "Add calibration loop before convert()"
    applies_to:
      - "**/*.py"

  - id: onnx-no-dynamic-axes
    name: ONNX Export Without Dynamic Axes
    severity: warning
    type: regex
    pattern:
      - "torch\\.onnx\\.export\\((?!.*dynamic_axes)"
      - "onnx\\.export\\((?!.*dynamic_axes)"
    message: "ONNX export without dynamic_axes creates fixed-shape model."
    fix_action: "Add: dynamic_axes={'input': {0: 'batch'}, 'output': {0: 'batch'}}"
    applies_to:
      - "**/*.py"

  - id: no-model-eval
    name: Quantization Without model.eval()
    severity: error
    type: regex
    pattern:
      - "quantize_dynamic\\((?!.*\\.eval\\(\\))"
      - "prepare\\((?!.*\\.eval\\(\\))"
    message: "Model must be in eval mode before quantization."
    fix_action: "Add: model.eval() before quantization"
    applies_to:
      - "**/*.py"

  - id: missing-opset-version
    name: ONNX Export Without Opset Version
    severity: info
    type: regex
    pattern:
      - "torch\\.onnx\\.export\\((?!.*opset_version)"
    message: "Specify opset_version for reproducible ONNX export."
    fix_action: "Add: opset_version=17 (or appropriate version)"
    applies_to:
      - "**/*.py"

  - id: fp16-no-scaler
    name: FP16 Training Without GradScaler
    severity: warning
    type: regex
    pattern:
      - "autocast.*float16(?!.*GradScaler)"
      - "torch\\.float16.*backward\\(\\)(?!.*scaler)"
    message: "FP16 training needs GradScaler to prevent gradient underflow."
    fix_action: "Use: scaler = GradScaler(); scaler.scale(loss).backward()"
    applies_to:
      - "**/*train*.py"

  - id: quantize-before-train
    name: Quantizing Untrained Model
    severity: warning
    type: regex
    pattern:
      - "quantize.*\\n.*\\.train\\("
      - "prepare_qat.*\\n.*for.*epoch.*range\\(\\d{2,}\\)"
    message: "Model should be trained before quantization for best results."
    fix_action: "Train model first, then apply quantization"
    applies_to:
      - "**/*.py"

  - id: no-onnx-check
    name: ONNX Export Without Validation
    severity: info
    type: regex
    pattern:
      - "torch\\.onnx\\.export\\((?!.*onnx\\.checker|onnx\\.load)"
    message: "Validate ONNX export with onnx.checker.check_model()."
    fix_action: "Add: onnx.checker.check_model(onnx.load(path))"
    applies_to:
      - "**/*.py"
