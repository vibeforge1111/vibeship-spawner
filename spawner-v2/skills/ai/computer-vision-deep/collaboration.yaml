id: computer-vision-deep-collaboration
skill: computer-vision-deep
version: 1.0.0

receives_from:
  - skill: model-optimization
    context: "Optimized vision model deployment"
    receives:
      - "Quantized model"
      - "TensorRT engine"
    provides: "Inference pipeline"

  - skill: distributed-training
    context: "Multi-GPU vision training"
    receives:
      - "DDP/FSDP configuration"
      - "Data loading strategy"
    provides: "Distributed training setup"

delegation_triggers:
  - trigger: "quantiz|deploy|tensorrt|onnx"
    delegate_to: model-optimization
    context: "Model optimization for deployment"

  - trigger: "multi.*gpu|distributed|fsdp"
    delegate_to: distributed-training
    context: "Distributed training setup"

  - trigger: "text.*image|clip|multi.*modal|vision.*language"
    delegate_to: nlp-advanced
    context: "Multi-modal vision-language"

  - trigger: "3d.*reconstruct|point.*cloud|mesh"
    delegate_to: neural-architecture-search
    context: "3D reconstruction architectures"

feedback_loops:
  receives_feedback_from:
    - skill: model-optimization
      signal: "Latency/memory constraints"
      action: "Choose appropriate model size"

    - skill: backend
      signal: "Inference requirements"
      action: "Select real-time capable model"

  sends_feedback_to:
    - skill: model-optimization
      signal: "Model for optimization"
      action: "Prepare for quantization/export"

    - skill: distributed-training
      signal: "Large-scale training need"
      action: "Set up multi-GPU pipeline"

common_combinations:
  - name: YOLO + SAM Pipeline
    skills:
      - computer-vision-deep
    workflow: |
      1. YOLO detection for class-aware boxes
      2. SAM segmentation with box prompts
      3. Combine for instance segmentation
      4. Post-process masks

  - name: Video Analysis Pipeline
    skills:
      - computer-vision-deep
    workflow: |
      1. Object detection per frame
      2. ByteTrack/BoT-SORT tracking
      3. Action recognition (optional)
      4. Generate analytics

  - name: Edge Deployment
    skills:
      - computer-vision-deep
      - model-optimization
    workflow: |
      1. Train/select vision model
      2. Quantize (INT8/TensorRT)
      3. Export to target format
      4. Deploy to edge device
      5. Benchmark performance

  - name: Large-Scale Training
    skills:
      - computer-vision-deep
      - distributed-training
    workflow: |
      1. Prepare dataset sharding
      2. Configure DDP/FSDP
      3. Set up distributed data loading
      4. Train with gradient accumulation
      5. Aggregate metrics

ecosystem:
  detection_frameworks:
    - "Ultralytics YOLO"
    - "Detectron2"
    - "MMDetection"
    - "DINO-DETR"

  segmentation_tools:
    - "Segment Anything (SAM)"
    - "SAM 2"
    - "SegFormer"
    - "Mask2Former"

  depth_estimation:
    - "Depth Anything"
    - "MiDaS"
    - "ZoeDepth"
    - "Metric3D"

  video_analysis:
    - "VideoMAE"
    - "ByteTrack"
    - "BoT-SORT"
    - "StrongSORT"

  augmentation:
    - "Albumentations"
    - "torchvision.transforms"
    - "Kornia"

references:
  papers:
    - "Segment Anything (Kirillov et al. 2023)"
    - "YOLO: Real-Time Object Detection"
    - "DETR: End-to-End Detection with Transformers"
    - "Depth Anything: Unlocking the Power of Large-Scale Unlabeled Data"

  tutorials:
    - "Ultralytics Documentation"
    - "SAM Segment Anything Tutorial"
    - "HuggingFace Vision Models"
