id: nlp-advanced-collaboration
skill: nlp-advanced
version: 1.0.0

receives_from:
  - skill: llm-fine-tuning
    context: "Domain-specific NLP model"
    receives:
      - "Fine-tuned NER model"
      - "Domain vocabulary"
    provides: "Information extraction pipeline"

  - skill: transformer-architecture
    context: "Custom NLP architecture"
    receives:
      - "Model architecture design"
      - "Attention patterns"
    provides: "Task-specific model"

delegation_triggers:
  - trigger: "fine.?tun|train.*model|domain.*adapt"
    delegate_to: llm-fine-tuning
    context: "Model training"

  - trigger: "architecture|attention|custom.*model"
    delegate_to: transformer-architecture
    context: "Model architecture"

  - trigger: "image.*text|document.*understand|ocr"
    delegate_to: computer-vision-deep
    context: "Multi-modal document processing"

  - trigger: "deploy|inference|optim.*speed"
    delegate_to: model-optimization
    context: "Deployment optimization"

feedback_loops:
  receives_feedback_from:
    - skill: computer-vision-deep
      signal: "OCR/document layout"
      action: "Process extracted text"

    - skill: backend
      signal: "Latency requirements"
      action: "Choose appropriate model size"

  sends_feedback_to:
    - skill: llm-fine-tuning
      signal: "Domain data requirements"
      action: "Prepare training data"

    - skill: model-optimization
      signal: "NLP model for deployment"
      action: "Optimize for inference"

common_combinations:
  - name: Full IE Pipeline
    skills:
      - nlp-advanced
    workflow: |
      1. Coreference resolution
      2. Named entity recognition
      3. Entity linking to KB
      4. Relation extraction
      5. Knowledge graph construction

  - name: Document Understanding
    skills:
      - nlp-advanced
      - computer-vision-deep
    workflow: |
      1. OCR/layout detection
      2. Text extraction
      3. NER on extracted text
      4. Table/form extraction
      5. Structure output

  - name: Domain NLP
    skills:
      - nlp-advanced
      - llm-fine-tuning
    workflow: |
      1. Collect domain data
      2. Annotate for NER/RE
      3. Fine-tune BERT model
      4. Evaluate on domain test set
      5. Deploy pipeline

  - name: Zero-Shot IE
    skills:
      - nlp-advanced
    workflow: |
      1. Define entity types
      2. Create LLM prompts
      3. Extract with few-shot examples
      4. Post-process and validate
      5. Build knowledge graph

ecosystem:
  ner_libraries:
    - "HuggingFace Transformers"
    - "SpaCy"
    - "Flair"
    - "Stanza"
    - "AllenNLP"

  relation_extraction:
    - "OpenNRE"
    - "DeepKE"
    - "REBEL"
    - "PL-Marker"

  coreference:
    - "SpaCy experimental coref"
    - "AllenNLP coref"
    - "Longformer coref"

  knowledge_graphs:
    - "NetworkX"
    - "RDFLib"
    - "Neo4j"
    - "Wikidata API"
    - "spacy-entity-linker"

  evaluation:
    - "seqeval"
    - "nervaluate"
    - "scikit-learn"

references:
  surveys:
    - "Relation Extraction Survey 2025"
    - "Named Entity Recognition: A Survey"
    - "Knowledge Graph Construction from Text"

  tutorials:
    - "HuggingFace Token Classification"
    - "SpaCy NER Tutorial"
    - "Building Knowledge Graphs with NLP"

  papers:
    - "BERT: Pre-training of Deep Bidirectional Transformers"
    - "SpanBERT: Improving Pre-training"
    - "REBEL: Relation Extraction By End-to-end Language generation"
