id: disaster-recovery-sharp-edges
skill: disaster-recovery
version: 1.0.0

sharp_edges:

  - id: untested-dr-plan
    severity: critical
    title: "Disaster Recovery Plan Never Tested"
    summary: "DR plan exists on paper but has never been executed"
    symptoms:
      - "Last DR test was years ago"
      - "Team doesn't know the runbook"
      - "Backup restore times are unknown"
    why: |
      An untested DR plan is not a plan - it's hopeful documentation.
      Real disasters reveal gaps: missing passwords, changed infrastructure,
      broken automation, and team members who don't know their roles.
    gotcha: |
      "Our DR plan says we can recover in 4 hours"
      "When did you last test it?"
      "We... haven't. But it's documented!"

      # The disaster happens. Recovery takes 3 days.
    solution: |
      1. Schedule regular DR drills:
         - Quarterly for critical systems
         - Annual full-scale exercises
         - Document and review results

      2. Game day exercises:
         - Simulate real scenarios
         - Include on-call team
         - Practice communication

      3. Automated testing:
         - Restore backups weekly
         - Verify data integrity
         - Measure actual RTO

  - id: single-region-backups
    severity: critical
    title: "Backups in Same Region as Primary"
    summary: "All backups stored in the same region as production data"
    symptoms:
      - "Fast backup/restore times"
      - "Low storage costs"
      - "No cross-region replication"
    why: |
      Regional disasters (data center fire, natural disaster, provider outage)
      can take out both your primary data AND your backups. Cross-region
      replication is essential for true disaster recovery.
    gotcha: |
      "Where are our backups stored?"
      "us-east-1, same as production for fast restores"
      "And if us-east-1 goes down?"
      "..."

      # AWS us-east-1 outage takes down both primary and backups
    solution: |
      1. Cross-region backup replication:
         - Replicate to at least one other region
         - Consider different cloud provider
         - Verify replication is working

      2. Backup verification:
         - Test restores from DR region
         - Verify data integrity
         - Document restore procedures

      3. Consider 3-2-1 rule:
         - 3 copies of data
         - 2 different storage types
         - 1 offsite location

  - id: manual-failover-steps
    severity: high
    title: "Manual Steps in Failover Process"
    summary: "Failover requires manual intervention that slows recovery"
    symptoms:
      - "Failover requires SSH access"
      - "Manual DNS changes needed"
      - "Database promotion is manual"
    why: |
      During a disaster, stress is high and people make mistakes.
      Manual steps add time to RTO and introduce human error.
      What takes 5 minutes in practice takes 30 under pressure.
    gotcha: |
      "Step 5: SSH to the replica and run promote_to_primary.sh"
      "I can't find the SSH key!"
      "It's in the password vault"
      "Which password vault?"

      # 45 minutes lost finding credentials
    solution: |
      1. Automate everything:
         - Scripted failover procedures
         - Automated health checks
         - Automatic DNS updates

      2. One-click failover:
         - Single command to initiate
         - All steps automated
         - Rollback capability

      3. Eliminate dependencies:
         - No SSH required
         - No manual approvals during DR
         - Pre-authorized actions

  - id: missing-dependency-map
    severity: high
    title: "Dependencies Not Mapped for DR"
    summary: "DR plan doesn't account for all system dependencies"
    symptoms:
      - "Service starts but can't function"
      - "Missing third-party services"
      - "Authentication fails after failover"
    why: |
      Modern systems have many dependencies: databases, caches, queues,
      third-party APIs, DNS, authentication providers. If your DR plan
      doesn't account for all of them, recovery is incomplete.
    gotcha: |
      "We failed over the application successfully!"
      "Great, is it working?"
      "No, it can't connect to Redis"
      "Did we fail over Redis?"
      "...that wasn't in the plan"

      # Application is up but non-functional
    solution: |
      1. Complete dependency mapping:
         - Internal services
         - Databases and caches
         - Third-party APIs
         - Authentication/SSO
         - DNS and CDN

      2. Tiered recovery plan:
         - Infrastructure first
         - Data stores second
         - Applications third
         - Verification last

      3. Regular dependency audits:
         - Review when adding services
         - Update DR plan accordingly
         - Test full-stack recovery

  - id: no-chaos-engineering
    severity: medium
    title: "No Chaos Engineering Practice"
    summary: "System resilience is assumed but never tested"
    symptoms:
      - "Single points of failure unknown"
      - "Failure modes untested"
      - "Team lacks incident experience"
    why: |
      You can't know how your system fails until you make it fail.
      Chaos engineering in production reveals weaknesses before
      real disasters do. Teams that practice handling failures
      respond better during real incidents.
    gotcha: |
      "Our system is highly available"
      "What happens if the database fails?"
      "It should fail over automatically"
      "Have you tested it?"
      "No, but we designed it that way"

      # Theory doesn't survive contact with reality
    solution: |
      1. Start small:
         - Kill single instances
         - Add network latency
         - Fill disk space

      2. Game days:
         - Planned chaos experiments
         - Team observes and learns
         - Document discoveries

      3. Continuous chaos:
         - Chaos Monkey in production
         - Random failure injection
         - Build resilience into culture

detection:
  file_patterns:
    - "**/*backup*.py"
    - "**/*disaster*.yaml"
    - "**/*failover*.sh"
    - "**/runbook*.md"
