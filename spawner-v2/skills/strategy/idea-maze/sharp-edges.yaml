# Idea Maze Sharp Edges
# The idea-finding mistakes that waste years on wrong problems

sharp_edges:
  - id: solution-first-thinking
    summary: Starting with a solution instead of a problem
    severity: critical
    situation: |
      "I want to build an AI chatbot" or "Let's use blockchain for something."
      Technology looking for a problem. Months spent building something
      nobody actually needs.
    why: |
      Solutions without problems are hobbies, not businesses. You'll never
      understand users as well as someone living the problem. The tech
      will drive decisions instead of user needs.
    solution: |
      # Flip your thinking:

      ## Instead of:
      "I want to build X technology"

      ## Ask:
      "What problem do I face repeatedly?"
      "What do I wish existed?"
      "What would I pay for right now?"

      ## Validation:
      - Do others have this problem?
      - How are they solving it today?
      - Why is today's solution inadequate?

      ## The PG test:
      "Live in the future, then build what's missing"
      Not: "Learn tech, then find application"
    symptoms:
      - Starting with technology choice
      - Searching for use cases
      - Building without talking to users
      - No personal pain with the problem
    detection_pattern: null

  - id: imaginary-problem
    summary: Solving a problem you invented, not discovered
    severity: critical
    situation: |
      "I think people would want..." Based on theory, not observation.
      No evidence anyone actually has this problem. Building on assumptions.
    why: |
      Invented problems feel real to inventors. But users don't have them.
      You can build a perfect solution to an imaginary problem. It will
      still fail.
    solution: |
      # Evidence requirements:

      ## Before building anything:
      - Talked to 20+ potential users
      - Found the problem exists (unprompted)
      - Saw them struggle with it
      - Understood how they currently cope

      ## Red flags (you invented the problem):
      - Users say "I guess that could be useful"
      - No one currently paying for alternatives
      - You have to explain why it's a problem
      - Problem only exists in specific framing

      ## Green flags (problem is real):
      - Users complain about it unprompted
      - Money being spent on bad solutions
      - Strong emotional reaction when discussed
      - Users ask when you'll be ready
    symptoms:
      - No user interviews before building
      - Users need education about the problem
      - Zero current spending on alternatives
      - Lukewarm user reactions
    detection_pattern: null

  - id: tarpit-attraction
    summary: Pursuing ideas that look good but have structural problems
    severity: high
    situation: |
      "It's a social network for X" or "A marketplace connecting Y to Z."
      Ideas that sound good in conversation but have fundamental challenges
      that make success nearly impossible.
    why: |
      Tarpits attract many founders because they sound exciting. But they
      have chicken-egg problems, network effect requirements, or capital
      intensity that makes them near-impossible for most teams.
    solution: |
      # Common tarpits:

      ## Social networks:
      - Need viral growth (very rare)
      - Winner-take-all dynamics
      - Competing with infinite-budget incumbents

      ## Two-sided marketplaces:
      - Need both sides simultaneously
      - Chicken-egg problem is brutal
      - Leakage once connected

      ## Hardware:
      - Needs millions in capital
      - Long development cycles
      - Manufacturing complexity

      # If you must pursue:
      - What is your wedge into the market?
      - What is your unfair advantage?
      - How do you bootstrap without network?
    symptoms:
      - Describing idea as "X for Y"
      - No clear wedge strategy
      - Relying on viral growth
      - No explanation for why incumbents haven't won
    detection_pattern: null

  - id: schlep-avoidance
    summary: Rejecting ideas because they involve hard, boring work
    severity: high
    situation: |
      Great idea. But execution would require calling businesses, dealing
      with regulations, or building complex infrastructure. Rejected in
      favor of "cleaner" idea. Clean idea fails because it's crowded.
    why: |
      Schleps (boring, hard work) are moats. Everyone avoids them, which
      is exactly why they're valuable. Stripe succeeded because payments
      were a schlep. Airbnb because photographing listings was a schlep.
    solution: |
      # Reframe schleps as opportunity:

      ## The schlep advantage:
      - Others avoid it (less competition)
      - Creates real value (hard to copy)
      - Builds domain expertise (compounds)

      ## Questions to ask:
      - What would I avoid doing even if it paid well?
      - What work do experts do that seems tedious?
      - What process does everyone hate but accept?

      ## The anti-pattern to avoid:
      Choosing "clean" ideas because they're easier
      Easy = crowded = commoditized

      ## Embrace the grind:
      "If I'm not willing to do the hard thing,
      I don't deserve the outcome"
    symptoms:
      - Rejecting ideas because "too hard"
      - Looking for "clean" tech-only solutions
      - Avoiding industries with complexity
      - Seeking ideas that scale immediately
    detection_pattern: null

  - id: small-thinking
    summary: Pursuing ideas that are safe but small
    severity: high
    situation: |
      "A slightly better to-do app" or "Improvement on existing product."
      Safe ideas that don't scare you. Also don't attract talent, investors,
      or press. Max outcome is acqui-hire.
    why: |
      Frighteningly ambitious ideas are paradoxically often easier. They
      attract better people, more capital, more press. Small ideas have
      small outcomes even when successful.
    solution: |
      # The ambitious idea test:

      ## PG's examples of frighteningly ambitious:
      - Replace email (Slack)
      - Replace money (Stripe)
      - Make all information accessible (Google)

      ## Signs you're thinking too small:
      - Easy to explain to parents
      - No one says "that's crazy"
      - Many similar competitors exist
      - Max outcome is a few million

      ## Think bigger:
      - What's the 100x version of this idea?
      - What would be worth 10 years of your life?
      - What would attract a world-class team?

      ## Caution:
      Ambitious doesn't mean impractical
      Start with a wedge, grow to the vision
    symptoms:
      - Ideas that feel "safe"
      - No moonshot element
      - Easy to explain in one sentence
      - Incremental improvement on existing
    detection_pattern: null

  - id: brainstorm-reliance
    summary: Generating ideas through brainstorming instead of observation
    severity: high
    situation: |
      Team brainstorming session. 50 ideas on whiteboard. Vote on best one.
      Build it. Fail. Because none of the ideas came from lived experience.
    why: |
      Brainstormed ideas are manufactured, not organic. They lack the deep
      understanding that comes from living the problem. Best ideas come
      from noticing what's missing in your own life.
    solution: |
      # Organic idea generation:

      ## Better than brainstorming:
      - Live in the future (use cutting-edge stuff)
      - Notice friction (what's annoying?)
      - Write down problems (idea journal)
      - Talk to people (what frustrates them?)

      ## The signal:
      Organic ideas feel obvious in hindsight
      "Of course this should exist"
      Not "wouldn't it be cool if..."

      ## If you must brainstorm:
      - Start with problems, not solutions
      - Only include people who have the problems
      - Validate with outsiders immediately

      ## PG's advice:
      If you have to ask "what should I build?"
      You don't know enough yet. Go get more experience.
    symptoms:
      - Ideas from brainstorm sessions
      - No founder has the problem personally
      - Choosing by vote not conviction
      - Ideas feel theoretical
    detection_pattern: null

  - id: market-research-oracle
    summary: Relying on reports instead of direct observation
    severity: medium
    situation: |
      "Gartner says this is a $50B market." Build based on report.
      Report reflects the past, not the future. Market exists but you
      have no edge. Fail to differentiate.
    why: |
      Market research is backward-looking. It tells you where value
      already exists, not where it's emerging. Everyone reads the same
      reports. No competitive insight.
    solution: |
      # Better than reports:

      ## Direct observation:
      - Talk to 30 potential customers
      - Understand their workflow
      - See their current solutions
      - Feel their frustrations

      ## Forward-looking signals:
      - What's changing in the world?
      - What technology just became possible?
      - What behavior is emerging?
      - What do sophisticated users do?

      ## Market sizing from first principles:
      - How many people have this problem?
      - How much do they spend on alternatives?
      - Why will they switch?
      - What's your capture rate?

      ## The danger:
      Reports create false confidence
      "Someone validated the market"
      No, someone described the past
    symptoms:
      - Citing analyst reports
      - No original user research
      - TAM from third-party sources
      - Market first, problem second
    detection_pattern: null

  - id: competitive-crowding
    summary: Entering markets with obvious opportunities and many players
    severity: medium
    situation: |
      "The to-do app market is huge!" Yes, and there are 1000 to-do apps.
      Obvious opportunities attract obvious competitors. Red ocean.
    why: |
      If an opportunity is obvious, others see it too. You're competing
      with everyone. The best opportunities look like bad ideas initially.
    solution: |
      # Find the non-obvious:

      ## Why good ideas look bad:
      - Schlep (hard work scared others)
      - Contrarian (consensus is wrong)
      - Wedge (starts small, gets big)
      - Expertise (you know something others don't)

      ## Questions:
      - Why hasn't this been done?
      - What do I know that others don't?
      - What's changing that makes this possible now?
      - Why would I win against everyone else?

      ## The test:
      If your idea sounds good at a dinner party,
      it's probably too crowded.

      If people say "that won't work,"
      you might be onto something.
    symptoms:
      - Idea sounds obviously good
      - Many existing competitors
      - No clear differentiation
      - Entering because market is big
    detection_pattern: null

  - id: user-request-driven
    summary: Building what users ask for instead of understanding their problems
    severity: medium
    situation: |
      "Users want X feature." Build it. Users don't use it. Because they
      described a solution, not their underlying problem.
    why: |
      Users are experts on their problems, not solutions. When they ask
      for features, they're guessing at solutions. Understanding the
      underlying problem reveals better solutions.
    solution: |
      # Dig deeper:

      ## When user requests a feature:
      - "What are you trying to accomplish?"
      - "Why is that important to you?"
      - "What happens if you can't do this?"
      - "How are you doing this today?"

      ## The 5 Whys:
      Keep asking why until you hit the root

      User: "I want to export to CSV"
      Why? "To put in Excel"
      Why? "To make a chart"
      Why? "To show my manager"
      Why? "To prove we should invest more"
      â†’ Real need: reporting for stakeholders

      ## Build for the need, not the request
    symptoms:
      - Roadmap is feature requests
      - No problem understanding
      - Features don't get used
      - Users still unsatisfied
    detection_pattern: null

  - id: premature-validation
    summary: Stopping validation too early with false positives
    severity: medium
    situation: |
      "5 people said they'd use it!" Built it. None of them use it.
      They were being polite. Or theoretical. Or didn't understand
      what they were agreeing to.
    why: |
      People are polite. Hypotheticals are easy to agree with. True
      validation is behavior, not words. Money, time, or effort.
    solution: |
      # Real validation signals:

      ## Strongest (action):
      - They pay money upfront
      - They sign a letter of intent
      - They commit significant time
      - They refer you to others unprompted

      ## Medium (effort):
      - They join a waitlist with real info
      - They schedule a follow-up call
      - They introduce you to others

      ## Weak (words):
      - "That sounds cool"
      - "I'd probably use that"
      - "Let me know when it's ready"

      ## The Mom Test rules:
      - Talk about their life, not your idea
      - Ask about the past, not hypotheticals
      - Look for emotion, not politeness
    symptoms:
      - Validation based on verbal interest
      - No money or commitment
      - Surveys instead of conversations
      - Mom/friends as validators
    detection_pattern: null
