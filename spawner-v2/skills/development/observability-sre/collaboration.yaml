# Observability SRE Collaboration Model
# How this skill works with other AI memory specialists

prerequisites:
  skills: []
  knowledge:
    - "Basic understanding of metrics (counters, gauges, histograms)"
    - "HTTP request/response model"
    - "Understanding of distributed systems basics"
    - "Familiarity with logs and log levels"

complementary_skills:
  - skill: infra-architect
    relationship: "Infrastructure monitoring"
    brings: "Kubernetes metrics, infrastructure observability stack"

  - skill: performance-hunter
    relationship: "Performance investigation"
    brings: "Profiling, bottleneck identification, optimization"

  - skill: postgres-wizard
    relationship: "Database monitoring"
    brings: "PostgreSQL metrics, query performance tracking"

  - skill: chaos-engineer
    relationship: "Resilience validation"
    brings: "Failure testing, monitoring verification"

  - skill: event-architect
    relationship: "Event system observability"
    brings: "Kafka/NATS metrics, consumer lag monitoring"

  - skill: api-designer
    relationship: "API observability"
    brings: "API metrics design, SLI definition"

delegation:
  - trigger: "infrastructure monitoring setup"
    delegate_to: infra-architect
    pattern: parallel
    context: "Monitoring requirements and Kubernetes setup"
    receive: "Prometheus operator, Grafana deployment"

  - trigger: "performance issue investigation"
    delegate_to: performance-hunter
    pattern: sequential
    context: "Metrics showing slow performance"
    receive: "Root cause analysis and optimization recommendations"

  - trigger: "database metrics setup"
    delegate_to: postgres-wizard
    pattern: parallel
    context: "Database monitoring requirements"
    receive: "pg_exporter config, key database metrics"

  - trigger: "monitoring resilience"
    delegate_to: chaos-engineer
    pattern: review
    context: "Current monitoring coverage"
    receive: "Gaps in failure detection"

  - trigger: "event queue monitoring"
    delegate_to: event-architect
    pattern: parallel
    context: "Kafka/NATS observability needs"
    receive: "Consumer lag metrics, event flow dashboards"

collaboration_patterns:
  sequential:
    - "I define SLOs, then performance-hunter validates under load"
    - "I set up alerting, then chaos-engineer tests alert firing"
    - "I create dashboards, then api-designer validates SLI accuracy"

  parallel:
    - "I instrument services while infra-architect deploys Prometheus"
    - "I create dashboards while postgres-wizard defines DB metrics"

  review:
    - "Review chaos-engineer's failure scenarios for monitoring gaps"
    - "Review performance-hunter's findings for missing metrics"
    - "Review infra-architect's monitoring infrastructure"

cross_domain_insights:
  - domain: statistics
    insight: "Histograms approximate distributions, percentiles are derived"
    applies_when: "Choosing metric types and bucket boundaries"

  - domain: signal-processing
    insight: "Smoothing (moving averages) reduces noise but adds lag"
    applies_when: "Designing alert queries with rate/avg"

  - domain: control-theory
    insight: "Feedback loops can oscillate without proper dampening"
    applies_when: "Designing auto-scaling based on metrics"

  - domain: economics
    insight: "Error budgets are risk management tools"
    applies_when: "Convincing stakeholders about SLO trade-offs"

  - domain: psychology
    insight: "Alert fatigue causes teams to ignore all alerts"
    applies_when: "Setting alert thresholds and severity"

ecosystem:
  primary_tools:
    - "Prometheus - Metrics collection and alerting"
    - "Grafana - Visualization and dashboards"
    - "OpenTelemetry - Tracing and instrumentation"
    - "Alertmanager - Alert routing and deduplication"
    - "Loki/ELK - Log aggregation"

  alternatives:
    - name: Datadog
      use_when: "Want all-in-one SaaS solution"
      avoid_when: "Cost-sensitive, want open-source control"

    - name: Jaeger
      use_when: "Need dedicated tracing with Jaeger UI"
      avoid_when: "Already using Tempo or Zipkin"

    - name: VictoriaMetrics
      use_when: "Need Prometheus-compatible with better storage"
      avoid_when: "Small scale, Prometheus is sufficient"

    - name: Honeycomb
      use_when: "Need high-cardinality exploration"
      avoid_when: "Budget constraints, standard metrics sufficient"

    - name: PagerDuty
      use_when: "Need robust on-call management"
      avoid_when: "Simple alerting to Slack is enough"

  deprecated:
    - "Alerting on causes instead of symptoms"
    - "High-cardinality metric labels"
    - "Logs without structured fields"
    - "Dashboards without SLO context"
    - "Sampling that drops error traces"
