# Collaboration - Autonomous Agents
# How this skill works with other skills

version: 1.0.0
skill_id: autonomous-agents

prerequisites:
  required: []

  recommended:
    - skill: llm-architect
      reason: "LLM selection and prompting for agents"
      what_to_know:
        - "Model selection for reasoning vs speed"
        - "Prompt engineering for agent loops"
        - "Token limits and context management"

    - skill: agent-tool-builder
      reason: "Tools for agents to call"
      what_to_know:
        - "Tool design principles"
        - "Error handling in tools"
        - "Idempotency requirements"

    - skill: agent-memory-systems
      reason: "Long-term memory for agents"
      what_to_know:
        - "Memory types and when to use each"
        - "Retrieval strategies"
        - "Context injection patterns"

delegation_triggers:
  - trigger: "user needs multi-agent coordination"
    delegate_to: multi-agent-orchestration
    context: "Multiple agents working together"

  - trigger: "user needs to test/evaluate agent"
    delegate_to: agent-evaluation
    context: "Benchmarking and testing"

  - trigger: "user needs tools for agent"
    delegate_to: agent-tool-builder
    context: "Tool design and implementation"

  - trigger: "user needs persistent memory"
    delegate_to: agent-memory-systems
    context: "Long-term memory architecture"

  - trigger: "user needs workflow automation"
    delegate_to: workflow-automation
    context: "When agent is overkill for the task"

  - trigger: "user needs computer control"
    delegate_to: computer-use-agents
    context: "GUI automation, screen interaction"

receives_context_from:
  - skill: agent-tool-builder
    receives:
      - "Tools the agent can call"
      - "Tool schemas and error handling"
      - "Idempotency patterns"

  - skill: agent-memory-systems
    receives:
      - "Memory infrastructure"
      - "Retrieval functions"
      - "Context management"

  - skill: product-strategy
    receives:
      - "Agent requirements and constraints"
      - "Use cases and user personas"
      - "Success criteria"

  - skill: llm-architect
    receives:
      - "Model selection guidance"
      - "Prompting strategies"
      - "Token optimization"

provides_context_to:
  - skill: agent-evaluation
    provides:
      - "Agent for testing"
      - "Expected behaviors"
      - "Failure modes to test"

  - skill: multi-agent-orchestration
    provides:
      - "Individual agents for coordination"
      - "Agent capabilities and limits"
      - "State management patterns"

  - skill: devops
    provides:
      - "Deployment requirements"
      - "Monitoring needs"
      - "Resource requirements"

escalation_paths:
  - situation: "Agent reliability too low"
    escalate_to: agent-evaluation
    context: "Need benchmarking and improvement"

  - situation: "Complex tool requirements"
    escalate_to: agent-tool-builder
    context: "Custom tool development"

  - situation: "Memory architecture needed"
    escalate_to: agent-memory-systems
    context: "Long-term memory design"

  - situation: "Multiple agents needed"
    escalate_to: multi-agent-orchestration
    context: "Multi-agent system design"

  - situation: "Performance issues"
    escalate_to: performance-thinker
    context: "Latency, cost optimization"

  - situation: "Security concerns"
    escalate_to: security-specialist
    context: "Guardrails, permissions, audit"

workflow_integration:
  typical_sequence:
    1:
      step: "Define agent requirements"
      skills: [product-strategy]
      output: "Use cases, constraints, success criteria"

    2:
      step: "Choose architecture"
      skills: [autonomous-agents]
      output: "ReAct vs Plan-Execute, framework selection"

    3:
      step: "Design tools"
      skills: [agent-tool-builder]
      output: "Tool specifications and implementations"

    4:
      step: "Implement agent"
      skills: [autonomous-agents]
      output: "Working agent with guardrails"

    5:
      step: "Add memory if needed"
      skills: [agent-memory-systems]
      output: "Memory architecture integrated"

    6:
      step: "Test and evaluate"
      skills: [agent-evaluation]
      output: "Benchmarks, reliability metrics"

    7:
      step: "Deploy with monitoring"
      skills: [devops]
      output: "Production deployment"

  decision_points:
    - question: "Agent or simpler automation?"
      guidance: |
        Use agent when:
        - Task requires reasoning and adaptation
        - Multiple tools needed dynamically
        - Goal can vary based on context

        Use workflow automation when:
        - Steps are predictable
        - Branching is simple
        - Reliability is critical

    - question: "ReAct or Plan-Execute?"
      guidance: |
        ReAct (Reason + Act):
        - Interactive exploration
        - Unknown number of steps
        - Learning as you go
        - Best for: Research, debugging, exploration

        Plan-Execute:
        - Full plan visibility before execution
        - Human can approve plan
        - Clearer audit trail
        - Best for: Known multi-step tasks, compliance

    - question: "Which framework?"
      guidance: |
        LangGraph:
        - Production-ready (1.0 Oct 2025)
        - Durable execution, checkpointing
        - Human-in-the-loop built-in
        - Best for: Production systems

        AutoGPT:
        - Maximum autonomy
        - Research and experimentation
        - Needs external guardrails
        - Best for: Controlled environments

        CrewAI:
        - Role-based agent teams
        - Good for specialized collaboration
        - Built-in delegation patterns
        - Best for: Multi-role scenarios

    - question: "How much autonomy?"
      guidance: |
        Start constrained, add autonomy as you prove reliability:

        Level 1 (Copilot):
        - Human approves every action
        - Agent suggests, human executes
        - Lowest risk

        Level 2 (Supervised):
        - Agent executes safe actions
        - Human approves dangerous actions
        - Balanced approach

        Level 3 (Autonomous):
        - Agent executes most actions
        - Human reviews periodically
        - High trust required

        Level 4 (Full autonomy):
        - Rarely appropriate
        - Only for non-critical, reversible tasks

collaboration_patterns:
  with_tools:
    when: "Building agent tool integrations"
    approach: |
      Tool requirements for agents:

      1. Idempotency:
         - Same input = same output
         - Safe to retry
         - No duplicate side effects

      2. Error handling:
         - Clear error messages
         - Structured error types
         - Retry hints

      3. Validation:
         - Input validation in tool
         - Output schemas
         - Confidence scores

      4. Timeout:
         - Every tool has timeout
         - Graceful timeout handling
         - Partial results if possible

  with_memory:
    when: "Adding long-term memory to agent"
    approach: |
      Memory integration patterns:

      1. Context injection:
         # Before each step
         relevant = memory.search(current_context)
         context = inject_memories(base_context, relevant)

      2. Memory formation:
         # After task completion
         memory.store(
             content=task_summary,
             metadata={"task_id": id, "outcome": result}
         )

      3. Working memory:
         # LangGraph state is working memory
         # Long-term in vector store

      4. Memory types:
         - Episodic: What happened
         - Semantic: What it means
         - Procedural: How to do things

  with_evaluation:
    when: "Testing and benchmarking agent"
    approach: |
      Evaluation requirements:

      1. Define success criteria:
         - Task completion (binary or partial)
         - Step efficiency
         - Cost bounds
         - Time bounds

      2. Create test suites:
         - Happy path
         - Edge cases
         - Adversarial
         - Failure scenarios

      3. Measure metrics:
         - Success rate (P50, P95, P99)
         - Cost per task
         - Latency distribution
         - Failure modes

      4. Iterate based on results:
         - Identify weak areas
         - Add guardrails
         - Improve prompts
         - Constrain scope

  with_orchestration:
    when: "Agent as part of multi-agent system"
    approach: |
      Multi-agent considerations:

      1. Clear boundaries:
         - Each agent has defined scope
         - No overlapping responsibilities
         - Explicit handoff points

      2. State sharing:
         - Shared state schema
         - Conflict resolution
         - Version tracking

      3. Communication:
         - Structured messages
         - Clear protocols
         - Error propagation

      4. Supervision:
         - Orchestrator pattern
         - Human-in-the-loop at system level
         - Global guardrails

platform_integration:
  langgraph:
    setup: |
      pip install langgraph langchain-openai

      from langgraph.graph import StateGraph
      from langgraph.checkpoint.postgres import PostgresSaver
      from langgraph.prebuilt import create_react_agent

      # Production setup
      checkpointer = PostgresSaver.from_conn_string(DATABASE_URL)

      agent = create_react_agent(
          model=ChatOpenAI(model="gpt-4o"),
          tools=tools,
          checkpointer=checkpointer,
      )
    considerations:
      - "Use PostgresSaver, not MemorySaver for production"
      - "Thread ID required for state persistence"
      - "interrupt_before/after for human-in-the-loop"
      - "State schema changes require migration"

  autogpt:
    setup: |
      pip install autogpt

      # Add external guardrails
      from your_guardrails import GuardedAgent

      agent = AutoGPT(
          ai_name="MyAgent",
          ai_role="...",
          goals=[...],
      )

      guarded = GuardedAgent(
          agent=agent,
          max_steps=20,
          max_cost=5.0,
          require_approval=["write_file", "send_email"],
      )
    considerations:
      - "No built-in guardrails - must add externally"
      - "Cost can spiral - set hard limits"
      - "Goals should be very specific"
      - "Monitor closely in production"

  crewai:
    setup: |
      pip install crewai

      from crewai import Agent, Task, Crew

      researcher = Agent(
          role="Researcher",
          goal="Find accurate information",
          tools=[search_tool, read_tool],
      )

      writer = Agent(
          role="Writer",
          goal="Create clear documentation",
          tools=[write_tool],
      )

      crew = Crew(
          agents=[researcher, writer],
          tasks=[research_task, write_task],
          verbose=True,
      )
    considerations:
      - "Define clear role boundaries"
      - "Delegation can create loops"
      - "Shared memory needs management"
      - "Each agent should have guardrails"

cost_optimization:
  model_selection:
    - "gpt-4o-mini for most steps (fast, cheap)"
    - "gpt-4o for complex reasoning (when needed)"
    - "Claude for long context (200K tokens)"

  context_management:
    - "Trim context aggressively"
    - "Summarize history, don't append forever"
    - "Use external memory instead of context"

  step_reduction:
    - "Combine steps where possible"
    - "Pre-compute context during user input"
    - "Cache tool results"

  monitoring:
    - "Track cost per task"
    - "Alert on cost anomalies"
    - "Set hard budget limits"
