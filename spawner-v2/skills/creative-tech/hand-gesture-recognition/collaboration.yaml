id: hand-gesture-recognition
skill: Hand Gesture Recognition
version: "1.0"

receives_context_from:
  - skill: ui-design
    receives:
      - Gesture vocabulary requirements
      - Interaction patterns
      - User flow designs
    provides:
      - Gesture feasibility assessment
      - Detection confidence data
      - Latency constraints

  - skill: accessibility
    receives:
      - Accessibility requirements
      - Alternative input needs
      - Inclusive design guidelines
    provides:
      - Gesture-to-action mappings
      - Fallback input integration
      - Gesture simplification options

  - skill: vr-ar-development
    receives:
      - XR interaction requirements
      - Spatial tracking needs
      - Controller alternatives
    provides:
      - Hand tracking implementation
      - Gesture detection algorithms
      - Pinch/grab mechanics

  - skill: threejs-3d-graphics
    receives:
      - 3D scene interaction needs
      - Object manipulation requirements
      - Visualization specs
    provides:
      - Hand landmark visualization
      - Real-time tracking data
      - Gesture event streams

delegation_triggers:
  - pattern: "pose estimation|body|skeleton"
    delegate_to: computer-vision-deep
    context: "Need full body pose beyond hands"

  - trigger: "sign language|asl|deaf|hard of hearing"
    delegate_to: accessibility
    context: "Sign language interpretation"

  - pattern: "3d visualization|render|webgl"
    delegate_to: threejs-3d-graphics
    context: "3D hand visualization"

  - pattern: "vr|ar|xr|quest|hololens"
    delegate_to: vr-ar-development
    context: "XR hand tracking integration"

  - pattern: "train model|custom ml|neural network"
    delegate_to: computer-vision-deep
    context: "Custom gesture ML training"

common_combinations:
  - name: Touchless Kiosk
    skills:
      - hand-gesture-recognition
      - ui-design
      - frontend
    workflow: |
      1. Design gesture vocabulary (ui-design)
      2. Implement gesture detection (hand-gesture-recognition)
      3. Build touchless UI (frontend)

  - name: VR Hand Interaction
    skills:
      - hand-gesture-recognition
      - vr-ar-development
      - threejs-3d-graphics
    workflow: |
      1. Set up WebXR hand tracking (vr-ar-development)
      2. Implement gesture detection (hand-gesture-recognition)
      3. Visualize hands in 3D (threejs-3d-graphics)

  - name: Accessible Interface
    skills:
      - hand-gesture-recognition
      - accessibility
      - ui-design
    workflow: |
      1. Define accessible gesture set (accessibility)
      2. Design inclusive interactions (ui-design)
      3. Implement with fallbacks (hand-gesture-recognition)

  - name: Interactive Art Installation
    skills:
      - hand-gesture-recognition
      - generative-art
      - threejs-3d-graphics
    workflow: |
      1. Design visual response (generative-art)
      2. Implement hand tracking (hand-gesture-recognition)
      3. Render interactive visuals (threejs-3d-graphics)

cross_domain_insights:
  - domain: Sign Language Research
    insight: ASL has well-defined gesture vocabulary
    application: Use linguistic research for gesture design

  - domain: Physical Therapy
    insight: Range of motion and fatigue considerations
    application: Design gestures that don't strain users

  - domain: Gaming Controllers
    insight: Ergonomic button placement and combos
    application: Design gesture combos that feel natural

  - domain: Conducting (Music)
    insight: Expressive hand movements convey nuance
    application: Continuous gestures for expressive control

  - domain: Magic/Illusion
    insight: Audience perception of hand movements
    application: Design gestures that look impressive

ecosystem_alternatives:
  tracking_libraries:
    - name: MediaPipe Hands
      when: Browser, cross-platform, well-supported
      tradeoff: 5-10MB model size
    - name: TensorFlow.js HandPose
      when: More control, TensorFlow ecosystem
      tradeoff: Larger bundle, more complex
    - name: OpenCV + Custom Model
      when: Server-side processing, custom needs
      tradeoff: More development effort
    - name: Leap Motion SDK
      when: Dedicated hardware, high precision
      tradeoff: Requires special hardware

  gesture_frameworks:
    - name: Custom classifier
      when: Specific gestures, full control
      tradeoff: Development time
    - name: TensorFlow.js
      when: Train custom models, ML pipeline
      tradeoff: Complexity
    - name: Rule-based detection
      when: Simple gestures, fast development
      tradeoff: Less robust

  platforms:
    - name: Web (Browser)
      when: Cross-platform, easy deployment
      tradeoff: Performance limits
    - name: Native (Python/C++)
      when: Best performance, system access
      tradeoff: Per-platform development
    - name: Unity/Unreal
      when: Game engines, VR/AR
      tradeoff: Engine dependency

feedback_loops:
  - from: user-testing
    incorporates:
      - Gesture success rates
      - User fatigue reports
      - False positive/negative data
    into: Gesture vocabulary refinement

  - from: analytics
    incorporates:
      - Detection confidence distributions
      - Usage patterns
      - Error rates by device
    into: Model and threshold tuning

prerequisites:
  required_knowledge:
    - JavaScript/TypeScript basics
    - Understanding of 2D/3D coordinates
    - Basic ML concepts
    - Camera/video handling

  recommended_tools:
    - VS Code with TypeScript
    - Chrome DevTools (Performance tab)
    - Webcam with good lighting
    - Diverse test subjects

  environment_setup: |
    # Browser-based hand tracking setup
    npm create vite@latest hand-tracking-demo -- --template vanilla-ts
    cd hand-tracking-demo

    # Install MediaPipe
    npm install @mediapipe/hands @mediapipe/camera_utils @mediapipe/drawing_utils

    # Basic setup
    cat > src/main.ts << 'EOF'
    import { Hands, HAND_CONNECTIONS, Results } from '@mediapipe/hands';
    import { Camera } from '@mediapipe/camera_utils';
    import { drawConnectors, drawLandmarks } from '@mediapipe/drawing_utils';

    const video = document.createElement('video');
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d')!;

    canvas.width = 1280;
    canvas.height = 720;
    document.body.appendChild(canvas);

    // Status display
    const status = document.createElement('div');
    status.style.cssText = 'position:fixed;top:10px;left:10px;color:white;font-family:monospace';
    document.body.appendChild(status);

    // Initialize MediaPipe Hands
    const hands = new Hands({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
    });

    hands.setOptions({
      maxNumHands: 2,
      modelComplexity: 1,
      minDetectionConfidence: 0.7,
      minTrackingConfidence: 0.5
    });

    hands.onResults((results: Results) => {
      ctx.save();
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // Draw camera feed
      ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

      // Draw hands
      if (results.multiHandLandmarks) {
        for (const landmarks of results.multiHandLandmarks) {
          drawConnectors(ctx, landmarks, HAND_CONNECTIONS, {
            color: '#00FF00',
            lineWidth: 3
          });
          drawLandmarks(ctx, landmarks, {
            color: '#FF0000',
            lineWidth: 1,
            radius: 4
          });
        }

        status.textContent = `Hands detected: ${results.multiHandLandmarks.length}`;
      } else {
        status.textContent = 'No hands detected';
      }

      ctx.restore();
    });

    // Start camera
    const camera = new Camera(video, {
      onFrame: async () => {
        await hands.send({ image: video });
      },
      width: 1280,
      height: 720
    });

    camera.start().then(() => {
      console.log('Camera started');
    });
    EOF

    # Add styles
    cat > src/style.css << 'EOF'
    body {
      margin: 0;
      background: #1a1a1a;
      display: flex;
      justify-content: center;
      align-items: center;
      min-height: 100vh;
    }

    canvas {
      max-width: 100%;
      height: auto;
      border-radius: 8px;
      box-shadow: 0 4px 6px rgba(0,0,0,0.3);
    }
    EOF

    npm run dev

    # Python alternative (for server-side or native)
    # pip install mediapipe opencv-python
