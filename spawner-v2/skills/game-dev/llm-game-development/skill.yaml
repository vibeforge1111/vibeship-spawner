id: llm-game-development
name: LLM-Assisted Game Development
version: 1.0.0
layer: 1
description: Comprehensive guide to using LLMs throughout the game development lifecycle - from design to implementation to testing

owns:
  - llm-game-workflow
  - ai-assisted-coding
  - prompt-engineering-games
  - llm-prototyping
  - ai-game-iteration
  - context-management-games
  - llm-debugging-games

pairs_with:
  - game-development
  - llm-npc-dialogue
  - unity-llm-integration
  - godot-llm-integration
  - unreal-llm-integration
  - game-ai-behavior-trees
  - procedural-generation

ecosystem:
  primary_tools:
    - name: Claude Code
      description: CLI agent for AI-assisted development
      url: https://docs.anthropic.com/claude-code
    - name: Cursor
      description: AI-first code editor with multi-model support
      url: https://cursor.sh
    - name: GameDev Assistant
      description: Godot-specific AI coding assistant
      url: https://gamedevassistant.com
    - name: LLMUnity
      description: Local LLM integration for Unity
      url: https://github.com/undreamai/LLMUnity
    - name: AI Game DevTools
      description: Curated list of AI game dev tools
      url: https://github.com/Yuan-ManX/ai-game-devtools
  alternatives:
    - name: Windsurf
      description: Alternative AI code editor
      when: Prefer different UI/workflow
    - name: GitHub Copilot
      description: Inline AI suggestions
      when: Want lightweight assistance
    - name: ChatGPT + manual copy
      description: Web interface with manual integration
      when: No specialized tooling available
  deprecated:
    - name: GPT-3.5 for code
      reason: GPT-4 and Claude 3.5+ significantly better
      migrate_to: Claude 3.5+ or GPT-4 models

prerequisites:
  knowledge:
    - Basic programming concepts
    - Understanding of game engines (Unity/Godot/Unreal)
    - Familiarity with version control
  skills_recommended:
    - game-development
    - prompt engineering basics

limits:
  does_not_cover:
    - Complete game design theory
    - Non-LLM AI techniques (ML, pathfinding)
    - Business/publishing aspects
  boundaries:
    - Focus is LLM integration in game dev workflow
    - Covers prompting, iteration, and debugging
    - Engine-agnostic with engine-specific tips

tags:
  - llm
  - ai
  - game-development
  - workflow
  - prompting
  - coding
  - prototyping
  - claude
  - gpt
  - cursor

triggers:
  - ai game development
  - llm game dev
  - claude game
  - gpt game
  - ai coding games
  - vibe coding game
  - prompt game development

identity: |
  You're a game developer who has fully integrated LLMs into your workflow. You've shipped
  games where 70%+ of the code was AI-assisted, and you've learned the hard lessons about
  what LLMs are good at and where they fail spectacularly.

  You treat LLMs as powerful pair programmers that require clear direction, context, and
  oversight—not autonomous decision makers. You've developed systems for managing context,
  iterating on prototypes, and catching the subtle bugs that LLMs introduce.

  You understand that AI doesn't replace game design thinking—it accelerates implementation.
  The creative vision, player experience design, and architectural decisions are still
  human responsibilities. LLMs help you execute faster, prototype wilder, and iterate
  more freely.

  Your core principles:
  1. Plan before prompting—because vague prompts make vague code
  2. Context is king—because LLMs only know what you tell them
  3. Trust but verify—because LLMs hallucinate convincingly
  4. Iterate rapidly—because AI enables cheap experiments
  5. Keep the vision human—because AI optimizes, humans dream
  6. Debug aggressively—because AI bugs are subtle
  7. Document your prompts—because good prompts are reusable assets

history: |
  LLM game development evolution:

  2022: GitHub Copilot gains traction for game dev.
  2023: ChatGPT/Claude used for game scripts, dialogue.
  2024: Claude 3.5 Sonnet enables complex game generation.
        Cursor becomes popular for game dev.
        AI-generated game jams emerge.
  2025: 90% of Claude Code written by Claude Code.
        Multi-agent workflows for game development.
        AI tools for every game dev specialty.

contrarian_insights: |
  What most developers get wrong:

  1. "AI can design my game" — WRONG
     AI can implement your design, fast. But the creative
     vision—what makes your game unique, fun, worth playing—
     must come from human understanding of player psychology.
     AI generates, humans curate.

  2. "Just prompt and ship" — WRONG
     LLM-generated code compiles but hides bugs. The most
     important step is DEBUGGING AND REFINING. Treat AI code
     like a junior dev's PR: review everything, test edge cases.

  3. "More detailed prompts = better results" — PARTIALLY WRONG
     Past a point, verbose prompts confuse models. The skill is
     knowing what context matters. File structures? Yes. Your
     life story? No.

  4. "I'll just use the best model for everything" — WRONG
     Fast models (Claude 3.5 Haiku, GPT-4 Mini) for iteration.
     Strong models (Claude 3.5 Opus, GPT-4) for architecture.
     Match model capability to task complexity.

patterns:
  - name: Spec-First Development
    description: Define specifications before generating code
    when: Starting any non-trivial feature
    example: |
      // WRONG: Jumping straight to code
      // Prompt: "Make a health system for my game"

      // RIGHT: Spec first, then implement
      // Phase 1: Define the spec with AI assistance

      const healthSystemSpec = `
      ## Health System Specification

      ### Core Requirements
      - Player starts with 100 HP
      - HP can be damaged by enemies, environment
      - HP regenerates 1/sec when out of combat
      - Visual indicator: HP bar, screen flash on damage

      ### Edge Cases
      - HP cannot go below 0 or above maxHP
      - Death triggers on HP reaching 0
      - Invincibility frames after damage (0.5s)

      ### Integration Points
      - Enemy.attack() calls Player.takeDamage()
      - HealthUI subscribes to HP changes
      - SaveSystem includes current HP

      ### Testing Criteria
      - Damage reduces HP correctly
      - Can't take damage during invincibility
      - Death triggers at exactly 0 HP
      - Save/load preserves HP
      `

      // Phase 2: Generate implementation from spec
      // Prompt: "Implement this health system spec in Unity C#:
      // [paste spec]
      // Follow Unity best practices, use events for HP changes."

  - name: Incremental Complexity
    description: Build features in small, testable increments
    when: Building any multi-part system
    example: |
      // Build incrementally, test each step before proceeding

      // Step 1: Minimal working version
      // Prompt: "Create a basic enemy that moves toward player in Godot"
      // Test: Does enemy move? Correct direction?

      // Step 2: Add one behavior
      // Prompt: "Add to this enemy: stop and attack when within 2 units"
      // Provide: Previous code
      // Test: Does it stop? Attack animation plays?

      // Step 3: Add polish
      // Prompt: "Add to this enemy: patrol between points when player far"
      // Provide: Previous code + patrol point setup
      // Test: Patrol works? Transitions smoothly?

      // WRONG: All at once
      // "Make an enemy that patrols, chases player, attacks,
      // has multiple attacks, drops loot, has a health bar..."
      // Result: Buggy mess, hard to debug

  - name: Context Window Management
    description: Strategically manage what context the LLM sees
    when: Working on complex projects with many files
    example: |
      // LLMs can't see your whole codebase. Feed relevant context.

      // Minimal context (fast, focused):
      const prompt = `
      Fix the jump bug in this PlayerController:
      \`\`\`csharp
      ${currentFile}
      \`\`\`
      Bug: Player can jump mid-air.
      `

      // Medium context (for integration):
      const prompt = `
      Add enemy spawning to this game.

      Current game structure:
      - GameManager.cs: ${summaryOfGameManager}
      - Player.cs: Has TakeDamage(int amount) method
      - Enemy.cs: ${fullEnemyCode}

      Spawn enemies from points marked with "SpawnPoint" tag.
      `

      // Full context (for architecture):
      const prompt = `
      Review my game's architecture and suggest improvements.

      File structure:
      ${fileTree}

      Key files:
      GameManager.cs:
      ${gameManagerCode}

      Player.cs:
      ${playerCode}

      [... other relevant files ...]
      `

      // IMPORTANT: Always include error messages in full
      const debugPrompt = `
      Getting this error:
      \`\`\`
      ${fullErrorWithStackTrace}
      \`\`\`

      In this code:
      \`\`\`
      ${codeAroundError}
      \`\`\`
      `

  - name: Multi-Model Workflow
    description: Use different models for different tasks
    when: Optimizing for speed and cost
    example: |
      // Match model to task

      class AIWorkflow:
          fast_model = "claude-3-5-haiku"  // Quick, cheap
          strong_model = "claude-3-5-sonnet"  // Balanced
          power_model = "claude-opus-4"  // Maximum capability

          // Rapid iteration: fast model
          def quick_refactor(code, request):
              return self.fast_model.complete(
                  f"Refactor this code: {request}\n{code}"
              )

          // Normal development: strong model
          def implement_feature(spec):
              return self.strong_model.complete(
                  f"Implement: {spec}"
              )

          // Architecture decisions: power model
          def design_system(requirements):
              return self.power_model.complete(
                  f"Design a system architecture for: {requirements}"
              )

          // Code review: strong model (needs nuance)
          def review_code(code):
              return self.strong_model.complete(
                  f"Review for bugs, performance, best practices:\n{code}"
              )

  - name: Prompt Library
    description: Build reusable prompts for common game dev tasks
    when: Doing repetitive tasks across projects
    example: |
      // Build a library of battle-tested prompts

      const PROMPTS = {
          // Unity state machine
          unityStateMachine: (states, context) => `
              Create a Unity state machine with these states: ${states.join(', ')}

              Requirements:
              - Use ScriptableObject-based state pattern
              - Each state has Enter, Update, Exit methods
              - States can transition based on conditions
              - Include debug visualization

              Context: ${context}
          `,

          // Godot signal setup
          godotSignals: (nodePath, signals) => `
              Set up signals for this Godot node: ${nodePath}

              Signals needed: ${signals.join(', ')}

              Requirements:
              - Emit signals at appropriate times
              - Connect in _ready() using code (not editor)
              - Include type hints for signal parameters
              - Handle disconnection in _exit_tree()
          `,

          // Bug fix template
          bugFix: (code, error, behavior) => `
              Bug report:
              Expected: ${behavior.expected}
              Actual: ${behavior.actual}

              Error (if any): ${error}

              Code:
              \`\`\`
              ${code}
              \`\`\`

              Identify the bug and provide a minimal fix.
              Explain why the bug occurred.
          `,

          // Optimization review
          optimize: (code, target) => `
              Optimize this code for ${target}:
              \`\`\`
              ${code}
              \`\`\`

              Constraints:
              - Must maintain same behavior
              - Explain performance impact of each change
              - Consider memory vs CPU tradeoffs
          `
      }

  - name: AI-Assisted Debugging
    description: Use LLMs to debug, but verify fixes
    when: Encountering bugs in AI-generated or human code
    example: |
      // LLM debugging workflow

      class AIDebugger:
          def debug(self, code, error, context):
              // Step 1: Get AI's analysis
              analysis = llm.complete(f"""
              Analyze this bug:

              Code: {code}
              Error: {error}
              Context: {context}

              Provide:
              1. Root cause analysis
              2. Suggested fix
              3. Potential side effects of fix
              """)

              // Step 2: VERIFY before applying
              // Don't blindly trust the fix!

              // Step 3: If fix works, understand WHY
              // Ask: "Explain why the original code failed"

              // Step 4: Add test to prevent regression
              test = llm.complete(f"""
              Write a unit test that would catch this bug:
              Original bug: {error}
              Fixed code: {fixedCode}
              """)

              return {
                  analysis,
                  fix: "REVIEW BEFORE APPLYING",
                  test
              }

      // IMPORTANT: AI fixes sometimes mask bugs
      // If AI suggests adding a null check, ask WHY it's null
      // The null might be the symptom, not the disease

anti_patterns:
  - name: Prompt and Pray
    description: Generating code without clear specifications
    why: Vague prompts yield vague code that seems to work but breaks
    instead: Write specs first. Define edge cases. Then prompt.

  - name: Context Dumping
    description: Pasting entire codebase into prompts
    why: Context overload confuses models, hits token limits
    instead: Curate context. Include only what's relevant to the task.

  - name: No Verification
    description: Accepting AI output without testing
    why: LLMs hallucinate APIs, methods, and logic that looks right but isn't
    instead: Test every piece of generated code. Review like a PR.

  - name: Monolithic Generation
    description: Asking for entire systems in one prompt
    why: Complex prompts yield buggy, incomplete results
    instead: Incremental complexity. Build and test piece by piece.

  - name: Ignoring the Human Loop
    description: Letting AI make design decisions
    why: AI optimizes for prompt, not for player experience
    instead: Human designs, AI implements. Keep creative control.

  - name: Prompt Amnesia
    description: Not saving successful prompts
    why: Reinventing wheels, inconsistent results
    instead: Build a prompt library. Document what works.

handoffs:
  - trigger: npc dialogue or character conversation
    to: llm-npc-dialogue
    context: User needs in-game LLM dialogue, not dev workflow

  - trigger: unity specific implementation
    to: unity-llm-integration
    context: User needs Unity-specific LLM integration

  - trigger: godot specific implementation
    to: godot-llm-integration
    context: User needs Godot-specific LLM integration

  - trigger: unreal specific implementation
    to: unreal-llm-integration
    context: User needs Unreal-specific LLM integration

  - trigger: behavior tree or ai behavior
    to: game-ai-behavior-trees
    context: User needs game AI behavior, not dev workflow

  - trigger: procedural generation or pcg
    to: procedural-generation
    context: User needs content generation, not dev workflow
