# Temporal Craftsman Collaboration Model
# How this skill works with other AI memory specialists

prerequisites:
  skills: []
  knowledge:
    - "Understanding of distributed systems concepts"
    - "Familiarity with async Python (asyncio)"
    - "Basic understanding of state machines"
    - "Experience with retry and error handling patterns"

complementary_skills:
  - skill: event-architect
    relationship: "Event-driven workflow triggers"
    brings: "Event sourcing to trigger and coordinate workflows"

  - skill: graph-engineer
    relationship: "Workflow graph updates"
    brings: "Graph database updates as workflow activities"

  - skill: vector-specialist
    relationship: "Embedding workflows"
    brings: "Batch embedding as durable workflow activities"

  - skill: ml-memory
    relationship: "Memory lifecycle workflows"
    brings: "Consolidation, promotion, forgetting as workflow steps"

  - skill: performance-hunter
    relationship: "Workflow optimization"
    brings: "Worker tuning and workflow profiling"

  - skill: privacy-guardian
    relationship: "Secure workflows"
    brings: "Encryption of workflow inputs/outputs, audit trails"

  - skill: infra-architect
    relationship: "Temporal infrastructure"
    brings: "Temporal cluster deployment, worker scaling, Kubernetes operators"

  - skill: observability-sre
    relationship: "Workflow monitoring"
    brings: "Workflow latency dashboards, failure rate alerts, tracing"

  - skill: test-architect
    relationship: "Workflow testing"
    brings: "Workflow test frameworks, activity mocking, replay testing"

delegation:
  - trigger: "need event-driven triggers for workflows"
    delegate_to: event-architect
    pattern: sequential
    context: "Events that should trigger workflows"
    receive: "Event schema and consumer design"

  - trigger: "workflow needs to update knowledge graph"
    delegate_to: graph-engineer
    pattern: parallel
    context: "Graph mutations needed in workflow activities"
    receive: "Activity design for graph updates"

  - trigger: "workflow needs to generate embeddings"
    delegate_to: vector-specialist
    pattern: parallel
    context: "Content to embed as workflow activity"
    receive: "Embedding activity with proper batching"

  - trigger: "memory consolidation workflow design"
    delegate_to: ml-memory
    pattern: sequential
    context: "Memory lifecycle requirements"
    receive: "Consolidation logic and promotion rules"

collaboration_patterns:
  sequential:
    - "I design workflow structure, then ml-memory defines consolidation steps"
    - "I create workflow skeleton, then event-architect adds event triggers"

  parallel:
    - "I orchestrate while graph-engineer implements graph activities"
    - "I manage durability while vector-specialist handles embedding activities"

  review:
    - "performance-hunter reviews worker configuration"
    - "privacy-guardian reviews workflow data handling"

cross_domain_insights:
  - domain: reliability-engineering
    insight: "Circuit breakers and bulkheads map to worker pools and retry policies"
    applies_when: "Designing fault-tolerant workflow systems"

  - domain: database-transactions
    insight: "Saga pattern is distributed equivalent of ACID transactions"
    applies_when: "Coordinating multi-service operations"

  - domain: operating-systems
    insight: "Workflow scheduling mirrors OS process scheduling with task queues"
    applies_when: "Designing task queue partitioning"

  - domain: aerospace
    insight: "Idempotency in spacecraft commands mirrors activity replay safety"
    applies_when: "Designing idempotent activities"

ecosystem:
  primary_tools:
    - "Temporal.io - Industry standard durable execution"
    - "Temporal Cloud - Managed service option"
    - "Temporal UI - Workflow visibility and debugging"
    - "tctl - CLI for workflow management"

  alternatives:
    - name: AWS Step Functions
      use_when: "AWS-native, serverless, simpler workflows"
      avoid_when: "Need code-first approach, complex logic, long-running"

    - name: Apache Airflow
      use_when: "Data pipelines, scheduled batch jobs"
      avoid_when: "Real-time workflows, event-driven, sub-second latency"

    - name: Prefect
      use_when: "Python data engineering, simpler mental model"
      avoid_when: "Need Temporal's durability guarantees, long-running workflows"

    - name: Inngest
      use_when: "Serverless functions, event-driven, simpler setup"
      avoid_when: "Need full control, complex saga patterns, self-hosted"

  deprecated:
    - "Celery for durable workflows (not designed for long-running)"
    - "Redis queues for saga patterns (no built-in compensation)"
    - "Manual state machines in database (reinventing Temporal poorly)"
