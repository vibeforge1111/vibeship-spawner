# Vector Specialist Collaboration Model
# How this skill works with other AI memory specialists

prerequisites:
  skills: []
  knowledge:
    - "Understanding of embeddings and vector spaces"
    - "Basic familiarity with similarity metrics (cosine, euclidean)"
    - "Async Python patterns"
    - "Basic understanding of information retrieval concepts"

complementary_skills:
  - skill: graph-engineer
    relationship: "Hybrid graph+vector retrieval"
    brings: "Graph traversal to complement semantic similarity"

  - skill: event-architect
    relationship: "Event-driven embedding updates"
    brings: "Event sourcing for embedding pipeline changes"

  - skill: ml-memory
    relationship: "Memory embedding strategy"
    brings: "Memory hierarchy design for embedding different memory types"

  - skill: performance-hunter
    relationship: "Retrieval optimization"
    brings: "Latency and throughput optimization for vector search"

  - skill: privacy-guardian
    relationship: "Embedding privacy"
    brings: "Privacy-preserving embeddings and secure vector storage"

  - skill: temporal-craftsman
    relationship: "Batch embedding workflows"
    brings: "Durable workflows for large-scale re-embedding"

  - skill: causal-scientist
    relationship: "Retrieval evaluation"
    brings: "Causal analysis of retrieval quality improvements"

  - skill: postgres-wizard
    relationship: "pgvector integration"
    brings: "PostgreSQL vector extension, HNSW indexes, hybrid queries"

  - skill: python-craftsman
    relationship: "Python implementation"
    brings: "Async patterns, Pydantic models, type-safe retrieval code"

  - skill: test-architect
    relationship: "Retrieval testing"
    brings: "Retrieval quality metrics, embedding test fixtures"

delegation:
  - trigger: "need graph-based relationships in retrieval"
    delegate_to: graph-engineer
    pattern: parallel
    context: "Vector search results that need graph enrichment"
    receive: "Graph traversal queries for result enhancement"

  - trigger: "need event-driven embedding updates"
    delegate_to: event-architect
    pattern: sequential
    context: "Content change events that need re-embedding"
    receive: "Event schema and consumer design for embedding pipeline"

  - trigger: "need memory hierarchy for embeddings"
    delegate_to: ml-memory
    pattern: sequential
    context: "Different memory types needing different embedding strategies"
    receive: "Memory-type-specific embedding recommendations"

  - trigger: "retrieval latency too high"
    delegate_to: performance-hunter
    pattern: review
    context: "Current retrieval pipeline, latency measurements"
    receive: "Optimization recommendations and profiling results"

collaboration_patterns:
  sequential:
    - "I design embedding pipeline, then event-architect creates event flow"
    - "I implement retrieval, then ml-memory designs memory-specific strategies"

  parallel:
    - "I handle vector search while graph-engineer handles graph enrichment"
    - "I optimize embeddings while performance-hunter profiles system"

  review:
    - "performance-hunter reviews retrieval latency"
    - "privacy-guardian reviews embedding security"

cross_domain_insights:
  - domain: information-retrieval
    insight: "BM25 and TF-IDF remain strong for keyword matching, complement vectors"
    applies_when: "Designing hybrid retrieval with keyword fallback"

  - domain: neural-networks
    insight: "Attention mechanisms in transformers determine what gets embedded"
    applies_when: "Understanding why certain content embeds poorly"

  - domain: psycholinguistics
    insight: "Word frequency affects embedding quality - rare words embed worse"
    applies_when: "Handling domain-specific terminology"

  - domain: compression-theory
    insight: "Quantization is lossy compression - information theory bounds apply"
    applies_when: "Deciding acceptable recall loss for memory savings"

ecosystem:
  primary_tools:
    - "Qdrant - Fast, feature-rich, excellent filtering"
    - "pgvector/pgvectorscale - PostgreSQL integration, familiar tooling"
    - "Milvus - Massive scale, GPU acceleration"
    - "OpenAI Embeddings - High quality, easy to use"

  alternatives:
    - name: Pinecone
      use_when: "Need managed service, don't want to run infrastructure"
      avoid_when: "Cost-sensitive, need data locality, complex filtering"

    - name: Weaviate
      use_when: "Need built-in ML models, GraphQL interface"
      avoid_when: "Pure vector store needed, simpler setup preferred"

    - name: Chroma
      use_when: "Development/prototyping, simple use cases"
      avoid_when: "Production scale, need durability guarantees"

    - name: Cohere Embed
      use_when: "Need multilingual, high quality at lower cost than OpenAI"
      avoid_when: "Need specific domain fine-tuning"

  deprecated:
    - "FAISS as primary store (no persistence, filtering limited)"
    - "Single embedding model without reranking"
    - "Pure keyword search for semantic queries"
    - "Storing embeddings in relational DB without vector extension"
