# Redis Specialist Sharp Edges
# Production-learned gotchas for Redis caching and data structures

sharp_edges:
  - id: cache-stampede
    title: Cache Stampede on Expiration
    severity: critical
    situation: |
      High-traffic key expires, hundreds of requests simultaneously query database
      and try to repopulate cache. Database gets overwhelmed.
    why: |
      TTL-based expiration is deterministic. All requests see cache miss at the
      same moment. Each request independently decides to fetch from database.
      N concurrent requests = N identical database queries.
    solution: |
      Use probabilistic early expiration or distributed lock:

      // Probabilistic early refresh (XFetch algorithm)
      async function getWithEarlyRefresh<T>(
        key: string,
        ttl: number,
        fetch: () => Promise<T>
      ): Promise<T> {
        const cached = await redis.get(key);
        if (!cached) {
          return refreshCache(key, ttl, fetch);
        }

        const { value, expiry, delta } = JSON.parse(cached);
        const now = Date.now();

        // Probabilistic early refresh
        // As expiry approaches, probability of refresh increases
        const beta = 1;  // Tuning parameter
        const random = Math.random();
        const xfetch = delta * beta * Math.log(random);

        if (now - xfetch >= expiry) {
          // Refresh in background, return stale value
          refreshCache(key, ttl, fetch);  // No await
        }

        return value;
      }

      // Alternative: Lock-based refresh
      async function getWithLock<T>(key: string, fetch: () => Promise<T>): Promise<T> {
        const cached = await redis.get(key);
        if (cached) return JSON.parse(cached);

        const lockKey = `lock:${key}`;
        const acquired = await redis.set(lockKey, '1', 'NX', 'EX', 5);

        if (!acquired) {
          // Another process is refreshing, wait and retry
          await sleep(100);
          return getWithLock(key, fetch);
        }

        try {
          const value = await fetch();
          await redis.setex(key, 3600, JSON.stringify(value));
          return value;
        } finally {
          await redis.del(lockKey);
        }
      }
    symptoms:
      - Database CPU spikes at regular intervals matching TTL
      - Latency spikes every N seconds/minutes
      - Cache hit rate drops to 0% then recovers
      - Multiple identical queries in database logs at same timestamp
    detection_pattern: "setex.*\\d{3,}.*(?!.*lock|mutex|refresh)"

  - id: hot-key-bottleneck
    title: Hot Key Single-Shard Bottleneck
    severity: critical
    situation: |
      One key receives disproportionate traffic (celebrity post, viral content,
      global config). In cluster mode, this key lives on one shard.
    why: |
      Redis Cluster shards by key hash. All requests for one key go to one node.
      That node becomes bottleneck while others sit idle. Cluster mode provides
      no help for single-key hotspots.
    solution: |
      Shard hot keys manually with random suffix:

      class HotKeyHandler {
        private shardCount = 10;

        async getHotKey(baseKey: string): Promise<string | null> {
          // Random read from any shard
          const shard = Math.floor(Math.random() * this.shardCount);
          const shardKey = `${baseKey}:${shard}`;
          return redis.get(shardKey);
        }

        async setHotKey(baseKey: string, value: string, ttl: number): Promise<void> {
          // Write to ALL shards
          const pipeline = redis.multi();
          for (let i = 0; i < this.shardCount; i++) {
            pipeline.setex(`${baseKey}:${i}`, ttl, value);
          }
          await pipeline.exec();
        }

        async deleteHotKey(baseKey: string): Promise<void> {
          const pipeline = redis.multi();
          for (let i = 0; i < this.shardCount; i++) {
            pipeline.del(`${baseKey}:${i}`);
          }
          await pipeline.exec();
        }
      }

      // Alternative: Local cache for hot keys
      const localCache = new LRU({ maxAge: 1000 });  // 1 second

      async function getWithLocalCache(key: string): Promise<string | null> {
        const local = localCache.get(key);
        if (local) return local;

        const value = await redis.get(key);
        if (value) localCache.set(key, value);
        return value;
      }
    symptoms:
      - One Redis node at 100% CPU, others idle
      - Cluster rebalancing doesn't help
      - Single key dominates slowlog
      - Latency spikes for specific keys only
    detection_pattern: "get\\(['\"]config['\"]\\)|get\\(['\"]global|get\\(['\"]featured"

  - id: large-value-blocking
    title: Large Values Block Single-Threaded Redis
    severity: critical
    situation: |
      Caching serialized objects (user profiles with history, product catalogs,
      session data with cart). Values grow to megabytes.
    why: |
      Redis is single-threaded. A 10MB GET blocks ALL other operations during
      network transfer. O(n) commands on large structures (HGETALL, SMEMBERS)
      block even longer. One bad key affects all traffic.
    solution: |
      Split large data, compress, or use references:

      // Split by access pattern
      // BAD: One big object
      await redis.set(`user:${id}`, JSON.stringify({
        profile: {...},      // Accessed often
        preferences: {...},  // Accessed often
        orderHistory: [...], // Accessed rarely, can be huge
        activityLog: [...]   // Accessed rarely, grows forever
      }));

      // GOOD: Split by access pattern
      await redis.hmset(`user:${id}:core`, {
        profile: JSON.stringify(profile),
        preferences: JSON.stringify(preferences)
      });
      await redis.set(`user:${id}:orders`, JSON.stringify(orders));
      // Don't cache activity log - query from database

      // Compress large values
      import { gzip, gunzip } from 'zlib';
      import { promisify } from 'util';

      const compress = promisify(gzip);
      const decompress = promisify(gunzip);

      async function setCompressed(key: string, value: any, ttl: number) {
        const json = JSON.stringify(value);
        if (json.length > 1024) {  // Only compress if worth it
          const compressed = await compress(Buffer.from(json));
          await redis.setex(`${key}:gz`, ttl, compressed.toString('base64'));
        } else {
          await redis.setex(key, ttl, json);
        }
      }
    symptoms:
      - Slowlog shows simple GET commands taking >100ms
      - Memory usage grows faster than expected
      - Latency increases as data grows
      - DEBUG OBJECT shows large serialized lengths
    detection_pattern: "JSON\\.stringify.*\\{[^}]{500,}|setex.*JSON\\.stringify\\(.*\\[.*\\]"

  - id: missing-ttl-memory-exhaustion
    title: Keys Without TTL Fill Memory
    severity: high
    situation: |
      Creating keys without expiration. Session keys, cache keys, temporary data.
      Memory grows over time until Redis evicts or crashes.
    why: |
      Redis keeps keys forever unless explicitly deleted or expired. With
      maxmemory-policy, Redis evicts but you lose control over WHAT gets evicted.
      volatile-lru only evicts keys WITH TTL - permanent keys never evicted.
    solution: |
      Always set TTL, even if long:

      // Wrapper that enforces TTL
      class SafeRedis {
        private defaultTTL = 86400;  // 24 hours
        private maxTTL = 604800;     // 7 days

        async set(key: string, value: string, ttl?: number): Promise<void> {
          const effectiveTTL = Math.min(ttl || this.defaultTTL, this.maxTTL);
          await redis.setex(key, effectiveTTL, value);
        }

        // Audit existing keys
        async auditNoTTL(): Promise<string[]> {
          const noTTL: string[] = [];
          let cursor = '0';

          do {
            const [newCursor, keys] = await redis.scan(cursor, 'COUNT', 100);
            cursor = newCursor;

            for (const key of keys) {
              const ttl = await redis.ttl(key);
              if (ttl === -1) {  // No expiry
                noTTL.push(key);
              }
            }
          } while (cursor !== '0');

          return noTTL;
        }
      }

      // Also configure Redis safety net
      // redis.conf:
      // maxmemory 2gb
      // maxmemory-policy volatile-lru  # Evict keys with TTL first
    symptoms:
      - Memory usage grows linearly over time
      - redis-cli INFO memory shows used_memory increasing
      - DBSIZE grows without corresponding deletes
      - Eventually OOM or mass eviction
    detection_pattern: "redis\\.set\\([^)]+\\)(?!.*ex|EX|setex|SETEX|expire)"

  - id: pubsub-message-loss
    title: Pub/Sub Messages Lost During Disconnect
    severity: high
    situation: |
      Using Redis pub/sub for critical data (orders, notifications, state sync).
      Subscriber disconnects briefly, misses messages.
    why: |
      Pub/sub is fire-and-forget. No persistence, no acknowledgment, no replay.
      If subscriber is disconnected when message published, message is gone forever.
      Even connected subscribers may lose messages under memory pressure.
    solution: |
      Use Redis Streams for reliable messaging:

      // Producer with Streams (reliable)
      async function publishReliable(stream: string, data: object): Promise<string> {
        const id = await redis.xadd(
          stream,
          'MAXLEN', '~', 10000,  // Approximate trim to 10k entries
          '*',                    // Auto-generate ID
          'data', JSON.stringify(data)
        );
        return id;  // Returns message ID for tracking
      }

      // Consumer Group (exactly-once semantics)
      class ReliableConsumer {
        async consume(stream: string, group: string, consumer: string) {
          // Create group if not exists
          try {
            await redis.xgroup('CREATE', stream, group, '0', 'MKSTREAM');
          } catch (e) {
            // Group exists, OK
          }

          while (true) {
            // First: Claim pending messages (from crashed consumers)
            const pending = await redis.xautoclaim(
              stream, group, consumer,
              60000,  // Claim if idle > 60s
              '0-0',
              'COUNT', 10
            );

            for (const [id, fields] of pending[1]) {
              await this.process(fields);
              await redis.xack(stream, group, id);
            }

            // Then: Read new messages
            const messages = await redis.xreadgroup(
              'GROUP', group, consumer,
              'BLOCK', 5000,
              'COUNT', 10,
              'STREAMS', stream, '>'
            );

            if (!messages) continue;

            for (const [, entries] of messages) {
              for (const [id, fields] of entries) {
                await this.process(fields);
                await redis.xack(stream, group, id);
              }
            }
          }
        }
      }
    symptoms:
      - Missing events in event-driven systems
      - Inconsistent state between services
      - '"Works most of the time" - fails under load or restart'
      - No way to replay or debug what was sent
    detection_pattern: "redis\\.publish|subscribe\\(|on\\(['\"]message"

  - id: distributed-lock-deadlock
    title: Distributed Lock Without Proper Release
    severity: high
    situation: |
      Acquiring distributed lock but process crashes before releasing.
      Or lock TTL too short, operation takes longer, lock expires mid-operation.
    why: |
      Lock TTL must be longer than maximum operation time. If operation takes
      longer, another process acquires lock while first still running. Two
      processes in critical section = data corruption.
    solution: |
      Use Redlock with proper TTL and extend mechanism:

      import Redlock from 'redlock';

      const redlock = new Redlock([redis], {
        retryCount: 3,
        retryDelay: 200,
        retryJitter: 100
      });

      async function withLock<T>(
        resource: string,
        ttl: number,
        fn: (extend: (ms: number) => Promise<void>) => Promise<T>
      ): Promise<T> {
        const lock = await redlock.acquire([`lock:${resource}`], ttl);

        try {
          // Pass extend function to operation
          const extend = async (ms: number) => {
            await lock.extend(ms);
          };

          return await fn(extend);
        } finally {
          await lock.release();
        }
      }

      // Usage with extension for long operations
      await withLock('order:123', 10000, async (extend) => {
        await step1();  // 3 seconds

        // Extend if operation takes longer than expected
        await extend(10000);

        await step2();  // 5 seconds
        await step3();  // 2 seconds
      });

      // Fencing token pattern for extra safety
      let fenceToken = 0;

      async function acquireWithFence(resource: string): Promise<number> {
        const token = ++fenceToken;
        await redis.set(`lock:${resource}`, token, 'NX', 'EX', 30);
        return token;
      }

      async function writeWithFence(resource: string, token: number, value: any) {
        const currentToken = await redis.get(`lock:${resource}`);
        if (parseInt(currentToken) !== token) {
          throw new Error('Lock lost - another process acquired it');
        }
        await db.write(resource, value);
      }
    symptoms:
      - Operations occasionally run concurrently when they shouldn't
      - Data corruption under load
      - "Lock acquired but operation still failed"
      - Deadlocks when process crashes holding lock
    detection_pattern: "setnx.*lock(?!.*finally.*del|release)"

  - id: scan-blocking-production
    title: KEYS Command Blocks Production
    severity: high
    situation: |
      Using KEYS command to find keys by pattern. Works in development,
      blocks production Redis for seconds.
    why: |
      KEYS is O(n) and blocks Redis during entire scan. With millions of keys,
      this can take seconds. All other operations queue behind it. One bad
      KEYS command can take down your entire application.
    solution: |
      Use SCAN for production key iteration:

      // BAD: Blocks Redis
      const keys = await redis.keys('user:*:session');

      // GOOD: Non-blocking iteration
      async function* scanKeys(pattern: string): AsyncGenerator<string> {
        let cursor = '0';

        do {
          const [newCursor, keys] = await redis.scan(
            cursor,
            'MATCH', pattern,
            'COUNT', 100  // Batch size hint
          );
          cursor = newCursor;

          for (const key of keys) {
            yield key;
          }
        } while (cursor !== '0');
      }

      // Usage
      for await (const key of scanKeys('user:*:session')) {
        await processKey(key);
      }

      // Batch operations
      async function deleteByPattern(pattern: string): Promise<number> {
        let deleted = 0;
        const batch: string[] = [];

        for await (const key of scanKeys(pattern)) {
          batch.push(key);

          if (batch.length >= 100) {
            await redis.del(...batch);
            deleted += batch.length;
            batch.length = 0;
          }
        }

        if (batch.length > 0) {
          await redis.del(...batch);
          deleted += batch.length;
        }

        return deleted;
      }

      // Disable KEYS in production
      // redis.conf: rename-command KEYS ""
    symptoms:
      - Periodic latency spikes in Redis
      - Redis slowlog shows KEYS command
      - All operations timeout during key enumeration
      - Works in dev, dies in production
    detection_pattern: "redis\\.keys\\(|KEYS ['\"]\\*"

  - id: transaction-wrong-expectations
    title: MULTI/EXEC Is Not ACID Transaction
    severity: medium
    situation: |
      Using MULTI/EXEC expecting database-style transactions with rollback.
      Conditional logic inside transaction fails silently.
    why: |
      Redis MULTI/EXEC is atomic execution, not ACID. Commands are queued, not
      executed until EXEC. You can't read values and branch during transaction.
      No rollback - if one command fails, others still execute.
    solution: |
      Use Lua scripts for atomic read-modify-write:

      // BAD: This doesn't work as expected
      const multi = redis.multi();
      const balance = await multi.get('balance');  // Returns QUEUED, not value!
      if (balance > 100) {
        multi.decrby('balance', 100);
      }
      await multi.exec();

      // GOOD: Lua script for atomic operations
      const transferScript = `
        local balance = tonumber(redis.call('GET', KEYS[1])) or 0
        local amount = tonumber(ARGV[1])

        if balance >= amount then
          redis.call('DECRBY', KEYS[1], amount)
          redis.call('INCRBY', KEYS[2], amount)
          return 1
        else
          return 0
        end
      `;

      async function transfer(from: string, to: string, amount: number): Promise<boolean> {
        const result = await redis.eval(
          transferScript,
          2,                    // Number of KEYS
          `balance:${from}`,    // KEYS[1]
          `balance:${to}`,      // KEYS[2]
          amount.toString()     // ARGV[1]
        );
        return result === 1;
      }

      // WATCH for optimistic locking
      async function incrementIfExists(key: string): Promise<boolean> {
        await redis.watch(key);

        const exists = await redis.exists(key);
        if (!exists) {
          await redis.unwatch();
          return false;
        }

        const result = await redis.multi()
          .incr(key)
          .exec();

        return result !== null;  // null means WATCH failed
      }
    symptoms:
      - Race conditions in "transactional" code
      - Conditional logic inside MULTI doesn't work
      - Partial updates when expecting all-or-nothing
      - Values read inside MULTI are undefined
    detection_pattern: "multi\\(\\).*get\\(|if.*multi.*exec"

  - id: connection-pool-exhaustion
    title: Connection Pool Exhaustion Under Load
    severity: medium
    situation: |
      Application creates new Redis connections per request or doesn't properly
      pool connections. Under load, runs out of connections or file descriptors.
    why: |
      Redis connections are TCP sockets - expensive to create. Without pooling,
      each request creates new connection, uses it once, closes it. Under load,
      you hit connection limits or file descriptor limits.
    solution: |
      Use proper connection pooling:

      import Redis from 'ioredis';

      // Single connection for most use cases
      const redis = new Redis({
        host: 'localhost',
        port: 6379,
        maxRetriesPerRequest: 3,
        retryStrategy: (times) => Math.min(times * 50, 2000),
        enableReadyCheck: true,
        lazyConnect: false
      });

      // Cluster with built-in pooling
      const cluster = new Redis.Cluster([
        { host: 'node1', port: 6379 },
        { host: 'node2', port: 6379 },
        { host: 'node3', port: 6379 }
      ], {
        scaleReads: 'slave',
        clusterRetryStrategy: (times) => Math.min(times * 100, 3000)
      });

      // For pub/sub, use separate connection
      const subscriber = redis.duplicate();

      // Monitor connection health
      redis.on('error', (err) => console.error('Redis error:', err));
      redis.on('connect', () => console.log('Redis connected'));
      redis.on('ready', () => console.log('Redis ready'));
      redis.on('close', () => console.log('Redis closed'));

      // Graceful shutdown
      process.on('SIGTERM', async () => {
        await redis.quit();  // Waits for pending commands
        process.exit(0);
      });
    symptoms:
      - '"ECONNREFUSED" or "too many connections" errors'
      - Connection count in Redis INFO climbs continuously
      - File descriptor exhaustion on application server
      - Slow performance during connection storm
    detection_pattern: "new Redis\\(.*\\)(?=.*new Redis)|createClient\\(\\)(?=.*createClient)"

  - id: serialization-type-loss
    title: Data Type Loss in JSON Serialization
    severity: medium
    situation: |
      Storing JavaScript objects in Redis via JSON.stringify. Dates become
      strings, Sets become objects, undefined values disappear.
    why: |
      JSON has limited type support. Date becomes ISO string, Set/Map become {},
      undefined values are stripped, BigInt throws error. Round-trip through
      cache changes your data.
    solution: |
      Use type-preserving serialization:

      // Custom replacer/reviver for Date
      function serialize(value: any): string {
        return JSON.stringify(value, (key, val) => {
          if (val instanceof Date) {
            return { __type: 'Date', value: val.toISOString() };
          }
          if (val instanceof Set) {
            return { __type: 'Set', value: [...val] };
          }
          if (val instanceof Map) {
            return { __type: 'Map', value: [...val] };
          }
          return val;
        });
      }

      function deserialize<T>(json: string): T {
        return JSON.parse(json, (key, val) => {
          if (val && typeof val === 'object' && val.__type) {
            switch (val.__type) {
              case 'Date': return new Date(val.value);
              case 'Set': return new Set(val.value);
              case 'Map': return new Map(val.value);
            }
          }
          return val;
        });
      }

      // Or use superjson for automatic handling
      import superjson from 'superjson';

      await redis.set(key, superjson.stringify(value));
      const restored = superjson.parse(await redis.get(key));

      // Use Redis native types when possible
      // Date -> store as timestamp (ZADD for sorted access)
      // Set -> use Redis SET (SADD, SMEMBERS)
      // Hash -> use Redis HASH (HSET, HGETALL)
    symptoms:
      - Dates compared as strings fail
      - Object equality checks fail after cache round-trip
      - Missing properties after deserialization
      - Sets/Maps become empty objects
    detection_pattern: "JSON\\.parse.*Date|new Date\\(.*JSON"

  - id: eviction-policy-mismatch
    title: Wrong Eviction Policy for Workload
    severity: medium
    situation: |
      Using default eviction policy (noeviction or volatile-lru) for workload
      that doesn't match. Cache fills up, either crashes or evicts wrong keys.
    why: |
      Different workloads need different eviction. LRU evicts least recently used,
      but some old keys are more valuable than recent ones. TTL-only eviction
      requires ALL keys to have TTL.
    solution: |
      Match eviction policy to workload:

      # For cache (can regenerate all data)
      maxmemory-policy allkeys-lru

      # For cache with TTL (only evict expiring keys)
      maxmemory-policy volatile-lru

      # For sessions (approximate LRU is fine)
      maxmemory-policy allkeys-lru

      # For leaderboards (need to keep all scores)
      maxmemory-policy noeviction  # And monitor closely!

      # For mix of cache + permanent data
      # Use separate Redis instances or keyspace prefixes

      // Monitor eviction
      class EvictionMonitor {
        async check(): Promise<void> {
          const info = await redis.info('stats');
          const evicted = this.parseEvictedKeys(info);

          if (evicted > 0) {
            console.warn(`Redis evicted ${evicted} keys`);
            // Alert if eviction rate is high
          }
        }

        async memoryUsage(): Promise<{ used: number; max: number; pct: number }> {
          const [used, max] = await Promise.all([
            redis.info('memory').then(i => this.parseUsedMemory(i)),
            redis.config('GET', 'maxmemory').then(c => parseInt(c[1]))
          ]);

          return {
            used,
            max,
            pct: (used / max) * 100
          };
        }
      }
    symptoms:
      - OOM errors with noeviction policy
      - Important keys disappearing unexpectedly
      - Cache hit rate drops as memory fills
      - Inconsistent behavior between dev (small data) and prod (full data)
    detection_pattern: "maxmemory-policy|CONFIG SET maxmemory"
