id: data-reproducibility-collaboration
skill: data-reproducibility
version: 1.0.0

receives_from:
  - skill: scientific-method
    context: "Need reproducible experimental setup"
    receives:
      - "Experiment design"
      - "Data requirements"
    provides: "Reproducible computational environment"

  - skill: ml-ops
    context: "Need ML experiment reproducibility"
    receives:
      - "Model training code"
      - "Hyperparameters"
    provides: "Versioned artifacts and reproducible pipeline"

delegation_triggers:
  - trigger: "docker|container"
    delegate_to: docker-containerization
    pattern: sequential
    context: "Need containerized environment"

  - trigger: "track experiment|mlflow"
    delegate_to: ml-ops
    pattern: parallel
    context: "Need ML experiment tracking"

feedback_loops:
  receives_feedback_from:
    - skill: ml-ops
      signal: "Model results not reproducible"
      action: "Check seeds, environment versions, data hashes"

  sends_feedback_to:
    - skill: scientific-method
      signal: "Reproducibility achieved"
      action: "Results can be published with confidence"

common_combinations:
  - name: Reproducible Research Pipeline
    skills:
      - data-reproducibility
      - scientific-method
      - statistical-analysis
    workflow: |
      1. Set up versioned environment (data-reproducibility)
      2. Version data with DVC (data-reproducibility)
      3. Pre-register analysis (scientific-method)
      4. Run analysis with manifest (data-reproducibility)
      5. Archive for publication (data-reproducibility)

ecosystem:
  versioning:
    - "DVC - Data version control"
    - "Git LFS - Large file storage"

  environments:
    - "Docker - Complete isolation"
    - "conda-lock - Locked environments"
    - "pip-compile - Pinned requirements"

  sharing:
    - "Zenodo - DOI for datasets"
    - "Binder - Live notebooks"
    - "OSF - Open Science Framework"
