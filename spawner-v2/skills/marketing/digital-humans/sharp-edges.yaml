id: digital-humans-sharp-edges
skill: digital-humans
version: 1.0.0

edges:
  - id: uncanny-valley-trap
    summary: Avatar looks almost human but something feels wrong
    severity: high
    situation: |
      Using photorealistic avatars that look almost human but have subtle
      issues with eyes, skin, or movement that trigger uncanny valley response.
    why: |
      Uncanny valley creates negative emotional response. Viewers feel
      uncomfortable without knowing why. Trust decreases. Message fails.
    solution: |
      AVOID UNCANNY VALLEY:

      1. GO STYLIZED:
         - Clearly animated/cartoon avatars don't trigger uncanny
         - Illustrated style is safer
         - Embrace non-realism

      2. GO FULLY REALISTIC:
         - HeyGen's best avatars cross the valley
         - Synthesia's premium avatars are safe
         - Test with fresh eyes before using

      3. CHECK THESE ELEMENTS:
         - Eye movement (dead eyes = uncanny)
         - Blinking (too much or too little)
         - Micro-expressions (face too static)
         - Lip sync accuracy (off-sync = uncanny)
         - Neck/shoulder movement (puppet-like = uncanny)

      4. TEST RESPONSE:
         - Show to people unfamiliar with project
         - Watch for discomfort reactions
         - \'"Does this feel weird?" test\'
    symptoms:
      - Viewer discomfort
      - \'"Something's off" feedback\'
      - Lower engagement
      - Negative comments
    detection_pattern: null

  - id: lip-sync-mismatch
    summary: Avatar lips don't match audio causing distraction
    severity: high
    situation: |
      Avatar's lip movements are noticeably out of sync with voice audio,
      or mouth shapes don't match sounds being spoken.
    why: |
      Humans are extremely sensitive to audio-visual sync. Even 50ms delay
      is noticeable. Poor lip sync screams "fake" and destroys credibility.
    solution: |
      LIP SYNC QUALITY:

      1. PLATFORM SELECTION:
         - HeyGen: Best lip sync accuracy
         - Synthesia: Very good sync
         - D-ID: Good but check carefully
         - Tavus: Excellent for personalization

      2. INPUT QUALITY:
         - Clean, well-recorded audio
         - Consistent speaking pace
         - No background noise
         - Clear enunciation

      3. LANGUAGE CONSIDERATIONS:
         - Native language performs best
         - Cross-language lip sync harder
         - Some languages sync better than others

      4. CHECK POINTS:
         - B, M, P sounds (lips together)
         - F, V sounds (teeth on lip)
         - Vowels (mouth opening)
         - Watch at 0.5x speed to check

      5. WORKAROUNDS:
         - Cut away during problem sections
         - Use B-roll over difficult parts
         - Re-generate with different audio
    symptoms:
      - Visible sync issues
      - \'"Dubbed movie" feel\'
      - Viewer distraction
      - Credibility damage
    detection_pattern: null

  - id: avatar-rights-confusion
    summary: Using avatars without proper licensing or consent
    severity: critical
    situation: |
      Using a digital human avatar without understanding the licensing terms,
      or creating a clone of someone without proper consent.
    why: |
      Avatar licensing varies significantly. Some are royalty-free, some
      require attribution, some are subscription-based. Using without
      rights = legal exposure.
    solution: |
      LICENSING TYPES:

      1. STOCK AVATARS (platform-provided):
         - HeyGen: Use on paid plan, don't claim as real
         - Synthesia: Similar terms
         - Check commercial use terms

      2. CUSTOM AVATARS (you create):
         - Must have consent from person cloned
         - Written agreement required
         - Specify use cases and duration

      3. BRANDED AVATARS:
         - You create from scratch
         - Full ownership
         - Most legally safe

      CONSENT TEMPLATE:
      ```
      I, [Name], consent to the creation of a digital
      avatar based on my likeness for use by [Company]
      for [specified purposes] from [date] to [date].
      I understand this avatar may appear in [contexts].
      Signature, date, witness.
      ```

      NEVER:
      - Clone celebrities without license
      - Use stock avatars claiming they're real people
      - Create deepfakes
    symptoms:
      - Legal threats
      - Platform suspension
      - Content removal
      - Reputation damage
    detection_pattern: null

  - id: disclosure-requirements
    summary: Not disclosing that presenter is AI-generated
    severity: high
    situation: |
      Publishing digital human content without disclosure, letting viewers
      believe they're watching a real person.
    why: |
      Regulations increasingly require AI disclosure (EU AI Act, FTC
      guidance). Deception damages trust. When discovered, backlash
      is severe.
    solution: |
      DISCLOSURE BEST PRACTICES:

      1. CLEAR LABELING:
         - "This video features an AI presenter"
         - \'"Digital avatar" in description\'
         - On-screen text where required

      2. PLATFORM REQUIREMENTS:
         - YouTube: May require disclosure
         - TikTok: Synthetic media labels
         - Instagram: Check current requirements
         - LinkedIn: Professional content standards

      3. LEGAL REQUIREMENTS:
         - EU AI Act: Disclosure required for AI content
         - FTC: Deceptive practices concern
         - Check local regulations

      4. ETHICAL STANDARD:
         - Viewers should know what they're watching
         - Trust is worth more than deception gains
         - Proactive disclosure is better

      EXAMPLES:
      - Small text: "AI presenter"
      - Video description mention
      - Verbal disclosure in video
      - Bio/profile mention
    symptoms:
      - Regulatory issues
      - Trust violations
      - Backlash when discovered
      - Platform penalties
    detection_pattern: null

  - id: audio-video-mismatch
    summary: Avatar style doesn't match voice characteristics
    severity: medium
    situation: |
      Young avatar with old voice, or formal avatar with casual voice,
      or avatar appearance that doesn't match accent/language.
    why: |
      Incongruence between visual and audio creates cognitive dissonance.
      Viewers feel something is wrong even if they can't pinpoint it.
    solution: |
      MATCHING PRINCIPLES:

      1. AGE MATCHING:
         - Young avatar = young voice
         - Older avatar = mature voice
         - ElevenLabs has age-appropriate voices

      2. STYLE MATCHING:
         - Professional avatar = professional voice
         - Casual avatar = conversational voice
         - Energy levels should match

      3. CULTURAL MATCHING:
         - Avatar appearance = accent expectation
         - Be thoughtful about cross-cultural
         - Avoid stereotyping

      4. BRAND MATCHING:
         - Avatar personality = brand voice
         - Consistent across all content
         - Document in brand guidelines

      WORKFLOW:
      - Select voice first
      - Choose avatar that matches
      - Or: Design avatar, then find matching voice
    symptoms:
      - \'"Something's off" feedback\'
      - Cognitive dissonance
      - Lower trust
      - Brand confusion
    detection_pattern: null

  - id: movement-unnaturalness
    summary: Avatar movements are robotic or puppet-like
    severity: medium
    situation: |
      Digital human moves like a puppet - stiff neck, no natural gestures,
      robotic head movements, or overly smooth motion.
    why: |
      Humans move with natural imperfections - micro-movements, weight
      shifts, asymmetry. Too perfect = robotic = uncanny.
    solution: |
      NATURAL MOVEMENT:

      1. GESTURE SELECTION:
         - HeyGen: Pre-set natural gestures
         - Synthesia: Gesture library
         - Select appropriate for content

      2. REDUCE MOVEMENT:
         - Sometimes less is more
         - Talking head doesn't need constant motion
         - Subtle > exaggerated

      3. ADD VARIETY:
         - Different gestures for emphasis
         - Occasional head tilts
         - Natural pauses

      4. CUT TECHNIQUES:
         - Multiple angles hide limitations
         - B-roll breaks up talking head
         - Screen shares reduce avatar time

      5. FRAMING:
         - Tighter shots hide body movement issues
         - Head and shoulders often safest
         - Full body is hardest
    symptoms:
      - \'"Robotic" feedback\'
      - Puppet-like movement
      - Viewer distraction
      - Amateur look
    detection_pattern: null

  - id: resolution-quality-mismatch
    summary: Avatar video quality doesn't match other content
    severity: medium
    situation: |
      Mixing digital human footage with other content of different quality,
      resolution, or color grade, making the avatar look out of place.
    why: |
      Quality mismatches highlight the artificiality. The digital human
      stands out as "different" from real footage.
    solution: |
      QUALITY MATCHING:

      1. RESOLUTION:
         - Export avatar at highest quality
         - Match to other content resolution
         - HeyGen: 4K available on higher tiers

      2. COLOR GRADING:
         - Apply same LUT/grade to all footage
         - Match white balance
         - Consistent contrast

      3. COMPRESSION:
         - Use same codec for all
         - Matching bitrate
         - Consistent export settings

      4. LIGHTING MATCH:
         - Select avatar lighting to match scene
         - Some platforms offer lighting control
         - Post-process to unify

      5. BACKGROUND:
         - Green screen avatar for integration
         - Match background lighting/style
         - Consistent visual language
    symptoms:
      - Avatar "pops out" of content
      - Quality inconsistency
      - Amateur production feel
      - Visible compositing
    detection_pattern: null

  - id: script-not-optimized
    summary: Scripts written for human delivery don't work for avatars
    severity: medium
    situation: |
      Using scripts with complex sentences, humor, sarcasm, or emotional
      nuance that AI avatars can't deliver properly.
    why: |
      AI avatars have limited emotional range. Complex delivery requirements
      fall flat. Humor without proper timing fails.
    solution: |
      AVATAR-OPTIMIZED SCRIPTS:

      1. SIMPLIFY SENTENCES:
         - Short, clear sentences
         - One idea per sentence
         - Avoid complex clauses

      2. AVOID:
         - Sarcasm (AI can't deliver)
         - Subtle humor
         - Emotional peaks
         - Heavy emphasis

      3. WORKS WELL:
         - Informational content
         - Explanations
         - Announcements
         - Product descriptions

      4. PUNCTUATION FOR PACING:
         - Periods create pauses
         - Commas are shorter pauses
         - Write for spoken rhythm

      5. PRONUNCIATION GUIDES:
         - Phonetic spelling for unusual words
         - Test and adjust
         - Platform-specific markup
    symptoms:
      - Flat delivery
      - Humor falls flat
      - Emotional disconnect
      - \'"Reading, not speaking" feel\'
    detection_pattern: null

  - id: platform-api-limits
    summary: Hitting API limits or unexpected charges
    severity: high
    situation: |
      Running many generations without tracking usage, hitting rate limits,
      or getting surprise bills.
    why: |
      Digital human generation is expensive. Minutes add up quickly.
      Rate limits can halt production. Surprise bills hurt budgets.
    solution: |
      USAGE MANAGEMENT:

      KNOWN PRICING (approximate, check current):
      - HeyGen: ~$0.10-0.20/minute
      - Synthesia: ~$0.20-0.40/minute
      - D-ID: ~$0.05-0.15/minute
      - Tavus: Custom pricing

      TRACKING:
      ```typescript
      async function generateWithTracking(script: string) {
        const minutes = estimateMinutes(script);
        const cost = minutes * PRICE_PER_MINUTE;
        await logCost({ service: 'heygen', minutes, cost });
        return await generate(script);
      }
      ```

      BUDGET RULES:
      - Set daily/weekly minute limits
      - Approve scripts before generation
      - Test with short clips first
      - Save renders, don't regenerate

      RATE LIMITS:
      - Queue generations
      - Respect concurrent limits
      - Plan for generation time (minutes, not seconds)
    symptoms:
      - Rate limit errors
      - Surprise invoices
      - Production delays
      - Budget overruns
    detection_pattern: null

  - id: multi-language-quality-drop
    summary: Avatar quality drops significantly in non-primary languages
    severity: medium
    situation: |
      Using avatar for multi-language content and noticing quality
      degrades for certain languages.
    why: |
      Models are typically trained primarily on English. Other languages
      may have worse lip sync, pronunciation, or emotion delivery.
    solution: |
      MULTI-LANGUAGE STRATEGY:

      1. TEST BEFORE COMMITTING:
         - Generate test clips in each language
         - Check lip sync quality
         - Verify pronunciation

      2. PLATFORM STRENGTHS:
         - HeyGen: Good multilingual support
         - Synthesia: Many languages
         - Check specific language support

      3. VOICE SELECTION:
         - Native speaker voices for each language
         - ElevenLabs multilingual models
         - Match accent to avatar appearance

      4. WORKAROUNDS:
         - Subtitles for problem languages
         - Different avatar per language
         - VO with non-speaking avatar

      5. REVIEW PROCESS:
         - Native speaker review for each language
         - Check cultural appropriateness
         - Pronunciation verification
    symptoms:
      - Poor lip sync in some languages
      - Pronunciation issues
      - Cultural mismatches
      - Viewer complaints
    detection_pattern: null

  - id: avatar-fatigue
    summary: Overusing same avatar causes viewer fatigue
    severity: low
    situation: |
      Using the same avatar for all content, every video, every platform,
      causing viewers to tune out.
    why: |
      Visual monotony breeds boredom. Seeing the same avatar repeatedly
      reduces engagement. Variety maintains interest.
    solution: |
      VARIETY STRATEGY:

      1. MULTIPLE AVATARS:
         - Different avatars for different content types
         - Rotate for series content
         - Match avatar to topic

      2. VISUAL VARIETY:
         - Different outfits
         - Different backgrounds
         - Different framings

      3. CONTENT MIX:
         - Not every video needs avatar
         - Mix with B-roll heavy content
         - Screen recordings with VO

      4. AVATAR EVOLUTION:
         - Update look periodically
         - New outfits per season
         - Refresh to maintain interest

      5. FORMAT VARIETY:
         - Some videos: full avatar
         - Some: avatar intro only
         - Some: avatar-free
    symptoms:
      - Declining engagement
      - \'"Same old" feedback\'
      - Viewer boredom
      - Channel fatigue
    detection_pattern: null
