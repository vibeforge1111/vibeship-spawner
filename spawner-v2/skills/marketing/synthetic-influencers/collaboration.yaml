id: synthetic-influencers-collaboration
skill: synthetic-influencers
version: 1.0.0

# ============================================================================
# PREREQUISITES
# ============================================================================
prerequisites:
  required:
    - name: AI Image Generation Platform
      description: Generate consistent visual content
      options:
        - tool: Midjourney
          url: https://midjourney.com/
          best_for: High-quality stylized imagery
          cost: Subscription ($10-60/mo)
        - tool: Flux Pro
          url: https://fal.ai/models/fal-ai/flux-pro
          best_for: Photorealistic, consistent characters
          cost: Usage-based
        - tool: Stable Diffusion + LoRA
          best_for: Maximum consistency via custom training
          cost: Free (hardware required)

    - name: Social Media Management
      description: Publishing and scheduling
      options:
        - Buffer (simple, affordable)
        - Hootsuite (comprehensive)
        - Sprout Social (enterprise, analytics)
        - Later (visual-first)

  recommended:
    - name: Digital Human Platform
      options:
        - HeyGen (video avatars)
        - Synthesia (professional video)
        - D-ID (talking photos)
        - Runway Gen-3 (cinematic AI video)
      reason: Video content extends synthetic influencer presence

    - name: Voice Synthesis
      options:
        - ElevenLabs (natural, multilingual)
        - Play.ht (variety of voices)
        - Murf.ai (accessible)
      reason: Consistent voice across audio/video content

    - name: Character Consistency Tools
      options:
        - IP-Adapter (reference-based)
        - LoRA Training (custom models)
        - ControlNet (pose control)
        - Dreambooth (subject training)
      reason: Maintaining visual consistency is critical

    - name: Community Management
      options:
        - Discord (community hub)
        - Zendesk (support integration)
        - Intercom (chat)
        - AI chat assistants (scaled responses)
      reason: Synthetic influencers need community engagement

# ============================================================================
# MCP TOOL CONFIGURATIONS
# ============================================================================
mcp_tools:
  # Image Generation for Influencer Content
  - name: influencer-visuals
    description: Generate consistent influencer imagery
    install: npx -y @anthropic/mcp-installer install fal-ai
    config:
      server:
        command: npx
        args: ["-y", "@fal-ai/mcp-server"]
        env:
          FAL_KEY: "${FAL_KEY}"
    capabilities:
      - flux-pro (high quality)
      - ip-adapter (consistency)
      - controlnet (pose control)
      - lora (custom training)
    example_usage: |
      Use Fal.ai for influencer content:
      - Generate daily posts with IP-Adapter consistency
      - Different poses with ControlNet
      - Train LoRA for important characters
      - Batch generate content for scheduling

  # Digital Human Video
  - name: influencer-video
    description: Create video content with digital humans
    install: npx -y @anthropic/mcp-installer install heygen
    config:
      server:
        command: npx
        args: ["-y", "@heygen/mcp-server"]
        env:
          HEYGEN_API_KEY: "${HEYGEN_API_KEY}"
    capabilities:
      - avatar-creation
      - video-generation
      - lip-sync
      - multi-language
    example_usage: |
      Use HeyGen for video content:
      - Create consistent avatar from character images
      - Generate video posts and stories
      - Produce product demos
      - Multi-language content

  # Voice Synthesis
  - name: influencer-voice
    description: Generate consistent influencer voice
    install: npx -y @anthropic/mcp-installer install elevenlabs
    config:
      server:
        command: npx
        args: ["-y", "@elevenlabs/mcp-server"]
        env:
          ELEVENLABS_API_KEY: "${ELEVENLABS_API_KEY}"
    capabilities:
      - voice-cloning
      - text-to-speech
      - voice-library
      - streaming
    example_usage: |
      Use ElevenLabs for voice:
      - Clone voice from samples
      - Generate voiceovers for video
      - Create audio content
      - Consistent voice across all content

  # Social Media via Buffer
  - name: social-publishing
    description: Schedule and publish content
    install: npx -y @anthropic/mcp-installer install buffer
    config:
      server:
        command: npx
        args: ["-y", "@buffer/mcp-server"]
        env:
          BUFFER_ACCESS_TOKEN: "${BUFFER_ACCESS_TOKEN}"
    capabilities:
      - schedule-posts
      - multi-platform
      - analytics
      - content-calendar

# ============================================================================
# API INTEGRATIONS
# ============================================================================
api_integrations:
  fal_ai_character:
    base_url: https://fal.run
    auth_header: "Authorization: Key ${FAL_KEY}"
    example: |
      import * as fal from "@fal-ai/serverless-client";

      fal.config({ credentials: process.env.FAL_KEY });

      // Generate consistent character image
      const characterPost = await fal.subscribe("fal-ai/ip-adapter-plus", {
        input: {
          prompt: "Luna in coffee shop, holding latte, warm lighting, lifestyle photo",
          image_url: characterReferenceUrl, // Character reference image
          ip_adapter_scale: 0.8,
          negative_prompt: "different face, inconsistent, wrong person"
        }
      });

      // Multiple poses with ControlNet
      const posedContent = await fal.subscribe("fal-ai/controlnet-sdxl", {
        input: {
          prompt: "Luna, casual pose, street style, summer outfit",
          control_image: poseReferenceUrl,
          controlnet_type: "openpose",
          ip_adapter_image: characterReferenceUrl,
          ip_adapter_scale: 0.7
        }
      });

      // Batch generation for content calendar
      const batchResults = await Promise.all([
        fal.subscribe("fal-ai/flux-pro", { input: { prompt: mondayPrompt } }),
        fal.subscribe("fal-ai/flux-pro", { input: { prompt: tuesdayPrompt } }),
        fal.subscribe("fal-ai/flux-pro", { input: { prompt: wednesdayPrompt } }),
      ]);

  heygen_video:
    base_url: https://api.heygen.com
    auth_header: "X-Api-Key: ${HEYGEN_API_KEY}"
    sdk: "@heygen/streaming-avatar"
    example: |
      // Create video with avatar
      const response = await fetch("https://api.heygen.com/v2/video/generate", {
        method: "POST",
        headers: {
          "X-Api-Key": process.env.HEYGEN_API_KEY,
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          video_inputs: [{
            character: {
              type: "avatar",
              avatar_id: influencerAvatarId
            },
            voice: {
              type: "audio",
              audio_url: voiceAudioUrl
            },
            background: {
              type: "color",
              value: "#FFFFFF"
            }
          }],
          dimension: { width: 1080, height: 1920 }, // Story format
          aspect_ratio: "9:16"
        })
      });

  elevenlabs_voice:
    base_url: https://api.elevenlabs.io/v1
    auth_header: "xi-api-key: ${ELEVENLABS_API_KEY}"
    sdk: "elevenlabs"
    example: |
      import { ElevenLabsClient } from "elevenlabs";

      const elevenlabs = new ElevenLabsClient({
        apiKey: process.env.ELEVENLABS_API_KEY
      });

      // Generate voice for influencer
      const audio = await elevenlabs.generate({
        voice: influencerVoiceId, // Pre-cloned voice
        text: "Hey everyone! Today I'm sharing my morning routine...",
        model_id: "eleven_multilingual_v2"
      });

      // Stream for real-time applications
      const stream = await elevenlabs.textToSpeech.convertAsStream(
        influencerVoiceId,
        { text: captionText }
      );

  buffer_social:
    base_url: https://api.bufferapp.com/1
    auth_header: "Authorization: Bearer ${BUFFER_ACCESS_TOKEN}"
    example: |
      // Schedule post across platforms
      const schedulePost = await fetch(
        "https://api.bufferapp.com/1/updates/create.json",
        {
          method: "POST",
          headers: {
            "Authorization": `Bearer ${process.env.BUFFER_ACCESS_TOKEN}`,
            "Content-Type": "application/json"
          },
          body: JSON.stringify({
            text: captionText,
            media: { link: imageUrl },
            profile_ids: [instagramProfileId, twitterProfileId],
            scheduled_at: scheduledTime
          })
        }
      );

  instagram_api:
    base_url: https://graph.instagram.com
    auth_header: "Bearer ${INSTAGRAM_ACCESS_TOKEN}"
    notes: |
      Instagram API for engagement monitoring:

      # Get post insights
      GET /{media-id}/insights?metric=engagement,reach,impressions

      # Get comments for response
      GET /{media-id}/comments

      # Reply to comments
      POST /{comment-id}/replies

      Requires approved Facebook app for Instagram API access.

# ============================================================================
# DELEGATION TRIGGERS
# ============================================================================
delegation_triggers:
  - trigger: "image|photo|visual|post"
    delegate_to: ai-image-generation
    pattern: parallel
    context: "Need visual content for influencer"
    handoff_data:
      - "Character reference images"
      - "Persona bible excerpt"
      - "Content theme"
      - "Platform format"
    receive: "Generated influencer imagery"

  - trigger: "video|talking|presenting|story"
    delegate_to: digital-humans
    pattern: parallel
    context: "Need video content for influencer"
    handoff_data:
      - "Avatar configuration"
      - "Script/content"
      - "Voice settings"
      - "Video format"
    receive: "Generated influencer video"

  - trigger: "character design|visual identity|world"
    delegate_to: ai-world-building
    pattern: sequential
    context: "Need comprehensive character design"
    handoff_data:
      - "Character concept"
      - "Brand context"
      - "Style direction"
    receive: "Complete character system"

  - trigger: "write|copy|caption|script"
    delegate_to: copywriting
    pattern: parallel
    context: "Need content in influencer voice"
    handoff_data:
      - "Persona bible voice section"
      - "Content topic"
      - "Platform requirements"
    receive: "On-voice copy"

  - trigger: "content plan|calendar|strategy"
    delegate_to: content-strategy
    pattern: sequential
    context: "Need content strategy for influencer"
    handoff_data:
      - "Persona overview"
      - "Brand goals"
      - "Platform presence"
    receive: "Content strategy"

  - trigger: "trend|real-time|viral"
    delegate_to: real-time-content
    pattern: parallel
    context: "Influencer trend response"
    handoff_data:
      - "Persona parameters"
      - "Trend context"
      - "Speed requirements"
    receive: "Trend content in character"

  - trigger: "marketing|campaign|promotion"
    delegate_to: marketing
    pattern: sequential
    context: "Influencer marketing campaign"
    handoff_data:
      - "Influencer assets"
      - "Campaign goals"
      - "Target audience"
    receive: "Marketing campaign"

  - trigger: "ad|advertising|paid"
    delegate_to: ai-ad-creative
    pattern: parallel
    context: "Paid content featuring influencer"
    handoff_data:
      - "Influencer visuals"
      - "Ad requirements"
      - "Platform specs"
    receive: "Ad creative"

# ============================================================================
# CROSS-DOMAIN INSIGHTS
# ============================================================================
cross_domain_insights:
  - domain: Character Acting
    insight: |
      Voice actors and character performers know:
      - Consistency comes from understanding the "why"
      - Core traits express in every action
      - Stay in character even when challenged
      - Character has opinions on everything
      Treat writing for synthetic influencer like character acting.
    applies_when: "Creating content in character voice"

  - domain: Brand Management
    insight: |
      Brand managers understand:
      - Every touchpoint matters
      - Consistency builds trust
      - Evolution must be managed
      - Crisis preparation is essential
      Synthetic influencer IS a brand. Manage accordingly.
    applies_when: "Managing influencer reputation"

  - domain: Parasocial Relationships
    insight: |
      Media psychologists study:
      - Audiences form attachments to characters
      - Consistency strengthens connection
      - Acknowledgment creates loyalty
      - Reciprocity (even simulated) deepens bond
      Understand the relationship you're building.
    applies_when: "Community building and engagement"

  - domain: Puppetry/Animation
    insight: |
      Puppeteers and animators know:
      - Believable characters have consistent movement
      - Small details create life
      - Audience completes the illusion
      - Less can be more
      Character doesn't need to be perfect, just consistent.
    applies_when: "Bringing character to life"

  - domain: Influencer Marketing
    insight: |
      Traditional influencer marketers know:
      - Authenticity beats perfection
      - Community > audience size
      - Engagement rate > follower count
      - Value first, promotion second
      Same principles apply, different execution.
    applies_when: "Building influencer strategy"

# ============================================================================
# COMMON COMBINATIONS
# ============================================================================
common_combinations:
  - name: Synthetic Influencer Genesis
    skills:
      - synthetic-influencers
      - ai-world-building
      - ai-image-generation
      - digital-humans
    workflow: |
      1. Develop persona (synthetic-influencers)
      2. Design character visually (ai-world-building)
      3. Create reference sheet and first images (ai-image-generation)
      4. Set up video avatar (digital-humans)
      5. Document in persona bible
      6. Launch content strategy

  - name: Content Production Pipeline
    skills:
      - synthetic-influencers
      - ai-image-generation
      - copywriting
    workflow: |
      1. Plan weekly content (synthetic-influencers)
      2. Generate batch imagery (ai-image-generation)
      3. Write on-voice captions (copywriting)
      4. Review for consistency
      5. Schedule and publish
      6. Monitor and engage

  - name: Multi-Format Campaign
    skills:
      - synthetic-influencers
      - ai-image-generation
      - digital-humans
      - ai-audio-production
    workflow: |
      1. Define campaign concept
      2. Generate image content
      3. Create video content (digital-humans)
      4. Produce audio elements
      5. Adapt for each platform
      6. Coordinate release

  - name: Trend Response
    skills:
      - synthetic-influencers
      - real-time-content
      - ai-image-generation
    workflow: |
      1. Detect relevant trend (real-time-content)
      2. Assess fit with persona
      3. Generate quick visual response
      4. Write in-character caption
      5. Rapid review
      6. Publish and engage

# ============================================================================
# PERSONA FRAMEWORKS
# ============================================================================
persona_frameworks:
  persona_bible_template:
    sections:
      - identity: "Name, origin, role, brand relationship"
      - visual: "Appearance, style, signature looks"
      - personality: "Core traits, values, fears, humor"
      - voice: "Speaking style, phrases, patterns"
      - content: "Topics covered, topics avoided, formats"
      - relationships: "With brand, audience, other characters"
      - evolution: "Growth plan, narrative arc"
      - disclosure: "How synthetic nature is communicated"

  voice_guidelines_template:
    sections:
      - overall_tone: "Warm, professional, casual, etc."
      - vocabulary: "Words they use, level of complexity"
      - phrases: "Catchphrases, signature expressions"
      - forbidden: "Words/phrases they NEVER use"
      - emoji_style: "Heavy, minimal, specific emojis"
      - caption_structure: "Hook, body, CTA patterns"
      - engagement_voice: "How they respond to comments"

  content_ratio_template:
    types:
      - entertainment: "40% - Funny, interesting, beautiful"
      - personality: "25% - Opinions, experiences, character"
      - value: "20% - Tips, insights, education"
      - promotional: "15% - Brand integration (max)"
      - community: "Ongoing - Responses, engagement"

# ============================================================================
# VERSION COMPATIBILITY
# ============================================================================
version_compatibility:
  image_generation:
    midjourney: "v6+"
    flux: "Pro, Schnell"
    stable_diffusion: "SDXL with LoRA support"

  digital_human:
    heygen: "Current API"
    synthesia: "Studio API"
    d_id: "Current API"

  voice:
    elevenlabs: "v2 API"
    play_ht: "v2 API"
    murf: "Current API"

  social:
    instagram: "Graph API v18+"
    tiktok: "Marketing API"
    twitter: "API v2"

  notes: |
    Synthetic influencer tech evolves rapidly.

    Key considerations:
    - Character consistency tools improving
    - Digital human quality increasing
    - Platform rules changing
    - Disclosure requirements evolving

    Stay current on:
    - Platform synthetic content policies
    - FTC disclosure requirements
    - AI generation capabilities
    - Community sentiment

    Current as of December 2024.
