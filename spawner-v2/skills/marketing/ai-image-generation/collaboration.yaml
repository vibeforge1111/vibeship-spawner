id: ai-image-generation-collaboration
skill: ai-image-generation
version: 1.0.0

# ============================================================================
# PREREQUISITES
# ============================================================================
prerequisites:
  required:
    - name: API Access (at least one)
      options:
        - provider: OpenAI (DALL-E 3)
          signup: https://platform.openai.com/
          env_var: OPENAI_API_KEY
          pricing: $0.04-0.12/image
          best_for: Prompt following, clean designs
        - provider: Replicate (Flux, SD, many models)
          signup: https://replicate.com/
          env_var: REPLICATE_API_TOKEN
          pricing: Pay per compute
          best_for: Access to latest open models
        - provider: Fal.ai (Flux, fast inference)
          signup: https://fal.ai/
          env_var: FAL_KEY
          pricing: ~$0.003-0.05/image
          best_for: Fast, cheap Flux access
        - provider: Midjourney (via Discord or API)
          signup: https://midjourney.com/
          pricing: $10-60/month
          best_for: Stylized, artistic images
        - provider: Ideogram
          signup: https://ideogram.ai/
          env_var: IDEOGRAM_API_KEY
          pricing: ~$0.02/image
          best_for: Text in images

  recommended:
    - name: Image editing software
      options:
        - Adobe Photoshop
        - Figma
        - GIMP (free)
        - Photopea (free, web)
      reason: AI output often needs refinement

    - name: Upscaling tool
      options:
        - Magnific AI
        - Topaz Gigapixel
        - Real-ESRGAN (free)
      reason: Scale AI output to print/production quality

# ============================================================================
# MCP TOOL CONFIGURATIONS
# ============================================================================
mcp_tools:
  # OpenAI MCP (DALL-E 3)
  - name: openai
    description: DALL-E 3 image generation
    install: npx -y @anthropic/mcp-installer install openai
    config:
      server:
        command: npx
        args: ["-y", "@openai/mcp-server"]
        env:
          OPENAI_API_KEY: "${OPENAI_API_KEY}"
    capabilities:
      - text-to-image
      - image-editing
      - vision-analysis
    example_usage: |
      Use openai to generate an image:
      - Prompt: "Professional product photograph of..."
      - Size: 1792x1024
      - Quality: hd
      - Style: natural

  # Fal.ai MCP (Flux and more)
  - name: fal-ai
    description: Access to Flux, Stable Diffusion, and many models
    install: npx -y @anthropic/mcp-installer install fal-ai
    config:
      server:
        command: npx
        args: ["-y", "@fal-ai/mcp-server"]
        env:
          FAL_KEY: "${FAL_KEY}"
    models_available:
      - fal-ai/flux/dev
      - fal-ai/flux/schnell
      - fal-ai/flux-pro
      - fal-ai/stable-diffusion-v3-medium
      - fal-ai/aura-flow
    capabilities:
      - text-to-image
      - image-to-image
      - inpainting
      - controlnet
    example_usage: |
      Use fal-ai to generate with Flux:
      - Model: flux-pro
      - Prompt: "Cinematic portrait of..."
      - Aspect ratio: 16:9
      - Seed: 42 (for reproducibility)

  # Replicate MCP
  - name: replicate
    description: Run any model on Replicate
    install: npx -y @anthropic/mcp-installer install replicate
    config:
      server:
        command: npx
        args: ["-y", "@replicate/mcp-server"]
        env:
          REPLICATE_API_TOKEN: "${REPLICATE_API_TOKEN}"
    models_available:
      - black-forest-labs/flux-1.1-pro
      - black-forest-labs/flux-schnell
      - stability-ai/sdxl
      - lucataco/realvisxl-v4.0
    example_usage: |
      Use replicate to run Flux 1.1 Pro:
      - Model: black-forest-labs/flux-1.1-pro
      - Prompt: "..."
      - Aspect ratio: 3:2
      - Output format: webp

  # ComfyUI MCP (advanced workflows)
  - name: comfyui
    description: Advanced workflows with ComfyUI
    install: python -m pip install comfyui-mcp
    config:
      server:
        command: python
        args: ["-m", "comfyui_mcp"]
        env:
          COMFYUI_URL: "http://localhost:8188"
    capabilities:
      - custom-workflows
      - controlnet
      - ip-adapter
      - lora
      - batch-processing
      - inpainting
    example_usage: |
      Use comfyui to run IP-Adapter workflow:
      - Workflow: style_transfer.json
      - Style reference: brand_style.jpg
      - Prompt: "Product shot in this style"

# ============================================================================
# API INTEGRATIONS
# ============================================================================
api_integrations:
  openai:
    base_url: https://api.openai.com/v1
    auth_header: "Authorization: Bearer ${OPENAI_API_KEY}"
    sdk: "openai"
    example: |
      import OpenAI from 'openai';

      const openai = new OpenAI();

      const response = await openai.images.generate({
        model: "dall-e-3",
        prompt: "Professional photograph of...",
        size: "1792x1024",
        quality: "hd",
        n: 1,
      });

      const imageUrl = response.data[0].url;

  fal:
    base_url: https://fal.run
    auth_header: "Authorization: Key ${FAL_KEY}"
    sdk: "@fal-ai/serverless-client"
    example: |
      import * as fal from "@fal-ai/serverless-client";

      fal.config({ credentials: process.env.FAL_KEY });

      const result = await fal.subscribe("fal-ai/flux-pro", {
        input: {
          prompt: "Professional product shot...",
          image_size: "landscape_16_9",
          num_images: 1,
          seed: 42
        }
      });

  replicate:
    base_url: https://api.replicate.com/v1
    auth_header: "Authorization: Token ${REPLICATE_API_TOKEN}"
    sdk: "replicate"
    example: |
      import Replicate from "replicate";

      const replicate = new Replicate();

      const output = await replicate.run(
        "black-forest-labs/flux-1.1-pro",
        {
          input: {
            prompt: "...",
            aspect_ratio: "16:9",
            output_format: "webp",
            output_quality: 90
          }
        }
      );

  stability:
    base_url: https://api.stability.ai/v2beta
    auth_header: "Authorization: Bearer ${STABILITY_API_KEY}"
    sdk: "@stability-ai/sdk"
    example: |
      const response = await fetch(
        "https://api.stability.ai/v2beta/stable-image/generate/sd3",
        {
          method: "POST",
          headers: {
            "Authorization": `Bearer ${process.env.STABILITY_API_KEY}`,
            "Content-Type": "application/json"
          },
          body: JSON.stringify({
            prompt: "...",
            aspect_ratio: "16:9",
            model: "sd3-large"
          })
        }
      );

# ============================================================================
# DELEGATION TRIGGERS
# ============================================================================
delegation_triggers:
  - trigger: "video|animate|motion|movement"
    delegate_to: ai-video-generation
    pattern: sequential
    context: "Static image needs to become video"
    handoff_data:
      - "Image can serve as seed frame for image-to-video"
      - "Maintain consistent style and subject"
      - "Consider what motion makes sense"
    receive: "Video file based on seed image"

  - trigger: "upscale|enhance|4K|8K|print quality"
    delegate_to: ai-visual-effects
    pattern: sequential
    context: "Image needs resolution enhancement"
    handoff_data:
      - "Raw AI output typically 1024-1792px"
      - "Use Magnific for creative enhancement"
      - "Use Topaz for faithful upscaling"
    receive: "High-resolution image file"

  - trigger: "prompt help|better prompts|prompt engineering"
    delegate_to: prompt-engineering-creative
    pattern: sequential
    context: "Need optimized prompts for better output"
    handoff_data:
      - "Share model being used (different prompting styles)"
      - "Describe desired outcome"
      - "Share failed attempts if any"
    receive: "Optimized prompt with structure"

  - trigger: "world building|character sheet|brand universe"
    delegate_to: ai-world-building
    pattern: parallel
    context: "Image is part of larger visual universe"
    handoff_data:
      - "Need consistency rules for this world"
      - "Character reference sheets needed"
      - "Style guide for series"
    receive: "World bible with visual guidelines"

  - trigger: "synthetic influencer|AI persona|virtual character"
    delegate_to: synthetic-influencers
    pattern: parallel
    context: "Character needs persona development"
    handoff_data:
      - "Visual design is foundation"
      - "Need personality, voice, content strategy"
    receive: "Persona bible for character"

  - trigger: "ad creative|advertising|campaign"
    delegate_to: ai-ad-creative
    pattern: parallel
    context: "Image for advertising use"
    handoff_data:
      - "Consider platform requirements"
      - "Need variants for testing"
      - "Text overlay considerations"
    receive: "Ad strategy and variant plan"

  - trigger: "orchestrate|multi-tool|full production"
    delegate_to: ai-creative-director
    pattern: sequential
    context: "Complex production needs coordination"
    handoff_data:
      - "Multiple outputs needed"
      - "Cross-tool consistency"
    receive: "Production plan"

# ============================================================================
# CROSS-DOMAIN INSIGHTS
# ============================================================================
cross_domain_insights:
  - domain: Photography
    insight: |
      All photography concepts translate to prompts:
      - Focal length: "shot on 85mm lens, f/1.4"
      - Lighting: "Rembrandt lighting, key light from 45 degrees"
      - Composition: "rule of thirds, subject in left third"
      - Color science: "Kodak Portra 400 color profile"
    applies_when: "Creating photorealistic images"

  - domain: Art history
    insight: |
      Historical art movements provide vocabulary:
      - "Baroque dramatic lighting"
      - "Impressionist brushstrokes"
      - "Art Nouveau organic lines"
      - "Bauhaus geometric simplicity"
      Reference deceased artists safely.
    applies_when: "Creating stylized or artistic images"

  - domain: Graphic design
    insight: |
      Design principles improve composition:
      - Visual hierarchy (size, color, placement)
      - Negative space usage
      - Color theory (complementary, analogous)
      - Typography integration (use Ideogram)
    applies_when: "Creating marketing or design assets"

  - domain: Psychology
    insight: |
      Visual psychology affects perception:
      - Color emotions (blue = trust, red = urgency)
      - Face recognition draws attention
      - Movement direction implies narrative
      - Cognitive load limits detail absorption
    applies_when: "Creating marketing or persuasive images"

  - domain: Film cinematography
    insight: |
      Film techniques translate to still images:
      - "Wes Anderson symmetrical framing"
      - "Roger Deakins natural lighting"
      - "Teal and orange color grading"
      - Aspect ratios convey different moods
    applies_when: "Creating cinematic or narrative images"

# ============================================================================
# COMMON COMBINATIONS
# ============================================================================
common_combinations:
  - name: Product Photography
    skills:
      - ai-image-generation
      - ai-visual-effects
      - prompt-engineering-creative
    workflow: |
      1. Craft detailed product prompt (prompt-engineering-creative)
      2. Generate with Flux Pro (ai-image-generation)
      3. Upscale to print resolution (ai-visual-effects)
      4. Export for platforms

  - name: Brand Visual System
    skills:
      - ai-image-generation
      - ai-world-building
      - ai-creative-director
    workflow: |
      1. Define brand world (ai-world-building)
      2. Generate hero images following world bible (ai-image-generation)
      3. Create character sheets for consistency
      4. Orchestrate asset production (ai-creative-director)

  - name: Social Media Content
    skills:
      - ai-image-generation
      - ai-ad-creative
      - real-time-content
    workflow: |
      1. Define content strategy (ai-ad-creative)
      2. Generate batch of variants (ai-image-generation)
      3. Optimize for trends (real-time-content)
      4. A/B test and iterate

  - name: Animated Content
    skills:
      - ai-image-generation
      - ai-video-generation
      - ai-audio-production
    workflow: |
      1. Generate seed frames (ai-image-generation)
      2. Animate with image-to-video (ai-video-generation)
      3. Add music/sound (ai-audio-production)

# ============================================================================
# VERSION COMPATIBILITY
# ============================================================================
version_compatibility:
  models:
    dalle_3: "Current (2024)"
    flux_pro: "1.1"
    flux_dev: "1.1"
    midjourney: "v6, v6.1"
    stable_diffusion: "SDXL, SD3"
    ideogram: "2.0"

  apis:
    openai: "v1"
    fal_ai: "v1"
    replicate: "v1"
    stability: "v2beta"

  notes: |
    Image generation models improve rapidly.
    Check provider docs for:
    - Latest model versions
    - New capabilities
    - Pricing changes
    - Rate limits

    Current as of December 2024.
