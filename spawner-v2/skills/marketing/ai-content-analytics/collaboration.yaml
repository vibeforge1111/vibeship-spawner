id: ai-content-analytics-collaboration
skill: ai-content-analytics
version: 1.0.0

# ============================================================================
# PREREQUISITES
# ============================================================================
prerequisites:
  required:
    - name: Analytics Platform
      description: Foundation for tracking AI content performance
      options:
        - tool: Google Analytics 4
          best_for: General web analytics, free tier, wide adoption
          cost: Free (with GA360 paid option)
        - tool: Mixpanel
          best_for: Event-based tracking, user journey analysis
          cost: Freemium
        - tool: Amplitude
          best_for: Product analytics, behavioral cohorts
          cost: Freemium
        - tool: Heap
          best_for: Auto-capture all events, retroactive analysis
          cost: Paid
        - tool: Segment
          best_for: Data infrastructure layer, multi-tool routing
          cost: Freemium
      reason: Cannot measure AI content without analytics infrastructure
      ecosystem_alternatives:
        free_tier: Google Analytics 4, Plausible (privacy-focused), Matomo (self-hosted)
        event_based: Mixpanel, Amplitude, Heap
        privacy_focused: Plausible, Fathom, Simple Analytics
        enterprise: Adobe Analytics, GA360, Amplitude Enterprise

    - name: AI Content Creation System
      description: Need AI-generated content to measure
      options:
        - tool: Jasper
          best_for: Marketing content at scale
          cost: Subscription
        - tool: Copy.ai
          best_for: Sales and marketing copy
          cost: Subscription
        - tool: OpenAI API
          best_for: Custom AI content workflows
          cost: Usage-based
        - tool: Claude API
          best_for: Long-form, nuanced content
          cost: Usage-based
        - tool: Custom LLM Integration
          best_for: Full control, proprietary workflows
          cost: Variable
      reason: Need AI content generation to measure performance
      ecosystem_alternatives:
        saas_tools: Jasper, Copy.ai, Writesonic, Rytr
        api_based: OpenAI, Anthropic, Cohere, AI21
        open_source: Llama, Mistral, GPT-J (self-hosted)

  recommended:
    - name: A/B Testing Platform
      options:
        - Optimizely
        - VWO (Visual Website Optimizer)
        - Google Optimize 360
        - Statsig
        - Split.io
      reason: Essential for testing AI variations scientifically

    - name: Attribution Platform
      options:
        - Triple Whale (e-commerce focused)
        - Rockerbox (multi-channel attribution)
        - Northbeam (data-driven attribution)
        - Attribution.io
        - Segment Connections
      reason: Track full customer journey with AI content touchpoints

    - name: Content Tracking System
      options:
        - UTM builder (built into analytics)
        - Bitly (link shortening + tracking)
        - Rebrandly (branded links + analytics)
        - Airtable (content inventory)
        - Notion (content database)
      reason: Organize and tag AI content for measurement

    - name: Data Visualization
      options:
        - Looker (Google)
        - Tableau
        - Metabase (open-source)
        - Grafana
        - Retool (custom dashboards)
      reason: Build AI content performance dashboards

# ============================================================================
# MCP TOOL CONFIGURATIONS
# ============================================================================
mcp_tools:
  - name: analytics-instrumentation-assistant
    description: AI-assisted analytics implementation
    install: Built into Claude Code
    capabilities:
      - event-schema-design
      - tracking-code-generation
      - utm-parameter-builder
      - conversion-funnel-mapping
    example_usage: |
      Use Claude for analytics implementation:
      - Design event tracking schema for AI content
      - Generate tracking code (Google Analytics, Mixpanel, etc.)
      - Build UTM parameter taxonomy (ai_variant, model, prompt_id)
      - Map conversion funnels for AI content journeys
      - Create attribution model configurations

  - name: dashboard-builder
    description: AI-powered dashboard design and implementation
    install: Built into Claude Code
    capabilities:
      - metric-selection
      - sql-query-generation
      - visualization-recommendations
      - alert-configuration
    example_usage: |
      Use Claude for dashboard creation:
      - Define metrics for AI content performance
      - Generate SQL queries for data extraction
      - Recommend chart types for different metrics
      - Configure alerts for quality degradation

# ============================================================================
# API INTEGRATIONS
# ============================================================================
api_integrations:
  google_analytics_4:
    base_url: https://www.googleapis.com/analytics/v3
    auth: OAuth 2.0 or API Key
    notes: |
      GA4 for AI content tracking:
      - Custom events: ai_content_view, ai_content_engaged, ai_content_converted
      - Custom dimensions: ai_model, ai_variant_id, ai_prompt_id
      - Custom metrics: ai_quality_score, ai_cost_per_piece
      - Conversions: Track as GA4 conversion events
    example: |
      // Track AI content view
      gtag('event', 'ai_content_view', {
        content_type: 'blog',
        ai_model: 'gpt-4',
        variant_id: 'v3',
        prompt_id: 'prompt-123'
      });

      // Track AI content conversion
      gtag('event', 'conversion', {
        send_to: 'AW-CONVERSION_ID/CONVERSION_LABEL',
        value: 99.99,
        currency: 'USD',
        transaction_id: 'T12345',
        content_type: 'ai',
        ai_variant_id: 'v3'
      });

  mixpanel_api:
    base_url: https://api.mixpanel.com
    auth_header: "Authorization: Basic ${MIXPANEL_API_SECRET}"
    notes: |
      Mixpanel for AI content analytics:
      - Event tracking: mixpanel.track('AI Content View', {...})
      - User profiles: Track AI content preferences
      - Funnels: AI content awareness → consideration → conversion
      - Cohorts: Segment by AI content interaction
    example: |
      // Track AI content interaction
      mixpanel.track('AI Content View', {
        content_id: 'blog-123',
        content_type: 'blog',
        ai_model: 'claude-3',
        variant_id: 'v5',
        quality_score: 8.5
      });

      // Track conversion with AI attribution
      mixpanel.track('Conversion', {
        value: 99.99,
        ai_assisted: true,
        first_touch_ai: true,
        ai_variant_id: 'v5'
      });

  segment_api:
    base_url: https://api.segment.io/v1
    auth_header: "Authorization: Basic ${SEGMENT_WRITE_KEY}"
    notes: |
      Segment as data infrastructure:
      - Route AI content events to multiple tools (GA4, Mixpanel, Amplitude)
      - Consistent event schema across platforms
      - Centralized tracking code
    example: |
      analytics.track('AI Content View', {
        content_id: 'blog-123',
        ai_model: 'gpt-4',
        variant_id: 'v3',
        quality_score: 8.2
      });
      // Automatically sent to all connected destinations (GA4, Mixpanel, etc.)

  claude_analytics_assistant:
    usage: Built-in
    example: |
      # Analytics implementation prompts

      EVENT SCHEMA DESIGN:
      "Design an event tracking schema for AI-generated blog content.

       Track:
       - Content views, engagement, conversions
       - AI model used, variant ID, prompt version
       - Quality score, cost per piece
       - Attribution (first-touch, last-touch, assisted)

       Output: Event names, properties, and tracking code"

      DASHBOARD SQL GENERATION:
      "Generate SQL query for AI content performance dashboard.

       Metrics needed:
       - Total AI content published (last 30 days)
       - Conversion rate by AI variant
       - ROI: (revenue - cost) / cost
       - Quality score trending over time
       - AI vs Human performance comparison

       Database: PostgreSQL with events table"

      UTM TAXONOMY:
      "Create UTM parameter taxonomy for AI content tracking.

       Need to track:
       - Content type (blog, email, landing_page)
       - AI model (gpt-4, claude-3, gemini)
       - Variant ID (for A/B testing)
       - Prompt version (for drift detection)

       Output: UTM structure and examples"

      ATTRIBUTION MODEL:
      "Design multi-touch attribution model for AI content.

       Customer journey:
       1. AI blog post (first touch)
       2. AI email (mid-funnel)
       3. Human sales call (last touch)
       4. Conversion

       Recommend attribution model and implementation approach"

# ============================================================================
# RECEIVES FROM (Integration Enhancement)
# ============================================================================
receives_from:
  - skill: content-strategy
    context: "Content strategy defines what to create, analytics measures what works"
    receives:
      - "Content calendar and topics"
      - "Target audience segments"
      - "Content goals (awareness, consideration, conversion)"
    provides: "Performance data to inform content strategy decisions"

  - skill: ai-creative-director
    context: "AI creative director generates content, analytics measures performance"
    receives:
      - "AI-generated content pieces"
      - "Variant IDs for A/B testing"
      - "Model and prompt metadata"
    provides: "Performance feedback to optimize AI content generation"

  - skill: marketing
    context: "Marketing campaigns distribute content, analytics tracks results"
    receives:
      - "Campaign structure and goals"
      - "Distribution channels"
      - "Budget allocation"
    provides: "Attribution data showing AI content contribution to campaigns"

  - skill: copywriting
    context: "Copywriting creates messaging, analytics validates effectiveness"
    receives:
      - "Copy variations (headlines, CTAs, body)"
      - "A/B test hypotheses"
    provides: "Conversion data showing which copy performs best"

  - skill: growth-strategy
    context: "Growth strategy sets goals, analytics measures progress"
    receives:
      - "Growth goals and KPIs"
      - "Optimization priorities"
      - "Experimentation roadmap"
    provides: "Data-driven insights for growth optimization"

# ============================================================================
# DELEGATION TRIGGERS
# ============================================================================
delegation_triggers:
  - trigger: "content strategy|plan content|editorial calendar"
    delegate_to: content-strategy
    pattern: sequential
    context: "Analytics insights inform content strategy"
    handoff_data:
      - "Top performing content topics"
      - "Conversion rate by content type"
      - "Audience engagement patterns"
      - "Content gaps (high search, low coverage)"
    receive: "Updated content strategy based on data"

  - trigger: "generate ai content|create with ai|ai variations"
    delegate_to: ai-creative-director
    pattern: parallel
    context: "Analytics findings guide AI content generation"
    handoff_data:
      - "Winning variation patterns"
      - "Optimal content length and structure"
      - "High-performing tone and style"
      - "A/B test results"
    receive: "New AI content incorporating performance insights"

  - trigger: "improve copy|optimize headlines|better cta"
    delegate_to: copywriting
    pattern: sequential
    context: "Analytics data shows what copy elements work"
    handoff_data:
      - "CTR by headline variation"
      - "Conversion rate by CTA type"
      - "Engagement by tone/style"
    receive: "Optimized copy based on performance data"

  - trigger: "marketing campaign|distribute content|promote"
    delegate_to: marketing
    pattern: parallel
    context: "Analytics shows which content to amplify"
    handoff_data:
      - "Top converting content pieces"
      - "Best performing channels"
      - "Optimal promotion timing"
      - "Audience segments most responsive"
    receive: "Campaign strategy leveraging high-performing content"

  - trigger: "growth optimization|conversion funnel|experimentation"
    delegate_to: growth-strategy
    pattern: ongoing
    context: "Analytics reveals growth opportunities"
    handoff_data:
      - "Funnel drop-off points"
      - "High-potential segments"
      - "Content ROI by type"
      - "Experimentation results"
    receive: "Growth strategy incorporating analytics insights"

  - trigger: "seo optimization|organic traffic|search rankings"
    delegate_to: seo
    pattern: parallel
    context: "Analytics shows organic performance of AI content"
    handoff_data:
      - "Organic traffic by content piece"
      - "Keyword rankings for AI content"
      - "Backlinks to AI vs human content"
      - "SERP CTR data"
    receive: "SEO recommendations for AI content"

  - trigger: "content quality|qa review|brand consistency"
    delegate_to: ai-content-qa
    pattern: sequential
    context: "Analytics identifies quality issues to address"
    handoff_data:
      - "Low-performing content (quality issues suspected)"
      - "High bounce rate content"
      - "Negative sentiment content"
    receive: "QA review and quality improvement recommendations"

# ============================================================================
# CROSS-DOMAIN INSIGHTS
# ============================================================================
cross_domain_insights:
  - domain: Data Science
    insight: |
      Data scientists know experimentation rigor:
      - Hypothesis before experiment (not fishing for insights)
      - Statistical significance (p-values, confidence intervals)
      - Sample size calculations (power analysis)
      - Multiple testing corrections (Bonferroni, FDR)
      - Causal inference (not just correlation)

      AI content analytics is data science applied to content.
      Don't just measure, experiment scientifically.
    applies_when: "Running A/B tests or analyzing AI content performance"

  - domain: Product Analytics
    insight: |
      Product teams know activation, engagement, retention:
      - Activation: Did user get value from content?
      - Engagement: Are they coming back?
      - Retention: Long-term content value
      - Cohort analysis: Compare user groups over time
      - North Star Metric: One metric that matters most

      Apply product thinking to content analytics.
    applies_when: "Designing AI content measurement framework"

  - domain: E-commerce Analytics
    insight: |
      E-commerce knows attribution complexity:
      - Multi-touch attribution (first, last, linear, position-based)
      - Assisted conversions matter (not just last-click)
      - Customer journey is non-linear
      - View-through conversions count
      - Incrementality testing (what's the lift?)

      AI content often assists rather than closes. Use e-commerce attribution.
    applies_when: "Attributing conversions to AI content"

  - domain: Marketing Attribution
    insight: |
      Marketers know the attribution problem:
      - Last-click attribution undercounts top-of-funnel
      - First-click overcredits awareness
      - Linear is simple but wrong
      - Data-driven attribution requires ML and data
      - No perfect model exists

      Choose attribution model based on your business model, not ideology.
    applies_when: "Selecting attribution model for AI content"

  - domain: Finance (ROI)
    insight: |
      Finance knows return on investment:
      - ROI = (Revenue - Cost) / Cost
      - Time value of money (payback period)
      - Opportunity cost (what else could we do?)
      - Risk-adjusted returns
      - Marginal ROI (does 10th piece have same ROI as 1st?)

      Measure AI content with financial discipline.
    applies_when: "Calculating AI content ROI and justifying investment"

  - domain: Quality Control (Manufacturing)
    insight: |
      Manufacturing knows process control:
      - Control charts (detect when process drifts)
      - Six Sigma (reduce variance)
      - Root cause analysis (5 whys)
      - Continuous improvement (kaizen)
      - Defect rates and acceptable quality levels

      Apply to AI content: monitor quality, detect drift, fix root causes.
    applies_when: "Monitoring AI model performance over time"

# ============================================================================
# COMMON COMBINATIONS
# ============================================================================
common_combinations:
  - name: AI Content Performance Stack
    skills:
      - ai-content-analytics
      - ai-creative-director
      - content-strategy
    workflow: |
      1. Generate AI content with metadata (ai-creative-director)
      2. Track performance with analytics (ai-content-analytics)
      3. Feed insights back to content strategy (content-strategy)
      4. Iterate: Generate better content based on data

      Continuous improvement loop.

  - name: AI A/B Testing Engine
    skills:
      - ai-content-analytics
      - ai-creative-director
      - copywriting
    workflow: |
      1. Generate 5-10 AI variations (ai-creative-director)
      2. A/B test with statistical rigor (ai-content-analytics)
      3. Identify winning patterns (ai-content-analytics)
      4. Create new variations based on winners (copywriting or ai-creative-director)
      5. Repeat

      Rapid iteration to find optimal content.

  - name: AI Content Attribution System
    skills:
      - ai-content-analytics
      - marketing
      - growth-strategy
    workflow: |
      1. Instrument AI content with tracking (ai-content-analytics)
      2. Distribute across channels (marketing)
      3. Track full customer journey (ai-content-analytics)
      4. Attribute revenue to AI content (ai-content-analytics)
      5. Optimize based on ROI (growth-strategy)

      Prove AI content value with attribution.

  - name: AI Content Quality Monitoring
    skills:
      - ai-content-analytics
      - ai-creative-director
      - ai-content-qa
    workflow: |
      1. Generate AI content with quality baseline (ai-creative-director)
      2. Track quality metrics over time (ai-content-analytics)
      3. Detect quality drift (ai-content-analytics)
      4. QA review low-quality content (ai-content-qa)
      5. Adjust prompts or models (ai-creative-director)

      Maintain consistent AI content quality.

# ============================================================================
# FEEDBACK LOOPS (Integration Enhancement)
# ============================================================================
feedback_loops:
  receives_feedback_from:
    - skill: ai-creative-director
      signal: "AI content generation metadata (model, prompt, version)"
      action: "Track performance by model and prompt to optimize generation"

    - skill: content-strategy
      signal: "Content calendar and publication schedule"
      action: "Align analytics tracking with content roadmap"

    - skill: marketing
      signal: "Campaign performance and channel effectiveness"
      action: "Attribute AI content impact across marketing channels"

    - skill: ai-content-qa
      signal: "Quality scores and QA findings"
      action: "Incorporate quality metrics into performance dashboard"

  sends_feedback_to:
    - skill: ai-creative-director
      signal: "Which AI variations and prompts perform best"
      action: "Optimize AI content generation based on performance data"

    - skill: content-strategy
      signal: "Which topics, formats, and funnel stages convert"
      action: "Inform content strategy with data on what works"

    - skill: growth-strategy
      signal: "AI content ROI and growth opportunities"
      action: "Prioritize growth initiatives based on AI content data"

    - skill: marketing
      signal: "Content attribution and channel performance"
      action: "Optimize marketing spend and channel mix"

# ============================================================================
# VERSION COMPATIBILITY
# ============================================================================
version_compatibility:
  analytics_platforms:
    google_analytics: "GA4 (Universal Analytics deprecated)"
    mixpanel: "Current"
    amplitude: "Current"
    heap: "Current"
    segment: "Current (Twilio Segment)"

  ai_platforms:
    openai: "API v1 (GPT-4, GPT-3.5)"
    anthropic: "API v1 (Claude 3 family)"
    google: "Gemini API"

  attribution_tools:
    triple_whale: "Current (Shopify focused)"
    rockerbox: "Current"
    northbeam: "Current"

  testing_platforms:
    optimizely: "Current (Web Experimentation, Feature Experimentation)"
    vwo: "Current"
    statsig: "Current"

  notes: |
    Analytics tools evolve rapidly.

    Key considerations:
    - GA4 is now standard (Universal Analytics sunset July 2023)
    - Segment is data infrastructure layer (routes to other tools)
    - AI platform APIs stable but models update frequently
    - Attribution tools vary by channel (e-commerce vs SaaS vs B2B)

    Current as of December 2024.

# ============================================================================
# IMPLEMENTATION PATTERNS
# ============================================================================
implementation_patterns:
  quick_start:
    description: "Minimal viable analytics for AI content"
    steps:
      - "Add Google Analytics 4 to site"
      - "Create custom event: ai_content_view"
      - "Tag AI content with metadata (ai_model, variant_id)"
      - "Track conversions with AI attribution"
      - "Build simple dashboard: AI conversions, ROI"
    time: "1 week"
    cost: "Low (free tier GA4)"

  professional:
    description: "Complete AI content analytics system"
    steps:
      - "Implement Segment as data layer"
      - "Connect GA4, Mixpanel, attribution tool"
      - "Define event schema for AI content journey"
      - "Implement A/B testing platform"
      - "Build comprehensive dashboard (Looker/Tableau)"
      - "Set up alerts for quality drift"
    time: "4-6 weeks"
    cost: "Medium ($500-2000/month for tools)"

  enterprise:
    description: "Advanced AI content measurement with ML attribution"
    steps:
      - "Custom data warehouse (Snowflake/BigQuery)"
      - "Event streaming (Kafka/Kinesis)"
      - "ML-based attribution modeling"
      - "Real-time dashboards (Grafana/custom)"
      - "Automated experimentation platform"
      - "Predictive analytics for content performance"
    time: "3-6 months"
    cost: "High ($10k+/month for infrastructure and tools)"
