id: ai-audio-production-collaboration
skill: ai-audio-production
version: 1.0.0

# ============================================================================
# PREREQUISITES
# ============================================================================
prerequisites:
  required:
    - name: API Access (at least one per category)
      voice_synthesis:
        - provider: ElevenLabs
          signup: https://elevenlabs.io/
          env_var: ELEVENLABS_API_KEY
          pricing: Free 10k chars, $5+ for more
          best_for: Highest quality AI voices, cloning
        - provider: Play.ht
          signup: https://play.ht/
          env_var: PLAYHT_API_KEY
          pricing: Similar tier structure
          best_for: Voice variety, accents
        - provider: Murf AI
          signup: https://murf.ai/
          env_var: MURF_API_KEY
          best_for: Business/enterprise voice

      music_generation:
        - provider: Suno
          signup: https://suno.ai/
          env_var: SUNO_API_KEY
          pricing: Free 50 songs, $10+ unlimited
          best_for: Pop, rock, electronic, vocals
        - provider: Udio
          signup: https://udio.com/
          env_var: UDIO_API_KEY
          best_for: Classical, jazz, complex arrangements
        - provider: Soundraw
          signup: https://soundraw.io/
          best_for: Background music, customizable length

  recommended:
    - name: DAW (Digital Audio Workstation)
      options:
        - DaVinci Resolve (free, includes Fairlight)
        - Audacity (free)
        - Logic Pro
        - Adobe Audition
        - Reaper (affordable)
      reason: AI audio needs mixing, editing, mastering

    - name: Audio enhancement tools
      options:
        - iZotope RX (noise, cleanup)
        - LANDR (automated mastering)
        - Adobe Podcast (AI enhancement)
      reason: Post-processing improves AI output quality

# ============================================================================
# MCP TOOL CONFIGURATIONS
# ============================================================================
mcp_tools:
  # ElevenLabs MCP
  - name: elevenlabs
    description: Premium AI voice synthesis and cloning
    install: npx -y @anthropic/mcp-installer install elevenlabs
    config:
      server:
        command: npx
        args: ["-y", "@elevenlabs/mcp-server"]
        env:
          ELEVENLABS_API_KEY: "${ELEVENLABS_API_KEY}"
    capabilities:
      - text-to-speech
      - voice-cloning
      - voice-design
      - sound-effects
      - dubbing
    example_usage: |
      Use elevenlabs to synthesize speech:
      - Text: "Welcome to our product showcase..."
      - Voice: Rachel (or custom voice ID)
      - Model: eleven_turbo_v2
      - Stability: 0.5
      - Similarity: 0.75

  # Suno MCP (if available)
  - name: suno
    description: AI music generation with vocals
    install: npx -y @anthropic/mcp-installer install suno
    config:
      server:
        command: npx
        args: ["-y", "@suno/mcp-server"]
        env:
          SUNO_API_KEY: "${SUNO_API_KEY}"
    capabilities:
      - text-to-music
      - lyrics-to-song
      - extend-audio
      - instrumental
    example_usage: |
      Use suno to generate music:
      - Prompt: "Upbeat indie pop, 120 BPM, acoustic guitar..."
      - Duration: 2 minutes
      - With vocals: true/false

  # Replicate for audio models
  - name: replicate-audio
    description: Access to various audio models
    install: npx -y @anthropic/mcp-installer install replicate
    config:
      server:
        command: npx
        args: ["-y", "@replicate/mcp-server"]
        env:
          REPLICATE_API_TOKEN: "${REPLICATE_API_TOKEN}"
    models_available:
      - suno-ai/bark (voice synthesis)
      - meta/musicgen (music generation)
      - openai/whisper (transcription)
      - coqui-ai/xtts (voice cloning)
    example_usage: |
      Use replicate to run MusicGen:
      - Model: meta/musicgen
      - Prompt: "Lo-fi hip hop, relaxing..."
      - Duration: 30 seconds

# ============================================================================
# API INTEGRATIONS
# ============================================================================
api_integrations:
  elevenlabs:
    base_url: https://api.elevenlabs.io/v1
    auth_header: "xi-api-key: ${ELEVENLABS_API_KEY}"
    sdk: "elevenlabs"
    example: |
      import { ElevenLabsClient } from "elevenlabs";

      const client = new ElevenLabsClient({
        apiKey: process.env.ELEVENLABS_API_KEY
      });

      const audio = await client.generate({
        voice: "Rachel",
        text: "Hello, welcome to our demo...",
        model_id: "eleven_turbo_v2",
        voice_settings: {
          stability: 0.5,
          similarity_boost: 0.75,
          style: 0.3
        }
      });

      // Stream or save audio
      await fs.writeFile("output.mp3", audio);

  suno:
    base_url: https://api.suno.ai/v1
    auth_header: "Authorization: Bearer ${SUNO_API_KEY}"
    example: |
      // Suno API example (check current docs)
      const response = await fetch("https://api.suno.ai/v1/generate", {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${process.env.SUNO_API_KEY}`,
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          prompt: "Upbeat indie pop...",
          duration: 120,
          make_instrumental: false
        })
      });

  replicate_audio:
    base_url: https://api.replicate.com/v1
    auth_header: "Authorization: Token ${REPLICATE_API_TOKEN}"
    sdk: "replicate"
    example: |
      import Replicate from "replicate";

      const replicate = new Replicate();

      // MusicGen
      const output = await replicate.run(
        "meta/musicgen:latest",
        {
          input: {
            prompt: "Lo-fi hip hop beat, relaxing...",
            duration: 30,
            model_version: "stereo-large"
          }
        }
      );

      // Bark (voice)
      const voice = await replicate.run(
        "suno-ai/bark:latest",
        {
          input: {
            prompt: "Hello, this is a test. [laughs]",
            text_temp: 0.7
          }
        }
      );

  soundraw:
    base_url: https://soundraw.io/api
    auth_header: "X-API-Key: ${SOUNDRAW_API_KEY}"
    example: |
      // Soundraw is primarily web-based
      // Use their API for integration:
      const response = await fetch("https://soundraw.io/api/v1/generate", {
        method: "POST",
        headers: {
          "X-API-Key": process.env.SOUNDRAW_API_KEY,
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          genre: "corporate",
          mood: "uplifting",
          length: 120,
          tempo: "medium"
        })
      });

# ============================================================================
# DELEGATION TRIGGERS
# ============================================================================
delegation_triggers:
  - trigger: "video|visuals|footage|animation"
    delegate_to: ai-video-generation
    pattern: parallel
    context: "Audio needs accompanying visuals"
    handoff_data:
      - "Share music tempo and mood for sync"
      - "Provide duration requirements"
      - "Consider beat-to-cut alignment"
    receive: "Video file to sync with audio"

  - trigger: "digital human|avatar|presenter|talking head"
    delegate_to: digital-humans
    pattern: sequential
    context: "Voice audio needs visual presenter"
    handoff_data:
      - "Voice characteristics for avatar matching"
      - "Script timing and emotions"
      - "Lip sync requirements"
    receive: "Digital human video with synced audio"

  - trigger: "prompt help|better prompts|music prompt"
    delegate_to: prompt-engineering-creative
    pattern: sequential
    context: "Need optimized prompts for audio generation"
    handoff_data:
      - "Target genre and mood"
      - "Reference tracks if any"
      - "Technical requirements (tempo, length)"
    receive: "Optimized audio generation prompts"

  - trigger: "voiceover script|copy|messaging"
    delegate_to: copywriting
    pattern: sequential
    context: "Need script for voice synthesis"
    handoff_data:
      - "Target audience and tone"
      - "Duration constraints"
      - "Key messages to convey"
    receive: "Script optimized for voice synthesis"

  - trigger: "localization|translation|multilingual"
    delegate_to: ai-localization
    pattern: parallel
    context: "Audio needs multi-language versions"
    handoff_data:
      - "Source language and script"
      - "Target languages"
      - "Voice matching requirements"
    receive: "Localized audio in target languages"

  - trigger: "ad|commercial|advertisement"
    delegate_to: ai-ad-creative
    pattern: parallel
    context: "Audio for advertising"
    handoff_data:
      - "Platform requirements"
      - "Call-to-action needs"
      - "Brand guidelines"
    receive: "Ad strategy influencing audio direction"

  - trigger: "orchestrate|full production|campaign"
    delegate_to: ai-creative-director
    pattern: sequential
    context: "Complex production needing coordination"
    handoff_data:
      - "Audio role in larger production"
      - "Other assets being created"
      - "Timeline and dependencies"
    receive: "Production coordination"

# ============================================================================
# CROSS-DOMAIN INSIGHTS
# ============================================================================
cross_domain_insights:
  - domain: Music production
    insight: |
      Traditional music production concepts apply:
      - Arrangement: intro, verse, chorus, bridge, outro
      - Dynamics: build-ups, drops, quiet moments
      - Frequency spectrum: bass, mids, highs balanced
      - Stereo field: width, depth, placement
      Prompt for these elements explicitly.
    applies_when: "Generating or directing AI music"

  - domain: Voice acting
    insight: |
      Voice performance concepts translate to AI settings:
      - Pacing: words per minute affects clarity
      - Emphasis: can be guided with punctuation
      - Emotion: stability settings affect expressiveness
      - Breath: natural pauses help comprehension
    applies_when: "Directing AI voice synthesis"

  - domain: Film sound design
    insight: |
      Sound design principles apply to AI audio:
      - Diegetic vs non-diegetic (in-world vs soundtrack)
      - Foley for texture and realism
      - Ambient for space and mood
      - Music scoring emotional beats
    applies_when: "Creating audio for video content"

  - domain: Psychology
    insight: |
      Audio psychology affects perception:
      - Tempo affects energy (high BPM = excitement)
      - Major keys = positive, minor = emotional/sad
      - Voice pitch affects trust (lower = more authoritative)
      - Silence is as powerful as sound
    applies_when: "Selecting mood and style for AI audio"

  - domain: Podcast production
    insight: |
      Podcast audio standards apply:
      - Voice level: -16 to -14 LUFS
      - Noise floor: below -60 dB
      - De-essing for sibilance
      - Consistent levels throughout
    applies_when: "Creating spoken word content"

# ============================================================================
# COMMON COMBINATIONS
# ============================================================================
common_combinations:
  - name: Video with Music and VO
    skills:
      - ai-audio-production
      - ai-video-generation
      - voiceover
      - ai-visual-effects
    workflow: |
      1. Write VO script (voiceover)
      2. Generate voice (ai-audio-production)
      3. Generate matching music (ai-audio-production)
      4. Generate visuals (ai-video-generation)
      5. Mix and master audio
      6. Final composite (ai-visual-effects)

  - name: Podcast Episode
    skills:
      - ai-audio-production
      - copywriting
      - ai-localization
    workflow: |
      1. Script content (copywriting)
      2. Generate voice narration (ai-audio-production)
      3. Add intro/outro music (ai-audio-production)
      4. Post-process and master
      5. Optionally localize (ai-localization)

  - name: Ad Audio
    skills:
      - ai-audio-production
      - ai-ad-creative
      - copywriting
    workflow: |
      1. Ad strategy (ai-ad-creative)
      2. Script development (copywriting)
      3. Voice synthesis (ai-audio-production)
      4. Background music (ai-audio-production)
      5. Mix for platform specs

  - name: Multi-language Content
    skills:
      - ai-audio-production
      - ai-localization
      - digital-humans
    workflow: |
      1. Original voice/script (ai-audio-production)
      2. Translate and adapt (ai-localization)
      3. Synthesize in each language (ai-audio-production)
      4. Match with localized avatars (digital-humans)

# ============================================================================
# VERSION COMPATIBILITY
# ============================================================================
version_compatibility:
  models:
    elevenlabs: "eleven_turbo_v2, eleven_multilingual_v2"
    suno: "v3.5"
    udio: "current"
    bark: "suno-ai/bark"
    musicgen: "meta/musicgen stereo-large"

  apis:
    elevenlabs: "v1"
    suno: "v1"
    replicate: "v1"

  notes: |
    AI audio models improve rapidly.
    ElevenLabs releases new models quarterly.
    Check for:
    - New voice models (quality improvements)
    - New music models (genre coverage)
    - Pricing changes
    - Character/generation limits

    Current as of December 2024.
