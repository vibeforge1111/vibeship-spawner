id: ai-world-building-collaboration
skill: ai-world-building
version: 1.0.0

# ============================================================================
# PREREQUISITES
# ============================================================================
prerequisites:
  required:
    - name: AI Image Generation Platform
      description: Core platform for generating world assets
      options:
        - tool: Midjourney
          url: https://midjourney.com/
          best_for: Stylized worlds, character consistency
          cost: Subscription ($10-60/mo)
        - tool: Flux Pro
          url: https://fal.ai/models/fal-ai/flux-pro
          best_for: Photorealism, fine control
          cost: Usage-based
        - tool: Stable Diffusion
          best_for: Local control, LoRA training
          cost: Free (hardware required)

    - name: World Documentation Tool
      description: Where the world bible lives
      options:
        - Notion (collaborative, visual)
        - Figma (visual-first, design integration)
        - GitBook (versioned, developer-friendly)
        - Confluence (enterprise)

  recommended:
    - name: Character Consistency Tools
      options:
        - IP-Adapter (reference-based consistency)
        - LoRA Training (custom model fine-tuning)
        - ControlNet (pose and structure control)
        - Dreambooth (subject training)
      reason: AI generation needs help maintaining character consistency

    - name: 3D Tools for Reference
      options:
        - Blender (free, comprehensive)
        - Character Creator (specialized)
        - MetaHuman (photorealistic humans)
        - Daz3D (accessible character posing)
      reason: 3D can provide consistent references for 2D generation

    - name: Asset Management
      options:
        - Bynder (enterprise DAM)
        - Brandfolder (brand asset management)
        - Air (creative asset management)
        - Playbook AI (AI-focused DAM)
      reason: World assets need organized storage and access

# ============================================================================
# MCP TOOL CONFIGURATIONS
# ============================================================================
mcp_tools:
  # Midjourney MCP (via Replicate)
  - name: midjourney-generation
    description: Generate world assets with Midjourney-style models
    install: npx -y @anthropic/mcp-installer install replicate
    config:
      server:
        command: npx
        args: ["-y", "@replicate/mcp-server"]
        env:
          REPLICATE_API_TOKEN: "${REPLICATE_API_TOKEN}"
    models_available:
      - playgroundai/playground-v2.5
      - lucataco/sdxl
      - black-forest-labs/flux-schnell
    example_usage: |
      Use Replicate for world asset generation:
      - Character reference sheets
      - Environment establishing shots
      - Detail and texture references
      - Style exploration

  # Fal.ai for World Building
  - name: fal-world-building
    description: Advanced AI generation for world assets
    install: npx -y @anthropic/mcp-installer install fal-ai
    config:
      server:
        command: npx
        args: ["-y", "@fal-ai/mcp-server"]
        env:
          FAL_KEY: "${FAL_KEY}"
    capabilities:
      - flux-pro (high quality generation)
      - flux-lora (custom trained models)
      - controlnet (structure control)
      - ip-adapter (reference consistency)
    example_usage: |
      Use Fal.ai for world building:
      - Flux Pro for high-quality hero assets
      - ControlNet for pose/structure matching
      - IP-Adapter for character consistency
      - LoRA training for brand style

  # Stability AI for Local/Custom Work
  - name: stability-world
    description: Stability AI models for world generation
    install: npx -y @anthropic/mcp-installer install stability-ai
    config:
      server:
        command: npx
        args: ["-y", "@stability-ai/mcp-server"]
        env:
          STABILITY_API_KEY: "${STABILITY_API_KEY}"
    capabilities:
      - SDXL (base generation)
      - Stable Diffusion 3 (latest)
      - style-transfer
      - outpainting (world expansion)

# ============================================================================
# API INTEGRATIONS
# ============================================================================
api_integrations:
  replicate:
    base_url: https://api.replicate.com/v1
    auth_header: "Authorization: Token ${REPLICATE_API_TOKEN}"
    sdk: "replicate"
    example: |
      import Replicate from "replicate";

      const replicate = new Replicate();

      // Generate character reference
      const characterRef = await replicate.run(
        "black-forest-labs/flux-schnell:latest",
        {
          input: {
            prompt: "Character design sheet, Luna, 28-year-old woman, pink hair, green eyes, multiple poses and expressions, white background, professional character art",
            num_outputs: 4,
            guidance: 7.5
          }
        }
      );

      // Generate environment reference
      const envRef = await replicate.run(
        "black-forest-labs/flux-schnell:latest",
        {
          input: {
            prompt: "Cozy coffee shop interior, warm lighting, exposed brick, wooden tables, plants, morning light through windows, establishing shot",
            num_outputs: 4
          }
        }
      );

  fal_ai:
    base_url: https://fal.run
    auth_header: "Authorization: Key ${FAL_KEY}"
    example: |
      import * as fal from "@fal-ai/serverless-client";

      fal.config({ credentials: process.env.FAL_KEY });

      // High-quality world asset with Flux Pro
      const worldAsset = await fal.subscribe("fal-ai/flux-pro", {
        input: {
          prompt: "Fantasy castle on mountain cliff, sunset, epic scale, detailed architecture, atmospheric perspective, cinematic lighting",
          image_size: "landscape_16_9",
          num_inference_steps: 50
        }
      });

      // Character with IP-Adapter for consistency
      const consistentChar = await fal.subscribe("fal-ai/ip-adapter-plus", {
        input: {
          prompt: "Luna walking through city street, casual outfit, daytime",
          image_url: characterRefUrl,
          ip_adapter_scale: 0.8
        }
      });

      // ControlNet for pose consistency
      const posedChar = await fal.subscribe("fal-ai/controlnet-sdxl", {
        input: {
          prompt: "Luna, professional pose, studio lighting",
          control_image: poseReferenceUrl,
          controlnet_type: "openpose"
        }
      });

  stability_ai:
    base_url: https://api.stability.ai/v1
    auth_header: "Authorization: Bearer ${STABILITY_API_KEY}"
    example: |
      // Outpainting for world expansion
      const expanded = await fetch(
        "https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/image-to-image/outpaint",
        {
          method: "POST",
          headers: {
            "Authorization": `Bearer ${process.env.STABILITY_API_KEY}`,
            "Content-Type": "application/json"
          },
          body: JSON.stringify({
            init_image: imageBase64,
            prompt: "continuation of fantasy landscape, same style",
            direction: "right",
            pixels: 512
          })
        }
      );

  notion_world_bible:
    type: documentation
    notes: |
      Notion API for world bible management:

      # Create world bible structure
      POST https://api.notion.com/v1/pages
      Authorization: Bearer ${NOTION_API_KEY}

      # Update character entries
      PATCH https://api.notion.com/v1/pages/{page_id}

      # Query for specific rules
      POST https://api.notion.com/v1/databases/{database_id}/query

      SDK: @notionhq/client

# ============================================================================
# DELEGATION TRIGGERS
# ============================================================================
delegation_triggers:
  - trigger: "generate|create|asset"
    delegate_to: ai-image-generation
    pattern: parallel
    context: "World defined, need assets generated"
    handoff_data:
      - "World bible rules"
      - "Relevant reference images"
      - "Prompt templates"
      - "Negative prompts"
    receive: "Generated assets following world rules"

  - trigger: "video|animation|motion"
    delegate_to: ai-video-generation
    pattern: parallel
    context: "World needs motion content"
    handoff_data:
      - "World visual language"
      - "Character references"
      - "Environment references"
    receive: "Video content in world style"

  - trigger: "persona|influencer|character personality"
    delegate_to: synthetic-influencers
    pattern: sequential
    context: "Character needs full persona development"
    handoff_data:
      - "Character visual design"
      - "Character backstory"
      - "Brand relationship"
    receive: "Complete persona bible"

  - trigger: "video presence|talking head|spokesperson"
    delegate_to: digital-humans
    pattern: parallel
    context: "Character needs video representation"
    handoff_data:
      - "Character reference images"
      - "Voice characteristics"
      - "Personality notes"
    receive: "Digital human setup"

  - trigger: "orchestrate|campaign|multi-asset"
    delegate_to: ai-creative-director
    pattern: sequential
    context: "World assets for production"
    handoff_data:
      - "World bible summary"
      - "Available assets"
      - "Generation capabilities"
    receive: "Production coordination"

  - trigger: "brand strategy|positioning"
    delegate_to: branding
    pattern: sequential
    context: "World needs brand strategy foundation"
    handoff_data:
      - "Current world vision"
      - "Target audience"
      - "Market context"
    receive: "Brand strategy for world"

# ============================================================================
# CROSS-DOMAIN INSIGHTS
# ============================================================================
cross_domain_insights:
  - domain: Game Development
    insight: |
      Game studios have solved world consistency at scale:
      - Art bibles with exhaustive documentation
      - Style guides that are law, not suggestion
      - Reference libraries for everything
      - Pipelines that enforce consistency
      Apply game studio discipline to marketing world building.
    applies_when: "Building comprehensive world systems"

  - domain: Film Production Design
    insight: |
      Production designers create coherent worlds:
      - Concept art before construction
      - Material palettes and color scripts
      - Set decoration rules
      - Continuity supervision
      Every detail serves the world's story.
    applies_when: "Designing environments and details"

  - domain: Architecture
    insight: |
      Architects think in systems:
      - Material specifications
      - Proportional relationships
      - Light and shadow planning
      - Human scale considerations
      Environments should feel designed, not random.
    applies_when: "Creating architectural elements"

  - domain: Fashion Design
    insight: |
      Fashion creates character through clothing:
      - Silhouette vocabulary
      - Color story
      - Material choices
      - Consistent design language
      Characters' wardrobes should be as designed as their faces.
    applies_when: "Designing character clothing and style"

  - domain: Mythology/Worldbuilding Fiction
    insight: |
      Fiction worldbuilders know:
      - Internal consistency matters most
      - Rules can be broken, but must be acknowledged
      - Details create believability
      - The world extends beyond what's shown
      A brand world should feel like it exists beyond the frame.
    applies_when: "Creating world depth and lore"

# ============================================================================
# COMMON COMBINATIONS
# ============================================================================
common_combinations:
  - name: Character Development Pipeline
    skills:
      - ai-world-building
      - ai-image-generation
      - synthetic-influencers
    workflow: |
      1. Design character in world context (world-building)
      2. Create reference sheet (image-generation)
      3. Develop persona and voice (synthetic-influencers)
      4. Test consistency across scenarios
      5. Document in world bible
      6. Create prompt templates for future generation

  - name: Environment Library Creation
    skills:
      - ai-world-building
      - ai-image-generation
      - ai-visual-effects
    workflow: |
      1. Define environment language (world-building)
      2. Generate key locations (image-generation)
      3. Create variations (time of day, weather)
      4. Enhance and unify look (visual-effects)
      5. Document in world bible
      6. Create ControlNet references for consistency

  - name: Full World Genesis
    skills:
      - ai-world-building
      - ai-image-generation
      - ai-video-generation
      - synthetic-influencers
      - ai-creative-director
    workflow: |
      1. Define world rules and visual language
      2. Create core characters with full documentation
      3. Build key environments
      4. Develop character personas
      5. Generate initial asset library
      6. Orchestrate into coherent production
      7. Document everything in world bible

  - name: World Expansion
    skills:
      - ai-world-building
      - ai-image-generation
      - prompt-engineering-creative
    workflow: |
      1. Review existing world bible
      2. Design new element following rules
      3. Create reference assets
      4. Test consistency with existing assets
      5. Engineer prompts for new element
      6. Update world bible
      7. Add to prompt library

# ============================================================================
# WORLD BUILDING FRAMEWORKS
# ============================================================================
world_building_frameworks:
  character_sheet_template:
    sections:
      - identity: "Name, age, background, role in world"
      - physical: "Height, build, distinguishing features"
      - clothing: "Signature outfits, style rules"
      - personality: "3-5 core traits, values, fears"
      - expressions: "Neutral, happy, sad, surprised, angry"
      - poses: "Standing, sitting, walking, gesturing"
      - forbidden: "What character NEVER does/wears"
      - prompt_formula: "Base prompt for generation"

  environment_sheet_template:
    sections:
      - overview: "Name, role, atmosphere"
      - architecture: "Style, materials, scale"
      - lighting: "Time of day, source, temperature"
      - props: "Required elements, forbidden elements"
      - variations: "Different times, conditions"
      - prompt_formula: "Base prompt for generation"

  world_bible_structure:
    sections:
      - visual_foundation: "Colors, typography, textures, light"
      - character_system: "Main characters, archetypes, rules"
      - environment_system: "Key locations, architectural language"
      - interaction_rules: "How elements combine"
      - prompt_library: "Reusable prompts for generation"
      - exclusions: "What NEVER appears"
      - version_history: "Changes over time"

# ============================================================================
# VERSION COMPATIBILITY
# ============================================================================
version_compatibility:
  generation_models:
    midjourney: "v6+"
    flux: "Pro, Schnell"
    stable_diffusion: "SDXL, SD3"
    dall_e: "DALL-E 3"

  consistency_tools:
    ip_adapter: "Plus, FaceID"
    controlnet: "SDXL compatible"
    lora: "SDXL format"

  documentation:
    notion: "Current API"
    figma: "Current"
    gitbook: "Current"

  notes: |
    AI generation tools evolve rapidly.

    Key considerations:
    - New models may handle consistency differently
    - IP-Adapter and ControlNet versions matter
    - LoRA training requires version matching
    - Keep world bible tool-agnostic

    Current as of December 2024.
