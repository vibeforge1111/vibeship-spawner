# AI for Learning Sharp Edges

sharp_edges:
  - id: ai-hallucination
    summary: AI tutor gives wrong information
    severity: critical
    situation: Students receive incorrect information from AI
    why: |
      LLMs hallucinate.
      No verification layer.
      Students trust AI.
      Spreads misinformation.
    solution: |
      ## Preventing AI Hallucination

      ### Technical Mitigations
      | Technique | How |
      |-----------|-----|
      | RAG | Ground AI in course content |
      | Temperature | Lower = more conservative |
      | Guardrails | "Only discuss course topics" |
      | Uncertainty | "If unsure, say so" |

      ### Prompt Guardrails
      ```
      You are a tutor for [specific course].

      RULES:
      - Only answer questions within course scope
      - If uncertain, say "I'm not sure, let me connect you with the instructor"
      - Never make up facts
      - Cite specific lessons when possible
      ```

      ### Monitoring
      - Log all AI conversations
      - Sample and review regularly
      - Student report mechanism
      - Track "I don't know" frequency

      ### Recovery
      - Public correction if needed
      - Update AI with correction
      - Thank student for reporting
    symptoms:
      - Students confused by AI answers
      - Contradictions with course content
      - AI answering outside scope
      - Wrong facts cited
    detection_pattern: "AI said|but the lesson says|that's not right|confused by"

  - id: ai-dependency
    summary: Students over-rely on AI, don't learn
    severity: medium
    situation: Students use AI to do work instead of learning
    why: |
      AI is easier than thinking.
      No friction on AI use.
      Students want easy path.
      Assessment doesn't check real learning.
    solution: |
      ## Managing AI Dependency

      ### Design Against Dependency
      | Technique | Implementation |
      |-----------|----------------|
      | AI guides, doesn't answer | Socratic method prompts |
      | Delayed AI access | Learn first, AI later |
      | AI limits | X questions per day |
      | AI-free assessments | Proctored or oral exams |

      ### Socratic AI Prompts
      ```
      Don't give direct answers to exercises.
      Instead:
      - Ask clarifying questions
      - Give hints
      - Point to relevant lesson
      - Guide them to discover answer
      ```

      ### Progressive AI Access
      | Stage | AI Access |
      |-------|-----------|
      | First attempt | None |
      | Struggling | Hints only |
      | Stuck | Guided help |
      | Review | Full explanation |

      ### Verify Learning
      - Oral assessments
      - Live demonstrations
      - Explain-back requirements
      - Applied projects (not AI-able)
    symptoms:
      - Students not watching content
      - Going straight to AI
      - Can't answer without AI
      - Projects too perfect (AI-generated)
    detection_pattern: "just asked AI|didn't need to watch|AI did it|can you help without AI"

  - id: ai-cost-explosion
    summary: AI API costs grow unexpectedly
    severity: medium
    situation: AI usage costs exceed budget
    why: |
      Didn't anticipate usage.
      No rate limiting.
      Students using for everything.
      Expensive models.
    solution: |
      ## Controlling AI Costs

      ### Cost Management
      | Strategy | Implementation |
      |----------|----------------|
      | Rate limiting | X requests per student/day |
      | Model tiering | GPT-3.5 for simple, GPT-4 for complex |
      | Caching | Cache common questions |
      | Monitoring | Alerts at spend thresholds |

      ### Usage Limits
      - Free tier: 10 questions/day
      - Paid tier: 50 questions/day
      - Premium: Unlimited

      ### Cost Optimization
      | Approach | Savings |
      |----------|---------|
      | Smaller model | 10-30x cheaper |
      | Shorter prompts | Reduce token cost |
      | Caching FAQs | Avoid repeat calls |
      | Batch processing | Lower per-request cost |

      ### Budget Alerts
      - Daily spend monitoring
      - Alert at 50% of budget
      - Automatic throttling at 80%
      - Human review before increase
    symptoms:
      - Unexpected API bills
      - Costs growing faster than students
      - Some students using excessively
      - Budget exceeded
    detection_pattern: "api cost|bill|usage spike|too expensive"

  - id: ai-cheating
    summary: Students using AI for assessments dishonestly
    severity: high
    situation: Students submitting AI-generated work as their own
    why: |
      AI is accessible.
      Hard to detect.
      Temptation is high.
      Unclear policies.
    solution: |
      ## Addressing AI in Assessments

      ### Policy First
      - Clear AI policy in syllabus
      - What's allowed vs not allowed
      - Consequences defined
      - Student acknowledgment

      ### Assessment Design
      | Design | Why It Works |
      |--------|--------------|
      | Process-based | Show your work |
      | Personal experience | AI can't know your story |
      | Live assessment | Can't use AI in real-time |
      | Iterative | Track changes over time |

      ### Detection (Limited Value)
      - AI detection tools are unreliable
      - False positives hurt students
      - Better to design around it
      - Focus on learning, not catching

      ### Positive Framing
      - "AI is a tool, you're the thinker"
      - Teach AI literacy
      - Show AI limitations
      - Reward original thinking
    symptoms:
      - Submissions too polished
      - Inconsistent with student's voice
      - Perfect answers, can't explain
      - Sudden quality jumps
    detection_pattern: "did you use|is this AI|doesn't sound like|can you explain"
