# Collaboration - Game AI & NPC Behavior
# How this skill works with other specialists

skill_id: game-ai-behavior
version: "1.0.0"

collaboration:
  # ==========================================
  # INBOUND HANDOFFS - Receiving work from others
  # ==========================================

  receives_context_from:
    - skill: unity-development
      description: "Unity specialist hands off AI implementation needs"
      receives:
        - "Game design document with NPC requirements"
        - "Existing MonoBehaviour structure to extend"
        - "NavMesh setup and configuration"
        - "Animation controller states to coordinate with"
        - "Performance budget for AI (target frame time)"
      expected_state: |
        Project has basic Unity setup with NavMesh baked.
        Animation controllers exist but may need AI-driven transitions.
        Basic enemy prefabs created without AI logic.
      response_protocol: |
        1. Review existing NavMesh for coverage
        2. Analyze animation controller for needed states
        3. Design AI architecture (BT vs FSM vs Utility)
        4. Implement with proper Update throttling
        5. Add debug visualization (OnDrawGizmos)
        6. Document decision frequencies and update rates

    - skill: godot-development
      description: "Godot specialist hands off AI implementation needs"
      receives:
        - "Scene structure and node hierarchy"
        - "Navigation2D/Navigation3D setup"
        - "AnimationTree configuration"
        - "Signals already defined for game events"
        - "GDScript style preferences"
      expected_state: |
        Navigation nodes configured in scene.
        CharacterBody2D/3D nodes ready for AI control.
        Basic state machine may exist.
      response_protocol: |
        1. Use Godot's built-in navigation system
        2. Implement states as Node children (state pattern)
        3. Use signals for AI events (target_acquired, etc.)
        4. Leverage _physics_process for movement
        5. Add @export for tunable parameters

    - skill: unreal-engine
      description: "Unreal specialist hands off AI needs"
      receives:
        - "AI Controller and Pawn setup"
        - "Existing Behavior Tree assets"
        - "Blackboard key definitions"
        - "EQS query requirements"
        - "Perception component configuration"
      expected_state: |
        AI Controller bound to Pawn.
        Behavior Tree asset created (may be empty).
        Blackboard asset with basic keys.
      response_protocol: |
        1. Design BT using UE patterns (BTTask, BTService, BTDecorator)
        2. Define all needed Blackboard keys
        3. Create EQS queries for positioning
        4. Configure AIPerception component
        5. Use AIController methods for movement

    - skill: game-networking
      description: "Networking specialist needs AI determinism or authority model"
      receives:
        - "Network architecture (client-server, P2P)"
        - "Tick rate and update frequency"
        - "Authority model (server-auth, distributed)"
        - "Existing state sync patterns"
      expected_state: |
        Network foundation implemented.
        Need AI that doesn't cause desync.
      response_protocol: |
        1. Evaluate deterministic vs server-auth AI
        2. If deterministic: use seeded RNG, fixed timestep
        3. If server-auth: design state serialization
        4. Define what AI state needs syncing
        5. Consider prediction for responsive feel

    - skill: game-animation
      description: "Animation specialist needs AI-driven animation requirements"
      receives:
        - "Animation state machine structure"
        - "Blend tree configuration"
        - "Root motion usage patterns"
        - "Transition requirements"
      expected_state: |
        Animations exist but need AI triggers.
        Animation controller has placeholders.
      response_protocol: |
        1. Map AI states to animation states
        2. Define parameters AI will control
        3. Coordinate locomotion blend with steering
        4. Handle root motion authority
        5. Design interrupt/cancel behaviors

    - skill: performance-profiling
      description: "Performance specialist identifies AI bottleneck"
      receives:
        - "Profiler data showing AI hotspots"
        - "Frame budget allocation for AI"
        - "Specific methods identified as slow"
        - "Target platform constraints"
      expected_state: |
        Profiling done, AI identified as issue.
        Need optimization without breaking behavior.
      response_protocol: |
        1. Review identified hotspots
        2. Apply LOD to AI (distance-based complexity)
        3. Implement staggered updates
        4. Add async/threaded pathfinding
        5. Cache expensive calculations
        6. Verify behavior unchanged

  # ==========================================
  # OUTBOUND HANDOFFS - Delegating to others
  # ==========================================

  provides_context_to:
    - skill: unity-development
      description: "Hand back implemented AI for Unity integration"
      provides:
        - "AI component scripts (FSM, BT, or hybrid)"
        - "Required Blackboard/data structures"
        - "Update frequency and performance characteristics"
        - "Debug visualization components"
        - "ScriptableObject configs for tuning"
      handoff_format: |
        ## AI Implementation Complete

        ### Components Created
        - `EnemyAI.cs` - Main brain component
        - `AIBlackboard.cs` - Shared state container
        - `PatrolBehavior.cs`, `CombatBehavior.cs` - Subtrees

        ### Setup Instructions
        1. Add `EnemyAI` to enemy prefab
        2. Assign `AIConfig` ScriptableObject
        3. Ensure NavMeshAgent is on same GameObject
        4. Animator parameters: `Speed`, `InCombat`, `IsAiming`

        ### Performance Notes
        - Perception updates: 150ms interval, staggered
        - Path requests: async, max 3 per frame
        - Recommended max AI count: 30 active

    - skill: godot-development
      description: "Hand back implemented AI for Godot integration"
      provides:
        - "AI node structure (scenes)"
        - "GDScript files with state implementations"
        - "Signal definitions for events"
        - "Export variables for tuning"
      handoff_format: |
        ## AI Implementation Complete

        ### Scene Structure
        ```
        Enemy (CharacterBody3D)
        ├── AIBrain (Node) - enemy_brain.gd
        ├── StateMachine (Node)
        │   ├── IdleState
        │   ├── PatrolState
        │   └── CombatState
        ├── Perception (Area3D)
        └── NavigationAgent3D
        ```

        ### Signals Emitted
        - `target_acquired(target: Node3D)`
        - `target_lost()`
        - `state_changed(old: String, new: String)`

    - skill: unreal-engine
      description: "Hand back implemented AI for Unreal integration"
      provides:
        - "Behavior Tree design document"
        - "Blackboard key specifications"
        - "C++ BTTask/BTService classes"
        - "EQS query descriptions"
        - "AIPerception configuration"
      handoff_format: |
        ## AI Implementation Complete

        ### Behavior Tree Structure
        ```
        Root
        ├── Selector [Combat Priority]
        │   ├── Sequence [Attack]
        │   │   ├── HasValidTarget (Decorator)
        │   │   ├── BTTask_MoveToTarget
        │   │   └── BTTask_Attack
        │   └── Sequence [Search]
        │       ├── HasLastKnownLocation (Decorator)
        │       └── BTTask_InvestigateLocation
        └── BTTask_Patrol (with BTService_UpdatePerception)
        ```

        ### Blackboard Keys
        | Key | Type | Description |
        |-----|------|-------------|
        | TargetActor | Object | Current target reference |
        | LastKnownLocation | Vector | Where target was last seen |
        | AlertLevel | Float | 0-1 awareness |

    - skill: game-networking
      description: "Hand off networking requirements for AI sync"
      provides:
        - "AI state that needs synchronization"
        - "Update frequency recommendations"
        - "Determinism requirements (if applicable)"
        - "Interpolation/prediction hints"
      handoff_format: |
        ## AI Networking Requirements

        ### Synchronized State
        - Position: Every tick (interpolate on clients)
        - Target ID: On change only
        - Current State: On change only
        - Health: On change only

        ### Authority Model Recommendation
        Server-authoritative AI recommended because:
        - Complex perception system
        - Non-trivial pathfinding
        - Avoids determinism complexity

        ### Prediction Notes
        Clients can predict position using current velocity.
        State changes should not be predicted.

    - skill: game-animation
      description: "Hand off animation requirements from AI"
      provides:
        - "AI states that need animation support"
        - "Parameters AI will drive"
        - "Transition timing requirements"
        - "Interrupt scenarios"
      handoff_format: |
        ## Animation Integration Requirements

        ### Parameters AI Controls
        | Parameter | Type | Range | AI State |
        |-----------|------|-------|----------|
        | Speed | Float | 0-1 | From velocity |
        | InCombat | Bool | - | Combat states |
        | AttackTrigger | Trigger | - | Attack action |
        | HitReaction | Int | 0-3 | Direction of hit |

        ### Critical Transitions
        - Idle -> Combat: immediate, AI sets InCombat=true
        - Any -> HitReaction: interrupt current, AI triggers
        - Attack startup: 0.3s, AI must wait for window

    - skill: performance-profiling
      description: "Request performance analysis of AI"
      provides:
        - "AI architecture description"
        - "Known expensive operations"
        - "Current update frequencies"
        - "Expected AI count at peak"
      handoff_format: |
        ## AI Performance Analysis Request

        ### Current Architecture
        - Behavior Tree with 4 major subtrees
        - A* pathfinding (custom implementation)
        - Staggered perception (150ms, 50 AI means 333/sec)
        - Utility scoring for target selection

        ### Suspected Bottlenecks
        1. Pathfinding - async but may overwhelm queue
        2. Perception raycasts - up to 50 per AI per check
        3. Cover point scoring - iterates all cover points

        ### Target Metrics
        - 50 active AI simultaneously
        - AI budget: 4ms per frame
        - Current measured: ~6ms (need 33% reduction)

  # ==========================================
  # COORDINATION PATTERNS
  # ==========================================

  coordination_patterns:
    unity_ai_integration:
      description: "Standard Unity AI integration flow"
      sequence:
        - step: 1
          skill: unity-development
          action: "Create enemy prefab with NavMeshAgent, Animator"
        - step: 2
          skill: game-ai-behavior
          action: "Implement AI brain, states, perception"
        - step: 3
          skill: game-animation
          action: "Connect animator parameters to AI states"
        - step: 4
          skill: performance-profiling
          action: "Profile with target AI count"
        - step: 5
          skill: game-ai-behavior
          action: "Optimize based on profiling"

    multiplayer_ai:
      description: "Multiplayer-aware AI implementation"
      sequence:
        - step: 1
          skill: game-networking
          action: "Define authority model and sync requirements"
        - step: 2
          skill: game-ai-behavior
          action: "Implement AI with determinism/authority in mind"
        - step: 3
          skill: game-networking
          action: "Implement state synchronization"
        - step: 4
          skill: game-ai-behavior
          action: "Tune for network latency"

    boss_ai_development:
      description: "Complex boss AI with heavy animation"
      sequence:
        - step: 1
          skill: game-ai-behavior
          action: "Design phase-based behavior tree"
        - step: 2
          skill: game-animation
          action: "Create complex attack animations with timing"
        - step: 3
          skill: game-ai-behavior
          action: "Integrate timing windows, telegraph attacks"
        - step: 4
          skill: performance-profiling
          action: "Ensure single boss AI doesn't spike"

  # ==========================================
  # BOUNDARY DEFINITIONS
  # ==========================================

  boundaries:
    owns:
      - "AI decision-making architecture (BT, FSM, GOAP, Utility)"
      - "Pathfinding algorithm selection and implementation"
      - "Steering behavior design and tuning"
      - "Perception system architecture"
      - "Tactical positioning and cover systems"
      - "AI debugging and visualization tools"
      - "Blackboard and knowledge representation"
      - "AI performance budgeting and LOD"

    delegates:
      - area: "Engine-specific implementation details"
        to: ["unity-development", "godot-development", "unreal-engine"]
        example: "Unity coroutines, Godot signals, UE EQS syntax"

      - area: "Network synchronization of AI state"
        to: ["game-networking"]
        example: "How to serialize AI state, authority model"

      - area: "Animation system integration"
        to: ["game-animation"]
        example: "Animation controller setup, blend trees, root motion"

      - area: "Performance profiling and metrics"
        to: ["performance-profiling"]
        example: "Identifying specific bottlenecks, measuring improvements"

      - area: "Overall game design and balancing"
        to: ["game-design"]
        example: "How difficult AI should be, enemy variety"

    shared_responsibilities:
      - area: "AI-Animation coordination"
        with: "game-animation"
        boundary: "AI defines WHAT to animate, Animation defines HOW"

      - area: "AI networking"
        with: "game-networking"
        boundary: "AI defines state model, Networking handles sync"

      - area: "Performance optimization"
        with: "performance-profiling"
        boundary: "AI implements fixes, Profiling measures impact"

  # ==========================================
  # CONFLICT RESOLUTION
  # ==========================================

  conflict_resolution:
    animation_vs_ai_timing:
      conflict: "AI wants instant state change but animation needs time"
      resolution: |
        Animation timing takes priority for responsiveness.
        AI must:
        1. Wait for animation windows
        2. Use animation events for state changes
        3. Cache intended actions during animation

    network_vs_ai_complexity:
      conflict: "Sophisticated AI vs network bandwidth/determinism"
      resolution: |
        Network constraints take priority.
        Options in order of preference:
        1. Run AI on server only (most complex AI allowed)
        2. Simplified deterministic AI on clients
        3. Hybrid: server AI, client prediction

    performance_vs_ai_quality:
      conflict: "Beautiful AI vs frame budget"
      resolution: |
        Frame budget is hard constraint.
        AI must implement LOD:
        1. Full AI for nearby/important enemies
        2. Simplified AI for distant enemies
        3. Disable AI for off-screen enemies
