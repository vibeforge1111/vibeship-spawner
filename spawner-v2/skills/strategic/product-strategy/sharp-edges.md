# Sharp Edges: Product Strategy

These are the brutal truths that kill products. Each edge represents millions of dollars in failed startups and careers derailed by avoidable mistakes.

---

## 1. The "Build It And They Will Come" Delusion

**Severity:** Critical

**The Trap:**
You have a brilliant idea. The technology is elegant. You spend 6 months building it in stealth mode. You launch to crickets. Nobody cares.

**Why It Happens:**
Founders fall in love with their solution before validating the problem. They assume their own pain is universal. They build in isolation because they fear someone will "steal the idea." They confuse technical innovation with market need.

**The Fix:**
Talk to 50+ potential customers before writing a line of code. Use the Mom Test - ask about their life, not your idea. Look for existing workarounds (spreadsheets, manual processes, duct-tape solutions). If people aren't actively trying to solve this problem with bad solutions, they won't pay for your good one.

**Detection Pattern:**
- "We'll validate after we build the MVP"
- "The product will sell itself"
- "We're in stealth mode"
- No customer interviews documented
- Features defined without customer input

---

## 2. The Feature Factory Trap

**Severity:** Critical

**The Trap:**
Your roadmap is a list of features. Success is measured by shipping. Customers request features and you build them. Your product becomes bloated, unfocused, and indistinguishable from competitors.

**Why It Happens:**
Features are easy to measure. Sales teams bring feature requests from prospects. Competitors ship features and you feel pressure to match. Nobody asks "what outcome does this drive?" Building feels like progress.

**The Fix:**
Shift from output to outcome. Every feature must tie to a measurable user outcome and business metric. Use the "Will this make the product 10x better at its core job?" test. Say no to 90% of feature requests. Remember: a focused product that does one thing brilliantly beats a bloated product that does everything poorly.

**Detection Pattern:**
- Roadmap is a feature list without outcomes
- "Competitors have X, we need X"
- Success measured in features shipped
- No kill criteria for features
- PRDs describe what, not why

---

## 3. The "More Data" Procrastination

**Severity:** High

**The Trap:**
You run survey after survey. You do 100 customer interviews. You analyze the market exhaustively. You build elaborate spreadsheets. You never ship anything because you're "still validating."

**Why It Happens:**
Research feels like progress without the risk of failure. There's always one more question to answer. Analysis paralysis disguises itself as rigor. Fear of being wrong masquerades as thoroughness.

**The Fix:**
Set a hard deadline for decision-making. After 20-30 interviews, you have enough signal. Use the "Disagree and Commit" principle. Build the smallest thing that could test your riskiest assumption. Real learning comes from market contact, not research.

**Detection Pattern:**
- "We need more data before deciding"
- Validation phase extending beyond 4-6 weeks
- Multiple pivots based on research alone
- No time-boxed experiments
- Perfect information seeking

---

## 4. The "We're Different" Blindness

**Severity:** High

**The Trap:**
You dismiss competitors because "we're different." You believe your approach is unique and therefore competition doesn't apply. Meanwhile, customers see you as yet another option in a crowded market.

**Why It Happens:**
Founders are too close to see from customer's perspective. Technical differences feel significant from inside but invisible from outside. Optimism bias makes us underweight competitive threats.

**The Fix:**
Do the "Screenshot Test" - put your landing page next to 5 competitors. If a customer can't immediately see why you're different, you're not. Define your category or be defined by it. Your differentiation must be obvious in 5 seconds, not explained in 5 minutes.

**Detection Pattern:**
- "Our competitors don't really compete with us"
- Differentiation requires explanation
- Feature comparison shows similarity
- No clear category ownership
- Positioning by features, not outcomes

---

## 5. The Premature Scaling Death Spiral

**Severity:** Critical

**The Trap:**
You get early traction - a few paying customers, some press, maybe funding. You hire aggressively, build out the product, scale marketing. Then you realize you didn't actually have product-market fit. You had early adopter curiosity.

**Why It Happens:**
Pressure from investors to show growth. Early success creates false confidence. Hiring feels like progress. The difference between "some people want this" and "the market wants this" is subtle but fatal.

**The Fix:**
Define PMF metrics before scaling: 40%+ would be "very disappointed" without your product, organic word-of-mouth growth, low churn, customers expanding usage unprompted. Don't scale until these metrics are hit. Growth before PMF is pouring water into a leaky bucket.

**Detection Pattern:**
- Scaling before clear retention metrics
- High CAC with unclear LTV
- "Growth will solve our problems"
- Hiring ahead of validated demand
- Churn > 5% monthly for B2B, > 10% for B2C

---

## 6. The "Everyone Is Our Customer" Trap

**Severity:** High

**The Trap:**
Your target market is "anyone who needs X." You're afraid to narrow because you might miss opportunities. Your messaging is generic. Your product tries to serve everyone and delights no one.

**Why It Happens:**
Narrowing feels like leaving money on the table. Investors want big TAM numbers. "Small" markets feel limiting. We optimize for not missing anyone rather than deeply serving someone.

**The Fix:**
Start with the smallest viable market that can sustain your business. Be the only solution for someone rather than an option for everyone. Use Geoffrey Moore's targeting: specific person, specific situation, specific problem. You can expand later; you can't un-dilute focus.

**Detection Pattern:**
- Target market described as broad demographic
- "Our TAM is $X billion"
- Messaging uses generic value props
- No clear ideal customer profile (ICP)
- Features designed for "users" not specific personas

---

## 7. The Solution-First Backwards Build

**Severity:** High

**The Trap:**
You start with technology ("We'll use AI to...") or solution ("An app that lets you...") instead of problem. You retrofit problems to justify your solution. The problem you solve isn't the problem customers care about.

**Why It Happens:**
Solutions are exciting; problems are boring. Technology capabilities inspire ideas. We pattern-match from what's possible, not what's needed. "Build something cool" is more fun than "understand deep pain."

**The Fix:**
Force yourself to articulate the problem without mentioning your solution. Use the "5 Whys" to get to root cause. Interview customers about their workflow without mentioning what you're building. If you can't describe the problem in their words, you don't understand it.

**Detection Pattern:**
- Pitch starts with solution or technology
- Problem statement uses your terminology
- Customers don't recognize problem description
- "Looking for a problem" for your tech
- Features before use cases

---

## 8. The Feedback Whiplash

**Severity:** Medium

**The Trap:**
Every customer interview sends you in a new direction. Negative feedback triggers pivots. You oscillate between strategies based on the last conversation. Your product becomes a Frankenstein of different visions.

**Why It Happens:**
Individual feedback feels compelling in the moment. We want to be responsive. Pattern recognition across feedback is hard. Confirmation bias makes us overweight feedback that matches our fears.

**The Fix:**
Collect feedback in batches before acting. Look for patterns across 10+ conversations. Distinguish between feedback on execution vs. strategy. Create a "feedback parking lot" - log it, but don't act until you see patterns. One person's opinion is an anecdote; ten people's pattern is data.

**Detection Pattern:**
- Strategy changes after single conversations
- Product direction unclear to team
- Multiple pivots in short timeframe
- No documented feedback synthesis
- Acting on outlier opinions

---

## 9. The Vanity Metrics Mirage

**Severity:** High

**The Trap:**
Your dashboard shows growing users, downloads, pageviews, or followers. You celebrate these wins. But revenue is flat, retention is poor, and engagement is shallow. You're measuring activity, not value.

**Why It Happens:**
Vanity metrics go up and to the right - they feel good. Real metrics (retention, NPS, revenue per user) are harder and often embarrassing. We report what looks good, not what matters.

**The Fix:**
Define your One Metric That Matters (OMTM) - the single number that indicates product health. For most products: weekly active users who complete core action, or monthly retention. If users aren't coming back unprompted and doing the core thing repeatedly, nothing else matters.

**Detection Pattern:**
- Celebrating signups without activation
- No cohort retention analysis
- Engagement metrics without depth (opens vs. completes)
- Revenue growth without unit economics
- "Users" counted without defining active

---

## 10. The "V2 Will Fix It" Denial

**Severity:** High

**The Trap:**
Early users complain about core issues. You acknowledge but say "we'll fix it in V2." You keep building new features instead of fixing fundamentals. V2 never comes because you're always chasing growth.

**Why It Happens:**
New features are more exciting than fixing old problems. The backlog grows faster than you can address it. Core issues feel expensive to fix. There's always pressure to ship something new.

**The Fix:**
If something is broken in your core flow, stop everything until it's fixed. Technical debt and UX debt compound like financial debt. A product that does one thing flawlessly beats a product with ten features that all kind of work. "V2 will fix it" is the biggest lie in product.

**Detection Pattern:**
- Known issues in core flow unfixed for months
- "We'll fix it later" in sprint notes
- New features shipping while fundamentals broken
- Growing list of "known issues"
- User complaints about same issues over time

---

## 11. The Copycat Deathmatch

**Severity:** High

**The Trap:**
You see a successful product and build a "better" version. You copy their features but add your twist. You enter a crowded market hoping to out-execute. You find yourself in a features arms race with no differentiation.

**Why It Happens:**
Validated markets feel safer than new ones. "X but better" is an easy pitch. Copying reduces research burden. We underestimate incumbent advantages (brand, distribution, network effects).

**The Fix:**
Compete on a dimension incumbents can't or won't. Find the underserved segment the leader ignores. Change the game entirely rather than playing better. Ask: "What can I be the only one doing?" not "What can I do better?"

**Detection Pattern:**
- Product described as "X but better"
- Feature roadmap mirrors competitor
- No clear segment ownership
- Competing on price or features alone
- Incumbent could easily copy your differentiation

---

## 12. The "Users Don't Know What They Want" Excuse

**Severity:** Medium

**The Trap:**
You invoke the Jobs/Ford quote about customers not asking for cars/iPods to justify ignoring feedback. You believe your vision is superior to user input. You build what you think they need, not what they demonstrate they need.

**Why It Happens:**
The quote is misunderstood. It's easier to trust your instinct than synthesize feedback. Some founders have been right ignoring feedback (survivorship bias). User feedback requires interpretation, not literal implementation.

**The Fix:**
Users don't know what solution they want - they DO know what problems they have. Your job is understanding the problem deeply enough to invent the right solution. Jobs spent thousands of hours understanding user behavior before inventing. The iPod came from seeing people's relationship with music, not ignoring their input.

**Detection Pattern:**
- Dismissing feedback as "users don't get it"
- No customer behavior observation
- Building based on internal intuition alone
- Surprise when users don't adopt features
- "They'll understand when they see it"
