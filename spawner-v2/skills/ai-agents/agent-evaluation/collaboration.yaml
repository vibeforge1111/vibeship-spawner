id: agent-evaluation-collaboration
skill: agent-evaluation
version: 1.0.0

receives_from:
  - skill: autonomous-agents
    context: "Agent needs testing"
    receives:
      - "Agent implementation"
      - "Expected behaviors"
      - "Use case descriptions"
    provides: "Evaluation results and recommendations"

  - skill: multi-agent-orchestration
    context: "Multi-agent system needs evaluation"
    receives:
      - "System architecture"
      - "Agent interactions"
      - "Performance requirements"
    provides: "System-level evaluation and bottleneck analysis"

  - skill: agent-communication
    context: "Communication layer needs testing"
    receives:
      - "Message protocols"
      - "Expected patterns"
    provides: "Communication reliability metrics"

delegation_triggers:
  - trigger: "implement|fix|improve"
    delegate_to: autonomous-agents
    pattern: sequential
    context: "Need to fix issues found in evaluation"

  - trigger: "orchestration|coordination"
    delegate_to: multi-agent-orchestration
    pattern: sequential
    context: "Need to evaluate orchestration patterns"

  - trigger: "communication|message"
    delegate_to: agent-communication
    pattern: sequential
    context: "Need to evaluate communication"

feedback_loops:
  receives_feedback_from:
    - skill: autonomous-agents
      signal: "Agent updated based on evaluation"
      action: "Re-run evaluation suite"

    - skill: multi-agent-orchestration
      signal: "System changes made"
      action: "Update system-level tests"

  sends_feedback_to:
    - skill: autonomous-agents
      signal: "Failure patterns and improvements needed"
      action: "Guide agent development"

    - skill: multi-agent-orchestration
      signal: "Bottlenecks and coordination issues"
      action: "Inform architecture decisions"

    - skill: agent-communication
      signal: "Communication failures"
      action: "Improve protocol reliability"

cross_domain_insights:
  from_domains:
    - domain: software-testing
      insight: "Test pyramid applies to agents too"
      application: "Unit tests for components, integration for agents, E2E for systems"

    - domain: statistics
      insight: "Hypothesis testing for stochastic systems"
      application: "Statistical methods for agent evaluation"

    - domain: ml-evaluation
      insight: "Train/test split and cross-validation"
      application: "Ensure evaluation data is independent"

common_combinations:
  - name: Complete Agent Development Cycle
    skills:
      - agent-evaluation
      - autonomous-agents
      - multi-agent-orchestration
    workflow: |
      1. Design agent with testability in mind
      2. Create evaluation suite before implementation
      3. Implement agent
      4. Evaluate against suite
      5. Iterate based on results

  - name: Production Agent Monitoring
    skills:
      - agent-evaluation
      - llm-security-audit
    workflow: |
      1. Establish baseline metrics
      2. Deploy with monitoring
      3. Continuous evaluation in production
      4. Alert on regression

  - name: Multi-Agent System Evaluation
    skills:
      - agent-evaluation
      - multi-agent-orchestration
      - agent-communication
    workflow: |
      1. Evaluate individual agents
      2. Evaluate communication reliability
      3. Evaluate end-to-end system
      4. Load testing for scalability
