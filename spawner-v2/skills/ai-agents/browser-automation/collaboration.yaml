# Collaboration - Browser Automation
# How this skill works with other skills

version: 1.0.0
skill_id: browser-automation

prerequisites:
  required: []

  recommended:
    - skill: backend
      reason: "Understanding async/await patterns"
      what_to_know:
        - "Promise handling"
        - "Error propagation"
        - "Resource cleanup patterns"

    - skill: test-architect
      reason: "Testing strategy and patterns"
      what_to_know:
        - "Test isolation principles"
        - "Fixture patterns"
        - "CI/CD integration"

    - skill: devops
      reason: "Deploying browser automation"
      what_to_know:
        - "Docker containers for headless browsers"
        - "CI runner configuration"
        - "Resource allocation"

delegation_triggers:
  - trigger: "user needs full desktop control beyond browser"
    delegate_to: computer-use-agents
    context: "Desktop automation for non-browser apps"

  - trigger: "user needs API testing alongside browser tests"
    delegate_to: backend
    context: "API integration and testing patterns"

  - trigger: "user needs testing strategy"
    delegate_to: test-architect
    context: "Overall test architecture decisions"

  - trigger: "user needs visual regression testing"
    delegate_to: ui-design
    context: "Visual comparison and design validation"

  - trigger: "user needs browser automation in workflows"
    delegate_to: workflow-automation
    context: "Durable execution for browser tasks"

  - trigger: "user building browser tools for agents"
    delegate_to: agent-tool-builder
    context: "Tool design patterns for LLM agents"

receives_context_from:
  - skill: agent-tool-builder
    receives:
      - "Requirements for browser-based tools"
      - "Tool interface specifications"
      - "Error handling requirements"

  - skill: workflow-automation
    receives:
      - "Browser steps within workflows"
      - "Retry requirements for browser tasks"
      - "Timeout constraints"

  - skill: test-architect
    receives:
      - "Test strategy and coverage goals"
      - "CI/CD pipeline requirements"
      - "Cross-browser testing needs"

  - skill: product-strategy
    receives:
      - "Critical user flows to test"
      - "Supported browser matrix"
      - "Mobile requirements"

provides_context_to:
  - skill: computer-use-agents
    provides:
      - "Browser interaction patterns"
      - "When browser-only vs full desktop"
      - "Selenium/Playwright handoff points"

  - skill: workflow-automation
    provides:
      - "Browser steps for workflow execution"
      - "Error handling for browser failures"
      - "Screenshot artifacts"

  - skill: agent-tool-builder
    provides:
      - "Browser tools implementation"
      - "Page interaction methods"
      - "Content extraction patterns"

  - skill: devops
    provides:
      - "Browser binary requirements"
      - "Docker configuration for headless"
      - "CI resource needs"

escalation_paths:
  - situation: "Bot detection blocking scraping"
    escalate_to: security-specialist
    context: "Anti-detection strategies, ethical considerations"

  - situation: "Browser automation performance issues"
    escalate_to: performance-thinker
    context: "Parallel execution, resource optimization"

  - situation: "Flaky tests in CI"
    escalate_to: devops
    context: "CI environment configuration, resource allocation"

  - situation: "Accessibility testing requirements"
    escalate_to: accessibility-specialist
    context: "ARIA, screen reader compatibility testing"

  - situation: "Mobile browser testing"
    escalate_to: mobile-specialist
    context: "Device emulation, real device testing"

workflow_integration:
  typical_sequence:
    1:
      step: "Define testing/scraping requirements"
      skills: [test-architect, product-strategy]
      output: "What needs to be automated and why"

    2:
      step: "Choose framework and approach"
      skills: [browser-automation]
      output: "Playwright vs Puppeteer, headed vs headless"

    3:
      step: "Implement automation"
      skills: [browser-automation, backend]
      output: "Working automation code"

    4:
      step: "Configure CI/CD"
      skills: [devops]
      output: "Automated runs in pipeline"

    5:
      step: "Handle failures"
      skills: [browser-automation, workflow-automation]
      output: "Retry logic, alerting, recovery"

  decision_points:
    - question: "Playwright or Puppeteer?"
      guidance: |
        Use Playwright when:
        - Cross-browser testing needed (Chromium, Firefox, WebKit)
        - Non-JavaScript team (Python, C#, Java support)
        - Auto-waiting is important
        - Parallel testing at scale
        - Best overall choice for new projects

        Use Puppeteer when:
        - Chrome-only is sufficient
        - Need puppeteer-extra-plugin-stealth for anti-detection
        - Existing Puppeteer codebase
        - Simpler API preferred

    - question: "Headless or headed mode?"
      guidance: |
        Use headless:
        - CI/CD pipelines (default)
        - High-volume automation
        - Server/container environments
        - Production scraping

        Use headed:
        - Local debugging
        - Initial development
        - Watching test execution
        - Verifying visual behavior

    - question: "Browser contexts or browser instances?"
      guidance: |
        Browser contexts (preferred):
        - Lightweight, fast to create
        - Share browser process, isolated state
        - 10 contexts use ~800MB
        - Use for parallel test isolation

        Browser instances:
        - Full process isolation
        - Different browser args per instance
        - Higher resource cost
        - 10 instances use ~1.5GB+

    - question: "Testing vs scraping approach?"
      guidance: |
        Testing (your own app):
        - Use data-testid for stable selectors
        - Trust page behavior (it's your code)
        - No anti-detection needed
        - Focus on assertions and coverage

        Scraping (external sites):
        - Prepare for detection avoidance
        - Handle site structure changes
        - Add delays and rate limiting
        - Capture errors gracefully
        - Respect robots.txt

collaboration_patterns:
  with_testing:
    when: "E2E testing strategy"
    approach: |
      - Use Page Object pattern for maintainability
      - Separate test data from test logic
      - Run smoke tests on every commit
      - Full suite on staging before deploy
      - Traces and videos for debugging

      Example structure:
      tests/
        e2e/
          pages/           # Page Objects
          fixtures/        # Test data
          specs/           # Test files
        playwright.config.ts

  with_scraping:
    when: "Web scraping projects"
    approach: |
      - Stealth first (puppeteer-extra or playwright-extra)
      - Rotate proxies for high-volume
      - Save screenshots on failure
      - Implement retry with backoff
      - Log everything for debugging

      - Ethical considerations:
        - Respect robots.txt
        - Don't overload target servers
        - Check terms of service
        - Consider API alternatives

  with_agents:
    when: "Browser tools for AI agents"
    approach: |
      - Create focused, single-purpose tools
      - Return structured data, not raw HTML
      - Include error details in responses
      - Capture screenshots for visual context
      - Handle timeouts gracefully

      Example tool:
      async function searchWeb(query: string): Promise<SearchResult[]> {
        const page = await context.newPage();
        try {
          await page.goto(`https://search.example.com?q=${query}`);
          return await extractResults(page);
        } finally {
          await page.close();
        }
      }

  with_workflows:
    when: "Browser steps in durable workflows"
    approach: |
      - Each browser action is a workflow step
      - Capture state between steps (URLs, cookies)
      - Handle step failures with retry
      - Close browser on workflow completion

      Example:
      await step.run("scrape-product", async () => {
        const context = await browser.newContext({
          storageState: previousStep.cookies
        });
        const page = await context.newPage();

        await page.goto(productUrl);
        const data = await extractProduct(page);

        await context.close();
        return data;
      });

platform_specifics:
  playwright:
    best_for:
      - "Cross-browser testing"
      - "Teams with non-JS developers"
      - "Parallel testing at scale"
      - "Best overall developer experience"
    setup: |
      npm init playwright@latest
      # or
      npx playwright install
    run: |
      npx playwright test
      npx playwright test --headed --debug
      npx playwright show-report

  puppeteer:
    best_for:
      - "Chrome-only automation"
      - "Anti-detection with stealth plugin"
      - "Existing Node.js scraping"
    setup: |
      npm install puppeteer puppeteer-extra puppeteer-extra-plugin-stealth
    considerations:
      - "No auto-waiting - use waitForSelector"
      - "Chrome binary downloads on install"
      - "Memory usage higher than Playwright"

  browserbase:
    best_for:
      - "Managed browser infrastructure"
      - "Built-in stealth mode"
      - "Session management"
    when_to_use: |
      - High-volume scraping
      - Need reliable anti-detection
      - Don't want to manage browser infrastructure
      - Complex session/cookie management

ci_integration:
  github_actions: |
    - name: Install Playwright
      run: npx playwright install --with-deps

    - name: Run tests
      run: npx playwright test

    - uses: actions/upload-artifact@v3
      if: failure()
      with:
        name: playwright-report
        path: playwright-report/

  docker: |
    FROM mcr.microsoft.com/playwright:v1.40.0-jammy

    WORKDIR /app
    COPY package*.json ./
    RUN npm ci
    COPY . .

    CMD ["npx", "playwright", "test"]
