id: quantitative-research
skill: Quantitative Research
version: "1.0"

receives_context_from:
  - skill: technical-analysis
    receives:
      - Pattern definitions to test
      - Historical signal data
      - Technical indicator formulas
    provides:
      - Statistical validation of patterns
      - Expected win rate and edge
      - Optimal parameter ranges

  - skill: sentiment-analysis-trading
    receives:
      - Sentiment signal time series
      - News event data
      - Social metrics
    provides:
      - Sentiment factor construction
      - Alpha contribution analysis
      - Optimal signal combination

  - skill: risk-management-trading
    receives:
      - Risk constraints
      - Position sizing requirements
      - Portfolio limitations
    provides:
      - Strategy statistics (Sharpe, drawdown)
      - Capacity estimates
      - Risk-adjusted returns

  - skill: execution-algorithms
    receives:
      - Execution quality data
      - Realized slippage statistics
      - Fill rate analysis
    provides:
      - Backtest cost assumptions
      - Turnover optimization
      - Execution-aware signal design

delegation_triggers:
  - pattern: "risk|position.*size|drawdown|stop.*loss"
    delegate_to: risk-management-trading
    context: "Apply risk management to validated strategy"

  - pattern: "execute|implement|live|production"
    delegate_to: execution-algorithms
    context: "Optimize execution for researched strategy"

  - pattern: "sentiment|news|social|alternative.*data"
    delegate_to: sentiment-analysis-trading
    context: "Need sentiment data for alpha research"

  - pattern: "chart|pattern|technical|indicator"
    delegate_to: technical-analysis
    context: "Need technical signals to test"

  - pattern: "emotion|discipline|psychology"
    delegate_to: trading-psychology
    context: "Psychological factors affecting research"

common_combinations:
  - name: Complete Strategy Development
    skills:
      - quantitative-research
      - technical-analysis
      - risk-management-trading
    workflow: |
      1. Define hypothesis from technical patterns (technical-analysis)
      2. Backtest and validate statistically (quantitative-research)
      3. Apply position sizing and risk rules (risk-management-trading)

  - name: Alternative Data Alpha
    skills:
      - quantitative-research
      - sentiment-analysis-trading
      - execution-algorithms
    workflow: |
      1. Generate sentiment signals (sentiment-analysis-trading)
      2. Validate alpha and build factors (quantitative-research)
      3. Design execution for signal decay (execution-algorithms)

  - name: Production Strategy Pipeline
    skills:
      - quantitative-research
      - risk-management-trading
      - execution-algorithms
    workflow: |
      1. Validate strategy robustness (quantitative-research)
      2. Define risk parameters (risk-management-trading)
      3. Implement execution logic (execution-algorithms)

cross_domain_insights:
  - domain: Scientific Method
    insight: Hypothesis → Test → Validate → Reproduce
    application: Pre-register hypotheses, use holdout data, require replication

  - domain: Clinical Trials
    insight: Double-blind, placebo-controlled, large sample
    application: Out-of-sample testing, benchmark comparison, statistical power

  - domain: Epidemiology
    insight: Correlation vs causation, confounding variables
    application: Factor adjustment, spurious correlation detection

  - domain: Engineering
    insight: Safety margins, worst-case design
    application: Conservative assumptions, stress testing

  - domain: Physics
    insight: Parsimony - simplest explanation preferred
    application: Fewer parameters, simpler models, Occam's razor

ecosystem_alternatives:
  backtesting_frameworks:
    - name: VectorBT
      when: Fast vectorized backtesting, quick iteration
      tradeoff: Different paradigm than event-driven
    - name: Backtrader
      when: Event-driven, realistic simulation
      tradeoff: Slower execution
    - name: QuantConnect
      when: Cloud-based, multiple assets
      tradeoff: Learning curve, vendor lock-in
    - name: Zipline
      when: Quantopian-style, educational
      tradeoff: Less maintained

  statistical_tools:
    - name: Statsmodels
      when: Classical statistics, econometrics
      tradeoff: Less ML integration
    - name: Scipy
      when: Basic statistics, hypothesis testing
      tradeoff: Limited financial-specific tools
    - name: TA-Lib
      when: Technical indicator calculations
      tradeoff: Limited to common indicators

  data_sources:
    - name: Yahoo Finance (yfinance)
      when: Free, quick prototyping
      tradeoff: Survivorship bias, limited history
    - name: Alpha Vantage
      when: Free API, reasonable quality
      tradeoff: Rate limits
    - name: Polygon
      when: Professional quality, reasonable cost
      tradeoff: Monthly fee
    - name: FactSet/Bloomberg
      when: Institutional quality, point-in-time
      tradeoff: Very expensive

feedback_loops:
  - from: risk-management-trading
    incorporates:
      - Live strategy performance
      - Drawdown analysis
      - Position sizing outcomes
    into: Backtest assumptions and validation criteria

  - from: execution-algorithms
    incorporates:
      - Realized slippage data
      - Execution quality metrics
      - Fill rate statistics
    into: Transaction cost modeling

  - from: sentiment-analysis-trading
    incorporates:
      - New alternative data sources
      - Sentiment factor performance
      - Signal decay analysis
    into: Alpha research pipeline

prerequisites:
  required_knowledge:
    - Statistics (hypothesis testing, regression)
    - Python (pandas, numpy, statsmodels)
    - Basic finance (returns, Sharpe, drawdown)
    - Probability theory

  recommended_tools:
    - Python 3.8+
    - Jupyter Lab
    - pandas, numpy, scipy, statsmodels
    - Backtesting framework (vectorbt or backtrader)

  environment_setup: |
    # Python quantitative research setup
    pip install pandas numpy scipy statsmodels
    pip install vectorbt yfinance ta-lib
    pip install matplotlib seaborn plotly
    pip install scikit-learn hmmlearn

    # Basic research template
    import pandas as pd
    import numpy as np
    from scipy import stats
    import yfinance as yf

    # Download data
    data = yf.download(['SPY', 'QQQ', 'IWM'], period='10y', interval='1d')
    prices = data['Adj Close']
    returns = prices.pct_change().dropna()

    # Calculate basic metrics
    def sharpe_ratio(returns, rf=0.0):
        excess = returns - rf/252
        return excess.mean() / excess.std() * np.sqrt(252)

    def max_drawdown(returns):
        cumulative = (1 + returns).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = cumulative / running_max - 1
        return drawdown.min()

    # Example analysis
    for col in returns.columns:
        print(f"{col}:")
        print(f"  Sharpe: {sharpe_ratio(returns[col]):.2f}")
        print(f"  Max DD: {max_drawdown(returns[col]):.2%}")
