id: risk-management-trading
skill: Risk Management for Trading
version: "1.0"

sharp_edges:
  - id: drawdown-recovery-math
    severity: CRITICAL
    title: Drawdown Recovery Is Exponentially Harder
    description: The math of recovery makes large drawdowns nearly impossible to overcome
    symptoms:
      - Account stuck in drawdown for months/years
      - Unrealistic recovery expectations
      - Emotional trading to "get back to even"
    detection_pattern: "recover|breakeven|get.*back"
    solution: |
      Drawdown Recovery Table:

      | Drawdown | Return Needed | At 20%/year | At 50%/year |
      |----------|---------------|-------------|-------------|
      | 10%      | 11%           | 7 months    | 3 months    |
      | 20%      | 25%           | 1.2 years   | 6 months    |
      | 30%      | 43%           | 2 years     | 10 months   |
      | 40%      | 67%           | 3 years     | 1.2 years   |
      | 50%      | 100%          | 4 years     | 2 years     |
      | 60%      | 150%          | 5.5 years   | 2.5 years   |
      | 75%      | 300%          | 8 years     | 4 years     |
      | 90%      | 900%          | 13 years    | 6 years     |

      Key Insights:
      1. Prevention > Recovery (always)
      2. Max acceptable drawdown: 20-30%
      3. At 50% drawdown, consider starting over
      4. Never try to "make it back fast"

      def years_to_recover(drawdown_pct, annual_return):
          recovery_needed = 1 / (1 - drawdown_pct) - 1
          years = np.log(1 + recovery_needed) / np.log(1 + annual_return)
          return years
    references:
      - Basic compound interest mathematics

  - id: stop-loss-gap-risk
    severity: CRITICAL
    title: Stop Losses Can Be Gapped Through
    description: Your stop at $100 doesn't guarantee fill at $100 - gaps happen
    symptoms:
      - Losses larger than planned
      - "My stop was at $100 but I got filled at $85"
      - Overnight gap destroys position
    detection_pattern: "stop.*guarantee|stop.*protection"
    solution: |
      Gap Risk Reality:

      Market Events That Cause Gaps:
      - Overnight/weekend holds
      - Earnings announcements
      - Fed decisions
      - Black swan events
      - Flash crashes

      Historical Gaps:
      - Oct 2020 BTC: -15% in hours
      - March 2020 SPY: -12% gap down
      - SNB 2015: CHF pairs gapped 20%+

      Protection Strategies:
      1. Reduce size for overnight holds
         - Day trade: Full size with stop
         - Swing trade: 50% size, expect gaps

      2. Use options for defined risk
         - Long put = guaranteed max loss
         - Cost is the "insurance premium"

      3. Avoid holding through known events
         - No positions through FOMC
         - Close before earnings

      4. Calculate gap-adjusted risk
         - Normal stop risk: 2%
         - With 10% gap possibility: 4-5% true risk
         - Size accordingly
    references:
      - Flash crash and gap analysis studies

  - id: correlation-crisis-spike
    severity: CRITICAL
    title: Correlations Spike to 1.0 in Crisis
    description: Your "diversified" portfolio becomes one position in a crash
    symptoms:
      - All positions drop simultaneously
      - "Diversification didn't work"
      - Portfolio loss much larger than expected
    detection_pattern: "diversif|uncorrelat|independent"
    solution: |
      Correlation Regimes:

      Normal Markets (VIX < 20):
      - BTC/ETH: 0.85
      - BTC/SPY: 0.40
      - SPY/Bonds: -0.20

      Crisis Markets (VIX > 40):
      - BTC/ETH: 0.98
      - BTC/SPY: 0.80
      - SPY/Bonds: 0.60 (even bonds sell off!)

      2022 Example:
      - Stocks: -25%
      - Bonds: -15%
      - Crypto: -75%
      - "Diversified" 60/40 portfolio: -20%

      Solutions:
      1. Assume crisis correlations for risk
         - Use 0.8+ correlation in VaR models
         - Stress test with all assets moving together

      2. True diversification is rare
         - Cash
         - Volatility products (VIX calls)
         - Managed futures (trend following)
         - Put options on holdings

      3. Size for correlated drawdown
         - If 5 positions at 2% risk each
         - With 0.8 correlation: ~8-9% true risk
         - Not 10% (uncorrelated) or 2% (single)
    references:
      - "All Correlations Go to One in a Crisis" - various research

  - id: leverage-path-dependency
    severity: CRITICAL
    title: Leverage Creates Devastating Path Dependency
    description: With leverage, order of returns matters - volatility destroys capital
    symptoms:
      - Leveraged position underperforms unleveraged over time
      - "The asset went up but my leveraged position lost money"
      - Volatility decay eating returns
    detection_pattern: "leverag|3x|2x|margin"
    solution: |
      Path Dependency Example:

      Unleveraged SPY:
      Day 1: +10% → $110
      Day 2: -10% → $99
      Net: -1%

      3x Leveraged:
      Day 1: +30% → $130
      Day 2: -30% → $91
      Net: -9%

      The Math (Volatility Decay):
      Expected return ≈ Leverage × Return - 0.5 × Leverage² × Variance

      For 3x leverage on 20% volatility asset:
      Decay ≈ 0.5 × 9 × 0.04 = 18% annual drag!

      Leverage Rules:
      1. Leverage < 2x for holding periods > 1 day
      2. Higher volatility = lower leverage
      3. Never hold leveraged ETFs long-term
      4. Calculate leverage-adjusted volatility:

      effective_vol = base_vol × leverage
      # 3x on 20% vol asset = 60% effective vol
      # Account for 60% vol, not 20%
    references:
      - "The Dynamics of Leveraged and Inverse ETFs"

  - id: max-drawdown-underestimate
    severity: HIGH
    title: Your Worst Drawdown Hasn't Happened Yet
    description: Max drawdown in backtest is the MINIMUM to expect live
    symptoms:
      - Live drawdown exceeds all backtests
      - "This never happened in testing"
      - Strategy abandoned at worst time
    detection_pattern: "max.*drawdown|worst.*case|backtest"
    solution: |
      Backtest vs Live Reality:

      Backtest max drawdown: 15%
      Expected live drawdown: 22-30% (1.5-2x)

      Why Live Is Worse:
      1. Slippage not fully modeled
      2. Gaps not captured
      3. Liquidity issues in stress
      4. Execution delays
      5. Emotional decisions
      6. Black swans by definition aren't in historical data

      Planning Rule:
      - Backtest max DD: 20%
      - Plan for: 40% live DD
      - Size so 40% DD is survivable

      If you can't handle 2x backtest DD:
      - Reduce position sizes
      - Add more diversification
      - Lower leverage

      def stress_test_drawdown(backtest_max_dd, multiplier=2.0):
          expected_live_dd = backtest_max_dd * multiplier

          recovery_needed = 1 / (1 - expected_live_dd) - 1

          return {
              'backtest_dd': backtest_max_dd,
              'expected_live_dd': expected_live_dd,
              'recovery_needed': recovery_needed,
              'acceptable': expected_live_dd < 0.35
          }
    references:
      - Out-of-sample testing research

  - id: risk-per-trade-compounding
    severity: HIGH
    title: Consecutive Losses Compound Faster Than You Think
    description: 10 losses at 2% each doesn't equal 20% - it's worse
    symptoms:
      - Account smaller than expected after losing streak
      - "I only risk 2% but I'm down 25%"
      - Underestimating sequence risk
    detection_pattern: "consecutive.*loss|losing.*streak|sequence"
    solution: |
      Compounding Loss Reality:

      10 consecutive losses at 2% per trade:
      $100,000 × (0.98)^10 = $81,707
      Total loss: 18.3% (not 20%)

      10 consecutive losses at 5% per trade:
      $100,000 × (0.95)^10 = $59,874
      Total loss: 40.1% (not 50%)

      Probability of Losing Streaks (50% win rate):
      - 5 in a row: 3.1% (will happen)
      - 7 in a row: 0.8% (will happen eventually)
      - 10 in a row: 0.1% (rare but possible)

      With 40% win rate:
      - 5 in a row: 7.8%
      - 7 in a row: 2.8%
      - 10 in a row: 0.6%

      def probability_losing_streak(win_rate, streak_length, num_trades):
          """Probability of experiencing N consecutive losses"""
          p_loss = 1 - win_rate
          p_streak = p_loss ** streak_length

          # Probability over many trades (approximate)
          p_experiencing = 1 - (1 - p_streak) ** (num_trades - streak_length + 1)
          return p_experiencing

      # Over 500 trades with 50% WR, 10-loss streak:
      # probability_losing_streak(0.50, 10, 500) ≈ 39%
      # It WILL happen!
    references:
      - Probability theory and risk of ruin calculations

  - id: position-sizing-after-loss
    severity: HIGH
    title: Don't Size Based on Recent P&L
    description: Reducing size after losses locks in drawdowns; increasing after wins sets up for bigger losses
    symptoms:
      - Tiny positions after losing streak (miss recovery)
      - Huge positions after winning streak (big loss wipes gains)
      - Emotional sizing decisions
    detection_pattern: "reduce.*size.*after|increase.*size.*after"
    solution: |
      Wrong Approaches:

      1. Reduce after losses:
         - Lose 20%, reduce to 50% size
         - Market recovers, you capture only 50%
         - Recovery takes 2x longer

      2. Increase after wins:
         - Win 20%, increase to 150% size
         - Inevitable loss at large size
         - One loss wipes multiple wins

      Correct Approaches:

      1. Fixed Percentage (Most Common)
         - Always risk 1% of CURRENT equity
         - Size automatically adjusts
         - Smaller $ after losses (correct)
         - Larger $ after wins (correct)

      2. Fixed Fractional with Smoothing
         - Use 20-day average equity for sizing
         - Smooths out daily volatility
         - Less emotional response

      3. Drawdown-Adjusted (Advanced)
         - Reduce size only at defined thresholds
         - Not after every loss
         - 10% DD: 80% size, 20% DD: 50% size
         - Systematic, not emotional
    references:
      - Van Tharp position sizing research

  - id: illiquidity-risk
    severity: HIGH
    title: You Can't Exit Positions in Illiquid Markets
    description: Your theoretical stop loss is worthless if there's no liquidity to fill it
    symptoms:
      - Massive slippage on exits
      - Can't close position at any reasonable price
      - "Stuck" in position during crisis
    detection_pattern: "liquidity|volume|slippage|exit"
    solution: |
      Liquidity Reality Check:

      Before entering, calculate:
      1. Average daily volume
      2. Your position as % of daily volume
      3. Time to exit at normal volume

      Rules:
      - Position < 1% of daily volume (easy exit)
      - Position 1-5% of daily volume (some impact)
      - Position > 5% of daily volume (significant impact)
      - Position > 10% of daily volume (YOU ARE THE MARKET)

      def check_liquidity(
          position_value: float,
          avg_daily_volume: float,
          avg_price: float
      ) -> dict:
          daily_dollar_volume = avg_daily_volume * avg_price
          position_as_pct_of_volume = position_value / daily_dollar_volume

          if position_as_pct_of_volume < 0.01:
              risk_level = "Low"
              expected_slippage = 0.001  # 0.1%
          elif position_as_pct_of_volume < 0.05:
              risk_level = "Medium"
              expected_slippage = 0.005  # 0.5%
          elif position_as_pct_of_volume < 0.10:
              risk_level = "High"
              expected_slippage = 0.02  # 2%
          else:
              risk_level = "Severe"
              expected_slippage = 0.05  # 5%+

          return {
              'position_pct_of_volume': position_as_pct_of_volume,
              'risk_level': risk_level,
              'expected_slippage': expected_slippage
          }

      # In crisis, volume might drop 50-80%
      # Your "medium risk" becomes "severe risk"
    references:
      - Market microstructure research

  - id: var-limitations
    severity: MEDIUM
    title: VaR Tells You Nothing About Tail Risk
    description: Value at Risk measures normal losses, not catastrophic losses
    symptoms:
      - "Our 95% VaR is only 3%"
      - Ignoring the 5% of cases that destroy accounts
      - False confidence from VaR metrics
    detection_pattern: "VaR|value.*at.*risk|95%.*confidence"
    solution: |
      VaR Limitation:

      "95% VaR of 3%" means:
      - 95% of days, loss < 3%
      - Says NOTHING about the 5%
      - That 5% could be -10%, -30%, or -100%

      Better Metrics:

      1. CVaR (Conditional VaR / Expected Shortfall)
         - Average loss in worst 5% of cases
         - "When things go bad, HOW bad?"

      2. Maximum Drawdown
         - Worst peak-to-trough loss
         - Historical worst case

      3. Tail Risk Measures
         - What's the 99.9% VaR?
         - What happened in 2008, 2020?

      import numpy as np

      def calculate_risk_metrics(returns):
          var_95 = np.percentile(returns, 5)
          var_99 = np.percentile(returns, 1)

          # CVaR: average of returns worse than VaR
          cvar_95 = returns[returns <= var_95].mean()

          return {
              'var_95': var_95,
              'var_99': var_99,
              'cvar_95': cvar_95,  # This is what matters
              'worst_day': returns.min(),
              'var_cvar_ratio': cvar_95 / var_95  # Higher = fatter tails
          }
    references:
      - "The Black Swan" - Nassim Taleb

  - id: single-strategy-risk
    severity: MEDIUM
    title: Single Strategy Will Eventually Stop Working
    description: Every strategy has periods of underperformance or death
    symptoms:
      - Strategy works for years, then stops
      - Drawdown longer than any backtest showed
      - "The market changed"
    detection_pattern: "strategy|system|edge"
    solution: |
      Strategy Lifecycle:

      1. Discovery: Edge is strong (few know it)
      2. Adoption: Edge weakens (more capital)
      3. Saturation: Edge disappears (crowded)
      4. Death or Rebirth: Strategy dies or evolves

      Protection Strategies:

      1. Strategy Diversification
         - Multiple uncorrelated strategies
         - Mean reversion + Trend following
         - Different timeframes

      2. Regime Detection
         - Monitor strategy performance
         - Reduce size when underperforming
         - Don't abandon at first sign of weakness

      3. Continuous Research
         - Always developing new strategies
         - Pipeline of ideas being tested
         - Don't rely on single source of alpha

      4. Allocation Limits
         - No single strategy > 30% of capital
         - Rotate based on recent performance
         - Kill strategies that underperform 2+ years
    references:
      - Alpha decay research
