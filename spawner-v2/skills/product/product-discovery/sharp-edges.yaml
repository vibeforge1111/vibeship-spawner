# Product Discovery Sharp Edges

sharp_edges:
  - id: leading-the-witness
    summary: Biasing customer responses
    severity: high
    situation: Customers tell you what you want to hear
    why: |
      Questions suggest the answer.
      Enthusiasm influences responses.
      Showing solution too early.
    solution: |
      ## Unbiased Customer Research

      ### Leading Question Detection

      | Leading | Neutral |
      |---------|---------|
      | "Wouldn't it be great if..." | "How do you handle X today?" |
      | "Do you have trouble with X?" | "Tell me about the last time..." |
      | "Most people find X difficult..." | "What's your experience with X?" |
      | "Would you use a product that..." | "What would change if X were solved?" |

      ### Enthusiasm Management

      ```
      Your excitement can bias responses:

      DON'T:
      - "We're building something amazing..."
      - Nodding enthusiastically at positive feedback
      - "That's exactly what we hoped!"

      DO:
      - Neutral demeanor
      - Follow-up on both positive and negative
      - "Tell me more" regardless of answer
      ```

      ### The 5-Second Rule

      After asking a question:
      - Stay silent for 5 seconds
      - Don't fill the pause
      - Let them think and elaborate
      - Resist the urge to clarify

      ### Solution Showing Timing

      ```
      Early: Talk about their world
      Middle: Explore problems
      Late (if at all): Show concepts

      Never show solution until you've exhausted
      problem exploration.
      ```

      ### Post-Interview Check

      Ask yourself:
      - Did I hear anything surprising?
      - Did they ever disagree with me?
      - Did I talk less than 30% of the time?
      - Did I follow up on negative signals?
    symptoms:
      - All feedback is positive
      - No surprises from interviews
      - Building what you expected
    detection_pattern: "interview|customer feedback|research"

  - id: wrong-sample
    summary: Talking to unrepresentative customers
    severity: high
    situation: Research doesn't reflect actual market
    why: |
      Convenience sampling.
      Too friendly to target.
      Missing key segments.
    solution: |
      ## Representative Research

      ### Sampling Mistakes

      | Mistake | Result |
      |---------|--------|
      | Only friends/network | Overly positive feedback |
      | Only power users | Miss adoption barriers |
      | Only complainers | Miss happy silent majority |
      | Only accessible | Miss time-constrained targets |

      ### Customer Segmentation for Research

      ```
      Interview across:
      - Usage level (none, light, heavy)
      - Lifecycle stage (prospect, new, established, churned)
      - Segment (enterprise, SMB, prosumer)
      - Outcome (successful, struggling, failed)
      ```

      ### Recruiting Mix

      | Segment | % of Interviews | Why |
      |---------|-----------------|-----|
      | Target prospects | 30% | Acquisition insights |
      | New users | 25% | Onboarding insights |
      | Power users | 20% | Deep usage insights |
      | Churned users | 15% | Failure insights |
      | Non-target | 10% | Boundary testing |

      ### Recruiting Channels

      ```
      Avoid over-reliance on one:
      - Email to user list
      - In-app prompts
      - Social media outreach
      - Paid recruiting services
      - Sales/support referrals
      ```

      ### The "Surprising Interview" Test

      If your last 5 interviews all confirmed beliefs,
      you're probably sampling wrong.

      Actively seek interviews that might prove you wrong.
    symptoms:
      - All interviews confirm beliefs
      - No disagreement or pushback
      - Insights match expectations
    detection_pattern: "sample|recruit|who to talk to"

  - id: discovery-delivery-disconnect
    summary: Discovery insights not reaching delivery
    severity: medium
    situation: Team builds different from what was learned
    why: |
      Discovery separate from delivery.
      Handoff losses.
      Teams siloed.
    solution: |
      ## Connecting Discovery to Delivery

      ### Integration Models

      **Co-located Discovery**
      ```
      Same people do discovery and delivery.
      Learning transfers naturally.
      Best for small teams.
      ```

      **Discovery Trio**
      ```
      Product + Design + Engineering
      All participate in discovery.
      Shared understanding.
      ```

      **Discovery Demos**
      ```
      Regular sharing of discovery findings.
      Team watches interview clips.
      Delivery team asks questions.
      ```

      ### Artifact Sharing

      | Artifact | Purpose | Access |
      |----------|---------|--------|
      | Interview recordings | Raw data | All team members |
      | Insight summaries | Digestible learnings | Shared weekly |
      | Opportunity map | Visual priorities | Always visible |
      | Assumption tracker | Risk awareness | Reviewed in planning |

      ### Decision Connection

      ```
      For each feature:
      - What discovery led to this?
      - Which interviews informed it?
      - What assumptions are we making?
      - How will we validate after shipping?
      ```

      ### Anti-Handoff Practices

      DON'T:
      - Write discovery docs nobody reads
      - Do discovery then throw over wall
      - Let PM be only discovery holder

      DO:
      - Involve delivery team in interviews
      - Share clips, not just summaries
      - Connect specs to discovery evidence
    symptoms:
      - Delivery team unaware of research
      - "Why are we building this?"
      - Research docs unread
    detection_pattern: "handoff|disconnect|delivery"

  - id: analysis-paralysis
    summary: Too much discovery, never shipping
    severity: medium
    situation: Endless research, no decisions
    why: |
      Seeking certainty in uncertain domain.
      Fear of building wrong thing.
      No clear decision criteria.
    solution: |
      ## Decisive Discovery

      ### Discovery Time-Boxing

      ```
      For each opportunity:
      - Discovery sprint: 1-2 weeks max
      - Decision point: Clear deadline
      - Evidence threshold: "Good enough" defined

      Not: "Keep researching until certain"
      ```

      ### Decision Criteria Upfront

      ```
      Before starting discovery, define:
      - What would make us proceed?
      - What would make us kill it?
      - What's "enough" evidence?

      Example:
      - Proceed if: 6+ of 10 interviews confirm problem
      - Kill if: <3 interviews show interest
      - Good enough: Clear patterns in 10 interviews
      ```

      ### Evidence Thresholds

      | Decision | Evidence Needed |
      |----------|-----------------|
      | Explore further | Directional signal (5 interviews) |
      | Build prototype | Clear problem pattern (10 interviews) |
      | Build feature | Validated solution + business case |
      | Major investment | Quantitative validation |

      ### The 70% Rule

      ```
      Decide when you have 70% confidence.
      Waiting for 100% means:
      - Too slow
      - Opportunity missed
      - Can always learn from shipping
      ```

      ### Ship to Learn

      Sometimes the best discovery is shipping:
      - Build smallest version
      - Measure actual behavior
      - Learn from real usage
    symptoms:
      - Months of research, no shipping
      - "Need more data" repeatedly
      - Fear of being wrong
    detection_pattern: "analysis paralysis|enough research|decide"

  - id: discovery-amnesia
    summary: Not retaining or using discovery learnings
    severity: medium
    situation: Repeating research already done
    why: |
      No central repository.
      Findings not documented.
      Team turnover loses knowledge.
    solution: |
      ## Discovery Knowledge Management

      ### Repository Structure

      ```
      Discovery Repository
      ├── Interviews
      │   ├── Recordings
      │   ├── Transcripts
      │   └── Summaries
      ├── Insights
      │   ├── By theme
      │   └── By segment
      ├── Opportunities
      │   └── Opportunity map
      └── Experiments
          ├── Completed
          └── In progress
      ```

      ### Interview Documentation

      ```
      Minimum per interview:
      - Date and participant type
      - Key quotes (verbatim)
      - Problems mentioned
      - Current solutions
      - Surprises

      Best: Recording + transcript + summary
      ```

      ### Insight Tagging

      Tag insights by:
      - Theme/topic
      - Segment
      - Confidence level
      - Related opportunity
      - Date (freshness)

      ### Making Knowledge Findable

      ```
      Before new discovery:
      1. Search existing repository
      2. Find related past interviews
      3. Build on what's known
      4. Identify gaps to fill
      ```

      ### Regular Synthesis

      | Cadence | Activity |
      |---------|----------|
      | Weekly | Add new insights |
      | Monthly | Synthesize patterns |
      | Quarterly | Prune stale insights |
    symptoms:
      - Repeating same research
      - "I think we looked at this before..."
      - Knowledge walking out the door
    detection_pattern: "repository|documentation|track insights"
