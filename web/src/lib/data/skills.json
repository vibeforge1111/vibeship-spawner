[
  {
    "id": "agents",
    "name": "Agents",
    "skills": [
      {
        "id": "agent-evaluation",
        "name": "Agent Evaluation",
        "version": "1.0.0",
        "layer": 1,
        "description": "Shipping agents without any evaluation",
        "principles": [
          "Eval what matters, not what's easy to measure",
          "Multi-turn, not single-turn - agents are conversations",
          "Trajectory matters as much as final answer",
          "LLM judges have biases - design around them",
          "Test environments must reset per eval",
          "Start with 20 well-chosen examples, not 1000 random ones",
          "Combine human review (quality) with automated evals (scale)"
        ],
        "owns": [
          "agent-evaluation",
          "agent-testing",
          "agent-benchmarking",
          "llm-as-judge",
          "multi-turn-evaluation",
          "trajectory-evaluation",
          "agent-metrics",
          "eval-datasets"
        ],
        "does_not_own": [
          "model-training → ml-engineer",
          "load-testing → devops",
          "security-testing → security-specialist",
          "observability-setup → devops"
        ],
        "triggers": [
          "agent evaluation",
          "test agent",
          "benchmark agent",
          "eval",
          "llm as judge",
          "agent testing",
          "agent metrics",
          "langsmith",
          "braintrust",
          "openevals"
        ],
        "tags": [
          "evaluation",
          "testing",
          "benchmarks",
          "metrics",
          "llm-judge",
          "langsmith",
          "multi-turn",
          "trajectory",
          "ci-cd"
        ],
        "pairs_with": [
          "autonomous-agents         # Agents to evaluate",
          "multi-agent-orchestration # Multi-agent testing",
          "agent-tool-builder        # Tool evaluation",
          "llm-architect             # Model evaluation"
        ],
        "requires": [],
        "category": "agents"
      },
      {
        "id": "agent-memory-systems",
        "name": "Agent Memory Systems",
        "version": "1.0.0",
        "layer": 1,
        "description": "Never deleting or archiving memories",
        "principles": [
          "Memory quality = retrieval quality, not storage quantity",
          "Chunk for retrieval, not for storage",
          "Context isolation is the enemy of memory",
          "Right memory type for right information",
          "Decay old memories - not everything should be forever",
          "Test retrieval accuracy before production",
          "Background memory formation beats real-time"
        ],
        "owns": [
          "agent-memory",
          "long-term-memory",
          "short-term-memory",
          "working-memory",
          "episodic-memory",
          "semantic-memory",
          "procedural-memory",
          "memory-retrieval",
          "memory-formation",
          "memory-decay"
        ],
        "does_not_own": [
          "vector-database-operations → data-engineer",
          "rag-pipeline-architecture → llm-architect",
          "embedding-model-selection → ml-engineer",
          "knowledge-graph-design → knowledge-engineer"
        ],
        "triggers": [
          "agent memory",
          "long-term memory",
          "memory systems",
          "remember across sessions",
          "memory retrieval",
          "episodic memory",
          "semantic memory",
          "vector store",
          "rag",
          "langmem",
          "memgpt",
          "conversation history"
        ],
        "tags": [
          "memory",
          "vector-store",
          "rag",
          "retrieval",
          "embedding",
          "episodic",
          "semantic",
          "procedural",
          "langmem",
          "memgpt",
          "pinecone",
          "qdrant",
          "chromadb"
        ],
        "pairs_with": [
          "autonomous-agents         # Memory for autonomous agents",
          "multi-agent-orchestration # Shared memory across agents",
          "llm-architect             # RAG and retrieval patterns",
          "agent-tool-builder        # Memory as tool"
        ],
        "requires": [],
        "category": "agents"
      },
      {
        "id": "agent-tool-builder",
        "name": "Agent Tool Builder",
        "version": "1.0.0",
        "layer": 1,
        "description": "Tool descriptions that don't explain when/how to use the tool",
        "principles": [
          "Description quality > implementation quality for LLM accuracy",
          "Aim for fewer than 20 tools - more causes confusion",
          "Every tool needs explicit error handling - silent failures poison agents",
          "Return strings, not objects - LLMs process text",
          "Validation gates before execution - reject, fix, or escalate, never silent fail",
          "Test tools with the LLM, not just unit tests"
        ],
        "owns": [
          "agent-tools",
          "function-calling",
          "tool-schema-design",
          "mcp-tools",
          "tool-validation",
          "tool-error-handling"
        ],
        "does_not_own": [
          "multi-agent-coordination → multi-agent-orchestration",
          "agent-memory → agent-memory-systems",
          "api-design → api-designer",
          "llm-prompting → prompt-engineering"
        ],
        "triggers": [
          "agent tool",
          "function calling",
          "tool schema",
          "tool design",
          "mcp server",
          "mcp tool",
          "tool use",
          "build tool for agent",
          "define function",
          "input_schema",
          "tool_use",
          "tool_result"
        ],
        "tags": [
          "agents",
          "tools",
          "function-calling",
          "mcp",
          "json-schema",
          "anthropic",
          "openai",
          "llm-tools"
        ],
        "pairs_with": [
          "multi-agent-orchestration  # Tools for orchestrated agents",
          "api-designer               # API design principles apply",
          "llm-architect              # Model capabilities for tools",
          "backend                    # Implementing tool logic"
        ],
        "requires": [],
        "category": "agents"
      },
      {
        "id": "autonomous-agents",
        "name": "Autonomous Agents",
        "version": "1.0.0",
        "layer": 1,
        "description": "Letting agents run without step/cost limits",
        "principles": [
          "Reliability over autonomy - every step compounds error probability",
          "Constrain scope - domain-specific beats general-purpose",
          "Treat outputs as proposals, not truth",
          "Build guardrails before expanding capabilities",
          "Human-in-the-loop for critical decisions is non-negotiable",
          "Log everything - every action must be auditable",
          "Fail safely with rollback, not silently with corruption"
        ],
        "owns": [
          "autonomous-agents",
          "agent-loops",
          "goal-decomposition",
          "self-correction",
          "reflection-patterns",
          "react-pattern",
          "plan-execute",
          "agent-reliability",
          "agent-guardrails"
        ],
        "does_not_own": [
          "multi-agent-systems → multi-agent-orchestration",
          "tool-building → agent-tool-builder",
          "memory-systems → agent-memory-systems",
          "workflow-orchestration → workflow-automation"
        ],
        "triggers": [
          "autonomous agent",
          "autogpt",
          "babyagi",
          "self-prompting",
          "goal decomposition",
          "react pattern",
          "agent loop",
          "self-correcting agent",
          "reflection agent",
          "langgraph",
          "agentic ai",
          "agent planning"
        ],
        "tags": [
          "autonomous",
          "agents",
          "langgraph",
          "react",
          "planning",
          "reflection",
          "guardrails",
          "reliability",
          "checkpointing"
        ],
        "pairs_with": [
          "agent-tool-builder       # Tools for agents to use",
          "agent-memory-systems     # Long-term memory",
          "multi-agent-orchestration # Multi-agent coordination",
          "agent-evaluation         # Testing and benchmarking"
        ],
        "requires": [],
        "category": "agents"
      },
      {
        "id": "browser-automation",
        "name": "Browser Automation",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using waitForTimeout or sleep instead of proper waits",
        "principles": [
          "Use user-facing locators (getByRole, getByText) over CSS/XPath",
          "Never add manual waits - Playwright's auto-wait handles it",
          "Each test/task should be fully isolated with fresh context",
          "Screenshots and traces are your debugging lifeline",
          "Headless for CI, headed for debugging",
          "Anti-detection is cat-and-mouse - stay current or get blocked"
        ],
        "owns": [
          "browser-automation",
          "playwright",
          "puppeteer",
          "headless-browsers",
          "web-scraping",
          "browser-testing",
          "e2e-testing",
          "ui-automation",
          "selenium-alternatives"
        ],
        "does_not_own": [
          "api-testing → backend",
          "load-testing → performance-thinker",
          "accessibility-testing → accessibility-specialist",
          "visual-regression-testing → ui-design"
        ],
        "triggers": [
          "playwright",
          "puppeteer",
          "browser automation",
          "headless",
          "web scraping",
          "e2e test",
          "end-to-end",
          "selenium",
          "chromium",
          "browser test",
          "page.click",
          "locator"
        ],
        "tags": [
          "playwright",
          "puppeteer",
          "browser",
          "automation",
          "testing",
          "scraping",
          "headless",
          "e2e",
          "selenium",
          "web-testing"
        ],
        "pairs_with": [
          "agent-tool-builder         # Browser tools for agents",
          "workflow-automation        # Browser steps in workflows",
          "computer-use-agents        # Full desktop vs browser",
          "test-architect             # Testing strategy"
        ],
        "requires": [],
        "category": "agents"
      },
      {
        "id": "multi-agent-orchestration",
        "name": "Multi-Agent Orchestration",
        "version": "1.0.0",
        "layer": 1,
        "description": "Adding agents without meaningful specialization",
        "principles": [
          "Start with a single agent. Multi-agent complexity is only justified when single-agent fails",
          "Handoffs are where failures hide - invest heavily in handoff reliability",
          "Context windows are finite - decide what context each agent actually needs",
          "Coordination latency grows quadratically with agent count - fewer agents is often better",
          "Every agent interaction is a potential failure point - design for graceful degradation",
          "Observable systems are debuggable systems - instrument every handoff"
        ],
        "owns": [
          "multi-agent-orchestration",
          "agent-coordination",
          "agent-handoffs",
          "agent-routing",
          "supervisor-patterns",
          "swarm-orchestration",
          "agent-pipelines",
          "group-chat-agents"
        ],
        "does_not_own": [
          "single-agent-design → agent-tool-builder",
          "agent-memory → agent-memory-systems",
          "agent-testing → agent-evaluation",
          "llm-selection → llm-architect"
        ],
        "triggers": [
          "multi-agent",
          "agent orchestration",
          "agent handoff",
          "agent coordination",
          "supervisor agent",
          "swarm",
          "agent pipeline",
          "multiple agents",
          "agent routing",
          "transfer between agents",
          "langgraph",
          "crewai",
          "autogen"
        ],
        "tags": [
          "agents",
          "orchestration",
          "multi-agent",
          "langgraph",
          "crewai",
          "autogen",
          "swarm",
          "coordination",
          "distributed-systems",
          "handoffs"
        ],
        "pairs_with": [
          "agent-memory-systems    # Shared memory between agents",
          "agent-tool-builder      # Tools for individual agents",
          "agent-evaluation        # Testing multi-agent systems",
          "workflow-automation     # Orchestration infrastructure"
        ],
        "requires": [
          "llm-architect           # Understanding LLM capabilities"
        ],
        "category": "agents"
      },
      {
        "id": "computer-use-agents",
        "name": "Perception-Reasoning-Action Loop",
        "version": "1.0.0",
        "layer": 1,
        "description": "The fundamental architecture of computer use agents: observe screen,\r\n    reason about next action, execute action, repeat. This loop integrates\r\n    vision models with action execution through an iterative pipeline.\r\n\n    Key components:\r\n    1. PERCEPTION: Screenshot captures current screen state\r\n    2. REASONING: Vision-language model analyzes and plans\r\n    3. ACTION: Execute mouse/keyboard operations\r\n    4. FEEDBACK: Observe result, continue or correct\r\n\n    Critical insight: Vision agents are completely still during \"thinking\"\r\n    phase (1-5 seconds), creating a detectable pause pattern.\r\n  when_to_use:\r\n    - \"Building any computer use agent from scratch\"\r\n    - \"Integrating vision models with desktop control\"\r\n    - \"Understanding agent behavior patterns\"\r\n  implementation: |\r\n    from anthropic import Anthropic\r\n    from PIL import Image\r\n    import base64\r\n    import pyautogui\r\n    import time\r\n\n    class ComputerUseAgent:\r\n        \"\"\"\r\n        Perception-Reasoning-Action loop implementation.\r\n        Based on Anthropic Computer Use patterns.\r\n        \"\"\"\r\n\n        def __init__(self, client: Anthropic, model: str = \"claude-sonnet-4-20250514\"):\r\n            self.client = client\r\n            self.model = model\r\n            self.max_steps = 50  # Prevent runaway loops\r\n            self.action_delay = 0.5  # Seconds between actions\r\n\n        def capture_screenshot(self) -> str:\r\n            \"\"\"Capture screen and return base64 encoded image.\"\"\"\r\n            screenshot = pyautogui.screenshot()\r\n\n            screenshot = screenshot.resize((1280, 800), Image.LANCZOS)\r\n\n            import io\r\n            buffer = io.BytesIO()\r\n            screenshot.save(buffer, format=\"PNG\")\r\n            return base64.b64encode(buffer.getvalue()).decode()\r\n\n        def execute_action(self, action: dict) -> dict:\r\n            \"\"\"Execute mouse/keyboard action on the computer.\"\"\"\r\n            action_type = action.get(\"type\")\r\n\n            if action_type == \"click\":\r\n                x, y = action[\"x\"], action[\"y\"]\r\n                button = action.get(\"button\", \"left\")\r\n                pyautogui.click(x, y, button=button)\r\n                return {\"success\": True, \"action\": f\"clicked at ({x}, {y})\"}\r\n\n            elif action_type == \"type\":\r\n                text = action[\"text\"]\r\n                pyautogui.typewrite(text, interval=0.02)\r\n                return {\"success\": True, \"action\": f\"typed {len(text)} chars\"}\r\n\n            elif action_type == \"key\":\r\n                key = action[\"key\"]\r\n                pyautogui.press(key)\r\n                return {\"success\": True, \"action\": f\"pressed {key}\"}\r\n\n            elif action_type == \"scroll\":\r\n                direction = action.get(\"direction\", \"down\")\r\n                amount = action.get(\"amount\", 3)\r\n                scroll = -amount if direction == \"down\" else amount\r\n                pyautogui.scroll(scroll)\r\n                return {\"success\": True, \"action\": f\"scrolled {direction}\"}\r\n\n            elif action_type == \"move\":\r\n                x, y = action[\"x\"], action[\"y\"]\r\n                pyautogui.moveTo(x, y)\r\n                return {\"success\": True, \"action\": f\"moved to ({x}, {y})\"}\r\n\n            else:\r\n                return {\"success\": False, \"error\": f\"Unknown action: {action_type}\"}\r\n\n        def run(self, task: str) -> dict:\r\n            \"\"\"\r\n            Run perception-reasoning-action loop until task complete.\r\n\n            The loop:\r\n            1. Screenshot current state\r\n            2. Send to vision model with task context\r\n            3. Parse action from response\r\n            4. Execute action\r\n            5. Repeat until done or max steps\r\n            \"\"\"\r\n            messages = []\r\n            step_count = 0\r\n\n            system_prompt = \"\"\"You are a computer use agent. You can see the screen\r\n            and control mouse/keyboard.\r\n\n            Available actions (respond with JSON):\r\n            - {\"type\": \"click\", \"x\": 100, \"y\": 200, \"button\": \"left\"}\r\n            - {\"type\": \"type\", \"text\": \"hello world\"}\r\n            - {\"type\": \"key\", \"key\": \"enter\"}\r\n            - {\"type\": \"scroll\", \"direction\": \"down\", \"amount\": 3}\r\n            - {\"type\": \"done\", \"result\": \"task completed successfully\"}\r\n\n            Always respond with ONLY a JSON action object.\r\n            Be precise with coordinates - click exactly where needed.\r\n            If you see an error, try to recover.\r\n            \"\"\"\r\n\n            while step_count < self.max_steps:\r\n                step_count += 1\r\n\n\n                screenshot_b64 = self.capture_screenshot()\r\n\n\n                user_content = [\r\n                    {\"type\": \"text\", \"text\": f\"Task: {task}\\n\\nStep {step_count}. What action should I take?\"},\r\n                    {\"type\": \"image\", \"source\": {\r\n                        \"type\": \"base64\",\r\n                        \"media_type\": \"image/png\",\r\n                        \"data\": screenshot_b64\r\n                    }}\r\n                ]\r\n\n                messages.append({\"role\": \"user\", \"content\": user_content})\r\n\n                response = self.client.messages.create(\r\n                    model=self.model,\r\n                    max_tokens=1024,\r\n                    system=system_prompt,\r\n                    messages=messages\r\n                )\r\n\n                assistant_message = response.content[0].text\r\n                messages.append({\"role\": \"assistant\", \"content\": assistant_message})\r\n\n\n                import json\r\n                try:\r\n                    action = json.loads(assistant_message)\r\n                except json.JSONDecodeError:\r\n\n                    import re\r\n                    match = re.search(r'\\{[^}]+\\}', assistant_message)\r\n                    if match:\r\n                        action = json.loads(match.group())\r\n                    else:\r\n                        continue\r\n\n\n                if action.get(\"type\") == \"done\":\r\n                    return {\r\n                        \"success\": True,\r\n                        \"result\": action.get(\"result\"),\r\n                        \"steps\": step_count\r\n                    }\r\n\n\n                result = self.execute_action(action)\r\n\n\n                time.sleep(self.action_delay)\r\n\n            return {\r\n                \"success\": False,\r\n                \"error\": \"Max steps reached\",\r\n                \"steps\": step_count\r\n            }\r\n\n\n    agent = ComputerUseAgent(Anthropic())\r\n    result = agent.run(\"Open Chrome and search for 'weather today'\")\r\n  anti_patterns:\r\n    - \"Running without step limits (infinite loops)\"\r\n    - \"No delay between actions (UI can't keep up)\"\r\n    - \"Screenshots at full resolution (token explosion)\"\r\n    - \"Ignoring action failures (no recovery)\"\r\n\n- id: sandboxed-environment-pattern\r\n  name: Sandboxed Environment Pattern\r\n  description: |\r\n    Computer use agents MUST run in isolated, sandboxed environments.\r\n    Never give agents direct access to your main system - the security\r\n    risks are too high. Use Docker containers with virtual desktops.\r\n\n    Key isolation requirements:\r\n    1. NETWORK: Restrict to necessary endpoints only\r\n    2. FILESYSTEM: Read-only or scoped to temp directories\r\n    3. CREDENTIALS: No access to host credentials\r\n    4. SYSCALLS: Filter dangerous system calls\r\n    5. RESOURCES: Limit CPU, memory, time\r\n\n    The goal is \"blast radius minimization\" - if the agent goes wrong,\r\n    damage is contained to the sandbox.\r\n  when_to_use:\r\n    - \"Deploying any computer use agent\"\r\n    - \"Testing agent behavior safely\"\r\n    - \"Running untrusted automation tasks\"\r\n  implementation: |\r\n\n\n\n    FROM ubuntu:22.04\r\n\n\n    RUN apt-get update && apt-get install -y \\\r\n        xvfb \\\r\n        x11vnc \\\r\n        fluxbox \\\r\n        xterm \\\r\n        firefox \\\r\n        python3 \\\r\n        python3-pip \\\r\n        supervisor\r\n\n\n    RUN useradd -m -s /bin/bash agent && \\\r\n        mkdir -p /home/agent/.vnc\r\n\n\n    COPY requirements.txt /tmp/\r\n    RUN pip3 install -r /tmp/requirements.txt\r\n\n\n    RUN apt-get install -y --no-install-recommends libcap2-bin && \\\r\n        setcap -r /usr/bin/python3 || true\r\n\n\n    COPY --chown=agent:agent . /app\r\n    WORKDIR /app\r\n\n\n    COPY supervisord.conf /etc/supervisor/conf.d/\r\n\n\n    EXPOSE 5900\r\n\n\n    USER agent\r\n\n    CMD [\"/usr/bin/supervisord\", \"-c\", \"/etc/supervisor/conf.d/supervisord.conf\"]\r\n\n    ---\r\n\n\n    version: '3.8'\r\n\n    services:\r\n      computer-use-agent:\r\n        build: .\r\n        ports:\r\n          - \"5900:5900\"  # VNC for observation\r\n          - \"8080:8080\"  # API for control\r\n\n\n        security_opt:\r\n          - no-new-privileges:true\r\n          - seccomp:seccomp-profile.json\r\n\n\n        deploy:\r\n          resources:\r\n            limits:\r\n              cpus: '2'\r\n              memory: 4G\r\n            reservations:\r\n              cpus: '0.5'\r\n              memory: 1G\r\n\n\n        networks:\r\n          - agent-network\r\n\n\n        volumes:\r\n          - agent-tmp:/tmp\r\n\n\n        read_only: true\r\n        tmpfs:\r\n          - /run\r\n          - /var/run\r\n\n\n        environment:\r\n          - DISPLAY=:99\r\n          - NO_PROXY=localhost\r\n\n    networks:\r\n      agent-network:\r\n        driver: bridge\r\n        internal: true  # No internet by default\r\n\n    volumes:\r\n      agent-tmp:\r\n\n    ---\r\n\n\n    import subprocess\r\n    import os\r\n    from dataclasses import dataclass\r\n    from typing import Optional\r\n\n    @dataclass\r\n    class SandboxConfig:\r\n        \"\"\"Configuration for agent sandbox.\"\"\"\r\n        network_allowed: list[str] = None  # Allowed domains\r\n        max_runtime_seconds: int = 300\r\n        max_memory_mb: int = 2048\r\n        allow_downloads: bool = False\r\n        allow_clipboard: bool = False\r\n\n    class SandboxedAgent:\r\n        \"\"\"\r\n        Run computer use agent in Docker sandbox.\r\n        \"\"\"\r\n\n        def __init__(self, config: SandboxConfig):\r\n            self.config = config\r\n            self.container_id: Optional[str] = None\r\n\n        def start(self):\r\n            \"\"\"Start sandboxed environment.\"\"\"\r\n\n            network_rules = \"\"\r\n            if self.config.network_allowed:\r\n                for domain in self.config.network_allowed:\r\n                    network_rules += f\"--add-host={domain}:$(dig +short {domain}) \"\r\n            else:\r\n                network_rules = \"--network=none\"\r\n\n            cmd = f\"\"\"\r\n            docker run -d \\\r\n                --name computer-use-sandbox-$$ \\\r\n                --security-opt no-new-privileges \\\r\n                --cap-drop ALL \\\r\n                --memory {self.config.max_memory_mb}m \\\r\n                --cpus 2 \\\r\n                --read-only \\\r\n                --tmpfs /tmp \\\r\n                {network_rules} \\\r\n                computer-use-agent:latest\r\n            \"\"\"\r\n\n            result = subprocess.run(cmd, shell=True, capture_output=True)\r\n            self.container_id = result.stdout.decode().strip()\r\n\n\n            subprocess.Popen([\r\n                \"sh\", \"-c\",\r\n                f\"sleep {self.config.max_runtime_seconds} && docker kill {self.container_id}\"\r\n            ])\r\n\n            return self.container_id\r\n\n        def execute_task(self, task: str) -> dict:\r\n            \"\"\"Execute task in sandbox.\"\"\"\r\n            if not self.container_id:\r\n                self.start()\r\n\n\n            import requests\r\n            response = requests.post(\r\n                f\"http://localhost:8080/task\",\r\n                json={\"task\": task},\r\n                timeout=self.config.max_runtime_seconds\r\n            )\r\n\n            return response.json()\r\n\n        def stop(self):\r\n            \"\"\"Stop and remove sandbox.\"\"\"\r\n            if self.container_id:\r\n                subprocess.run(f\"docker rm -f {self.container_id}\", shell=True)\r\n                self.container_id = None\r\n  anti_patterns:\r\n    - \"Running agents on host system directly\"\r\n    - \"Giving sandbox full network access\"\r\n    - \"Running as root in container\"\r\n    - \"No resource limits (denial of service)\"\r\n    - \"Persistent storage (data can leak between runs)\"\r\n\n- id: anthropic-computer-use\r\n  name: Anthropic Computer Use Implementation\r\n  description: |\r\n    Official implementation pattern using Claude's computer use capability.\r\n    Claude 3.5 Sonnet was the first frontier model to offer computer use.\r\n    Claude Opus 4.5 is now the \"best model in the world for computer use.\"\r\n\n    Key capabilities:\r\n    - screenshot: Capture current screen state\r\n    - mouse: Click, move, drag operations\r\n    - keyboard: Type text, press keys\r\n    - bash: Run shell commands\r\n    - text_editor: View and edit files\r\n\n    Tool versions:\r\n    - computer_20251124 (Opus 4.5): Adds zoom action for detailed inspection\r\n    - computer_20250124 (All other models): Standard capabilities\r\n\n    Critical limitation: \"Some UI elements (like dropdowns and scrollbars)\r\n    might be tricky for Claude to manipulate\" - Anthropic docs\r\n  when_to_use:\r\n    - \"Building production computer use agents\"\r\n    - \"Need highest quality vision understanding\"\r\n    - \"Full desktop control (not just browser)\"\r\n  implementation: |\r\n    from anthropic import Anthropic\r\n    from anthropic.types.beta import (\r\n        BetaToolComputerUse20241022,\r\n        BetaToolBash20241022,\r\n        BetaToolTextEditor20241022,\r\n    )\r\n    import subprocess\r\n    import base64\r\n    from PIL import Image\r\n    import io\r\n\n    class AnthropicComputerUse:\r\n        \"\"\"\r\n        Official Anthropic Computer Use implementation.\r\n\n        Requires:\r\n        - Docker container with virtual display\r\n        - VNC for viewing agent actions\r\n        - Proper tool implementations\r\n        \"\"\"\r\n\n        def __init__(self):\r\n            self.client = Anthropic()\r\n            self.model = \"claude-sonnet-4-20250514\"  # Best for computer use\r\n            self.screen_size = (1280, 800)\r\n\n        def get_tools(self) -> list:\r\n            \"\"\"Define computer use tools.\"\"\"\r\n            return [\r\n                BetaToolComputerUse20241022(\r\n                    type=\"computer_20241022\",\r\n                    name=\"computer\",\r\n                    display_width_px=self.screen_size[0],\r\n                    display_height_px=self.screen_size[1],\r\n                ),\r\n                BetaToolBash20241022(\r\n                    type=\"bash_20241022\",\r\n                    name=\"bash\",\r\n                ),\r\n                BetaToolTextEditor20241022(\r\n                    type=\"text_editor_20241022\",\r\n                    name=\"str_replace_editor\",\r\n                ),\r\n            ]\r\n\n        def execute_tool(self, name: str, input: dict) -> dict:\r\n            \"\"\"Execute a tool and return result.\"\"\"\r\n\n            if name == \"computer\":\r\n                return self._handle_computer_action(input)\r\n            elif name == \"bash\":\r\n                return self._handle_bash(input)\r\n            elif name == \"str_replace_editor\":\r\n                return self._handle_editor(input)\r\n            else:\r\n                return {\"error\": f\"Unknown tool: {name}\"}\r\n\n        def _handle_computer_action(self, input: dict) -> dict:\r\n            \"\"\"Handle computer control actions.\"\"\"\r\n            action = input.get(\"action\")\r\n\n            if action == \"screenshot\":\r\n\n                subprocess.run([\"scrot\", \"/tmp/screenshot.png\"])\r\n\n                with open(\"/tmp/screenshot.png\", \"rb\") as f:\r\n                    img_data = f.read()\r\n\n\n                img = Image.open(io.BytesIO(img_data))\r\n                img = img.resize(self.screen_size, Image.LANCZOS)\r\n\n                buffer = io.BytesIO()\r\n                img.save(buffer, format=\"PNG\")\r\n\n                return {\r\n                    \"type\": \"image\",\r\n                    \"source\": {\r\n                        \"type\": \"base64\",\r\n                        \"media_type\": \"image/png\",\r\n                        \"data\": base64.b64encode(buffer.getvalue()).decode()\r\n                    }\r\n                }\r\n\n            elif action == \"mouse_move\":\r\n                x, y = input.get(\"coordinate\", [0, 0])\r\n                subprocess.run([\"xdotool\", \"mousemove\", str(x), str(y)])\r\n                return {\"success\": True}\r\n\n            elif action == \"left_click\":\r\n                subprocess.run([\"xdotool\", \"click\", \"1\"])\r\n                return {\"success\": True}\r\n\n            elif action == \"right_click\":\r\n                subprocess.run([\"xdotool\", \"click\", \"3\"])\r\n                return {\"success\": True}\r\n\n            elif action == \"double_click\":\r\n                subprocess.run([\"xdotool\", \"click\", \"--repeat\", \"2\", \"1\"])\r\n                return {\"success\": True}\r\n\n            elif action == \"type\":\r\n                text = input.get(\"text\", \"\")\r\n\n                subprocess.run([\"xdotool\", \"type\", \"--delay\", \"50\", text])\r\n                return {\"success\": True}\r\n\n            elif action == \"key\":\r\n                key = input.get(\"key\", \"\")\r\n\n                key_map = {\r\n                    \"return\": \"Return\",\r\n                    \"enter\": \"Return\",\r\n                    \"tab\": \"Tab\",\r\n                    \"escape\": \"Escape\",\r\n                    \"backspace\": \"BackSpace\",\r\n                }\r\n                xdotool_key = key_map.get(key.lower(), key)\r\n                subprocess.run([\"xdotool\", \"key\", xdotool_key])\r\n                return {\"success\": True}\r\n\n            elif action == \"scroll\":\r\n                direction = input.get(\"direction\", \"down\")\r\n                amount = input.get(\"amount\", 3)\r\n                button = \"5\" if direction == \"down\" else \"4\"\r\n                for _ in range(amount):\r\n                    subprocess.run([\"xdotool\", \"click\", button])\r\n                return {\"success\": True}\r\n\n            return {\"error\": f\"Unknown action: {action}\"}\r\n\n        def _handle_bash(self, input: dict) -> dict:\r\n            \"\"\"Execute bash command.\"\"\"\r\n            command = input.get(\"command\", \"\")\r\n\n\n            dangerous_patterns = [\"rm -rf\", \"mkfs\", \"dd if=\", \"> /dev/\"]\r\n            for pattern in dangerous_patterns:\r\n                if pattern in command:\r\n                    return {\"error\": \"Dangerous command blocked\"}\r\n\n            try:\r\n                result = subprocess.run(\r\n                    command,\r\n                    shell=True,\r\n                    capture_output=True,\r\n                    text=True,\r\n                    timeout=30\r\n                )\r\n                return {\r\n                    \"stdout\": result.stdout[:10000],  # Limit output\r\n                    \"stderr\": result.stderr[:1000],\r\n                    \"returncode\": result.returncode\r\n                }\r\n            except subprocess.TimeoutExpired:\r\n                return {\"error\": \"Command timed out\"}\r\n\n        def _handle_editor(self, input: dict) -> dict:\r\n            \"\"\"Handle text editor operations.\"\"\"\r\n            command = input.get(\"command\")\r\n            path = input.get(\"path\")\r\n\n            if command == \"view\":\r\n                try:\r\n                    with open(path, \"r\") as f:\r\n                        content = f.read()\r\n                    return {\"content\": content[:50000]}  # Limit size\r\n                except Exception as e:\r\n                    return {\"error\": str(e)}\r\n\n            elif command == \"str_replace\":\r\n                old_str = input.get(\"old_str\")\r\n                new_str = input.get(\"new_str\")\r\n                try:\r\n                    with open(path, \"r\") as f:\r\n                        content = f.read()\r\n                    if old_str not in content:\r\n                        return {\"error\": \"old_str not found in file\"}\r\n                    content = content.replace(old_str, new_str, 1)\r\n                    with open(path, \"w\") as f:\r\n                        f.write(content)\r\n                    return {\"success\": True}\r\n                except Exception as e:\r\n                    return {\"error\": str(e)}\r\n\n            return {\"error\": f\"Unknown editor command: {command}\"}\r\n\n        def run_task(self, task: str, max_steps: int = 50) -> dict:\r\n            \"\"\"Run computer use task with agentic loop.\"\"\"\r\n            messages = [{\"role\": \"user\", \"content\": task}]\r\n            tools = self.get_tools()\r\n\n            for step in range(max_steps):\r\n                response = self.client.beta.messages.create(\r\n                    model=self.model,\r\n                    max_tokens=4096,\r\n                    tools=tools,\r\n                    messages=messages,\r\n                    betas=[\"computer-use-2024-10-22\"]\r\n                )\r\n\n\n                if response.stop_reason == \"end_turn\":\r\n                    return {\r\n                        \"success\": True,\r\n                        \"result\": response.content[0].text if response.content else \"\",\r\n                        \"steps\": step + 1\r\n                    }\r\n\n\n                if response.stop_reason == \"tool_use\":\r\n                    messages.append({\"role\": \"assistant\", \"content\": response.content})\r\n\n                    tool_results = []\r\n                    for block in response.content:\r\n                        if block.type == \"tool_use\":\r\n                            result = self.execute_tool(block.name, block.input)\r\n                            tool_results.append({\r\n                                \"type\": \"tool_result\",\r\n                                \"tool_use_id\": block.id,\r\n                                \"content\": result\r\n                            })\r\n\n                    messages.append({\"role\": \"user\", \"content\": tool_results})\r\n\n            return {\"success\": False, \"error\": \"Max steps reached\"}\r\n  anti_patterns:\r\n    - \"Not using betas=['computer-use-2024-10-22'] flag\"\r\n    - \"Full resolution screenshots (wasteful)\"\r\n    - \"No command sanitization for bash tool\"\r\n    - \"Unbounded execution time\"\r\n\n- id: browser-use-pattern\r\n  name: Browser-Use Pattern (Playwright-based)\r\n  description: |\r\n    For browser-only automation, using structured DOM access is more efficient\r\n    than pixel-based computer use. Playwright MCP allows LLMs to control\r\n    browsers using accessibility snapshots rather than screenshots.\r\n\n    Advantages over vision-based:\r\n    - Faster: No image processing required\r\n    - Cheaper: Text tokens vs image tokens\r\n    - More precise: Direct element targeting\r\n    - More reliable: No coordinate drift\r\n\n    When to use vision vs structured:\r\n    - Vision: Desktop apps, complex UIs, visual verification\r\n    - Structured: Web automation, form filling, data extraction\r\n  when_to_use:\r\n    - \"Browser-only automation tasks\"\r\n    - \"Form filling and web interactions\"\r\n    - \"When speed and cost matter more than visual understanding\"\r\n  implementation: |\r\n    from playwright.async_api import async_playwright\r\n    from dataclasses import dataclass\r\n    from typing import Optional\r\n    import asyncio\r\n\n    @dataclass\r\n    class BrowserAction:\r\n        \"\"\"Structured browser action.\"\"\"\r\n        action: str  # click, type, navigate, scroll, extract\r\n        selector: Optional[str] = None\r\n        text: Optional[str] = None\r\n        url: Optional[str] = None\r\n\n    class BrowserUseAgent:\r\n        \"\"\"\r\n        Browser automation using Playwright with structured commands.\r\n        More efficient than pixel-based for web tasks.\r\n        \"\"\"\r\n\n        def __init__(self):\r\n            self.browser = None\r\n            self.page = None\r\n\n        async def start(self, headless: bool = True):\r\n            \"\"\"Start browser session.\"\"\"\r\n            self.playwright = await async_playwright().start()\r\n            self.browser = await self.playwright.chromium.launch(headless=headless)\r\n            self.page = await self.browser.new_page()\r\n\n        async def get_page_snapshot(self) -> dict:\r\n            \"\"\"\r\n            Get structured snapshot of page for LLM.\r\n            Uses accessibility tree for efficiency.\r\n            \"\"\"\r\n\n            snapshot = await self.page.accessibility.snapshot()\r\n\n\n            elements = await self.page.evaluate('''() => {\r\n                const interactable = [];\r\n                const selector = 'a, button, input, select, textarea, [role=\"button\"]';\r\n                document.querySelectorAll(selector).forEach((el, i) => {\r\n                    const rect = el.getBoundingClientRect();\r\n                    if (rect.width > 0 && rect.height > 0) {\r\n                        interactable.push({\r\n                            index: i,\r\n                            tag: el.tagName.toLowerCase(),\r\n                            text: el.textContent?.trim().slice(0, 100),\r\n                            type: el.type,\r\n                            placeholder: el.placeholder,\r\n                            name: el.name,\r\n                            id: el.id,\r\n                            class: el.className\r\n                        });\r\n                    }\r\n                });\r\n                return interactable;\r\n            }''')\r\n\n            return {\r\n                \"url\": self.page.url,\r\n                \"title\": await self.page.title(),\r\n                \"accessibility_tree\": snapshot,\r\n                \"interactable_elements\": elements[:50]  # Limit for token efficiency\r\n            }\r\n\n        async def execute_action(self, action: BrowserAction) -> dict:\r\n            \"\"\"Execute structured browser action.\"\"\"\r\n\n            try:\r\n                if action.action == \"navigate\":\r\n                    await self.page.goto(action.url, wait_until=\"domcontentloaded\")\r\n                    return {\"success\": True, \"url\": self.page.url}\r\n\n                elif action.action == \"click\":\r\n                    await self.page.click(action.selector, timeout=5000)\r\n                    await self.page.wait_for_load_state(\"networkidle\", timeout=5000)\r\n                    return {\"success\": True}\r\n\n                elif action.action == \"type\":\r\n                    await self.page.fill(action.selector, action.text)\r\n                    return {\"success\": True}\r\n\n                elif action.action == \"scroll\":\r\n                    direction = action.text or \"down\"\r\n                    distance = 500 if direction == \"down\" else -500\r\n                    await self.page.evaluate(f\"window.scrollBy(0, {distance})\")\r\n                    return {\"success\": True}\r\n\n                elif action.action == \"extract\":\r\n\n                    if action.selector:\r\n                        text = await self.page.text_content(action.selector)\r\n                    else:\r\n                        text = await self.page.text_content(\"body\")\r\n                    return {\"success\": True, \"text\": text[:5000]}\r\n\n                elif action.action == \"screenshot\":\r\n\n                    screenshot = await self.page.screenshot(type=\"png\")\r\n                    import base64\r\n                    return {\r\n                        \"success\": True,\r\n                        \"image\": base64.b64encode(screenshot).decode()\r\n                    }\r\n\n            except Exception as e:\r\n                return {\"success\": False, \"error\": str(e)}\r\n\n            return {\"success\": False, \"error\": f\"Unknown action: {action.action}\"}\r\n\n        async def run_with_llm(self, task: str, llm_client, max_steps: int = 20):\r\n            \"\"\"\r\n            Run browser task with LLM decision making.\r\n            Uses structured DOM instead of screenshots.\r\n            \"\"\"\r\n\n            system_prompt = \"\"\"You are a browser automation agent. You receive\r\n            page snapshots with interactable elements and decide actions.\r\n\n            Respond with JSON action:\r\n            - {\"action\": \"navigate\", \"url\": \"https://...\"}\r\n            - {\"action\": \"click\", \"selector\": \"button.submit\"}\r\n            - {\"action\": \"type\", \"selector\": \"input[name='email']\", \"text\": \"...\"}\r\n            - {\"action\": \"scroll\", \"text\": \"down\"}\r\n            - {\"action\": \"extract\", \"selector\": \".results\"}\r\n            - {\"action\": \"done\", \"result\": \"task completed\"}\r\n\n            Use CSS selectors based on the element info provided.\r\n            Prefer id > name > class > text content for selectors.\r\n            \"\"\"\r\n\n            messages = []\r\n\n            for step in range(max_steps):\r\n\n                snapshot = await self.get_page_snapshot()\r\n\n                user_message = f\"\"\"Task: {task}\r\n\n                Current page:\r\n                URL: {snapshot['url']}\r\n                Title: {snapshot['title']}\r\n\n                Interactable elements:\r\n                {snapshot['interactable_elements']}\r\n\n                What action should I take?\"\"\"\r\n\n                messages.append({\"role\": \"user\", \"content\": user_message})\r\n\n\n                response = llm_client.messages.create(\r\n                    model=\"claude-sonnet-4-20250514\",\r\n                    max_tokens=1024,\r\n                    system=system_prompt,\r\n                    messages=messages\r\n                )\r\n\n                assistant_text = response.content[0].text\r\n                messages.append({\"role\": \"assistant\", \"content\": assistant_text})\r\n\n\n                import json\r\n                action_dict = json.loads(assistant_text)\r\n\n                if action_dict.get(\"action\") == \"done\":\r\n                    return {\"success\": True, \"result\": action_dict.get(\"result\")}\r\n\n                action = BrowserAction(**action_dict)\r\n                result = await self.execute_action(action)\r\n\n                if not result.get(\"success\"):\r\n                    messages.append({\r\n                        \"role\": \"user\",\r\n                        \"content\": f\"Action failed: {result.get('error')}\"\r\n                    })\r\n\n                await asyncio.sleep(0.5)  # Rate limit\r\n\n            return {\"success\": False, \"error\": \"Max steps reached\"}\r\n\n        async def close(self):\r\n            \"\"\"Clean up browser.\"\"\"\r\n            if self.browser:\r\n                await self.browser.close()\r\n            if hasattr(self, 'playwright'):\r\n                await self.playwright.stop()\r\n\n\n    async def main():\r\n        agent = BrowserUseAgent()\r\n        await agent.start(headless=False)\r\n\n        from anthropic import Anthropic\r\n        result = await agent.run_with_llm(\r\n            \"Go to weather.com and find the weather for New York\",\r\n            Anthropic()\r\n        )\r\n\n        print(result)\r\n        await agent.close()\r\n\n    asyncio.run(main())\r\n  anti_patterns:\r\n    - \"Using screenshots when DOM access works\"\r\n    - \"Not waiting for page loads\"\r\n    - \"Hardcoded selectors that break\"\r\n    - \"No error recovery for stale elements\"\r\n\n- id: user-confirmation-pattern\r\n  name: User Confirmation Pattern\r\n  description: |\r\n    For sensitive actions, agents should pause and ask for human confirmation.\r\n    \"ChatGPT agent also pauses and asks for confirmation prior to taking\r\n    sensitive steps such as completing a purchase.\"\r\n\n    Sensitivity levels:\r\n    1. LOW: Navigation, reading (auto-approve)\r\n    2. MEDIUM: Form filling, clicking (log, maybe confirm)\r\n    3. HIGH: Purchases, authentication, file operations (always confirm)\r\n    4. CRITICAL: Credential entry, financial transactions (confirm + review)\r\n  when_to_use:\r\n    - \"Actions with real-world consequences\"\r\n    - \"Financial transactions\"\r\n    - \"Authentication flows\"\r\n    - \"File modifications\"\r\n  implementation: |\r\n    from enum import Enum\r\n    from dataclasses import dataclass\r\n    from typing import Callable, Optional\r\n    import asyncio\r\n\n    class ActionSeverity(Enum):\r\n        LOW = \"low\"           # Auto-approve\r\n        MEDIUM = \"medium\"     # Log, optional confirm\r\n        HIGH = \"high\"         # Always confirm\r\n        CRITICAL = \"critical\" # Confirm + review details\r\n\n    @dataclass\r\n    class SensitiveAction:\r\n        \"\"\"Action that may need user confirmation.\"\"\"\r\n        action_type: str\r\n        description: str\r\n        severity: ActionSeverity\r\n        details: dict\r\n\n    class ConfirmationGate:\r\n        \"\"\"\r\n        Gate sensitive actions through user confirmation.\r\n        \"\"\"\r\n\n\n        ACTION_SEVERITY = {\r\n\n            \"navigate\": ActionSeverity.LOW,\r\n            \"scroll\": ActionSeverity.LOW,\r\n            \"read\": ActionSeverity.LOW,\r\n            \"screenshot\": ActionSeverity.LOW,\r\n\n\n            \"click\": ActionSeverity.MEDIUM,\r\n            \"type\": ActionSeverity.MEDIUM,\r\n            \"search\": ActionSeverity.MEDIUM,\r\n\n\n            \"download\": ActionSeverity.HIGH,\r\n            \"submit_form\": ActionSeverity.HIGH,\r\n            \"login\": ActionSeverity.HIGH,\r\n            \"file_write\": ActionSeverity.HIGH,\r\n\n\n            \"purchase\": ActionSeverity.CRITICAL,\r\n            \"enter_password\": ActionSeverity.CRITICAL,\r\n            \"enter_credit_card\": ActionSeverity.CRITICAL,\r\n            \"send_money\": ActionSeverity.CRITICAL,\r\n            \"delete\": ActionSeverity.CRITICAL,\r\n        }\r\n\n        def __init__(\r\n            self,\r\n            confirm_callback: Callable[[SensitiveAction], bool] = None,\r\n            auto_confirm_low: bool = True,\r\n            auto_confirm_medium: bool = False\r\n        ):\r\n            self.confirm_callback = confirm_callback or self._default_confirm\r\n            self.auto_confirm_low = auto_confirm_low\r\n            self.auto_confirm_medium = auto_confirm_medium\r\n            self.action_log = []\r\n\n        def _default_confirm(self, action: SensitiveAction) -> bool:\r\n            \"\"\"Default confirmation via CLI prompt.\"\"\"\r\n            print(f\"\\n{'='*60}\")\r\n            print(f\"ACTION CONFIRMATION REQUIRED\")\r\n            print(f\"{'='*60}\")\r\n            print(f\"Type: {action.action_type}\")\r\n            print(f\"Severity: {action.severity.value.upper()}\")\r\n            print(f\"Description: {action.description}\")\r\n            print(f\"Details: {action.details}\")\r\n            print(f\"{'='*60}\")\r\n\n            while True:\r\n                response = input(\"Allow this action? [y/n]: \").lower().strip()\r\n                if response in ['y', 'yes']:\r\n                    return True\r\n                elif response in ['n', 'no']:\r\n                    return False\r\n\n        def classify_action(self, action_type: str, context: dict) -> ActionSeverity:\r\n            \"\"\"Classify action severity, considering context.\"\"\"\r\n            base_severity = self.ACTION_SEVERITY.get(action_type, ActionSeverity.MEDIUM)\r\n\n\n            if context.get(\"involves_credentials\"):\r\n                return ActionSeverity.CRITICAL\r\n            if context.get(\"involves_money\"):\r\n                return ActionSeverity.CRITICAL\r\n            if context.get(\"irreversible\"):\r\n                return max(base_severity, ActionSeverity.HIGH, key=lambda x: x.value)\r\n\n            return base_severity\r\n\n        def check_action(\r\n            self,\r\n            action_type: str,\r\n            description: str,\r\n            details: dict = None\r\n        ) -> tuple[bool, str]:\r\n            \"\"\"\r\n            Check if action should proceed.\r\n            Returns (approved, reason).\r\n            \"\"\"\r\n            details = details or {}\r\n            severity = self.classify_action(action_type, details)\r\n\n            action = SensitiveAction(\r\n                action_type=action_type,\r\n                description=description,\r\n                severity=severity,\r\n                details=details\r\n            )\r\n\n\n            self.action_log.append({\r\n                \"action\": action,\r\n                \"timestamp\": __import__('datetime').datetime.now().isoformat()\r\n            })\r\n\n\n            if severity == ActionSeverity.LOW and self.auto_confirm_low:\r\n                return True, \"auto-approved (low severity)\"\r\n\n\n            if severity == ActionSeverity.MEDIUM and self.auto_confirm_medium:\r\n                return True, \"auto-approved (medium severity)\"\r\n\n\n            approved = self.confirm_callback(action)\r\n\n            if approved:\r\n                return True, \"user approved\"\r\n            else:\r\n                return False, \"user rejected\"\r\n\n    class ConfirmedComputerUseAgent:\r\n        \"\"\"\r\n        Computer use agent with confirmation gates.\r\n        \"\"\"\r\n\n        def __init__(self, base_agent, confirmation_gate: ConfirmationGate):\r\n            self.agent = base_agent\r\n            self.gate = confirmation_gate\r\n\n        def execute_action(self, action: dict) -> dict:\r\n            \"\"\"Execute action with confirmation check.\"\"\"\r\n            action_type = action.get(\"type\", \"unknown\")\r\n\n\n            if action_type == \"click\":\r\n                desc = f\"Click at ({action.get('x')}, {action.get('y')})\"\r\n            elif action_type == \"type\":\r\n                text = action.get('text', '')\r\n\n                if self._looks_sensitive(text):\r\n                    desc = f\"Type sensitive text ({len(text)} chars)\"\r\n                else:\r\n                    desc = f\"Type: {text[:50]}...\"\r\n            else:\r\n                desc = f\"Execute: {action_type}\"\r\n\n\n            context = {\r\n                \"involves_credentials\": self._looks_sensitive(action.get(\"text\", \"\")),\r\n                \"involves_money\": self._mentions_money(action),\r\n            }\r\n\n\n            approved, reason = self.gate.check_action(\r\n                action_type, desc, context\r\n            )\r\n\n            if not approved:\r\n                return {\r\n                    \"success\": False,\r\n                    \"error\": f\"Action blocked: {reason}\",\r\n                    \"action\": action_type\r\n                }\r\n\n\n            return self.agent.execute_action(action)\r\n\n        def _looks_sensitive(self, text: str) -> bool:\r\n            \"\"\"Check if text looks like sensitive data.\"\"\"\r\n            if not text:\r\n                return False\r\n\n            patterns = [\r\n                r'\\b\\d{16}\\b',  # Credit card\r\n                r'\\b\\d{3,4}\\b.*\\b\\d{3,4}\\b',  # CVV-like\r\n                r'password',\r\n                r'secret',\r\n                r'api.?key',\r\n                r'token'\r\n            ]\r\n            import re\r\n            return any(re.search(p, text.lower()) for p in patterns)\r\n\n        def _mentions_money(self, action: dict) -> bool:\r\n            \"\"\"Check if action involves money.\"\"\"\r\n            text = str(action)\r\n            money_patterns = [\r\n                r'\\$\\d+', r'pay', r'purchase', r'buy', r'checkout',\r\n                r'credit', r'debit', r'invoice', r'payment'\r\n            ]\r\n            import re\r\n            return any(re.search(p, text.lower()) for p in money_patterns)\r\n\n\n    gate = ConfirmationGate(\r\n        auto_confirm_low=True,\r\n        auto_confirm_medium=False  # Confirm clicks, typing\r\n    )\r\n\n    agent = ConfirmedComputerUseAgent(base_agent, gate)\r\n    result = agent.execute_action({\"type\": \"click\", \"x\": 500, \"y\": 300})\r\n  anti_patterns:\r\n    - \"Auto-approving all actions\"\r\n    - \"Not logging rejected actions\"\r\n    - \"Showing full passwords in confirmation\"\r\n    - \"No timeout on confirmation (hangs forever)\"\r\n\n- id: action-logging-pattern\r\n  name: Action Logging Pattern\r\n  description: |\r\n    All computer use agent actions should be logged for:\r\n    1. Debugging failed automations\r\n    2. Security auditing\r\n    3. Reproducibility\r\n    4. Compliance requirements\r\n\n    Log format should capture:\r\n    - Timestamp\r\n    - Action type and parameters\r\n    - Screenshot before/after\r\n    - Success/failure status\r\n    - Model reasoning (if available)\r\n  when_to_use:\r\n    - \"Production computer use deployments\"\r\n    - \"Debugging automation failures\"\r\n    - \"Security-sensitive environments\"\r\n  implementation: |\r\n    from dataclasses import dataclass, field\r\n    from datetime import datetime\r\n    from typing import Optional, Any\r\n    import json\r\n    import os\r\n\n    @dataclass\r\n    class ActionLogEntry:\r\n        \"\"\"Single action log entry.\"\"\"\r\n        timestamp: datetime\r\n        action_type: str\r\n        parameters: dict\r\n        success: bool\r\n        error: Optional[str] = None\r\n        screenshot_before: Optional[str] = None  # Path to screenshot\r\n        screenshot_after: Optional[str] = None\r\n        model_reasoning: Optional[str] = None\r\n        duration_ms: Optional[int] = None\r\n\n        def to_dict(self) -> dict:\r\n            return {\r\n                \"timestamp\": self.timestamp.isoformat(),\r\n                \"action_type\": self.action_type,\r\n                \"parameters\": self._sanitize_params(self.parameters),\r\n                \"success\": self.success,\r\n                \"error\": self.error,\r\n                \"screenshot_before\": self.screenshot_before,\r\n                \"screenshot_after\": self.screenshot_after,\r\n                \"model_reasoning\": self.model_reasoning,\r\n                \"duration_ms\": self.duration_ms\r\n            }\r\n\n        def _sanitize_params(self, params: dict) -> dict:\r\n            \"\"\"Remove sensitive data from params.\"\"\"\r\n            sanitized = {}\r\n            sensitive_keys = ['password', 'secret', 'token', 'key', 'credit_card']\r\n\n            for k, v in params.items():\r\n                if any(s in k.lower() for s in sensitive_keys):\r\n                    sanitized[k] = \"[REDACTED]\"\r\n                elif isinstance(v, str) and len(v) > 100:\r\n                    sanitized[k] = v[:100] + \"...[truncated]\"\r\n                else:\r\n                    sanitized[k] = v\r\n\n            return sanitized\r\n\n    @dataclass\r\n    class TaskSession:\r\n        \"\"\"A complete task execution session.\"\"\"\r\n        session_id: str\r\n        task: str\r\n        start_time: datetime\r\n        end_time: Optional[datetime] = None\r\n        actions: list[ActionLogEntry] = field(default_factory=list)\r\n        success: bool = False\r\n        final_result: Optional[str] = None\r\n\n    class ActionLogger:\r\n        \"\"\"\r\n        Comprehensive action logging for computer use agents.\r\n        \"\"\"\r\n\n        def __init__(self, log_dir: str = \"./agent_logs\"):\r\n            self.log_dir = log_dir\r\n            self.screenshot_dir = os.path.join(log_dir, \"screenshots\")\r\n            os.makedirs(self.screenshot_dir, exist_ok=True)\r\n\n            self.current_session: Optional[TaskSession] = None\r\n\n        def start_session(self, task: str) -> str:\r\n            \"\"\"Start a new task session.\"\"\"\r\n            import uuid\r\n            session_id = str(uuid.uuid4())[:8]\r\n\n            self.current_session = TaskSession(\r\n                session_id=session_id,\r\n                task=task,\r\n                start_time=datetime.now()\r\n            )\r\n\n            return session_id\r\n\n        def log_action(\r\n            self,\r\n            action_type: str,\r\n            parameters: dict,\r\n            success: bool,\r\n            error: Optional[str] = None,\r\n            screenshot_before: bytes = None,\r\n            screenshot_after: bytes = None,\r\n            model_reasoning: str = None,\r\n            duration_ms: int = None\r\n        ):\r\n            \"\"\"Log a single action.\"\"\"\r\n            if not self.current_session:\r\n                raise RuntimeError(\"No active session\")\r\n\n\n            screenshot_paths = {}\r\n            timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\r\n\n            if screenshot_before:\r\n                path = os.path.join(\r\n                    self.screenshot_dir,\r\n                    f\"{self.current_session.session_id}_{timestamp_str}_before.png\"\r\n                )\r\n                with open(path, \"wb\") as f:\r\n                    f.write(screenshot_before)\r\n                screenshot_paths[\"before\"] = path\r\n\n            if screenshot_after:\r\n                path = os.path.join(\r\n                    self.screenshot_dir,\r\n                    f\"{self.current_session.session_id}_{timestamp_str}_after.png\"\r\n                )\r\n                with open(path, \"wb\") as f:\r\n                    f.write(screenshot_after)\r\n                screenshot_paths[\"after\"] = path\r\n\n\n            entry = ActionLogEntry(\r\n                timestamp=datetime.now(),\r\n                action_type=action_type,\r\n                parameters=parameters,\r\n                success=success,\r\n                error=error,\r\n                screenshot_before=screenshot_paths.get(\"before\"),\r\n                screenshot_after=screenshot_paths.get(\"after\"),\r\n                model_reasoning=model_reasoning,\r\n                duration_ms=duration_ms\r\n            )\r\n\n            self.current_session.actions.append(entry)\r\n\n\n            self._append_to_log(entry)\r\n\n        def _append_to_log(self, entry: ActionLogEntry):\r\n            \"\"\"Append entry to JSONL log file.\"\"\"\r\n            log_file = os.path.join(\r\n                self.log_dir,\r\n                f\"session_{self.current_session.session_id}.jsonl\"\r\n            )\r\n\n            with open(log_file, \"a\") as f:\r\n                f.write(json.dumps(entry.to_dict()) + \"\\n\")\r\n\n        def end_session(self, success: bool, result: str = None):\r\n            \"\"\"End current session.\"\"\"\r\n            if not self.current_session:\r\n                return\r\n\n            self.current_session.end_time = datetime.now()\r\n            self.current_session.success = success\r\n            self.current_session.final_result = result\r\n\n\n            summary_file = os.path.join(\r\n                self.log_dir,\r\n                f\"session_{self.current_session.session_id}_summary.json\"\r\n            )\r\n\n            summary = {\r\n                \"session_id\": self.current_session.session_id,\r\n                \"task\": self.current_session.task,\r\n                \"start_time\": self.current_session.start_time.isoformat(),\r\n                \"end_time\": self.current_session.end_time.isoformat(),\r\n                \"duration_seconds\": (\r\n                    self.current_session.end_time -\r\n                    self.current_session.start_time\r\n                ).total_seconds(),\r\n                \"total_actions\": len(self.current_session.actions),\r\n                \"successful_actions\": sum(\r\n                    1 for a in self.current_session.actions if a.success\r\n                ),\r\n                \"failed_actions\": sum(\r\n                    1 for a in self.current_session.actions if not a.success\r\n                ),\r\n                \"success\": success,\r\n                \"final_result\": result\r\n            }\r\n\n            with open(summary_file, \"w\") as f:\r\n                json.dump(summary, f, indent=2)\r\n\n            self.current_session = None\r\n\n        def get_session_replay(self, session_id: str) -> list[dict]:\r\n            \"\"\"Get all actions from a session for replay/debugging.\"\"\"\r\n            log_file = os.path.join(self.log_dir, f\"session_{session_id}.jsonl\")\r\n\n            actions = []\r\n            with open(log_file, \"r\") as f:\r\n                for line in f:\r\n                    actions.append(json.loads(line))\r\n\n            return actions\r\n\n\n    class LoggedComputerUseAgent:\r\n        \"\"\"Computer use agent with comprehensive logging.\"\"\"\r\n\n        def __init__(self, base_agent, logger: ActionLogger):\r\n            self.agent = base_agent\r\n            self.logger = logger\r\n\n        def run_task(self, task: str) -> dict:\r\n            \"\"\"Run task with full logging.\"\"\"\r\n            session_id = self.logger.start_session(task)\r\n\n            try:\r\n                result = self._run_with_logging(task)\r\n                self.logger.end_session(\r\n                    success=result.get(\"success\", False),\r\n                    result=result.get(\"result\")\r\n                )\r\n                return result\r\n            except Exception as e:\r\n                self.logger.end_session(success=False, result=str(e))\r\n                raise\r\n\n        def _run_with_logging(self, task: str) -> dict:\r\n            \"\"\"Internal run with action logging.\"\"\"\r\n\n\n            pass\r\n  anti_patterns:\r\n    - \"Not sanitizing sensitive data in logs\"\r\n    - \"Storing screenshots indefinitely (storage costs)\"\r\n    - \"Not rotating log files\"\r\n    - \"Logging synchronously (blocks agent)\"",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "computer use",
          "desktop automation agent",
          "screen control AI",
          "vision-based agent",
          "GUI automation",
          "Claude computer",
          "OpenAI Operator",
          "browser agent",
          "visual agent",
          "RPA with AI"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "agents"
      },
      {
        "id": "voice-agents",
        "name": "Voice Agents",
        "version": "1.0.0",
        "layer": 1,
        "description": "Adding components without considering latency impact",
        "principles": [
          "Latency is the constraint - target <800ms end-to-end",
          "Jitter (variance) matters as much as absolute latency",
          "VAD quality determines conversation flow",
          "Interruption handling makes or breaks the experience",
          "Start with focused MVP, iterate based on real conversations",
          "Combine best-in-class components (Deepgram STT + ElevenLabs TTS)"
        ],
        "owns": [
          "voice-agents",
          "speech-to-speech",
          "speech-to-text",
          "text-to-speech",
          "conversational-ai",
          "voice-activity-detection",
          "turn-taking",
          "barge-in-detection",
          "voice-interfaces"
        ],
        "does_not_own": [
          "phone-system-integration → backend",
          "audio-processing-dsp → audio-specialist",
          "music-generation → audio-specialist",
          "accessibility-compliance → accessibility-specialist"
        ],
        "triggers": [
          "voice agent",
          "speech to text",
          "text to speech",
          "whisper",
          "elevenlabs",
          "deepgram",
          "realtime api",
          "voice assistant",
          "voice ai",
          "conversational ai",
          "tts",
          "stt",
          "asr"
        ],
        "tags": [
          "voice",
          "speech",
          "tts",
          "stt",
          "whisper",
          "elevenlabs",
          "deepgram",
          "realtime",
          "conversational-ai",
          "vad",
          "barge-in"
        ],
        "pairs_with": [
          "agent-tool-builder         # Tools for voice agents",
          "multi-agent-orchestration  # Voice in multi-agent systems",
          "llm-architect              # LLM integration",
          "backend                    # Phone integration"
        ],
        "requires": [],
        "category": "agents"
      },
      {
        "id": "workflow-automation",
        "name": "Workflow Automation",
        "version": "1.0.0",
        "layer": 1,
        "description": "Processing payments without crash recovery",
        "principles": [
          "Durable execution is non-negotiable for money or state-critical workflows",
          "Events are the universal language of workflow triggers",
          "Steps are checkpoints - each should be independently retryable",
          "Start simple, add complexity only when reliability demands it",
          "Observability isn't optional - you need to see where workflows fail",
          "Workflows and agents co-evolve - design for both"
        ],
        "owns": [
          "workflow-automation",
          "workflow-orchestration",
          "durable-execution",
          "event-driven-workflows",
          "step-functions",
          "job-queues",
          "background-jobs",
          "scheduled-tasks"
        ],
        "does_not_own": [
          "multi-agent-coordination → multi-agent-orchestration",
          "ci-cd-pipelines → devops",
          "data-pipelines → data-engineer",
          "api-design → api-designer"
        ],
        "triggers": [
          "workflow",
          "automation",
          "n8n",
          "temporal",
          "inngest",
          "step function",
          "background job",
          "durable execution",
          "event-driven",
          "scheduled task",
          "job queue",
          "cron",
          "trigger"
        ],
        "tags": [
          "workflow",
          "automation",
          "n8n",
          "temporal",
          "inngest",
          "durable-execution",
          "event-driven",
          "serverless",
          "background-jobs"
        ],
        "pairs_with": [
          "multi-agent-orchestration  # Orchestration patterns",
          "agent-tool-builder         # Tools within workflows",
          "backend                    # Implementation details",
          "devops                     # Deployment and monitoring"
        ],
        "requires": [],
        "category": "agents"
      },
      {
        "id": "zapier-make-patterns",
        "name": "Zapier & Make Patterns",
        "version": "1.0.0",
        "layer": 1,
        "description": "Entering text when IDs are expected",
        "principles": [
          "Start simple, add complexity only when needed",
          "Test with real data before going live",
          "Document every automation with clear naming",
          "Monitor errors - 95% error rate auto-disables Zaps",
          "Know when to graduate to code-based solutions",
          "Operations/tasks cost money - design efficiently"
        ],
        "owns": [
          "zapier",
          "make",
          "integromat",
          "no-code-automation",
          "zaps",
          "scenarios",
          "workflow-builders",
          "business-process-automation"
        ],
        "does_not_own": [
          "code-based-workflows → workflow-automation",
          "browser-automation → browser-automation",
          "custom-integrations → backend",
          "api-development → api-designer"
        ],
        "triggers": [
          "zapier",
          "make",
          "integromat",
          "zap",
          "scenario",
          "no-code automation",
          "trigger action",
          "workflow automation",
          "connect apps",
          "automate"
        ],
        "tags": [
          "zapier",
          "make",
          "integromat",
          "no-code",
          "automation",
          "workflow",
          "integration",
          "business-process",
          "triggers",
          "actions"
        ],
        "pairs_with": [
          "workflow-automation        # When to upgrade from no-code",
          "agent-tool-builder         # MCP and Zapier Agents",
          "backend                    # Custom code steps",
          "api-designer               # API integrations"
        ],
        "requires": [],
        "category": "agents"
      }
    ]
  },
  {
    "id": "ai",
    "name": "AI & Machine Learning",
    "skills": [
      {
        "id": "nlp-advanced",
        "name": "Advanced NLP",
        "version": "1.0.0",
        "layer": 1,
        "description": "Begin-Inside-Last-Outside-Unit",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "ai"
      },
      {
        "id": "art-consistency",
        "name": "Art Consistency & Visual QA",
        "version": "1.0.0",
        "layer": 1,
        "description": "Generating images without reference or documentation and hoping they match",
        "principles": [],
        "owns": [
          "character-consistency",
          "art-style-consistency",
          "visual-identity-management",
          "character-bible-creation",
          "turnaround-sheet-generation",
          "prompt-engineering-for-consistency",
          "pre-generation-validation",
          "post-generation-qa",
          "style-reference-management",
          "color-palette-enforcement",
          "visual-series-continuity"
        ],
        "does_not_own": [],
        "triggers": [
          "character consistency",
          "art style",
          "same character",
          "consistent character",
          "visual continuity",
          "series",
          "turnaround sheet",
          "character sheet",
          "reference image",
          "character bible",
          "style guide",
          "anime character",
          "consistent look",
          "face consistency",
          "outfit consistency",
          "lora training",
          "ip-adapter",
          "flux kontext",
          "visual qa",
          "art quality",
          "generation review",
          "style drift",
          "character drift"
        ],
        "tags": [
          "character-consistency",
          "art-style",
          "visual-qa",
          "ai-art",
          "image-generation",
          "video-generation",
          "anime",
          "illustration",
          "lora",
          "ip-adapter",
          "flux",
          "midjourney",
          "stable-diffusion"
        ],
        "pairs_with": [
          "ai-image-generation",
          "ai-video-generation",
          "ai-creative-director",
          "ui-design",
          "branding",
          "prompt-engineering-creative"
        ],
        "requires": [],
        "category": "ai"
      },
      {
        "id": "causal-scientist",
        "name": "Causal Scientist",
        "version": "1.0.0",
        "layer": 1,
        "description": "Assuming all confounders are measured",
        "principles": [],
        "owns": [
          "causal-inference",
          "structural-causal-models",
          "causal-discovery",
          "counterfactuals",
          "intervention-effects",
          "confound-detection",
          "dowhy-gcm"
        ],
        "does_not_own": [],
        "triggers": [
          "causal inference",
          "causal discovery",
          "counterfactual",
          "intervention effect",
          "confounder",
          "structural causal model",
          "SCM",
          "dowhy",
          "causal graph"
        ],
        "tags": [
          "causal",
          "dowhy",
          "scm",
          "dag",
          "counterfactual",
          "intervention",
          "causalnex",
          "confounding",
          "ai-memory"
        ],
        "pairs_with": [
          "graph-engineer",
          "ml-memory",
          "vector-specialist",
          "event-architect",
          "performance-hunter"
        ],
        "requires": [],
        "category": "ai"
      },
      {
        "id": "computer-vision-deep",
        "name": "Computer Vision Deep",
        "version": "1.0.0",
        "layer": 1,
        "description": "Self-supervised vision transformer",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "ai"
      },
      {
        "id": "distributed-training",
        "name": "Distributed Training",
        "version": "1.0.0",
        "layer": 1,
        "description": "Shard optimizer, gradients, parameters",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "ai"
      },
      {
        "id": "llm-architect",
        "name": "LLM Architect",
        "version": "1.0.0",
        "layer": 1,
        "description": "Filling context with everything \"just in case",
        "principles": [],
        "owns": [
          "rag-architecture",
          "prompt-engineering",
          "structured-output",
          "multi-agent-systems",
          "context-management",
          "llm-orchestration",
          "hallucination-mitigation",
          "token-optimization"
        ],
        "does_not_own": [],
        "triggers": [
          "rag system",
          "prompt engineering",
          "llm application",
          "ai agent",
          "structured output",
          "chain of thought",
          "multi-agent",
          "context window",
          "hallucination",
          "token optimization"
        ],
        "tags": [
          "llm",
          "rag",
          "prompting",
          "agents",
          "structured-output",
          "anthropic",
          "openai",
          "langchain",
          "ai-architecture"
        ],
        "pairs_with": [
          "vector-specialist",
          "ml-memory",
          "event-architect",
          "api-designer",
          "privacy-guardian",
          "performance-hunter"
        ],
        "requires": [],
        "category": "ai"
      },
      {
        "id": "llm-fine-tuning",
        "name": "LLM Fine-Tuning",
        "version": "1.0.0",
        "layer": 1,
        "description": "Scaling factor",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "ai"
      },
      {
        "id": "ml-memory",
        "name": "ML Memory Engineer",
        "version": "1.0.0",
        "layer": 1,
        "description": "No connection between memory retrieval and decision quality",
        "principles": [],
        "owns": [
          "memory-hierarchy",
          "memory-consolidation",
          "memory-decay",
          "salience-learning",
          "entity-resolution",
          "outcome-feedback",
          "temporal-memory"
        ],
        "does_not_own": [],
        "triggers": [
          "memory system",
          "memory hierarchy",
          "memory consolidation",
          "forgetting strategy",
          "salience learning",
          "outcome feedback",
          "temporal memory levels",
          "entity resolution"
        ],
        "tags": [
          "memory",
          "zep",
          "graphiti",
          "mem0",
          "letta",
          "hierarchical",
          "consolidation",
          "salience",
          "forgetting",
          "ai-memory"
        ],
        "pairs_with": [
          "vector-specialist",
          "graph-engineer",
          "temporal-craftsman",
          "causal-scientist",
          "privacy-guardian",
          "performance-hunter"
        ],
        "requires": [],
        "category": "ai"
      },
      {
        "id": "model-optimization",
        "name": "Model Optimization",
        "version": "1.0.0",
        "layer": 1,
        "description": "Convert to optimized runtime",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "ai"
      },
      {
        "id": "neural-architecture-search",
        "name": "Neural Architecture Search",
        "version": "1.0.0",
        "layer": 1,
        "description": "Stop unpromising trials early",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "ai"
      },
      {
        "id": "reinforcement-learning",
        "name": "Reinforcement Learning",
        "version": "1.0.0",
        "layer": 1,
        "description": "Optimize policy with KL penalty",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "ai"
      },
      {
        "id": "transformer-architecture",
        "name": "Transformer Architecture",
        "version": "1.0.0",
        "layer": 1,
        "description": "Fewer KV heads than query heads",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "ai"
      }
    ]
  },
  {
    "id": "ai-ml",
    "name": "Ai-ml",
    "skills": [
      {
        "id": "ai-code-generation",
        "name": "AI Code Generation",
        "version": "1.0.0",
        "layer": 1,
        "description": "Generate code with strict schema validation",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "code generation",
          "AI code assistant",
          "function calling",
          "structured output",
          "code review AI",
          "automated refactoring",
          "tool use",
          "code completion",
          "agent code"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "ai-ml"
      },
      {
        "id": "ai-music-audio",
        "name": "AI Music & Audio Generation",
        "version": "1.0.0",
        "layer": 1,
        "description": "Generate music from text descriptions using Meta's MusicGen",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "music generation",
          "text to music",
          "AI music",
          "voice cloning",
          "text to speech",
          "TTS API",
          "ElevenLabs",
          "MusicGen",
          "Bark",
          "audio synthesis",
          "sound effects generation",
          "voice synthesis",
          "AudioCraft"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "ai-ml"
      },
      {
        "id": "ai-observability",
        "name": "ai-observability",
        "version": "1.0.0",
        "layer": 1,
        "description": "Running LLM apps without observability",
        "principles": [
          "name: \"Trace Every LLM Call"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [
          "llm-monitoring",
          "tracing",
          "langfuse",
          "helicone",
          "cost-tracking",
          "ragas",
          "evaluation",
          "hallucination-detection",
          "prompt-caching"
        ],
        "pairs_with": [],
        "requires": [],
        "category": "ai-ml"
      },
      {
        "id": "ai-personalization",
        "name": "ai-personalization",
        "version": "1.0.0",
        "layer": 1,
        "description": "Basic collaborative filtering with embeddings",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "recommendation system",
          "personalization",
          "collaborative filtering",
          "content-based filtering",
          "user preferences",
          "recommend",
          "suggestions",
          "for you",
          "similar items",
          "you might like"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "ai-ml"
      },
      {
        "id": "ai-safety-alignment",
        "name": "ai-safety-alignment",
        "version": "1.0.0",
        "layer": 1,
        "description": "Passing user input directly to LLM without validation",
        "principles": [
          "name: \"Defense in Depth"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [
          "guardrails",
          "content-moderation",
          "prompt-injection",
          "jailbreak-prevention",
          "pii-detection",
          "nemo-guardrails",
          "openai-moderation",
          "llama-guard",
          "safety"
        ],
        "pairs_with": [],
        "requires": [],
        "category": "ai-ml"
      },
      {
        "id": "document-ai",
        "name": "Document AI",
        "version": "1.0.0",
        "layer": 1,
        "description": "Extract structured data from PDFs using Claude's vision",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "document parsing",
          "PDF extraction",
          "OCR",
          "invoice processing",
          "receipt extraction",
          "document understanding",
          "LlamaParse",
          "Unstructured",
          "vision document",
          "table extraction",
          "structured output from PDF"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "ai-ml"
      },
      {
        "id": "ai-image-editing",
        "name": "Inpainting with Replicate API",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use Replicate's Flux Fill model for professional inpainting.\r\n    Mask white areas to be filled, black to preserve.\r\n\n    Model options:\r\n    - flux-fill-pro: Best quality, seamless blending\r\n    - flux-dev-inpainting: Good balance of speed/quality\r\n    - sdxl-inpainting: SDXL-based, lower cost\r\n\n  code_example: |\r\n\n\n    import replicate\r\n    import base64\r\n    from pathlib import Path\r\n\n\n    client = replicate.Client(api_token=os.environ[\"REPLICATE_API_TOKEN\"])\r\n\n\n    def encode_image(path: str) -> str:\r\n        \"\"\"Encode image to base64 data URI.\"\"\"\r\n        data = Path(path).read_bytes()\r\n        return f\"data:image/png;base64,{base64.b64encode(data).decode()}\"\r\n\n\n    output = client.run(\r\n        \"black-forest-labs/flux-fill-pro\",\r\n        input={\r\n            \"image\": encode_image(\"input.png\"),\r\n            \"mask\": encode_image(\"mask.png\"),  # White = edit, Black = keep\r\n            \"prompt\": \"a red sports car parked on the street\",\r\n            \"output_format\": \"png\",\r\n        }\r\n    )\r\n\n\n    with open(\"output.png\", \"wb\") as f:\r\n        f.write(output.read())\r\n\n\n    output = client.run(\r\n        \"zsxkib/flux-dev-inpainting\",\r\n        input={\r\n            \"image\": encode_image(\"input.png\"),\r\n            \"mask\": encode_image(\"mask.png\"),\r\n            \"prompt\": \"modern office furniture\",\r\n            \"num_inference_steps\": 28,\r\n            \"guidance_scale\": 3.5,\r\n            \"strength\": 0.85,  # 0.5-0.85 recommended\r\n        }\r\n    )\r\n\n\n    prediction = client.predictions.create(\r\n        model=\"black-forest-labs/flux-fill-pro\",\r\n        input={\r\n            \"image\": encode_image(\"input.png\"),\r\n            \"mask\": encode_image(\"mask.png\"),\r\n            \"prompt\": \"vintage furniture in cozy room\",\r\n        }\r\n    )\r\n\n\n    prediction = client.predictions.wait(prediction)\r\n    print(f\"Status: {prediction.status}\")\r\n    print(f\"Output: {prediction.output}\")\r\n\n  anti_patterns:\r\n    - pattern: \"Mask with inverted colors\"\r\n      why: \"White should be edit area, black should be preserve\"\r\n      fix: \"Invert mask before sending to API\"\r\n\n    - pattern: \"Very high strength for subtle edits\"\r\n      why: \"Strength 0.9+ completely replaces content\"\r\n      fix: \"Use 0.5-0.75 for balanced edits\"\r\n\n  references:\r\n    - \"https://replicate.com/black-forest-labs/flux-fill-pro\"\r\n    - \"https://replicate.com/collections/image-editing\"\r\n\n- id: stability-search-replace\r\n  name: Stability AI Search and Replace\r\n  description: |\r\n    Replace objects without creating masks manually.\r\n    Describe what to find and what to replace it with.\r\n\n    Available on AWS Bedrock and direct API.\r\n    No mask required - AI automatically segments.\r\n\n  code_example: |\r\n    import requests\r\n    import base64\r\n    from pathlib import Path\r\n\n    STABILITY_API_KEY = os.environ[\"STABILITY_API_KEY\"]\r\n\n    def search_and_replace(\r\n        image_path: str,\r\n        search_prompt: str,\r\n        replace_prompt: str,\r\n        output_path: str = \"output.png\"\r\n    ):\r\n        \"\"\"Replace objects in image by description.\"\"\"\r\n\n        with open(image_path, \"rb\") as f:\r\n            image_data = f.read()\r\n\n        response = requests.post(\r\n            \"https://api.stability.ai/v2beta/stable-image/edit/search-and-replace\",\r\n            headers={\r\n                \"Authorization\": f\"Bearer {STABILITY_API_KEY}\",\r\n                \"Accept\": \"image/*\",\r\n            },\r\n            files={\r\n                \"image\": image_data,\r\n            },\r\n            data={\r\n                \"search_prompt\": search_prompt,\r\n                \"prompt\": replace_prompt,\r\n                \"output_format\": \"png\",\r\n            },\r\n        )\r\n\n        if response.status_code == 200:\r\n            with open(output_path, \"wb\") as f:\r\n                f.write(response.content)\r\n            return output_path\r\n        else:\r\n            raise Exception(f\"Error: {response.status_code} - {response.text}\")\r\n\n\n    search_and_replace(\r\n        image_path=\"room.png\",\r\n        search_prompt=\"old wooden chair\",\r\n        replace_prompt=\"modern ergonomic office chair\",\r\n        output_path=\"room_updated.png\"\r\n    )\r\n\n\n    def erase_object(image_path: str, mask_path: str, output_path: str):\r\n        \"\"\"Remove object and fill with background.\"\"\"\r\n\n        with open(image_path, \"rb\") as img_f:\r\n            image_data = img_f.read()\r\n        with open(mask_path, \"rb\") as mask_f:\r\n            mask_data = mask_f.read()\r\n\n        response = requests.post(\r\n            \"https://api.stability.ai/v2beta/stable-image/edit/erase\",\r\n            headers={\r\n                \"Authorization\": f\"Bearer {STABILITY_API_KEY}\",\r\n                \"Accept\": \"image/*\",\r\n            },\r\n            files={\r\n                \"image\": image_data,\r\n                \"mask\": mask_data,  # White = area to erase\r\n            },\r\n            data={\r\n                \"output_format\": \"png\",\r\n            },\r\n        )\r\n\n        if response.status_code == 200:\r\n            with open(output_path, \"wb\") as f:\r\n                f.write(response.content)\r\n\n\n    def remove_background(image_path: str, output_path: str):\r\n        \"\"\"Remove background, return transparent PNG.\"\"\"\r\n\n        with open(image_path, \"rb\") as f:\r\n            image_data = f.read()\r\n\n        response = requests.post(\r\n            \"https://api.stability.ai/v2beta/stable-image/edit/remove-background\",\r\n            headers={\r\n                \"Authorization\": f\"Bearer {STABILITY_API_KEY}\",\r\n                \"Accept\": \"image/*\",\r\n            },\r\n            files={\"image\": image_data},\r\n            data={\"output_format\": \"png\"},\r\n        )\r\n\n        if response.status_code == 200:\r\n            with open(output_path, \"wb\") as f:\r\n                f.write(response.content)\r\n\n  anti_patterns:\r\n    - pattern: \"Vague search prompts\"\r\n      why: \"AI may match wrong objects\"\r\n      fix: \"Be specific: 'red leather sofa' not 'furniture'\"\r\n\n    - pattern: \"Not handling rate limits\"\r\n      why: \"API has usage limits\"\r\n      fix: \"Add retry logic with exponential backoff\"\r\n\n  references:\r\n    - \"https://platform.stability.ai/docs/api-reference\"\r\n    - \"https://aws.amazon.com/bedrock/stability-ai/\"\r\n\n- id: outpainting-extend\r\n  name: Outpainting and Image Extension\r\n  description: |\r\n    Extend images beyond original boundaries.\r\n    AI generates seamless content matching style.\r\n\n    Key concepts:\r\n    - Extend in any direction (left, right, up, down)\r\n    - Maintain color/style consistency\r\n    - Handle aspect ratio changes\r\n\n  code_example: |\r\n    import replicate\r\n    import requests\r\n    from PIL import Image\r\n    import io\r\n\n\n    def outpaint_replicate(\r\n        image_path: str,\r\n        direction: str = \"right\",  # left, right, up, down\r\n        extend_pixels: int = 512,\r\n        prompt: str = \"\"\r\n    ) -> bytes:\r\n        \"\"\"Extend image in specified direction.\"\"\"\r\n\n\n        img = Image.open(image_path)\r\n        orig_w, orig_h = img.size\r\n\n\n        if direction == \"right\":\r\n            new_w, new_h = orig_w + extend_pixels, orig_h\r\n            paste_pos = (0, 0)\r\n        elif direction == \"left\":\r\n            new_w, new_h = orig_w + extend_pixels, orig_h\r\n            paste_pos = (extend_pixels, 0)\r\n        elif direction == \"down\":\r\n            new_w, new_h = orig_w, orig_h + extend_pixels\r\n            paste_pos = (0, 0)\r\n        elif direction == \"up\":\r\n            new_w, new_h = orig_w, orig_h + extend_pixels\r\n            paste_pos = (0, extend_pixels)\r\n\n\n        canvas = Image.new(\"RGB\", (new_w, new_h), (128, 128, 128))\r\n        canvas.paste(img, paste_pos)\r\n\n\n        mask = Image.new(\"L\", (new_w, new_h), 255)  # All white\r\n        mask_region = Image.new(\"L\", img.size, 0)   # Black for original\r\n        mask.paste(mask_region, paste_pos)\r\n\n\n        def to_bytes(pil_img, format=\"PNG\"):\r\n            buf = io.BytesIO()\r\n            pil_img.save(buf, format=format)\r\n            return buf.getvalue()\r\n\n\n        client = replicate.Client()\r\n        output = client.run(\r\n            \"black-forest-labs/flux-fill-pro\",\r\n            input={\r\n                \"image\": to_bytes(canvas),\r\n                \"mask\": to_bytes(mask),\r\n                \"prompt\": prompt or \"seamless extension of the scene\",\r\n            }\r\n        )\r\n\n        return output.read()\r\n\n\n    def outpaint_stability(\r\n        image_path: str,\r\n        left: int = 0,\r\n        right: int = 512,\r\n        up: int = 0,\r\n        down: int = 0,\r\n        prompt: str = \"\",\r\n    ):\r\n        \"\"\"Extend image using Stability AI.\"\"\"\r\n\n        with open(image_path, \"rb\") as f:\r\n            image_data = f.read()\r\n\n        response = requests.post(\r\n            \"https://api.stability.ai/v2beta/stable-image/edit/outpaint\",\r\n            headers={\r\n                \"Authorization\": f\"Bearer {os.environ['STABILITY_API_KEY']}\",\r\n                \"Accept\": \"image/*\",\r\n            },\r\n            files={\"image\": image_data},\r\n            data={\r\n                \"left\": left,\r\n                \"right\": right,\r\n                \"up\": up,\r\n                \"down\": down,\r\n                \"prompt\": prompt,\r\n                \"output_format\": \"png\",\r\n            },\r\n        )\r\n\n        if response.status_code == 200:\r\n            return response.content\r\n        raise Exception(f\"Outpaint failed: {response.text}\")\r\n\n\n\n    result = outpaint_stability(\r\n        \"portrait.png\",\r\n        left=256,\r\n        right=256,\r\n        prompt=\"continue the scenic landscape naturally\"\r\n    )\r\n\n\n    result = outpaint_stability(\r\n        \"square.png\",\r\n        left=128,\r\n        right=128,\r\n        prompt=\"extend the environment seamlessly\"\r\n    )\r\n\n  anti_patterns:\r\n    - pattern: \"Extending without prompt context\"\r\n      why: \"AI may generate inconsistent content\"\r\n      fix: \"Provide descriptive prompt matching original style\"\r\n\n    - pattern: \"Very large extensions at once\"\r\n      why: \"Quality degrades with massive extensions\"\r\n      fix: \"Chain smaller extensions (256-512px each)\"\r\n\n  references:\r\n    - \"https://myaiforce.com/flux-fill-model-inpainting-workflow/\"\r\n    - \"https://aws.amazon.com/about-aws/whats-new/2025/10/stability-ai-image-updates-amazon-bedrock/\"\r\n\n- id: controlnet-guidance\r\n  name: ControlNet Structure Control\r\n  description: |\r\n    Control image generation with structural guidance.\r\n\n    Control types:\r\n    - Canny: Edge detection, sharp boundaries\r\n    - Depth: 3D spatial relationships\r\n    - Pose: Human body positioning\r\n    - HED/Soft Edge: Organic, softer boundaries\r\n\n    Combine multiple controls for precise results.\r\n\n  code_example: |\r\n    import replicate\r\n    from PIL import Image\r\n    import cv2\r\n    import numpy as np\r\n\n\n    def create_canny_map(image_path: str, low: int = 100, high: int = 200):\r\n        \"\"\"Create Canny edge detection map.\"\"\"\r\n        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\r\n        edges = cv2.Canny(img, low, high)\r\n        return Image.fromarray(edges)\r\n\n\n    def generate_with_controlnet(\r\n        control_image_path: str,\r\n        prompt: str,\r\n        control_type: str = \"canny\",  # canny, depth, pose\r\n        control_strength: float = 0.8,\r\n    ):\r\n        \"\"\"Generate image with ControlNet guidance.\"\"\"\r\n\n        client = replicate.Client()\r\n\n\n        if control_type == \"canny\":\r\n            model = \"black-forest-labs/flux-canny-pro\"\r\n        elif control_type == \"depth\":\r\n            model = \"black-forest-labs/flux-depth-pro\"\r\n        else:\r\n\n            model = \"xlabs-ai/flux-controlnet\"\r\n\n        output = client.run(\r\n            model,\r\n            input={\r\n                \"control_image\": open(control_image_path, \"rb\"),\r\n                \"prompt\": prompt,\r\n                \"control_strength\": control_strength,\r\n                \"num_inference_steps\": 28,\r\n                \"guidance_scale\": 3.5,\r\n            }\r\n        )\r\n\n        return output\r\n\n\n    def multi_controlnet(\r\n        pose_image: str,\r\n        depth_image: str,\r\n        prompt: str,\r\n        pose_strength: float = 0.5,\r\n        depth_strength: float = 0.4,\r\n    ):\r\n        \"\"\"Combine pose and depth control.\"\"\"\r\n\n\n\n\n        client = replicate.Client()\r\n\n        output = client.run(\r\n            \"xlabs-ai/flux-controlnet\",\r\n            input={\r\n                \"control_image\": open(pose_image, \"rb\"),\r\n                \"control_image_2\": open(depth_image, \"rb\"),\r\n                \"control_type\": \"pose\",\r\n                \"control_type_2\": \"depth\",\r\n                \"control_strength\": pose_strength,\r\n                \"control_strength_2\": depth_strength,\r\n                \"prompt\": prompt,\r\n            }\r\n        )\r\n\n        return output\r\n\n\n    def create_depth_map(image_path: str):\r\n        \"\"\"Generate depth map using MiDaS.\"\"\"\r\n\n        client = replicate.Client()\r\n\n        output = client.run(\r\n            \"cjwbw/midas:a6ba5798f04f80d3b314de0f0a62277f21ab3c8a6eb7f3bb0bb9d7e6b62c3c0d\",\r\n            input={\r\n                \"image\": open(image_path, \"rb\"),\r\n                \"model_type\": \"DPT_Large\",\r\n            }\r\n        )\r\n\n        return output\r\n\n\n    def sketch_to_art(sketch_path: str, style_prompt: str):\r\n        \"\"\"Convert rough sketch to polished artwork.\"\"\"\r\n\n\n        canny_map = create_canny_map(sketch_path, low=50, high=150)\r\n        canny_map.save(\"temp_canny.png\")\r\n\n\n        client = replicate.Client()\r\n        output = client.run(\r\n            \"black-forest-labs/flux-canny-pro\",\r\n            input={\r\n                \"control_image\": open(\"temp_canny.png\", \"rb\"),\r\n                \"prompt\": f\"{style_prompt}, high detail, professional\",\r\n                \"control_strength\": 0.75,\r\n            }\r\n        )\r\n\n        return output\r\n\n  anti_patterns:\r\n    - pattern: \"Control strength 1.0 with multiple controls\"\r\n      why: \"Combined strength exceeds 1.0, over-constrains generation\"\r\n      fix: \"Use 0.4-0.5 per control when combining\"\r\n\n    - pattern: \"Using Canny for organic subjects like faces\"\r\n      why: \"Hard edges don't capture facial nuances\"\r\n      fix: \"Use depth or soft edge for organic subjects\"\r\n\n    - pattern: \"Wrong resolution control images\"\r\n      why: \"Control images must match output resolution\"\r\n      fix: \"Resize control image to target dimensions\"\r\n\n  references:\r\n    - \"https://stable-diffusion-art.com/controlnet/\"\r\n    - \"https://blog.segmind.com/flux-1-controlnets-what-are-they-all-you-need-to-know/\"\r\n\n- id: image-to-image\r\n  name: Image-to-Image Transformation\r\n  description: |\r\n    Transform existing images with style/content changes.\r\n    Control transformation strength to balance original vs new.\r\n\n    Use cases:\r\n    - Style transfer (photo to art)\r\n    - Retexturing (change materials/surfaces)\r\n    - Color grading\r\n    - Detail enhancement\r\n\n  code_example: |\r\n    import replicate\r\n    import fal_client\r\n\n\n    def transform_image_replicate(\r\n        image_path: str,\r\n        prompt: str,\r\n        strength: float = 0.75,  # 0.0 = keep original, 1.0 = ignore original\r\n        model: str = \"flux\"\r\n    ):\r\n        \"\"\"Transform image with prompt guidance.\"\"\"\r\n\n        client = replicate.Client()\r\n\n        if model == \"flux\":\r\n            output = client.run(\r\n                \"black-forest-labs/flux-dev\",\r\n                input={\r\n                    \"image\": open(image_path, \"rb\"),\r\n                    \"prompt\": prompt,\r\n                    \"prompt_strength\": strength,\r\n                    \"num_inference_steps\": 28,\r\n                    \"guidance_scale\": 3.5,\r\n                }\r\n            )\r\n        else:  # SDXL\r\n            output = client.run(\r\n                \"stability-ai/sdxl\",\r\n                input={\r\n                    \"image\": open(image_path, \"rb\"),\r\n                    \"prompt\": prompt,\r\n                    \"prompt_strength\": strength,\r\n                    \"num_inference_steps\": 25,\r\n                }\r\n            )\r\n\n        return output\r\n\n\n    def transform_image_fal(\r\n        image_url: str,\r\n        prompt: str,\r\n        strength: float = 0.75,\r\n    ):\r\n        \"\"\"Transform using Fal.ai's fast inference.\"\"\"\r\n\n        result = fal_client.submit(\r\n            \"fal-ai/flux/dev/image-to-image\",\r\n            arguments={\r\n                \"image_url\": image_url,\r\n                \"prompt\": prompt,\r\n                \"strength\": strength,\r\n                \"num_inference_steps\": 28,\r\n            }\r\n        )\r\n\n        return result.get()\r\n\n\n\n\n\n\n\n\n    def apply_art_style(photo_path: str, style: str):\r\n        \"\"\"Convert photo to artistic style.\"\"\"\r\n\n        style_prompts = {\r\n            \"watercolor\": \"watercolor painting, soft brushstrokes, flowing colors\",\r\n            \"oil_painting\": \"oil painting, rich textures, dramatic lighting\",\r\n            \"anime\": \"anime style, vibrant colors, clean lines, studio ghibli\",\r\n            \"pencil_sketch\": \"detailed pencil sketch, cross-hatching, artistic\",\r\n            \"cyberpunk\": \"cyberpunk aesthetic, neon lights, futuristic\",\r\n        }\r\n\n        prompt = style_prompts.get(style, style)\r\n\n        return transform_image_replicate(\r\n            photo_path,\r\n            prompt=prompt,\r\n            strength=0.65,  # Preserve composition\r\n        )\r\n\n\n    async def batch_transform(\r\n        images: list[str],\r\n        prompt: str,\r\n        strength: float = 0.75,\r\n    ):\r\n        \"\"\"Process multiple images concurrently.\"\"\"\r\n        import asyncio\r\n\n        client = replicate.Client()\r\n\n        async def process_one(image_path: str):\r\n            prediction = client.predictions.create(\r\n                model=\"black-forest-labs/flux-dev\",\r\n                input={\r\n                    \"image\": open(image_path, \"rb\"),\r\n                    \"prompt\": prompt,\r\n                    \"prompt_strength\": strength,\r\n                }\r\n            )\r\n            return await asyncio.to_thread(\r\n                client.predictions.wait,\r\n                prediction\r\n            )\r\n\n        tasks = [process_one(img) for img in images]\r\n        return await asyncio.gather(*tasks)\r\n\n  anti_patterns:\r\n    - pattern: \"Strength 0.9+ for style transfer\"\r\n      why: \"Loses original composition and content\"\r\n      fix: \"Use 0.5-0.75 to preserve structure\"\r\n\n    - pattern: \"No negative prompt for quality\"\r\n      why: \"May generate artifacts\"\r\n      fix: \"Add negative: 'blurry, distorted, low quality'\"\r\n\n  references:\r\n    - \"https://replicate.com/blog/run-sdxl-with-an-api\"\r\n    - \"https://www.aifreeapi.com/en/posts/free-image-to-image-api\"\r\n\n- id: multi-step-editing\r\n  name: Multi-Step Iterative Editing\r\n  description: |\r\n    Chain multiple editing operations for complex results.\r\n    Each step builds on the previous, enabling sophisticated edits.\r\n\n    Strategy:\r\n    1. Use lower denoise per step\r\n    2. Expand masks gradually\r\n    3. Verify intermediate results\r\n\n  code_example: |\r\n    from PIL import Image\r\n    import replicate\r\n    from typing import Callable\r\n    import io\r\n\n    class ImageEditPipeline:\r\n        \"\"\"Chain multiple AI editing operations.\"\"\"\r\n\n        def __init__(self, image_path: str):\r\n            self.image = Image.open(image_path)\r\n            self.history = [self.image.copy()]\r\n            self.client = replicate.Client()\r\n\n        def _image_to_bytes(self, img: Image.Image) -> bytes:\r\n            buf = io.BytesIO()\r\n            img.save(buf, format=\"PNG\")\r\n            return buf.getvalue()\r\n\n        def inpaint(\r\n            self,\r\n            mask: Image.Image,\r\n            prompt: str,\r\n            strength: float = 0.75\r\n        ) -> \"ImageEditPipeline\":\r\n            \"\"\"Inpaint masked area.\"\"\"\r\n\n            output = self.client.run(\r\n                \"black-forest-labs/flux-fill-pro\",\r\n                input={\r\n                    \"image\": self._image_to_bytes(self.image),\r\n                    \"mask\": self._image_to_bytes(mask),\r\n                    \"prompt\": prompt,\r\n                    \"strength\": strength,\r\n                }\r\n            )\r\n\n            self.image = Image.open(io.BytesIO(output.read()))\r\n            self.history.append(self.image.copy())\r\n            return self\r\n\n        def transform(self, prompt: str, strength: float = 0.5) -> \"ImageEditPipeline\":\r\n            \"\"\"Apply image-to-image transformation.\"\"\"\r\n\n            output = self.client.run(\r\n                \"black-forest-labs/flux-dev\",\r\n                input={\r\n                    \"image\": self._image_to_bytes(self.image),\r\n                    \"prompt\": prompt,\r\n                    \"prompt_strength\": strength,\r\n                }\r\n            )\r\n\n            self.image = Image.open(io.BytesIO(output.read()))\r\n            self.history.append(self.image.copy())\r\n            return self\r\n\n        def upscale(self, scale: int = 2) -> \"ImageEditPipeline\":\r\n            \"\"\"Upscale image resolution.\"\"\"\r\n\n            output = self.client.run(\r\n                \"nightmareai/real-esrgan:f121d640bd286e1fdc67f9799164c1d5be36ff74576ee11c803ae5b665dd46aa\",\r\n                input={\r\n                    \"image\": self._image_to_bytes(self.image),\r\n                    \"scale\": scale,\r\n                }\r\n            )\r\n\n            self.image = Image.open(io.BytesIO(output.read()))\r\n            self.history.append(self.image.copy())\r\n            return self\r\n\n        def undo(self) -> \"ImageEditPipeline\":\r\n            \"\"\"Revert to previous state.\"\"\"\r\n            if len(self.history) > 1:\r\n                self.history.pop()\r\n                self.image = self.history[-1].copy()\r\n            return self\r\n\n        def save(self, path: str):\r\n            \"\"\"Save current result.\"\"\"\r\n            self.image.save(path)\r\n            return self\r\n\n\n    def edit_product_photo(image_path: str):\r\n        \"\"\"Multi-step product photo enhancement.\"\"\"\r\n\n        pipeline = ImageEditPipeline(image_path)\r\n\n\n        bg_mask = create_background_mask(image_path)\r\n        pipeline.inpaint(\r\n            mask=bg_mask,\r\n            prompt=\"clean white studio background, professional product photography\",\r\n            strength=0.6\r\n        )\r\n\n\n        pipeline.transform(\r\n            prompt=\"professional product photography, soft studio lighting, high-end commercial\",\r\n            strength=0.3  # Subtle enhancement\r\n        )\r\n\n\n        pipeline.upscale(scale=2)\r\n\n\n        pipeline.save(\"product_enhanced.png\")\r\n\n        return pipeline\r\n\n\n    def iterative_inpaint(\r\n        image_path: str,\r\n        base_mask: Image.Image,\r\n        prompt: str,\r\n        iterations: int = 3,\r\n    ):\r\n        \"\"\"Inpaint with gradually expanding mask.\"\"\"\r\n\n        from scipy.ndimage import binary_dilation\r\n        import numpy as np\r\n\n        pipeline = ImageEditPipeline(image_path)\r\n        current_mask = np.array(base_mask)\r\n\n\n        strengths = [0.7, 0.5, 0.3]\r\n\n        for i in range(iterations):\r\n\n            if i > 0:\r\n                current_mask = binary_dilation(current_mask, iterations=10)\r\n\n            mask_img = Image.fromarray(current_mask.astype(np.uint8) * 255)\r\n\n            pipeline.inpaint(\r\n                mask=mask_img,\r\n                prompt=prompt,\r\n                strength=strengths[min(i, len(strengths)-1)]\r\n            )\r\n\n        return pipeline\r\n\n  anti_patterns:\r\n    - pattern: \"Single high-denoise pass for complex edits\"\r\n      why: \"Hard to control, may produce artifacts\"\r\n      fix: \"Use multiple passes with decreasing strength\"\r\n\n    - pattern: \"No history/undo capability\"\r\n      why: \"Can't recover from bad edits\"\r\n      fix: \"Maintain edit history for rollback\"\r\n\n  references:\r\n    - \"https://docs.comfy.org/tutorials/basic/inpaint\"\r\n    - \"https://medium.com/@techlatest.net/inpainting-and-outpainting-techniques-in-comfyui-d708d3ea690d\"\r\n\n- id: content-moderation\r\n  name: Content Moderation for Generated Images\r\n  description: |\r\n    Ensure generated images comply with content policies.\r\n    Check both inputs and outputs for safety.\r\n\n    Key concerns:\r\n    - NSFW/explicit content\r\n    - Violence/gore\r\n    - Hate symbols\r\n    - Deepfakes/impersonation\r\n\n  code_example: |\r\n    import requests\r\n    import openai\r\n    from typing import Tuple\r\n    from enum import Enum\r\n\n    class ContentRating(Enum):\r\n        SAFE = \"safe\"\r\n        WARNING = \"warning\"\r\n        BLOCKED = \"blocked\"\r\n\n\n    def check_prompt_safety(prompt: str) -> Tuple[bool, dict]:\r\n        \"\"\"Check if prompt is safe for image generation.\"\"\"\r\n\n        client = openai.OpenAI()\r\n\n        response = client.moderations.create(input=prompt)\r\n        result = response.results[0]\r\n\n\n        flags = {\r\n            \"sexual\": result.categories.sexual,\r\n            \"violence\": result.categories.violence,\r\n            \"hate\": result.categories.hate,\r\n            \"self_harm\": result.categories.self_harm,\r\n        }\r\n\n        is_safe = not any(flags.values())\r\n        return is_safe, flags\r\n\n\n    def moderate_image(image_url: str) -> ContentRating:\r\n        \"\"\"Check generated image for policy violations.\"\"\"\r\n\n\n        response = requests.get(\r\n            \"https://api.sightengine.com/1.0/check.json\",\r\n            params={\r\n                \"url\": image_url,\r\n                \"models\": \"nudity-2.1,offensive,gore\",\r\n                \"api_user\": os.environ[\"SIGHTENGINE_USER\"],\r\n                \"api_secret\": os.environ[\"SIGHTENGINE_SECRET\"],\r\n            }\r\n        )\r\n\n        result = response.json()\r\n\n\n        nudity = result.get(\"nudity\", {})\r\n        if nudity.get(\"sexual_activity\", 0) > 0.5:\r\n            return ContentRating.BLOCKED\r\n        if nudity.get(\"sexual_display\", 0) > 0.5:\r\n            return ContentRating.BLOCKED\r\n\n\n        if result.get(\"gore\", {}).get(\"prob\", 0) > 0.5:\r\n            return ContentRating.BLOCKED\r\n\n\n        if result.get(\"offensive\", {}).get(\"prob\", 0) > 0.7:\r\n            return ContentRating.WARNING\r\n\n        return ContentRating.SAFE\r\n\n\n    class SafeImageGenerator:\r\n        \"\"\"Generate images with content safety checks.\"\"\"\r\n\n        def __init__(self, replicate_client):\r\n            self.client = replicate_client\r\n\n        def generate(\r\n            self,\r\n            prompt: str,\r\n            **kwargs\r\n        ) -> dict:\r\n            \"\"\"Generate image with safety checks.\"\"\"\r\n\n\n            is_safe, flags = check_prompt_safety(prompt)\r\n            if not is_safe:\r\n                return {\r\n                    \"success\": False,\r\n                    \"error\": \"Prompt blocked by content policy\",\r\n                    \"flags\": flags,\r\n                }\r\n\n\n            try:\r\n                output = self.client.run(\r\n                    \"black-forest-labs/flux-schnell\",\r\n                    input={\r\n                        \"prompt\": prompt,\r\n                        \"safety_checker\": True,  # Enable model's safety\r\n                        **kwargs\r\n                    }\r\n                )\r\n\n                image_url = output[0] if isinstance(output, list) else str(output)\r\n\n\n                rating = moderate_image(image_url)\r\n\n                if rating == ContentRating.BLOCKED:\r\n                    return {\r\n                        \"success\": False,\r\n                        \"error\": \"Generated image blocked by content policy\",\r\n                    }\r\n\n                return {\r\n                    \"success\": True,\r\n                    \"image_url\": image_url,\r\n                    \"content_rating\": rating.value,\r\n                }\r\n\n            except Exception as e:\r\n                return {\r\n                    \"success\": False,\r\n                    \"error\": str(e),\r\n                }\r\n\n\n    generator = SafeImageGenerator(replicate.Client())\r\n    result = generator.generate(\r\n        prompt=\"professional headshot of a business person\",\r\n        num_outputs=1\r\n    )\r\n\n    if result[\"success\"]:\r\n        print(f\"Image: {result['image_url']}\")\r\n    else:\r\n        print(f\"Blocked: {result['error']}\")\r\n\n  anti_patterns:\r\n    - pattern: \"No content moderation in production\"\r\n      why: \"Users may generate harmful content\"\r\n      fix: \"Always check prompts and outputs\"\r\n\n    - pattern: \"Only checking prompts, not outputs\"\r\n      why: \"Safe prompts can still produce unsafe images\"\r\n      fix: \"Check both input prompts and output images\"\r\n\n  references:\r\n    - \"https://www.edenai.co/post/best-image-moderation-apis\"\r\n    - \"https://medium.com/@API4AI/automated-nsfw-detection-the-2025-content-safety-playbook-7ac82fd2f351\"",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "ai image editing",
          "inpainting",
          "outpainting",
          "controlnet",
          "image to image",
          "remove object from image",
          "extend image",
          "flux inpaint",
          "sdxl editing"
        ],
        "tags": [
          "image-editing",
          "inpainting",
          "outpainting",
          "controlnet",
          "stable-diffusion",
          "flux",
          "replicate",
          "stability-ai",
          "comfyui"
        ],
        "pairs_with": [],
        "requires": [],
        "category": "ai-ml"
      },
      {
        "id": "multimodal-ai",
        "name": "Multimodal AI",
        "version": "1.0.0",
        "layer": 1,
        "description": "Process images with GPT-4o vision",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "multimodal AI",
          "vision API",
          "image understanding",
          "GPT-4V",
          "Claude vision",
          "audio transcription",
          "Whisper",
          "document extraction",
          "image to text"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "ai-ml"
      },
      {
        "id": "on-device-ai",
        "name": "On-Device AI",
        "version": "1.0.0",
        "layer": 1,
        "description": "Set up Transformers.js for browser inference",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "on-device AI",
          "browser AI",
          "WebLLM",
          "Transformers.js",
          "WebGPU",
          "edge inference",
          "offline AI",
          "client-side ML",
          "ONNX web"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "ai-ml"
      },
      {
        "id": "semantic-search",
        "name": "Semantic Search",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using only vector search without reranking",
        "principles": [
          "name: \"Hybrid Search by Default"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [
          "vector-search",
          "embeddings",
          "rag",
          "pinecone",
          "qdrant",
          "weaviate",
          "llama-index",
          "langchain",
          "hybrid-search",
          "reranking"
        ],
        "pairs_with": [],
        "requires": [],
        "category": "ai-ml"
      },
      {
        "id": "synthetic-data",
        "name": "Synthetic Data Generation",
        "version": "1.0.0",
        "layer": 1,
        "description": "Generate synthetic data using LLMs",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "synthetic data",
          "generate training data",
          "fake data generation",
          "data augmentation",
          "SDV",
          "Gretel",
          "test data",
          "privacy-preserving data"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "ai-ml"
      },
      {
        "id": "text-to-video",
        "name": "Text-to-Video with Replicate",
        "version": "1.0.0",
        "layer": 1,
        "description": "Generate videos from text prompts using Replicate models.\r\n\n    Model recommendations:\r\n    - Wan 2.2: Open-source, fast, good quality\r\n    - Kling 2.1: High quality, character consistency\r\n    - minimax/hailuo: Physics realism\r\n\n    Videos typically take 30-150 seconds to generate.\r\n\n  code_example: |\r\n    import replicate\r\n    import asyncio\r\n    from typing import Optional\r\n\n\n    client = replicate.Client(api_token=os.environ[\"REPLICATE_API_TOKEN\"])\r\n\n\n    def generate_video_wan(\r\n        prompt: str,\r\n        resolution: str = \"480p\",  # 480p, 720p\r\n        duration: int = 5,  # seconds\r\n    ) -> str:\r\n        \"\"\"Generate video from text with Wan 2.2.\"\"\"\r\n\n        model = f\"wavespeedai/wan-2.1-t2v-{resolution}\"\r\n\n        output = client.run(\r\n            model,\r\n            input={\r\n                \"prompt\": prompt,\r\n                \"num_frames\": duration * 16,  # ~16 FPS\r\n                \"guidance_scale\": 6.0,\r\n                \"num_inference_steps\": 30,\r\n            }\r\n        )\r\n\n        return output  # Video URL\r\n\n\n    def generate_video_kling(\r\n        prompt: str,\r\n        duration: int = 5,  # 5 or 10 seconds\r\n        resolution: str = \"720p\",\r\n    ) -> str:\r\n        \"\"\"Generate video with Kling v2.1.\"\"\"\r\n\n        output = client.run(\r\n            \"kwaivgi/kling-v2.1\",\r\n            input={\r\n                \"prompt\": prompt,\r\n                \"duration\": duration,\r\n                \"aspect_ratio\": \"16:9\",\r\n                \"negative_prompt\": \"blurry, distorted, low quality\",\r\n            }\r\n        )\r\n\n        return output\r\n\n\n    async def generate_video_async(\r\n        prompt: str,\r\n        model: str = \"wavespeedai/wan-2.1-t2v-480p\",\r\n        timeout: int = 300,\r\n    ) -> str:\r\n        \"\"\"Generate video asynchronously with status polling.\"\"\"\r\n\n        prediction = client.predictions.create(\r\n            model=model,\r\n            input={\"prompt\": prompt}\r\n        )\r\n\n        start = asyncio.get_event_loop().time()\r\n\n        while True:\r\n            prediction = client.predictions.get(prediction.id)\r\n\n            if prediction.status == \"succeeded\":\r\n                return prediction.output\r\n\n            if prediction.status == \"failed\":\r\n                raise Exception(f\"Generation failed: {prediction.error}\")\r\n\n            if asyncio.get_event_loop().time() - start > timeout:\r\n                client.predictions.cancel(prediction.id)\r\n                raise TimeoutError(\"Video generation timed out\")\r\n\n            await asyncio.sleep(5)  # Poll every 5 seconds\r\n\n\n    async def generate_batch(prompts: list[str]) -> list[str]:\r\n        \"\"\"Generate multiple videos concurrently.\"\"\"\r\n\n        tasks = [\r\n            generate_video_async(prompt)\r\n            for prompt in prompts\r\n        ]\r\n\n        return await asyncio.gather(*tasks)\r\n\n  anti_patterns:\r\n    - pattern: \"Blocking synchronous generation\"\r\n      why: \"Videos take 30-150 seconds to generate\"\r\n      fix: \"Use async with polling or webhooks\"\r\n\n    - pattern: \"No timeout on generation\"\r\n      why: \"Failed generations can hang forever\"\r\n      fix: \"Add timeout and cancellation logic\"\r\n\n  references:\r\n    - \"https://replicate.com/collections/text-to-video\"\r\n    - \"https://replicate.com/blog/wan-21-generate-videos-with-an-api\"\r\n\n- id: image-to-video\r\n  name: Image-to-Video Animation\r\n  description: |\r\n    Animate still images into videos.\r\n    Preserve image content while adding motion.\r\n\n    Best for:\r\n    - Product animations\r\n    - Character motion\r\n    - Scene transitions\r\n    - Social media content\r\n\n  code_example: |\r\n    import replicate\r\n    import fal_client\r\n\n\n    def animate_image_wan(\r\n        image_url: str,\r\n        prompt: str,\r\n        duration: int = 5,\r\n    ) -> str:\r\n        \"\"\"Animate image with Wan 2.2.\"\"\"\r\n\n        client = replicate.Client()\r\n\n        output = client.run(\r\n            \"wavespeedai/wan-2.1-i2v-480p\",\r\n            input={\r\n                \"image\": image_url,\r\n                \"prompt\": prompt,\r\n                \"num_frames\": duration * 16,\r\n                \"guidance_scale\": 6.0,\r\n            }\r\n        )\r\n\n        return output\r\n\n\n    def animate_image_kling(\r\n        image_url: str,\r\n        prompt: str,\r\n        duration: int = 5,  # 5 or 10 seconds\r\n        motion_amount: float = 0.5,  # 0-1\r\n    ) -> str:\r\n        \"\"\"Animate image with Kling v2.1.\"\"\"\r\n\n        client = replicate.Client()\r\n\n        output = client.run(\r\n            \"kwaivgi/kling-v2.1\",\r\n            input={\r\n                \"image\": image_url,\r\n                \"prompt\": prompt,\r\n                \"duration\": duration,\r\n                \"cfg_scale\": 0.5,\r\n                \"negative_prompt\": \"static, frozen, no motion\",\r\n            }\r\n        )\r\n\n        return output\r\n\n\n    def animate_image_fal(\r\n        image_url: str,\r\n        prompt: str,\r\n    ) -> dict:\r\n        \"\"\"Animate image with Fal.ai.\"\"\"\r\n\n        result = fal_client.submit(\r\n            \"fal-ai/wan-i2v\",\r\n            arguments={\r\n                \"image_url\": image_url,\r\n                \"prompt\": prompt,\r\n                \"num_inference_steps\": 30,\r\n            }\r\n        )\r\n\n        return result.get()\r\n\n\n    def animate_with_camera_motion(\r\n        image_url: str,\r\n        camera_motion: str = \"zoom_in\",  # zoom_in, zoom_out, pan_left, pan_right, orbit\r\n        prompt: str = \"\",\r\n    ) -> str:\r\n        \"\"\"Animate with specific camera motion.\"\"\"\r\n\n\n        MOTION_PROMPTS = {\r\n            \"zoom_in\": \"smooth zoom in, camera pushing forward\",\r\n            \"zoom_out\": \"smooth zoom out, camera pulling back\",\r\n            \"pan_left\": \"smooth pan left, camera sliding left\",\r\n            \"pan_right\": \"smooth pan right, camera sliding right\",\r\n            \"orbit\": \"camera orbiting around subject, 3D parallax\",\r\n            \"tilt_up\": \"camera tilting upward, looking up\",\r\n            \"tilt_down\": \"camera tilting downward, looking down\",\r\n        }\r\n\n        motion_prompt = MOTION_PROMPTS.get(camera_motion, \"\")\r\n        full_prompt = f\"{prompt}, {motion_prompt}\".strip(\", \")\r\n\n        client = replicate.Client()\r\n        output = client.run(\r\n            \"wavespeedai/wan-2.1-i2v-720p\",\r\n            input={\r\n                \"image\": image_url,\r\n                \"prompt\": full_prompt,\r\n                \"guidance_scale\": 7.0,\r\n            }\r\n        )\r\n\n        return output\r\n\n\n    def create_product_turntable(\r\n        product_image_url: str,\r\n        rotation_degrees: int = 360,\r\n        duration: int = 5,\r\n    ) -> str:\r\n        \"\"\"Create 360-degree product rotation video.\"\"\"\r\n\n        prompt = f\"product rotating {rotation_degrees} degrees on turntable, smooth continuous rotation, studio lighting, white background\"\r\n\n        return animate_image_kling(\r\n            image_url=product_image_url,\r\n            prompt=prompt,\r\n            duration=duration,\r\n            motion_amount=0.7,\r\n        )\r\n\n  anti_patterns:\r\n    - pattern: \"Vague motion prompts\"\r\n      why: \"Results in random or no motion\"\r\n      fix: \"Be specific about motion type and direction\"\r\n\n    - pattern: \"Expecting perfect character consistency\"\r\n      why: \"Current models drift across frames\"\r\n      fix: \"Use shorter clips, or models with element/character features\"\r\n\n  references:\r\n    - \"https://replicate.com/collections/image-to-video\"\r\n    - \"https://lumalabs.ai/dream-machine\"\r\n\n- id: video-prompting\r\n  name: Video Prompting Best Practices\r\n  description: |\r\n    Write effective prompts for video generation.\r\n    Key elements: subject, action, camera, lighting, style.\r\n\n    Video prompts differ from image prompts:\r\n    - Emphasize motion and action\r\n    - Describe camera movement\r\n    - Specify timing and pacing\r\n\n  code_example: |\r\n\n    class VideoPrompt:\r\n        \"\"\"Build structured video prompts.\"\"\"\r\n\n        def __init__(self):\r\n            self.subject = \"\"\r\n            self.action = \"\"\r\n            self.camera = \"\"\r\n            self.lighting = \"\"\r\n            self.style = \"\"\r\n            self.negative = \"\"\r\n\n        def with_subject(self, subject: str) -> \"VideoPrompt\":\r\n            self.subject = subject\r\n            return self\r\n\n        def with_action(self, action: str) -> \"VideoPrompt\":\r\n            self.action = action\r\n            return self\r\n\n        def with_camera(self, camera: str) -> \"VideoPrompt\":\r\n            self.camera = camera\r\n            return self\r\n\n        def with_lighting(self, lighting: str) -> \"VideoPrompt\":\r\n            self.lighting = lighting\r\n            return self\r\n\n        def with_style(self, style: str) -> \"VideoPrompt\":\r\n            self.style = style\r\n            return self\r\n\n        def build(self) -> str:\r\n            parts = [\r\n                self.subject,\r\n                self.action,\r\n                self.camera,\r\n                self.lighting,\r\n                self.style,\r\n            ]\r\n            return \", \".join(p for p in parts if p)\r\n\n\n    prompt = (\r\n        VideoPrompt()\r\n        .with_subject(\"a young woman in a red dress\")\r\n        .with_action(\"walking confidently through a busy city street\")\r\n        .with_camera(\"tracking shot, following from the side\")\r\n        .with_lighting(\"golden hour sunlight, dramatic shadows\")\r\n        .with_style(\"cinematic, film grain, shallow depth of field\")\r\n        .build()\r\n    )\r\n\n\n    CAMERA_MOTIONS = {\r\n        \"static\": \"locked off shot, stationary camera\",\r\n        \"pan\": \"horizontal pan, smooth lateral movement\",\r\n        \"tilt\": \"vertical tilt, camera looking up/down\",\r\n        \"zoom\": \"slow zoom in, pushing forward\",\r\n        \"dolly\": \"dolly shot, camera moving forward\",\r\n        \"tracking\": \"tracking shot, following subject\",\r\n        \"orbit\": \"orbital shot, camera circling subject\",\r\n        \"crane\": \"crane shot, camera rising upward\",\r\n        \"handheld\": \"handheld camera, slight shake\",\r\n        \"steadicam\": \"steadicam shot, smooth floating movement\",\r\n    }\r\n\n\n    SPEED_MODIFIERS = {\r\n        \"slow\": \"slow motion, graceful movement, 0.5x speed\",\r\n        \"normal\": \"natural pace, realistic timing\",\r\n        \"fast\": \"quick movement, energetic, rapid motion\",\r\n        \"timelapse\": \"time lapse, accelerated, fast forward\",\r\n    }\r\n\n\n    GENRE_TEMPLATES = {\r\n        \"commercial\": \"{subject}, {action}, professional lighting, clean composition, 4K quality, commercial production\",\r\n        \"cinematic\": \"{subject}, {action}, cinematic lighting, film grain, anamorphic lens, movie quality\",\r\n        \"social\": \"{subject}, {action}, vibrant colors, engaging, vertical format, social media style\",\r\n        \"documentary\": \"{subject}, {action}, natural lighting, authentic, observational, documentary style\",\r\n    }\r\n\n    def build_genre_prompt(\r\n        subject: str,\r\n        action: str,\r\n        genre: str = \"commercial\"\r\n    ) -> str:\r\n        template = GENRE_TEMPLATES.get(genre, GENRE_TEMPLATES[\"commercial\"])\r\n        return template.format(subject=subject, action=action)\r\n\n\n    NEGATIVE_PROMPTS = {\r\n        \"quality\": \"blurry, distorted, low resolution, pixelated, artifacts\",\r\n        \"motion\": \"jittery, stuttering, frozen, static, no motion\",\r\n        \"anatomy\": \"deformed, extra limbs, missing limbs, bad anatomy\",\r\n        \"all\": \"blurry, distorted, low quality, jittery, deformed, extra limbs, artifacts, watermark\",\r\n    }\r\n\n  anti_patterns:\r\n    - pattern: \"Image-style prompts for video\"\r\n      why: \"Video needs motion and action descriptions\"\r\n      fix: \"Add verbs, camera motion, and timing\"\r\n\n    - pattern: \"Overly complex prompts\"\r\n      why: \"Models struggle with many elements\"\r\n      fix: \"Focus on key subject and single clear action\"\r\n\n  references:\r\n    - \"https://apatero.com/blog/avoid-slow-motion-wan-22-video-generation-2025\"\r\n\n- id: runway-gen3-integration\r\n  name: Runway Gen-3 API Integration\r\n  description: |\r\n    Integrate Runway's Gen-3 Alpha for professional video.\r\n    Features: 4K resolution, camera controls, lip sync.\r\n\n    Note: Requires Runway API access (paid).\r\n    Credits: ~10 credits/second for Gen-3 Alpha.\r\n\n  code_example: |\r\n    import httpx\r\n    from typing import Optional\r\n    import asyncio\r\n\n    class RunwayClient:\r\n        \"\"\"Runway Gen-3 API client.\"\"\"\r\n\n        def __init__(self, api_key: str):\r\n            self.api_key = api_key\r\n            self.base_url = \"https://api.runwayml.com/v1\"\r\n\n        async def generate_video(\r\n            self,\r\n            prompt: str,\r\n            image_url: Optional[str] = None,\r\n            duration: int = 5,  # seconds\r\n            resolution: str = \"720p\",\r\n            aspect_ratio: str = \"16:9\",\r\n        ) -> dict:\r\n            \"\"\"Generate video with Gen-3 Alpha.\"\"\"\r\n\n            async with httpx.AsyncClient() as client:\r\n\n                response = await client.post(\r\n                    f\"{self.base_url}/generation\",\r\n                    headers={\r\n                        \"Authorization\": f\"Bearer {self.api_key}\",\r\n                        \"Content-Type\": \"application/json\",\r\n                    },\r\n                    json={\r\n                        \"model\": \"gen3a_turbo\",  # or \"gen3a\" for Alpha\r\n                        \"prompt_text\": prompt,\r\n                        \"prompt_image\": image_url,\r\n                        \"duration\": duration,\r\n                        \"resolution\": resolution,\r\n                        \"aspect_ratio\": aspect_ratio,\r\n                    },\r\n                    timeout=30,\r\n                )\r\n\n                if response.status_code != 200:\r\n                    raise Exception(f\"Generation failed: {response.text}\")\r\n\n                task = response.json()\r\n                return await self._wait_for_completion(task[\"id\"])\r\n\n        async def _wait_for_completion(\r\n            self,\r\n            task_id: str,\r\n            timeout: int = 300,\r\n            poll_interval: int = 5,\r\n        ) -> dict:\r\n            \"\"\"Poll for task completion.\"\"\"\r\n\n            start = asyncio.get_event_loop().time()\r\n\n            async with httpx.AsyncClient() as client:\r\n                while True:\r\n                    response = await client.get(\r\n                        f\"{self.base_url}/generation/{task_id}\",\r\n                        headers={\r\n                            \"Authorization\": f\"Bearer {self.api_key}\",\r\n                        },\r\n                    )\r\n\n                    task = response.json()\r\n\n                    if task[\"status\"] == \"completed\":\r\n                        return task\r\n\n                    if task[\"status\"] == \"failed\":\r\n                        raise Exception(f\"Task failed: {task.get('error')}\")\r\n\n                    if asyncio.get_event_loop().time() - start > timeout:\r\n                        raise TimeoutError(\"Generation timed out\")\r\n\n                    await asyncio.sleep(poll_interval)\r\n\n        async def extend_video(\r\n            self,\r\n            video_url: str,\r\n            prompt: str,\r\n            extend_seconds: int = 4,\r\n        ) -> dict:\r\n            \"\"\"Extend existing video.\"\"\"\r\n\n            async with httpx.AsyncClient() as client:\r\n                response = await client.post(\r\n                    f\"{self.base_url}/extend\",\r\n                    headers={\r\n                        \"Authorization\": f\"Bearer {self.api_key}\",\r\n                        \"Content-Type\": \"application/json\",\r\n                    },\r\n                    json={\r\n                        \"model\": \"gen3a_turbo\",\r\n                        \"video_url\": video_url,\r\n                        \"prompt_text\": prompt,\r\n                        \"extend_duration\": extend_seconds,\r\n                    },\r\n                )\r\n\n                task = response.json()\r\n                return await self._wait_for_completion(task[\"id\"])\r\n\n\n    runway = RunwayClient(os.environ[\"RUNWAY_API_KEY\"])\r\n\n\n    result = await runway.generate_video(\r\n        prompt=\"A drone shot flying over misty mountains at sunrise\",\r\n        duration=5,\r\n        resolution=\"1080p\",\r\n    )\r\n    print(f\"Video URL: {result['output_url']}\")\r\n\n\n    result = await runway.generate_video(\r\n        prompt=\"Camera slowly zooming in, subject looking at camera\",\r\n        image_url=\"https://example.com/portrait.jpg\",\r\n        duration=5,\r\n    )\r\n\n  anti_patterns:\r\n    - pattern: \"Not tracking credit usage\"\r\n      why: \"Gen-3 uses 10 credits/second, costs add up\"\r\n      fix: \"Track usage and set budget limits\"\r\n\n    - pattern: \"Synchronous API calls\"\r\n      why: \"Generation takes 30+ seconds\"\r\n      fix: \"Use async with proper polling\"\r\n\n  references:\r\n    - \"https://runwayml.com/research/introducing-gen-3-alpha\"\r\n    - \"https://docs.runwayml.com/api\"\r\n\n- id: luma-dream-machine\r\n  name: Luma Dream Machine Integration\r\n  description: |\r\n    Integrate Luma's Dream Machine for cinematic video.\r\n    Features: HDR output, keyframes, character reference.\r\n\n    Ray3: Latest model with studio-grade HDR.\r\n    Draft Mode: Fast exploration before final render.\r\n\n  code_example: |\r\n    import httpx\r\n    from typing import Optional, List\r\n    import asyncio\r\n\n    class LumaClient:\r\n        \"\"\"Luma Dream Machine API client.\"\"\"\r\n\n        def __init__(self, api_key: str):\r\n            self.api_key = api_key\r\n            self.base_url = \"https://api.lumalabs.ai/dream-machine/v1\"\r\n\n        async def generate(\r\n            self,\r\n            prompt: str,\r\n            aspect_ratio: str = \"16:9\",\r\n            loop: bool = False,\r\n            keyframes: Optional[dict] = None,\r\n        ) -> dict:\r\n            \"\"\"Generate video with Dream Machine.\"\"\"\r\n\n            payload = {\r\n                \"prompt\": prompt,\r\n                \"aspect_ratio\": aspect_ratio,\r\n                \"loop\": loop,\r\n            }\r\n\n            if keyframes:\r\n                payload[\"keyframes\"] = keyframes\r\n\n            async with httpx.AsyncClient() as client:\r\n                response = await client.post(\r\n                    f\"{self.base_url}/generations\",\r\n                    headers={\r\n                        \"Authorization\": f\"Bearer {self.api_key}\",\r\n                        \"Content-Type\": \"application/json\",\r\n                    },\r\n                    json=payload,\r\n                )\r\n\n                if response.status_code != 201:\r\n                    raise Exception(f\"Failed: {response.text}\")\r\n\n                task = response.json()\r\n                return await self._poll(task[\"id\"])\r\n\n        async def generate_from_image(\r\n            self,\r\n            image_url: str,\r\n            prompt: str,\r\n            end_image_url: Optional[str] = None,  # Ray3 keyframe feature\r\n        ) -> dict:\r\n            \"\"\"Generate video from start image, optionally with end keyframe.\"\"\"\r\n\n            keyframes = {\r\n                \"frame0\": {\"type\": \"image\", \"url\": image_url},\r\n            }\r\n\n            if end_image_url:\r\n                keyframes[\"frame1\"] = {\"type\": \"image\", \"url\": end_image_url}\r\n\n            return await self.generate(\r\n                prompt=prompt,\r\n                keyframes=keyframes,\r\n            )\r\n\n        async def _poll(\r\n            self,\r\n            generation_id: str,\r\n            timeout: int = 300,\r\n        ) -> dict:\r\n            \"\"\"Poll for completion.\"\"\"\r\n\n            start = asyncio.get_event_loop().time()\r\n\n            async with httpx.AsyncClient() as client:\r\n                while True:\r\n                    response = await client.get(\r\n                        f\"{self.base_url}/generations/{generation_id}\",\r\n                        headers={\r\n                            \"Authorization\": f\"Bearer {self.api_key}\",\r\n                        },\r\n                    )\r\n\n                    result = response.json()\r\n\n                    if result[\"state\"] == \"completed\":\r\n                        return result\r\n\n                    if result[\"state\"] == \"failed\":\r\n                        raise Exception(f\"Failed: {result.get('failure_reason')}\")\r\n\n                    if asyncio.get_event_loop().time() - start > timeout:\r\n                        raise TimeoutError(\"Generation timed out\")\r\n\n                    await asyncio.sleep(5)\r\n\n\n    luma = LumaClient(os.environ[\"LUMA_API_KEY\"])\r\n\n\n    result = await luma.generate(\r\n        prompt=\"A spaceship traveling through a colorful nebula, cinematic\",\r\n        aspect_ratio=\"16:9\",\r\n    )\r\n\n\n    result = await luma.generate_from_image(\r\n        image_url=\"https://example.com/landscape.jpg\",\r\n        prompt=\"Camera slowly panning right, revealing the scene\",\r\n    )\r\n\n\n    result = await luma.generate_from_image(\r\n        image_url=\"https://example.com/start.jpg\",\r\n        prompt=\"Smooth transition, morphing\",\r\n        end_image_url=\"https://example.com/end.jpg\",\r\n    )\r\n\n  anti_patterns:\r\n    - pattern: \"Ignoring HDR capabilities\"\r\n      why: \"Ray3 supports native HDR for pro workflows\"\r\n      fix: \"Export as 16-bit EXR for high-end projects\"\r\n\n  references:\r\n    - \"https://lumalabs.ai/dream-machine\"\r\n    - \"https://lumalabs.ai/ray\"\r\n\n- id: video-processing-pipeline\r\n  name: Video Processing Pipeline\r\n  description: |\r\n    Build end-to-end video generation pipelines.\r\n    Handle upload, generation, post-processing, delivery.\r\n\n    Components:\r\n    - Input validation\r\n    - Queue management\r\n    - Progress tracking\r\n    - Error handling\r\n\n  code_example: |\r\n    import asyncio\r\n    from enum import Enum\r\n    from dataclasses import dataclass\r\n    from typing import Optional, Callable\r\n    import uuid\r\n\n    class VideoStatus(Enum):\r\n        PENDING = \"pending\"\r\n        GENERATING = \"generating\"\r\n        PROCESSING = \"processing\"\r\n        COMPLETED = \"completed\"\r\n        FAILED = \"failed\"\r\n\n    @dataclass\r\n    class VideoJob:\r\n        id: str\r\n        prompt: str\r\n        image_url: Optional[str]\r\n        status: VideoStatus\r\n        progress: int\r\n        output_url: Optional[str]\r\n        error: Optional[str]\r\n        created_at: float\r\n        updated_at: float\r\n\n    class VideoGenerationPipeline:\r\n        \"\"\"End-to-end video generation pipeline.\"\"\"\r\n\n        def __init__(\r\n            self,\r\n            replicate_client,\r\n            storage_client,\r\n            max_concurrent: int = 5,\r\n        ):\r\n            self.replicate = replicate_client\r\n            self.storage = storage_client\r\n            self.max_concurrent = max_concurrent\r\n            self.jobs: dict[str, VideoJob] = {}\r\n            self.semaphore = asyncio.Semaphore(max_concurrent)\r\n\n        async def submit(\r\n            self,\r\n            prompt: str,\r\n            image_url: Optional[str] = None,\r\n            model: str = \"wavespeedai/wan-2.1-t2v-480p\",\r\n            callback: Optional[Callable] = None,\r\n        ) -> str:\r\n            \"\"\"Submit video generation job.\"\"\"\r\n\n            job_id = str(uuid.uuid4())\r\n            now = asyncio.get_event_loop().time()\r\n\n            job = VideoJob(\r\n                id=job_id,\r\n                prompt=prompt,\r\n                image_url=image_url,\r\n                status=VideoStatus.PENDING,\r\n                progress=0,\r\n                output_url=None,\r\n                error=None,\r\n                created_at=now,\r\n                updated_at=now,\r\n            )\r\n\n            self.jobs[job_id] = job\r\n\n\n            asyncio.create_task(\r\n                self._process_job(job, model, callback)\r\n            )\r\n\n            return job_id\r\n\n        async def _process_job(\r\n            self,\r\n            job: VideoJob,\r\n            model: str,\r\n            callback: Optional[Callable],\r\n        ):\r\n            \"\"\"Process a single video job.\"\"\"\r\n\n            async with self.semaphore:\r\n                try:\r\n\n                    job.status = VideoStatus.GENERATING\r\n                    job.progress = 10\r\n                    await self._notify(callback, job)\r\n\n\n                    input_data = {\"prompt\": job.prompt}\r\n                    if job.image_url:\r\n                        input_data[\"image\"] = job.image_url\r\n\n                    prediction = self.replicate.predictions.create(\r\n                        model=model,\r\n                        input=input_data,\r\n                    )\r\n\n\n                    while True:\r\n                        prediction = self.replicate.predictions.get(prediction.id)\r\n\n                        if prediction.status == \"processing\":\r\n                            job.progress = min(80, job.progress + 10)\r\n                            await self._notify(callback, job)\r\n\n                        if prediction.status == \"succeeded\":\r\n                            video_url = prediction.output\r\n                            break\r\n\n                        if prediction.status == \"failed\":\r\n                            raise Exception(prediction.error)\r\n\n                        await asyncio.sleep(5)\r\n\n\n                    job.status = VideoStatus.PROCESSING\r\n                    job.progress = 90\r\n                    await self._notify(callback, job)\r\n\n\n                    permanent_url = await self.storage.upload_from_url(\r\n                        video_url,\r\n                        f\"videos/{job.id}.mp4\",\r\n                    )\r\n\n\n                    job.status = VideoStatus.COMPLETED\r\n                    job.progress = 100\r\n                    job.output_url = permanent_url\r\n                    await self._notify(callback, job)\r\n\n                except Exception as e:\r\n                    job.status = VideoStatus.FAILED\r\n                    job.error = str(e)\r\n                    await self._notify(callback, job)\r\n\n        async def _notify(\r\n            self,\r\n            callback: Optional[Callable],\r\n            job: VideoJob,\r\n        ):\r\n            \"\"\"Notify callback of job update.\"\"\"\r\n            job.updated_at = asyncio.get_event_loop().time()\r\n\n            if callback:\r\n                await callback(job)\r\n\n        def get_status(self, job_id: str) -> Optional[VideoJob]:\r\n            \"\"\"Get job status.\"\"\"\r\n            return self.jobs.get(job_id)\r\n\n        def get_queue_stats(self) -> dict:\r\n            \"\"\"Get queue statistics.\"\"\"\r\n            statuses = [job.status for job in self.jobs.values()]\r\n            return {\r\n                \"total\": len(self.jobs),\r\n                \"pending\": statuses.count(VideoStatus.PENDING),\r\n                \"generating\": statuses.count(VideoStatus.GENERATING),\r\n                \"completed\": statuses.count(VideoStatus.COMPLETED),\r\n                \"failed\": statuses.count(VideoStatus.FAILED),\r\n            }\r\n\n\n    pipeline = VideoGenerationPipeline(\r\n        replicate_client=replicate.Client(),\r\n        storage_client=s3_client,\r\n        max_concurrent=5,\r\n    )\r\n\n\n    job_id = await pipeline.submit(\r\n        prompt=\"A cat playing piano in a jazz club\",\r\n        callback=lambda job: print(f\"Job {job.id}: {job.status.value} - {job.progress}%\"),\r\n    )\r\n\n\n    job = pipeline.get_status(job_id)\r\n\n  anti_patterns:\r\n    - pattern: \"No concurrency limits\"\r\n      why: \"Can overwhelm API rate limits\"\r\n      fix: \"Use semaphores to limit concurrent jobs\"\r\n\n    - pattern: \"Storing videos in memory\"\r\n      why: \"Videos are large, exhaust memory\"\r\n      fix: \"Stream to cloud storage\"\r\n\n  references:\r\n    - \"https://songwenx.medium.com/turning-images-into-videos-a-programmable-and-cost-effective-approach-cf17ce849a02\"",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "text to video",
          "video generation",
          "image to video",
          "runway api",
          "kling video",
          "luma dream machine",
          "wan video",
          "animate image",
          "ai video"
        ],
        "tags": [
          "video-generation",
          "text-to-video",
          "image-to-video",
          "runway",
          "kling",
          "luma",
          "wan",
          "replicate",
          "ai-video"
        ],
        "pairs_with": [],
        "requires": [],
        "category": "ai-ml"
      }
    ]
  },
  {
    "id": "biotech",
    "name": "Biotech",
    "skills": [
      {
        "id": "bioinformatics-workflows",
        "name": "Hardcoded Resource Specifications",
        "version": "1.0.0",
        "layer": 1,
        "description": "Modern Nextflow pipeline with modules",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "biotech"
      },
      {
        "id": "clinical-trial-analysis",
        "name": "Inadequate Power for Safety Endpoints",
        "version": "1.0.0",
        "layer": 1,
        "description": "Time-to-event analysis for clinical endpoints",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "biotech"
      },
      {
        "id": "protein-structure",
        "name": "Interpreting Low-Confidence Regions as Structure",
        "version": "1.0.0",
        "layer": 1,
        "description": "Run structure prediction with proper settings",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "biotech"
      },
      {
        "id": "lab-automation",
        "name": "Unversioned Protocols",
        "version": "1.0.0",
        "layer": 1,
        "description": "Write protocols for Opentrons OT-2/Flex liquid handlers",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "biotech"
      },
      {
        "id": "genomics-pipelines",
        "name": "Using DNA Aligner for RNA-seq",
        "version": "1.0.0",
        "layer": 1,
        "description": "Choose appropriate workflow manager for genomics",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "biotech"
      },
      {
        "id": "drug-discovery-informatics",
        "name": "Using Non-Covalent Docking for Covalent Targets",
        "version": "1.0.0",
        "layer": 1,
        "description": "Screen large compound libraries against targets",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "biotech"
      }
    ]
  },
  {
    "id": "climate",
    "name": "Climate",
    "skills": [
      {
        "id": "carbon-accounting",
        "name": "Carbon Accounting & GHG Protocol",
        "version": "1.0.0",
        "layer": 1,
        "description": "GHG Protocol scope classifications and calculations",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "carbon accounting",
          "GHG emissions",
          "scope 1",
          "scope 2",
          "scope 3",
          "carbon footprint",
          "emission factor",
          "science-based target",
          "SBTi",
          "net zero"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "climate"
      },
      {
        "id": "climate-modeling",
        "name": "Climate Modeling & Analysis",
        "version": "1.0.0",
        "layer": 1,
        "description": "Access and process CMIP6 climate model data",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "climate model",
          "climate projection",
          "CMIP6",
          "climate data",
          "downscaling",
          "climate scenario",
          "RCP",
          "SSP",
          "global warming"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "climate"
      },
      {
        "id": "energy-systems",
        "name": "Energy Systems & Grid Modeling",
        "version": "1.0.0",
        "layer": 1,
        "description": "AC and DC power flow for grid state analysis",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "power flow|load flow|grid model",
          "energy storage|battery dispatch|ESS",
          "demand response|load management|peak shaving",
          "electricity market|LMP|locational marginal price",
          "grid stability|frequency|voltage",
          "capacity planning|resource adequacy",
          "unit commitment|economic dispatch",
          "transmission|distribution|power system"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "climate"
      },
      {
        "id": "renewable-energy",
        "name": "Renewable Energy Systems",
        "version": "1.0.0",
        "layer": 1,
        "description": "Photovoltaic system modeling and simulation",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "renewable energy",
          "solar power",
          "solar PV",
          "wind energy",
          "wind turbine",
          "energy storage",
          "battery storage",
          "grid integration",
          "capacity factor"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "climate"
      },
      {
        "id": "sustainability-metrics",
        "name": "Sustainability Metrics & ESG Reporting",
        "version": "1.0.0",
        "layer": 1,
        "description": "Double materiality analysis for ESG topics",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "ESG|sustainability reporting|disclosure",
          "CDP|climate disclosure|carbon disclosure",
          "TCFD|climate risk|scenario analysis",
          "GRI|global reporting initiative",
          "SASB|materiality|industry standards",
          "CSRD|ESRS|EU sustainability",
          "SDG|sustainable development goals",
          "impact measurement|social impact"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "climate"
      }
    ]
  },
  {
    "id": "communications",
    "name": "Communications",
    "skills": [
      {
        "id": "community-building",
        "name": "Community Building",
        "version": "1.0.0",
        "layer": 2,
        "description": "Creating community channels nobody uses",
        "principles": [
          "Community is about members connecting with each other, not just with you",
          "Small, engaged communities beat large, silent ones",
          "Value first, ask second - give before you expect to receive",
          "Consistency compounds - regular engagement beats occasional bursts",
          "Your superfans are your secret weapon - empower them",
          "Community isn't marketing - it's relationship building at scale",
          "The best community content comes from members, not you"
        ],
        "owns": [
          "community-building",
          "user-community",
          "developer-relations",
          "discord-management",
          "forum-management",
          "ambassador-programs",
          "community-events",
          "community-content",
          "member-engagement"
        ],
        "does_not_own": [
          "social-media-marketing → marketing",
          "customer-support → user-communications",
          "product-feedback-loops → product-strategy",
          "content-marketing → marketing"
        ],
        "triggers": [
          "community",
          "discord",
          "forum",
          "user group",
          "ambassador",
          "champions",
          "developer relations",
          "devrel",
          "community engagement",
          "community growth",
          "power users",
          "superfans"
        ],
        "tags": [
          "community",
          "discord",
          "engagement",
          "devrel",
          "ambassador",
          "forum",
          "user-community",
          "growth",
          "retention",
          "champions"
        ],
        "pairs_with": [
          "user-communications     # Customer communication",
          "marketing              # Growth and awareness",
          "crisis-communications  # Community during crisis",
          "dev-communications     # Developer-specific communities"
        ],
        "requires": [],
        "category": "communications"
      },
      {
        "id": "crisis-communications",
        "name": "Crisis Communications",
        "version": "1.0.0",
        "layer": 2,
        "description": "Minimizing customer impact with corporate language",
        "principles": [
          "Speed beats perfection - acknowledge first, explain later",
          "Silence is interpreted as guilt or incompetence",
          "Empathy before explanation - they don't care why until they feel heard",
          "Internal communication precedes external - your team shouldn't learn from Twitter",
          "One voice, many channels - consistency prevents confusion",
          "Actions speak louder - what you do matters more than what you say",
          "The cover-up is always worse than the crime"
        ],
        "owns": [
          "crisis-communications",
          "incident-response-comms",
          "public-apologies",
          "status-page-updates",
          "data-breach-notifications",
          "outage-communications",
          "pr-crisis-response",
          "customer-trust-recovery",
          "media-statements",
          "crisis-messaging"
        ],
        "does_not_own": [
          "technical-incident-response → incident-responder",
          "legal-liability → legal",
          "media-relations-strategy → marketing",
          "internal-hr-crises → operations"
        ],
        "triggers": [
          "crisis",
          "incident",
          "outage",
          "down",
          "breach",
          "apology",
          "we messed up",
          "customers are angry",
          "PR disaster",
          "viral complaint",
          "status page",
          "postmortem",
          "trust recovery",
          "bad press"
        ],
        "tags": [
          "crisis",
          "incident",
          "communications",
          "apology",
          "trust",
          "status-page",
          "outage",
          "breach",
          "postmortem",
          "recovery"
        ],
        "pairs_with": [
          "incident-responder     # Technical response",
          "executive-communications # Leadership messaging",
          "user-communications    # Ongoing customer comms",
          "community-building     # Community management during crisis",
          "dev-communications     # Technical incident details"
        ],
        "requires": [],
        "category": "communications"
      },
      {
        "id": "dev-communications",
        "name": "Developer Communications",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using sales language instead of technical precision",
        "principles": [
          "Accuracy over polish—wrong information destroys trust instantly",
          "Show, don't tell—working code beats explanation",
          "Developers detect bullshit immediately—be genuine",
          "Documentation is a product, not an afterthought",
          "Every tutorial should have a working outcome",
          "Error messages are documentation",
          "Time to first success is the only metric that matters for getting started guides"
        ],
        "owns": [
          "api-documentation",
          "developer-tutorials",
          "getting-started-guides",
          "technical-blog-posts",
          "changelogs",
          "release-notes",
          "sdk-documentation",
          "code-examples",
          "error-messages",
          "developer-experience"
        ],
        "does_not_own": [
          "marketing-campaigns → marketing",
          "product-announcements → product-management",
          "internal-documentation → backend",
          "user-facing-help → ux-design",
          "community-management → marketing"
        ],
        "triggers": [
          "documentation",
          "docs",
          "tutorial",
          "getting started",
          "API reference",
          "changelog",
          "release notes",
          "developer guide",
          "devrel",
          "developer relations",
          "code examples",
          "SDK docs",
          "README"
        ],
        "tags": [
          "documentation",
          "devrel",
          "tutorials",
          "api-docs",
          "developer-experience",
          "technical-writing",
          "getting-started",
          "changelogs"
        ],
        "pairs_with": [
          "backend           # API design alignment",
          "frontend          # SDK/client documentation",
          "product-management # Feature documentation",
          "copywriting       # Writing quality",
          "content-strategy  # Content planning",
          "marketing         # Developer marketing"
        ],
        "requires": [],
        "category": "communications"
      },
      {
        "id": "stakeholder-management",
        "name": "Stakeholder Management",
        "version": "1.0.0",
        "layer": 2,
        "description": "Only reaching out when you need something",
        "principles": [
          "Consistency beats intensity - regular updates build more trust than occasional epics",
          "Bad news travels faster when you deliver it yourself",
          "Every stakeholder wants to feel like an insider, not an outsider",
          "The best ask is one they're already expecting",
          "Communication debt compounds faster than technical debt",
          "Relationships are built in the quiet months, not just fundraising crises",
          "Different stakeholders need different frequencies and formats"
        ],
        "owns": [
          "stakeholder-management",
          "investor-updates",
          "board-communications",
          "advisor-engagement",
          "partner-communications",
          "vendor-management",
          "monthly-updates",
          "quarterly-reviews"
        ],
        "does_not_own": [
          "fundraising-process → fundraising-strategy",
          "crisis-communications → crisis-communications",
          "team-communications → team-communications",
          "executive-voice → executive-communications",
          "customer-communications → user-communications"
        ],
        "triggers": [
          "stakeholder",
          "investor update",
          "board meeting",
          "board deck",
          "advisor",
          "partner",
          "vendor",
          "monthly update",
          "quarterly update",
          "keep stakeholders informed",
          "investor relations"
        ],
        "tags": [
          "stakeholder",
          "investor",
          "board",
          "advisor",
          "partner",
          "vendor",
          "updates",
          "communications",
          "relationship",
          "engagement"
        ],
        "pairs_with": [
          "fundraising-strategy    # Investor context",
          "executive-communications # Leadership voice",
          "crisis-communications    # When things go wrong",
          "founder-operating-system # Personal effectiveness"
        ],
        "requires": [],
        "category": "communications"
      },
      {
        "id": "team-communications",
        "name": "Team Communications",
        "version": "1.0.0",
        "layer": 2,
        "description": "Treating chat as the source of truth",
        "principles": [
          "Write it down - if it's not documented, it doesn't exist",
          "Async by default, sync when necessary",
          "Context is a gift - over-explain rather than under-explain",
          "The best meetings are the ones that could have been async",
          "Transparency builds trust, but information overload destroys focus",
          "Every message should answer: why does this matter to the reader?",
          "Communication is what the receiver understood, not what you said"
        ],
        "owns": [
          "team-communications",
          "internal-comms",
          "async-communication",
          "all-hands-meetings",
          "team-updates",
          "information-architecture",
          "knowledge-management",
          "company-announcements"
        ],
        "does_not_own": [
          "external-communications → user-communications",
          "executive-voice → executive-communications",
          "crisis-internal → crisis-communications",
          "hiring-communications → hiring-strategy"
        ],
        "triggers": [
          "team communication",
          "all hands",
          "internal update",
          "async",
          "team meeting",
          "company announcement",
          "knowledge base",
          "documentation",
          "remote team",
          "hybrid work",
          "information flow"
        ],
        "tags": [
          "team",
          "internal",
          "async",
          "meetings",
          "communication",
          "documentation",
          "slack",
          "remote",
          "hybrid",
          "all-hands",
          "updates"
        ],
        "pairs_with": [
          "executive-communications  # Leadership messaging",
          "crisis-communications     # Crisis internal comms",
          "founder-operating-system  # Personal communication",
          "hiring-strategy          # New hire onboarding"
        ],
        "requires": [],
        "category": "communications"
      }
    ]
  },
  {
    "id": "data",
    "name": "Data & Databases",
    "skills": [
      {
        "id": "data-engineer",
        "name": "Data Engineer",
        "version": "1.0.0",
        "layer": 1,
        "description": "Treating streaming data like batch or vice versa",
        "principles": [],
        "owns": [
          "etl-pipelines",
          "data-quality",
          "cdc-patterns",
          "batch-processing",
          "stream-processing",
          "data-modeling",
          "data-validation",
          "pipeline-orchestration"
        ],
        "does_not_own": [],
        "triggers": [
          "data pipeline",
          "etl",
          "cdc",
          "data quality",
          "batch processing",
          "stream processing",
          "data transformation",
          "data warehouse",
          "data lake",
          "data validation"
        ],
        "tags": [
          "data-engineering",
          "etl",
          "cdc",
          "batch",
          "streaming",
          "data-quality",
          "dbt",
          "airflow",
          "dagster",
          "data-pipeline",
          "ai-memory"
        ],
        "pairs_with": [
          "postgres-wizard",
          "event-architect",
          "ml-memory",
          "observability-sre",
          "infra-architect",
          "migration-specialist"
        ],
        "requires": [],
        "category": "data"
      },
      {
        "id": "database-schema-design",
        "name": "Database Schema Design",
        "version": "1.0.0",
        "layer": 1,
        "description": "Storing denormalized data everywhere without thinking about updates",
        "principles": [],
        "owns": [
          "schema-design",
          "data-modeling",
          "database-migrations",
          "table-relationships",
          "foreign-keys",
          "primary-keys",
          "indexing-strategy",
          "normalization",
          "denormalization",
          "soft-delete",
          "hard-delete",
          "uuid-design",
          "enum-handling",
          "junction-tables",
          "polymorphic-associations",
          "audit-trails",
          "timestamps"
        ],
        "does_not_own": [],
        "triggers": [
          "database schema",
          "data model",
          "migration",
          "prisma schema",
          "drizzle schema",
          "create table",
          "add column",
          "foreign key",
          "primary key",
          "uuid",
          "auto increment",
          "soft delete",
          "normalization",
          "denormalization",
          "one to many",
          "many to many",
          "junction table",
          "polymorphic",
          "enum type",
          "index strategy"
        ],
        "tags": [
          "database",
          "schema",
          "migration",
          "data-model",
          "prisma",
          "drizzle",
          "typeorm",
          "postgresql",
          "mysql",
          "sqlite"
        ],
        "pairs_with": [
          "backend",
          "postgres-wizard",
          "supabase-backend",
          "devops",
          "performance-hunter"
        ],
        "requires": [],
        "category": "data"
      },
      {
        "id": "drizzle-orm",
        "name": "Drizzle ORM",
        "version": "1.0.0",
        "layer": 1,
        "description": "Defining relations without the corresponding foreign key constraint",
        "principles": [],
        "owns": [
          "drizzle-schema",
          "drizzle-migrations",
          "drizzle-relations",
          "drizzle-kit",
          "drizzle-queries"
        ],
        "does_not_own": [],
        "triggers": [
          "drizzle",
          "drizzle orm",
          "drizzle-kit",
          "drizzle schema",
          "drizzle migration",
          "drizzle relations",
          "sql orm typescript",
          "edge database",
          "d1 database"
        ],
        "tags": [
          "orm",
          "database",
          "typescript",
          "sql",
          "edge",
          "serverless",
          "d1",
          "postgres",
          "mysql",
          "sqlite"
        ],
        "pairs_with": [
          "hono-patterns",
          "sveltekit-fullstack",
          "nuxt3-patterns",
          "cloudflare-workers",
          "trpc-patterns",
          "fastapi-patterns"
        ],
        "requires": [],
        "category": "data"
      },
      {
        "id": "graph-engineer",
        "name": "Graph Engineer",
        "version": "1.0.0",
        "layer": 1,
        "description": "Creating nodes without deduplication",
        "principles": [],
        "owns": [
          "knowledge-graphs",
          "falkordb",
          "neo4j",
          "cypher-queries",
          "causal-graphs",
          "entity-resolution",
          "graph-algorithms"
        ],
        "does_not_own": [],
        "triggers": [
          "knowledge graph",
          "graph database",
          "falkordb",
          "neo4j",
          "cypher query",
          "entity resolution",
          "causal relationships",
          "graph traversal"
        ],
        "tags": [
          "graph-database",
          "knowledge-graph",
          "falkordb",
          "neo4j",
          "cypher",
          "entity-resolution",
          "causal-graph",
          "ai-memory"
        ],
        "pairs_with": [
          "event-architect",
          "vector-specialist",
          "causal-scientist",
          "ml-memory",
          "performance-hunter"
        ],
        "requires": [],
        "category": "data"
      },
      {
        "id": "graphile-worker",
        "name": "Graphile Worker",
        "version": "1.0.0",
        "layer": 1,
        "description": "Disabling LISTEN/NOTIFY and using polling",
        "principles": [
          "PostgreSQL triggers can queue jobs - react to database changes instantly",
          "LISTEN/NOTIFY makes it fast - jobs start in milliseconds, not seconds",
          "Tasks are just functions - simple JavaScript/TypeScript, nothing exotic",
          "SQL API means queue from anywhere - triggers, functions, any language",
          "Jobs are transactional - queue in the same transaction as your data",
          "Cron is built-in - no external scheduler needed",
          "Batch by identifier - process related jobs together efficiently",
          "The worker is the only moving part - PostgreSQL handles the rest"
        ],
        "owns": [
          "graphile-worker-tasks",
          "postgres-trigger-jobs",
          "listen-notify-queues",
          "transactional-job-creation",
          "cron-scheduling",
          "batch-processing",
          "job-deduplication",
          "worker-scaling"
        ],
        "does_not_own": [
          "redis-queues -> bullmq-specialist",
          "serverless-queues -> upstash-qstash",
          "workflow-orchestration -> temporal-craftsman",
          "basic-pg-queues -> pg-boss"
        ],
        "triggers": [
          "graphile worker",
          "postgres trigger job",
          "listen notify queue",
          "postgraphile worker",
          "database trigger queue",
          "transactional job"
        ],
        "tags": [
          "graphile-worker",
          "postgresql",
          "triggers",
          "listen-notify",
          "job-queue",
          "postgraphile",
          "high-performance",
          "supabase"
        ],
        "pairs_with": [
          "postgres-wizard",
          "supabase-backend",
          "graphql-architect",
          "backend",
          "email-systems",
          "drizzle-orm"
        ],
        "requires": [],
        "category": "data"
      },
      {
        "id": "pg-boss",
        "name": "pg-boss Specialist",
        "version": "1.0.0",
        "layer": 1,
        "description": "Jobs without expireInSeconds",
        "principles": [
          "PostgreSQL is your queue - no separate infrastructure needed",
          "SKIP LOCKED is the magic - built for exactly this use case",
          "Transactions are your friend - job completion is atomic",
          "Expiration prevents zombie jobs - always set reasonable timeouts",
          "Archiving keeps the queue lean - don't let completed jobs pile up",
          "Throttling protects resources - rate limit by queue or globally",
          "Scheduling is native - delays and cron built into the database",
          "Monitoring is just SQL - query your job state directly"
        ],
        "owns": [
          "pg-boss-queues",
          "postgresql-job-scheduling",
          "delayed-jobs-postgres",
          "cron-jobs-postgres",
          "job-throttling",
          "job-archiving",
          "singleton-jobs",
          "job-batching"
        ],
        "does_not_own": [
          "redis-queues -> bullmq-specialist",
          "serverless-queues -> upstash-qstash",
          "workflow-orchestration -> temporal-craftsman",
          "postgres-optimization -> postgres-wizard"
        ],
        "triggers": [
          "pg-boss",
          "postgres queue",
          "postgresql job",
          "supabase background job",
          "neon job queue",
          "postgres scheduling",
          "database job queue"
        ],
        "tags": [
          "pg-boss",
          "postgresql",
          "job-queue",
          "background-jobs",
          "supabase",
          "neon",
          "exactly-once",
          "scheduling"
        ],
        "pairs_with": [
          "postgres-wizard",
          "supabase-backend",
          "backend",
          "nextjs-app-router",
          "email-systems",
          "drizzle-orm"
        ],
        "requires": [],
        "category": "data"
      },
      {
        "id": "postgres-wizard",
        "name": "PostgreSQL Wizard",
        "version": "1.0.0",
        "layer": 1,
        "description": "Creating indexes without query analysis",
        "principles": [],
        "owns": [
          "query-optimization",
          "index-design",
          "partitioning-strategy",
          "postgresql-internals",
          "explain-analysis",
          "vacuum-tuning",
          "connection-pooling",
          "replication-setup"
        ],
        "does_not_own": [],
        "triggers": [
          "postgresql",
          "postgres",
          "slow query",
          "index",
          "explain analyze",
          "vacuum",
          "connection pool",
          "pgbouncer",
          "partitioning",
          "replication"
        ],
        "tags": [
          "postgresql",
          "postgres",
          "database",
          "sql",
          "indexing",
          "optimization",
          "partitioning",
          "vacuum",
          "explain",
          "pgvector",
          "ai-memory"
        ],
        "pairs_with": [
          "performance-hunter",
          "data-engineer",
          "migration-specialist",
          "infra-architect",
          "observability-sre",
          "vector-specialist"
        ],
        "requires": [],
        "category": "data"
      },
      {
        "id": "redis-specialist",
        "name": "Redis Specialist",
        "version": "1.0.0",
        "layer": 1,
        "description": "Adding cache without planning how to invalidate it",
        "principles": [],
        "owns": [
          "redis-caching",
          "cache-invalidation",
          "redis-pub-sub",
          "redis-data-structures",
          "redis-cluster",
          "session-storage",
          "rate-limiting",
          "distributed-locks"
        ],
        "does_not_own": [],
        "triggers": [
          "redis",
          "caching strategy",
          "cache invalidation",
          "pub/sub",
          "rate limiting",
          "distributed lock",
          "session storage",
          "leaderboard",
          "message queue",
          "upstash"
        ],
        "tags": [
          "redis",
          "caching",
          "pub-sub",
          "session",
          "rate-limiting",
          "distributed-lock",
          "upstash",
          "elasticache",
          "memorystore"
        ],
        "pairs_with": [
          "performance-hunter",
          "realtime-engineer",
          "event-architect",
          "auth-specialist",
          "infra-architect",
          "postgres-wizard"
        ],
        "requires": [],
        "category": "data"
      },
      {
        "id": "temporal-craftsman",
        "name": "Temporal Craftsman",
        "version": "1.0.0",
        "layer": 1,
        "description": "Changing workflow code without patching",
        "principles": [],
        "owns": [
          "temporal-workflows",
          "durable-execution",
          "saga-patterns",
          "workflow-orchestration",
          "activity-design",
          "workflow-versioning",
          "long-running-processes"
        ],
        "does_not_own": [],
        "triggers": [
          "temporal workflow",
          "durable execution",
          "saga pattern",
          "workflow orchestration",
          "long running process",
          "activity retry",
          "workflow versioning"
        ],
        "tags": [
          "temporal",
          "workflows",
          "durable-execution",
          "saga",
          "orchestration",
          "activities",
          "long-running",
          "ai-memory"
        ],
        "pairs_with": [
          "event-architect",
          "graph-engineer",
          "ml-memory",
          "performance-hunter",
          "privacy-guardian"
        ],
        "requires": [],
        "category": "data"
      },
      {
        "id": "vector-specialist",
        "name": "Vector Specialist",
        "version": "1.0.0",
        "layer": 1,
        "description": "Embedding entire documents as single vectors",
        "principles": [],
        "owns": [
          "vector-databases",
          "embedding-models",
          "qdrant",
          "pgvector",
          "similarity-search",
          "hybrid-retrieval",
          "reranking",
          "quantization"
        ],
        "does_not_own": [],
        "triggers": [
          "vector search",
          "embeddings",
          "semantic search",
          "qdrant",
          "pgvector",
          "similarity search",
          "reranking",
          "hybrid retrieval"
        ],
        "tags": [
          "embeddings",
          "vector-search",
          "qdrant",
          "pgvector",
          "semantic-search",
          "retrieval",
          "reranking",
          "ai-memory"
        ],
        "pairs_with": [
          "event-architect",
          "graph-engineer",
          "ml-memory",
          "performance-hunter",
          "privacy-guardian"
        ],
        "requires": [],
        "category": "data"
      }
    ]
  },
  {
    "id": "design",
    "name": "Design",
    "skills": [
      {
        "id": "branding",
        "name": "Branding",
        "version": "1.0.0",
        "layer": 1,
        "description": "Starting with logo design before understanding brand strategy and positioning",
        "principles": [
          "Simple marks last—complexity dates",
          "Consistency builds recognition; recognition builds trust",
          "A logo is not a brand; it's a symbol of one",
          "Design for the smallest application first",
          "Color is more memorable than shape",
          "Guidelines exist to enable, not to police",
          "Test in context, not in isolation—brands live in the real world"
        ],
        "owns": [
          "logo-design",
          "visual-identity",
          "color-systems",
          "typography-systems",
          "brand-guidelines",
          "naming",
          "verbal-identity",
          "brand-applications",
          "brand-architecture",
          "identity-refresh"
        ],
        "does_not_own": [
          "brand-strategy → brand-positioning",
          "marketing-campaigns → marketing",
          "product-design → ui-design",
          "content-creation → content-strategy",
          "creative-production → creative-communications"
        ],
        "triggers": [
          "logo",
          "branding",
          "brand identity",
          "brand guidelines",
          "visual identity",
          "color palette",
          "typography",
          "brand book",
          "naming",
          "rebrand",
          "brand refresh",
          "brand system"
        ],
        "tags": [
          "branding",
          "identity",
          "logo",
          "visual-design",
          "guidelines",
          "naming",
          "typography",
          "color"
        ],
        "pairs_with": [
          "brand-positioning    # Strategy to execution",
          "ui-design            # Digital application",
          "creative-communications # Production guidelines",
          "copywriting          # Verbal identity application",
          "marketing            # Campaign branding",
          "content-strategy     # Brand voice in content"
        ],
        "requires": [],
        "category": "design"
      },
      {
        "id": "landing-page-design",
        "name": "Landing Page Design",
        "version": "1.0.0",
        "layer": 1,
        "description": "Including site-wide navigation that offers exit paths from the conversion funnel",
        "principles": [
          "One page, one goal, one action",
          "Above the fold is 80% of the battle",
          "Every element either helps conversion or hurts it",
          "Speed is a feature—every second costs conversions",
          "Reduce friction, increase motivation",
          "Specificity beats generality",
          "Test everything, assume nothing"
        ],
        "owns": [
          "landing-page-structure",
          "hero-sections",
          "conversion-elements",
          "page-flow",
          "social-proof-placement",
          "CTA-design",
          "form-optimization",
          "page-speed",
          "mobile-landing-pages",
          "lead-capture",
          "pricing-pages",
          "signup-flows"
        ],
        "does_not_own": [
          "copywriting → copywriting",
          "brand-design → branding",
          "full-website → frontend",
          "advertising → marketing",
          "analytics-setup → analytics"
        ],
        "triggers": [
          "landing page",
          "conversion page",
          "lead capture",
          "signup page",
          "pricing page",
          "hero section",
          "above the fold",
          "CTA design",
          "conversion rate",
          "page optimization",
          "lead gen page",
          "squeeze page",
          "sales page"
        ],
        "tags": [
          "landing-pages",
          "conversion",
          "CRO",
          "design",
          "optimization",
          "lead-generation",
          "signups",
          "forms"
        ],
        "pairs_with": [
          "copywriting        # Page copy",
          "ui-design          # Visual design",
          "marketing          # Traffic source",
          "a-b-testing        # Optimization",
          "analytics          # Measurement"
        ],
        "requires": [],
        "category": "design"
      },
      {
        "id": "ui-design",
        "name": "UI Design",
        "version": "1.0.0",
        "layer": 2,
        "description": "Obsessing over visual polish before validating that the design actually works for users",
        "principles": [
          "Clarity beats cleverness every time",
          "Consistency reduces cognitive load",
          "Hierarchy guides the eye",
          "White space is not empty - it's breathing room",
          "Accessibility is not an afterthought",
          "Design for the worst case, delight in the best",
          "Motion should inform, not decorate"
        ],
        "owns": [
          "visual-hierarchy",
          "color-systems",
          "typography-systems",
          "spacing-systems",
          "component-design",
          "icon-design",
          "animation-design",
          "responsive-design",
          "accessibility-visuals",
          "design-systems",
          "layout-patterns",
          "interaction-feedback"
        ],
        "does_not_own": [
          "user-flows → ux-design",
          "research → ux-design",
          "information-architecture → ux-design",
          "brand-identity → branding",
          "copywriting → copywriting",
          "frontend-code → frontend"
        ],
        "triggers": [
          "ui design",
          "visual design",
          "interface design",
          "component",
          "design system",
          "figma",
          "sketch",
          "color",
          "typography",
          "spacing",
          "layout",
          "animation",
          "motion",
          "responsive",
          "mobile design",
          "button",
          "form design",
          "card",
          "modal",
          "navigation",
          "icon"
        ],
        "tags": [
          "ui",
          "design",
          "visual",
          "interface",
          "components",
          "design-system",
          "figma",
          "accessibility"
        ],
        "pairs_with": [
          "ux-design          # User flows inform visual design",
          "frontend           # Implementation partnership",
          "branding           # Brand application",
          "accessibility      # WCAG compliance"
        ],
        "requires": [],
        "category": "design"
      },
      {
        "id": "ux-design",
        "name": "UX Design",
        "version": "1.0.0",
        "layer": 2,
        "description": "Optimizing for rare scenarios before solving the common case",
        "principles": [
          "Observe behavior, not just opinions",
          "Reduce friction at every step",
          "The user's mental model is the only model that matters",
          "Complexity is a design failure, not a user failure",
          "Fast failure is better than slow success",
          "Good UX is good business",
          "Design for the journey, not just the destination"
        ],
        "owns": [
          "user-research",
          "user-flows",
          "information-architecture",
          "wireframing",
          "prototyping",
          "usability-testing",
          "persona-development",
          "journey-mapping",
          "interaction-design",
          "accessibility-strategy",
          "onboarding-design",
          "error-recovery"
        ],
        "does_not_own": [
          "visual-design → ui-design",
          "implementation → frontend",
          "business-metrics → analytics",
          "brand-identity → branding",
          "marketing-messaging → copywriting"
        ],
        "triggers": [
          "ux design",
          "user experience",
          "user flow",
          "user journey",
          "wireframe",
          "prototype",
          "usability",
          "user research",
          "persona",
          "information architecture",
          "onboarding",
          "navigation",
          "user testing",
          "friction",
          "confusion",
          "drop-off",
          "conversion",
          "task completion",
          "heuristics"
        ],
        "tags": [
          "ux",
          "design",
          "research",
          "user-experience",
          "usability",
          "flows",
          "prototyping",
          "accessibility"
        ],
        "pairs_with": [
          "ui-design          # Visual execution",
          "product-management # Requirements and priorities",
          "analytics          # Behavioral data",
          "frontend           # Implementation reality"
        ],
        "requires": [],
        "category": "design"
      }
    ]
  },
  {
    "id": "development",
    "name": "Development",
    "skills": [
      {
        "id": "accessibility",
        "name": "Accessibility (a11y)",
        "version": "1.0.0",
        "layer": 2,
        "description": "Using div or span as clickable elements instead of button",
        "principles": [
          "Semantic HTML first - ARIA is a repair tool, not a replacement",
          "If you can't use it with a keyboard, it's broken",
          "Color is never the only indicator",
          "All images need alt text - decorative images get empty alt=\\\"\\\"",
          "Focus states are not optional",
          "Accessible experiences should be equivalent, not separate",
          "Test with real assistive technology, not just automated tools"
        ],
        "owns": [
          "accessibility",
          "wcag",
          "aria",
          "keyboard-navigation",
          "screen-readers",
          "focus-management",
          "color-contrast",
          "semantic-html",
          "skip-links"
        ],
        "does_not_own": [
          "general-styling → tailwind-ui",
          "component-architecture → frontend",
          "testing-framework → testing",
          "legal-compliance → legal"
        ],
        "triggers": [
          "accessibility",
          "a11y",
          "wcag",
          "aria",
          "screen reader",
          "keyboard navigation",
          "focus trap",
          "alt text",
          "color contrast",
          "skip link",
          "accessible"
        ],
        "tags": [
          "accessibility",
          "a11y",
          "wcag",
          "aria",
          "screen-reader",
          "keyboard",
          "inclusive",
          "semantic-html"
        ],
        "pairs_with": [
          "frontend            # Component implementation",
          "tailwind-ui         # Accessible styling",
          "testing             # Accessibility testing"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "ai-agents-architect",
        "name": "AI Agents Architect",
        "version": "1.0.0",
        "layer": 2,
        "description": "Using multiple agents when one suffices",
        "principles": [],
        "owns": [
          "Agent architecture design",
          "Tool and function calling",
          "Agent memory systems",
          "Planning and reasoning strategies",
          "Multi-agent orchestration",
          "Agent evaluation and debugging"
        ],
        "does_not_own": [],
        "triggers": [
          "build agent",
          "AI agent",
          "autonomous agent",
          "tool use",
          "function calling",
          "multi-agent",
          "agent memory",
          "agent planning",
          "langchain agent",
          "crewai",
          "autogen",
          "claude agent sdk"
        ],
        "tags": [
          "ai-agents",
          "langchain",
          "autogen",
          "crewai",
          "tool-use",
          "function-calling",
          "autonomous",
          "llm",
          "orchestration"
        ],
        "pairs_with": [
          "rag-engineer          # Knowledge retrieval for agents",
          "prompt-engineer       # Agent prompts and instructions",
          "backend               # Tool implementations and APIs",
          "mcp-builder           # MCP tool integration"
        ],
        "requires": [
          "LLM API usage",
          "Understanding of function calling",
          "Basic prompt engineering"
        ],
        "category": "development"
      },
      {
        "id": "ai-product",
        "name": "AI Product Development",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use function calling or JSON mode with schema validation",
        "principles": [
          "name: LLMs are probabilistic, not deterministic"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "development"
      },
      {
        "id": "analytics-architecture",
        "name": "Analytics Architecture",
        "version": "1.0.0",
        "layer": 2,
        "description": "Instrumenting every possible event without clear questions",
        "principles": [
          "If you can't measure it, you can't improve it",
          "Track events, not pageviews",
          "Design your schema before you ship",
          "Attribution is harder than you think",
          "Privacy is not optional",
          "Data without analysis is just storage costs"
        ],
        "owns": [
          "event-tracking-design",
          "analytics-schema",
          "funnel-analysis",
          "cohort-analysis",
          "attribution-modeling",
          "experimentation-platform",
          "analytics-integration",
          "user-identification",
          "session-tracking",
          "conversion-tracking",
          "analytics-privacy",
          "data-collection"
        ],
        "does_not_own": [
          "data-warehousing → data-engineering",
          "bi-tools → data-engineering",
          "marketing-campaigns → marketing",
          "growth-tactics → growth-strategy",
          "ab-testing-statistics → experimentation"
        ],
        "triggers": [
          "analytics",
          "tracking",
          "events",
          "funnel",
          "conversion",
          "attribution",
          "segment",
          "amplitude",
          "mixpanel",
          "posthog",
          "ab testing",
          "experiment",
          "cohort",
          "retention",
          "measure",
          "metrics"
        ],
        "tags": [
          "analytics",
          "tracking",
          "events",
          "funnel",
          "conversion",
          "attribution",
          "data"
        ],
        "pairs_with": [
          "growth-strategy        # What to measure",
          "product-strategy       # Success metrics",
          "marketing              # Campaign tracking",
          "data-engineering       # Data infrastructure"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "api-designer",
        "name": "API Designer",
        "version": "1.0.0",
        "layer": 1,
        "description": "\"An error occurred\" without context",
        "principles": [],
        "owns": [
          "rest-api-design",
          "graphql-schema",
          "grpc-protobuf",
          "api-versioning",
          "rate-limiting",
          "api-documentation",
          "error-handling",
          "pagination"
        ],
        "does_not_own": [],
        "triggers": [
          "api design",
          "rest",
          "graphql",
          "grpc",
          "openapi",
          "swagger",
          "versioning",
          "pagination",
          "rate limiting",
          "endpoint"
        ],
        "tags": [
          "api",
          "rest",
          "graphql",
          "grpc",
          "openapi",
          "swagger",
          "versioning",
          "pagination",
          "rate-limiting",
          "ai-memory"
        ],
        "pairs_with": [
          "sdk-builder",
          "docs-engineer",
          "performance-hunter",
          "privacy-guardian",
          "test-architect",
          "observability-sre"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "auth-specialist",
        "name": "Auth Specialist",
        "version": "1.0.0",
        "layer": 1,
        "description": "Storing JWTs in browser localStorage",
        "principles": [],
        "owns": [
          "oauth-oidc-flows",
          "session-management",
          "jwt-security",
          "password-hashing",
          "mfa-implementation",
          "token-lifecycle",
          "csrf-protection",
          "auth-middleware"
        ],
        "does_not_own": [],
        "triggers": [
          "authentication flow",
          "login system",
          "oauth integration",
          "jwt tokens",
          "session management",
          "password hashing",
          "mfa setup",
          "refresh tokens",
          "social login",
          "role-based access"
        ],
        "tags": [
          "authentication",
          "authorization",
          "oauth",
          "oidc",
          "jwt",
          "sessions",
          "mfa",
          "passkeys",
          "nextauth",
          "supabase-auth",
          "clerk"
        ],
        "pairs_with": [
          "security-engineer",
          "api-designer",
          "frontend-react",
          "backend-node",
          "database-specialist",
          "privacy-guardian"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "authentication-oauth",
        "name": "Authentication & OAuth",
        "version": "1.0.0",
        "layer": 2,
        "description": "Storing JWT tokens in localStorage",
        "principles": [],
        "owns": [
          "OAuth 2.0 / OpenID Connect flows",
          "JWT token generation and validation",
          "Session management strategies",
          "Password hashing and storage",
          "Multi-factor authentication",
          "Token refresh flows",
          "Social login integration",
          "Auth middleware design"
        ],
        "does_not_own": [
          "Authorization/permissions → authorization skill",
          "API rate limiting → rate-limiting skill",
          "Encryption at rest → security-hardening skill",
          "Network security → infrastructure-as-code",
          "Audit logging → logging-strategies skill"
        ],
        "triggers": [
          "implement authentication",
          "oauth login",
          "jwt tokens",
          "session management",
          "social login",
          "password reset",
          "multi-factor auth",
          "refresh tokens",
          "Working with Auth0, Clerk, NextAuth, Passport.js"
        ],
        "tags": [
          "authentication",
          "oauth",
          "jwt",
          "session",
          "security",
          "login",
          "password",
          "mfa",
          "oidc"
        ],
        "pairs_with": [
          "security-hardening",
          "backend",
          "database-schema-design",
          "frontend"
        ],
        "requires": [
          "HTTPS for all auth endpoints",
          "Secure password storage (never plaintext)",
          "Understanding of token security"
        ],
        "category": "development"
      },
      {
        "id": "backend",
        "name": "Backend Engineering",
        "version": "1.0.0",
        "layer": 1,
        "description": "Starting async operations without awaiting or handling errors",
        "principles": [],
        "owns": [
          "api-design",
          "database-architecture",
          "data-modeling",
          "authentication-systems",
          "authorization-patterns",
          "caching-strategies",
          "queue-systems",
          "background-jobs",
          "rate-limiting",
          "error-handling",
          "logging-patterns",
          "transaction-management",
          "migration-strategies",
          "webhook-systems",
          "file-storage",
          "search-implementation"
        ],
        "does_not_own": [],
        "triggers": [
          "backend",
          "api",
          "database",
          "postgres",
          "mysql",
          "mongodb",
          "redis",
          "graphql",
          "rest",
          "authentication",
          "authorization",
          "caching",
          "queue",
          "background job",
          "webhook",
          "migration",
          "transaction",
          "n+1",
          "rate limit",
          "server",
          "node.js",
          "python",
          "go"
        ],
        "tags": [
          "backend",
          "api",
          "database",
          "architecture",
          "performance",
          "reliability",
          "security"
        ],
        "pairs_with": [
          "frontend",
          "devops",
          "cybersecurity",
          "qa-engineering",
          "analytics"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "rate-limiting",
        "name": "Bottleneck",
        "version": "1.0.0",
        "layer": 1,
        "description": "Rate limits reset on restart, don't work across servers",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "development"
      },
      {
        "id": "caching-patterns",
        "name": "Caching Patterns",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using Redis KEYS command for pattern matching",
        "principles": [],
        "owns": [
          "cache-invalidation",
          "cache-aside-pattern",
          "write-through-cache",
          "write-behind-cache",
          "read-through-cache",
          "cache-stampede-prevention",
          "ttl-strategies",
          "redis-caching",
          "in-memory-cache",
          "http-caching",
          "cdn-caching",
          "cache-warming",
          "distributed-cache",
          "cache-eviction"
        ],
        "does_not_own": [],
        "triggers": [
          "cache",
          "caching",
          "redis",
          "memcached",
          "cdn",
          "ttl",
          "invalidation",
          "stale",
          "cache aside",
          "write through",
          "cache stampede",
          "thundering herd",
          "cache warming",
          "etag",
          "cache-control"
        ],
        "tags": [
          "caching",
          "redis",
          "memcached",
          "cdn",
          "performance",
          "http-cache",
          "ttl",
          "invalidation"
        ],
        "pairs_with": [
          "backend",
          "database-schema-design",
          "performance-optimization",
          "infrastructure-as-code"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "chaos-engineer",
        "name": "Chaos Engineer",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using chaos to prove team isn't ready",
        "principles": [],
        "owns": [
          "failure-injection",
          "game-days",
          "resilience-testing",
          "fault-tolerance",
          "recovery-verification",
          "blast-radius-control",
          "steady-state-definition",
          "hypothesis-testing"
        ],
        "does_not_own": [],
        "triggers": [
          "chaos engineering",
          "resilience testing",
          "failure injection",
          "game day",
          "fault tolerance",
          "chaos experiment",
          "disaster recovery",
          "reliability testing"
        ],
        "tags": [
          "chaos-engineering",
          "resilience",
          "failure-injection",
          "game-day",
          "fault-tolerance",
          "reliability",
          "testing",
          "litmus",
          "chaos-monkey",
          "ai-memory"
        ],
        "pairs_with": [
          "infra-architect",
          "observability-sre",
          "test-architect",
          "performance-hunter",
          "event-architect",
          "postgres-wizard"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "ci-cd-pipeline",
        "name": "CI/CD Pipeline",
        "version": "1.0.0",
        "layer": 1,
        "description": "Allowing deployments outside the CI/CD pipeline",
        "principles": [],
        "owns": [
          "github-actions",
          "gitlab-ci",
          "circleci",
          "jenkins",
          "workflow-automation",
          "deployment-strategies",
          "blue-green-deployment",
          "canary-deployment",
          "rolling-deployment",
          "pipeline-security",
          "secrets-management",
          "workflow-optimization",
          "build-caching",
          "artifact-management",
          "environment-promotion"
        ],
        "does_not_own": [],
        "triggers": [
          "ci/cd",
          "cicd",
          "pipeline",
          "github actions",
          "gitlab ci",
          "circleci",
          "jenkins",
          "workflow",
          "deployment",
          "deploy",
          "release",
          "blue green",
          "canary",
          "rollback",
          "build",
          "test automation",
          "continuous integration",
          "continuous deployment"
        ],
        "tags": [
          "cicd",
          "github-actions",
          "gitlab-ci",
          "deployment",
          "automation",
          "devops",
          "pipelines",
          "continuous-integration",
          "continuous-deployment"
        ],
        "pairs_with": [
          "docker-containerization",
          "kubernetes-deployment",
          "infrastructure-as-code",
          "cybersecurity"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "cicd-pipelines",
        "name": "CI/CD Pipelines",
        "version": "1.0.0",
        "layer": 2,
        "description": "Downloading all dependencies on every run",
        "principles": [
          "Fast feedback - developers should know in minutes, not hours",
          "Fail fast - put quick checks first, slow ones last",
          "Cache aggressively - don't download the internet on every build",
          "Parallelize when possible - matrix builds, parallel jobs",
          "Keep pipelines DRY - reusable workflows and templates",
          "Secure by default - least privilege, no secrets in logs",
          "Pipeline as code - version control your workflows"
        ],
        "owns": [
          "github-actions",
          "gitlab-ci",
          "azure-pipelines",
          "jenkins-pipelines",
          "ci-cd-design",
          "deployment-strategies",
          "build-optimization",
          "test-automation"
        ],
        "does_not_own": [
          "container-orchestration -> kubernetes",
          "infrastructure-provisioning -> aws-services",
          "container-builds -> docker",
          "application-testing -> testing"
        ],
        "triggers": [
          "github actions",
          "gitlab ci",
          "ci cd",
          "pipeline",
          "workflow",
          "deploy automation",
          "continuous integration",
          "continuous deployment",
          "build pipeline",
          "yaml workflow"
        ],
        "tags": [
          "ci-cd",
          "github-actions",
          "gitlab-ci",
          "devops",
          "automation",
          "deployment",
          "pipelines"
        ],
        "pairs_with": [
          "docker              # Build container images",
          "kubernetes          # Deploy to clusters",
          "testing             # Test automation",
          "backend             # Application builds",
          "aws-services        # Cloud deployments"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "code-architecture-review",
        "name": "Code Architecture Review",
        "version": "1.0.0",
        "layer": 3,
        "description": "One module that does everything",
        "principles": [],
        "owns": [
          "Dependency graph analysis",
          "Module boundary evaluation",
          "Coupling and cohesion assessment",
          "Layer separation review",
          "Change impact analysis",
          "Technical debt identification"
        ],
        "does_not_own": [
          "Code formatting/style → linting tools",
          "Performance optimization → performance skill",
          "Security vulnerabilities → security-audit skill",
          "Test coverage → testing skill",
          "Deployment architecture → devops skill"
        ],
        "triggers": [
          "Reviewing pull requests with structural changes",
          "Planning refactoring work",
          "Evaluating new feature architecture",
          "Assessing technical debt",
          "Before major releases",
          "When code feels \"hard to change"
        ],
        "tags": [
          "architecture",
          "code-review",
          "refactoring",
          "design-patterns",
          "technical-debt",
          "dependencies",
          "maintainability"
        ],
        "pairs_with": [
          "typescript-strict",
          "testing-patterns",
          "api-design"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "code-cleanup",
        "name": "Code Cleanup Agent",
        "version": "1.0.0",
        "layer": 1,
        "description": "Refactoring code without test coverage to verify behavior",
        "principles": [],
        "owns": [
          "Identifying unused imports, variables, and exports",
          "Finding dead code paths and unreachable code",
          "Organizing imports (grouping, sorting, removing duplicates)",
          "Improving type annotations (any → specific, missing return types)",
          "Standardizing naming conventions",
          "Splitting large files by domain",
          "Removing backwards-compatibility hacks"
        ],
        "does_not_own": [
          "Feature implementation → relevant feature skill",
          "Bug fixes that change behavior → debugging skill",
          "Performance optimization → optimization skill",
          "Security fixes → security skill",
          "Testing → testing skill"
        ],
        "triggers": [
          "User asks to \"clean up\" code",
          "User mentions \"dead code\" or \"unused",
          "User wants to \"organize imports",
          "User asks about \"code quality",
          "User wants to \"refactor\" without changing behavior",
          "Code review identifies cleanup items",
          "After major feature completion"
        ],
        "tags": [
          "cleanup",
          "refactoring",
          "code-quality",
          "maintenance",
          "organization"
        ],
        "pairs_with": [],
        "requires": [
          "TypeScript or JavaScript codebase",
          "Working build system (to verify no breaks)"
        ],
        "category": "development"
      },
      {
        "id": "code-review",
        "name": "Code Review",
        "version": "1.0.0",
        "layer": 1,
        "description": "Blocking for personal preferences, not actual issues",
        "principles": [],
        "owns": [
          "code-quality",
          "review-standards",
          "review-process",
          "pr-management",
          "review-automation",
          "linting-standards",
          "commit-hygiene",
          "documentation-review",
          "architecture-review",
          "security-review"
        ],
        "does_not_own": [],
        "triggers": [
          "code review",
          "PR review",
          "pull request",
          "merge request",
          "review comments",
          "LGTM",
          "review feedback",
          "approve PR",
          "request changes",
          "review checklist",
          "code quality",
          "review standards"
        ],
        "tags": [
          "code-review",
          "pull-request",
          "PR",
          "quality",
          "standards",
          "feedback",
          "collaboration",
          "mentoring"
        ],
        "pairs_with": [
          "frontend",
          "backend",
          "qa-engineering",
          "cybersecurity",
          "codebase-optimization",
          "devops"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "code-reviewer",
        "name": "Code Reviewer",
        "version": "1.0.0",
        "layer": 1,
        "description": "Letting PRs sit for days without feedback",
        "principles": [],
        "owns": [
          "code-quality",
          "design-patterns",
          "security-review",
          "review-process",
          "technical-debt",
          "refactoring",
          "code-style",
          "best-practices"
        ],
        "does_not_own": [],
        "triggers": [
          "code review",
          "pull request",
          "PR review",
          "code quality",
          "refactor",
          "technical debt",
          "design pattern",
          "best practice"
        ],
        "tags": [
          "code-review",
          "quality",
          "patterns",
          "security",
          "refactoring",
          "best-practices",
          "pull-request",
          "review",
          "ai-memory"
        ],
        "pairs_with": [
          "test-architect",
          "performance-hunter",
          "privacy-guardian",
          "api-designer",
          "python-craftsman",
          "docs-engineer"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "codebase-optimization",
        "name": "Codebase Optimization",
        "version": "1.0.0",
        "layer": 1,
        "description": "Optimizing metrics that don't represent real user experience",
        "principles": [],
        "owns": [
          "refactoring",
          "performance-optimization",
          "technical-debt",
          "code-architecture",
          "dependency-management",
          "code-cleanup",
          "dead-code-removal",
          "bundle-optimization",
          "query-optimization",
          "memory-management"
        ],
        "does_not_own": [],
        "triggers": [
          "refactor",
          "optimize",
          "performance",
          "technical debt",
          "cleanup",
          "architecture",
          "speed up",
          "bundle size",
          "memory leak",
          "slow query",
          "code smell",
          "complexity",
          "dead code"
        ],
        "tags": [
          "performance",
          "refactoring",
          "optimization",
          "technical-debt",
          "architecture",
          "cleanup",
          "bundle",
          "memory"
        ],
        "pairs_with": [
          "frontend",
          "backend",
          "devops",
          "qa-engineering",
          "code-review"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "cybersecurity",
        "name": "Cybersecurity",
        "version": "1.0.0",
        "layer": 1,
        "description": "Returning stack traces, SQL queries, or internal details in errors",
        "principles": [],
        "owns": [
          "application-security",
          "authentication",
          "authorization",
          "encryption",
          "secrets-management",
          "vulnerability-management",
          "security-testing",
          "secure-coding",
          "compliance",
          "incident-response",
          "access-control",
          "audit-logging"
        ],
        "does_not_own": [],
        "triggers": [
          "security",
          "authentication",
          "authorization",
          "encryption",
          "OWASP",
          "vulnerability",
          "XSS",
          "SQL injection",
          "CSRF",
          "secrets",
          "password",
          "JWT",
          "OAuth",
          "permissions",
          "audit",
          "compliance"
        ],
        "tags": [
          "security",
          "authentication",
          "authorization",
          "encryption",
          "vulnerabilities",
          "OWASP",
          "compliance",
          "audit"
        ],
        "pairs_with": [
          "backend",
          "frontend",
          "devops",
          "code-review",
          "qa-engineering"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "database-architect",
        "name": "Database Architect",
        "version": "1.0.0",
        "layer": 1,
        "description": "Relying on application code for referential integrity",
        "principles": [],
        "owns": [
          "database-design",
          "schema-modeling",
          "query-optimization",
          "indexing-strategies",
          "data-integrity",
          "normalization",
          "migration-strategies",
          "database-scaling"
        ],
        "does_not_own": [],
        "triggers": [
          "database design",
          "schema",
          "indexes",
          "query optimization",
          "migrations",
          "normalization",
          "database scaling",
          "foreign keys",
          "data modeling"
        ],
        "tags": [
          "database",
          "sql",
          "postgres",
          "mysql",
          "mongodb",
          "schema",
          "indexes",
          "migrations",
          "normalization",
          "optimization"
        ],
        "pairs_with": [
          "backend",
          "api-designer",
          "performance-hunter",
          "devops",
          "data-engineering",
          "security-analyst"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "defi-architect",
        "name": "DeFi Architect",
        "version": "1.0.0",
        "layer": 1,
        "description": "Fixed rates, thresholds in code",
        "principles": [],
        "owns": [
          "defi-protocol-design",
          "amm-mechanics",
          "lending-protocols",
          "yield-optimization",
          "tokenomics",
          "oracle-integration",
          "liquidation-mechanics",
          "protocol-security"
        ],
        "does_not_own": [],
        "triggers": [
          "defi",
          "amm",
          "liquidity pool",
          "lending protocol",
          "yield farming",
          "oracle",
          "liquidation",
          "tokenomics",
          "tvl",
          "impermanent loss"
        ],
        "tags": [
          "defi",
          "amm",
          "lending",
          "yield",
          "liquidity",
          "oracle",
          "tokenomics",
          "protocol",
          "ethereum",
          "web3"
        ],
        "pairs_with": [
          "smart-contract-engineer",
          "wallet-integration",
          "security-analyst",
          "backend",
          "data-engineering",
          "product-manager"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "devops",
        "name": "DevOps Engineering",
        "version": "1.0.0",
        "layer": 1,
        "description": "Terraform state file on local machine or in repo",
        "principles": [],
        "owns": [
          "infrastructure-as-code",
          "ci-cd-pipelines",
          "container-orchestration",
          "cloud-architecture",
          "monitoring-alerting",
          "logging-infrastructure",
          "deployment-strategies",
          "disaster-recovery",
          "cost-optimization",
          "secrets-management",
          "service-mesh",
          "load-balancing",
          "auto-scaling",
          "backup-strategies"
        ],
        "does_not_own": [],
        "triggers": [
          "devops",
          "infrastructure",
          "deployment",
          "ci/cd",
          "docker",
          "kubernetes",
          "aws",
          "gcp",
          "azure",
          "terraform",
          "cloudflare",
          "vercel",
          "monitoring",
          "alerting",
          "pipeline",
          "container",
          "scaling",
          "downtime",
          "incident",
          "sre"
        ],
        "tags": [
          "devops",
          "infrastructure",
          "cloud",
          "ci-cd",
          "monitoring",
          "reliability",
          "sre",
          "containers"
        ],
        "pairs_with": [
          "backend",
          "frontend",
          "cybersecurity",
          "qa-engineering"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "microservices-patterns",
        "name": "Distributed Monolith",
        "version": "1.0.0",
        "layer": 1,
        "description": "Microservices tightly coupled like a monolith",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "development"
      },
      {
        "id": "docker",
        "name": "Docker & Containers",
        "version": "^2.x",
        "layer": 2,
        "description": "Using full OS images when slim/alpine works",
        "principles": [
          "Smallest possible base image for production",
          "Multi-stage builds to separate build and runtime",
          "One process per container",
          "Layers are cached - order matters",
          "Never run as root in production",
          "No secrets in images - use runtime injection",
          ".dockerignore is as important as Dockerfile"
        ],
        "owns": [
          "dockerfile",
          "docker-compose",
          "docker-networking",
          "docker-volumes",
          "container-security",
          "multi-stage-builds",
          "container-registries",
          "docker-buildx"
        ],
        "does_not_own": [
          "container-orchestration -> kubernetes",
          "ci-cd-pipelines -> devops",
          "cloud-infrastructure -> aws-services",
          "monitoring -> devops"
        ],
        "triggers": [
          "docker",
          "dockerfile",
          "container",
          "docker compose",
          "docker build",
          "containerize",
          "docker image",
          "multi-stage build",
          "docker network",
          "docker volume"
        ],
        "tags": [
          "docker",
          "containers",
          "devops",
          "deployment",
          "infrastructure",
          "security",
          "optimization"
        ],
        "pairs_with": [
          "devops              # CI/CD integration",
          "kubernetes          # Orchestration",
          "backend             # App containerization",
          "postgres-wizard     # Database containers"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "docker-containerization",
        "name": "Docker Containerization",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using ADD for simple file copies",
        "principles": [],
        "owns": [
          "dockerfile",
          "docker-compose",
          "container-images",
          "multi-stage-builds",
          "base-images",
          "layer-caching",
          "image-optimization",
          "container-security",
          "health-checks",
          "signal-handling",
          "build-context",
          "dockerignore",
          "container-registries",
          "image-scanning"
        ],
        "does_not_own": [],
        "triggers": [
          "docker",
          "dockerfile",
          "container",
          "image",
          "docker-compose",
          "build",
          "multi-stage",
          "alpine",
          "distroless",
          "scratch",
          "docker build",
          "docker run",
          "registry",
          "ecr",
          "gcr",
          "dockerhub",
          "layer",
          "cache"
        ],
        "tags": [
          "docker",
          "containers",
          "dockerfile",
          "images",
          "containerization",
          "devops",
          "cloud-native",
          "microservices"
        ],
        "pairs_with": [
          "kubernetes-deployment",
          "devops",
          "infrastructure-as-code",
          "ci-cd-pipeline"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "docker-specialist",
        "name": "Docker Specialist",
        "version": "1.0.0",
        "layer": 1,
        "description": "One RUN command with everything",
        "principles": [],
        "owns": [
          "docker-images",
          "dockerfile-optimization",
          "docker-compose",
          "container-security",
          "multi-stage-builds",
          "container-networking",
          "volume-management",
          "registry-management"
        ],
        "does_not_own": [],
        "triggers": [
          "docker",
          "dockerfile",
          "container",
          "docker-compose",
          "image",
          "containerize",
          "docker build",
          "multi-stage build"
        ],
        "tags": [
          "docker",
          "containers",
          "dockerfile",
          "docker-compose",
          "images",
          "kubernetes",
          "devops",
          "containerization",
          "microservices"
        ],
        "pairs_with": [
          "devops",
          "backend",
          "infra-architect",
          "security-analyst",
          "performance-hunter",
          "ci-cd-specialist"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "docs-engineer",
        "name": "Documentation Engineer",
        "version": "1.0.0",
        "layer": 1,
        "description": "Critical info only in people's heads",
        "principles": [],
        "owns": [
          "api-documentation",
          "tutorials",
          "architecture-docs",
          "code-comments",
          "readme-files",
          "developer-guides",
          "changelog",
          "doc-automation"
        ],
        "does_not_own": [],
        "triggers": [
          "documentation",
          "docs",
          "readme",
          "tutorial",
          "api docs",
          "guide",
          "changelog",
          "comments",
          "openapi"
        ],
        "tags": [
          "documentation",
          "api-docs",
          "tutorials",
          "readme",
          "openapi",
          "swagger",
          "developer-experience",
          "technical-writing",
          "ai-memory"
        ],
        "pairs_with": [
          "api-designer",
          "sdk-builder",
          "code-reviewer",
          "test-architect",
          "migration-specialist",
          "python-craftsman"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "event-architect",
        "name": "Event Architect",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using random(), datetime.now(), or external state in handlers",
        "principles": [],
        "owns": [
          "event-sourcing",
          "cqrs-patterns",
          "nats-jetstream",
          "kafka-events",
          "event-projections",
          "event-schema-design"
        ],
        "does_not_own": [],
        "triggers": [
          "event sourcing",
          "event store",
          "cqrs",
          "nats jetstream",
          "kafka events",
          "event projection",
          "replay events",
          "event schema"
        ],
        "tags": [
          "event-sourcing",
          "cqrs",
          "nats",
          "kafka",
          "projections",
          "event-driven",
          "memory-architecture",
          "ai-memory"
        ],
        "pairs_with": [
          "graph-engineer",
          "vector-specialist",
          "temporal-craftsman",
          "ml-memory",
          "performance-hunter"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "frontend",
        "name": "Frontend Engineering",
        "version": "1.0.0",
        "layer": 1,
        "description": "import _ from 'lodash' instead of import debounce from 'lodash/debounce",
        "principles": [],
        "owns": [
          "frontend-architecture",
          "component-design",
          "state-management",
          "performance-optimization",
          "accessibility-implementation",
          "responsive-design",
          "client-side-routing",
          "form-handling",
          "data-fetching",
          "error-boundaries",
          "code-splitting",
          "bundle-optimization",
          "browser-compatibility",
          "animation-implementation"
        ],
        "does_not_own": [],
        "triggers": [
          "frontend",
          "react",
          "vue",
          "svelte",
          "next.js",
          "nuxt",
          "component",
          "state management",
          "redux",
          "zustand",
          "client side",
          "spa",
          "ssr",
          "hydration",
          "bundle size",
          "web vitals",
          "accessibility",
          "a11y",
          "responsive",
          "css",
          "tailwind"
        ],
        "tags": [
          "frontend",
          "react",
          "typescript",
          "performance",
          "accessibility",
          "components",
          "state",
          "architecture"
        ],
        "pairs_with": [
          "ui-design",
          "ux-design",
          "backend",
          "devops",
          "qa-engineering"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "game-development",
        "name": "Game Development",
        "version": "1.0.0",
        "layer": 1,
        "description": "Systems directly accessing each other's internals",
        "principles": [],
        "owns": [
          "game-architecture",
          "gameplay-programming",
          "physics-systems",
          "game-loop",
          "entity-systems",
          "input-handling",
          "collision-detection",
          "game-state",
          "asset-pipeline",
          "performance-optimization"
        ],
        "does_not_own": [],
        "triggers": [
          "game",
          "gamedev",
          "game development",
          "phaser",
          "unity",
          "unreal",
          "godot",
          "gameplay",
          "game loop",
          "sprites",
          "collision",
          "physics",
          "player",
          "level",
          "tilemap"
        ],
        "tags": [
          "games",
          "gamedev",
          "interactive",
          "gameplay",
          "physics",
          "engines",
          "performance",
          "player-experience"
        ],
        "pairs_with": [
          "frontend",
          "backend",
          "qa-engineering",
          "codebase-optimization"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "git-workflow",
        "name": "Git Workflow",
        "version": "1.0.0",
        "layer": 2,
        "description": "Making commits directly to the main branch",
        "principles": [
          "Commit early, commit often - small commits are easier to review and revert",
          "Write commit messages for future you who doesn't remember the context",
          "Never force push to shared branches - coordinate with your team",
          "Prefer rebase for local work, merge for shared branches",
          "Keep branches short-lived - merge or delete within days, not weeks",
          "The main branch should always be deployable",
          "Use git reflog before panicking - almost nothing is truly lost"
        ],
        "owns": [
          "git-workflow",
          "git-branching",
          "git-commits",
          "git-merging",
          "git-rebasing",
          "conflict-resolution",
          "git-history",
          "git-hooks"
        ],
        "does_not_own": [
          "ci-cd-pipelines → devops",
          "code-review-process → code-review",
          "deployment-automation → devops",
          "monorepo-tooling → monorepo-management"
        ],
        "triggers": [
          "git workflow",
          "branching strategy",
          "git merge",
          "git rebase",
          "merge conflict",
          "git commit",
          "trunk-based",
          "gitflow",
          "git history",
          "git revert",
          "git reset"
        ],
        "tags": [
          "git",
          "version-control",
          "workflow",
          "branching",
          "commits",
          "merge",
          "rebase",
          "collaboration"
        ],
        "pairs_with": [
          "devops               # CI/CD integration",
          "code-review          # PR workflow",
          "testing              # Pre-commit hooks"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "graphql-architect",
        "name": "GraphQL Architect",
        "version": "1.0.0",
        "layer": 1,
        "description": "All logic in resolvers instead of services",
        "principles": [],
        "owns": [
          "graphql-schema-design",
          "graphql-resolvers",
          "graphql-federation",
          "graphql-subscriptions",
          "graphql-performance",
          "graphql-security",
          "graphql-tooling",
          "dataloader-patterns"
        ],
        "does_not_own": [],
        "triggers": [
          "graphql",
          "schema design",
          "resolvers",
          "federation",
          "apollo",
          "relay",
          "dataloader",
          "n+1 problem",
          "graphql security"
        ],
        "tags": [
          "graphql",
          "api",
          "schema",
          "resolvers",
          "federation",
          "subscriptions",
          "apollo",
          "relay",
          "dataloader"
        ],
        "pairs_with": [
          "api-designer",
          "backend",
          "frontend",
          "database-design",
          "performance-hunter",
          "security-analyst"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "infra-architect",
        "name": "Infrastructure Architect",
        "version": "1.0.0",
        "layer": 1,
        "description": "Storing sensitive data in ConfigMaps",
        "principles": [],
        "owns": [
          "kubernetes-orchestration",
          "terraform-iac",
          "gitops-workflows",
          "service-mesh",
          "cloud-platforms",
          "container-orchestration",
          "infrastructure-security"
        ],
        "does_not_own": [],
        "triggers": [
          "kubernetes",
          "k8s",
          "terraform",
          "infrastructure",
          "deployment",
          "helm",
          "argocd",
          "gitops",
          "service mesh",
          "istio",
          "cloud platform"
        ],
        "tags": [
          "kubernetes",
          "terraform",
          "gitops",
          "argocd",
          "helm",
          "istio",
          "aws",
          "gcp",
          "azure",
          "infrastructure",
          "platform",
          "devops",
          "ai-memory"
        ],
        "pairs_with": [
          "observability-sre",
          "postgres-wizard",
          "event-architect",
          "performance-hunter",
          "chaos-engineer",
          "migration-specialist"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "infrastructure-as-code",
        "name": "Infrastructure as Code",
        "version": "1.0.0",
        "layer": 1,
        "description": "Giving Terraform AdministratorAccess or Action = \"*",
        "principles": [],
        "owns": [
          "terraform",
          "pulumi",
          "cloudformation",
          "state-management",
          "remote-backends",
          "state-locking",
          "modules",
          "workspaces",
          "environments",
          "resource-lifecycle",
          "drift-detection",
          "import-existing",
          "destroy-protection",
          "secret-management",
          "iam-policies",
          "provider-versioning"
        ],
        "does_not_own": [],
        "triggers": [
          "terraform",
          "pulumi",
          "cloudformation",
          "infrastructure",
          "iac",
          "state file",
          "remote backend",
          "s3 backend",
          "dynamodb lock",
          "terraform plan",
          "terraform apply",
          "terraform destroy",
          "module",
          "workspace",
          "provider",
          "resource",
          "state drift",
          "import",
          "aws",
          "gcp",
          "azure"
        ],
        "tags": [
          "infrastructure",
          "terraform",
          "pulumi",
          "cloudformation",
          "iac",
          "devops",
          "aws",
          "gcp",
          "azure",
          "cloud"
        ],
        "pairs_with": [
          "devops",
          "cybersecurity",
          "backend",
          "observability-sre"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "ios-swift-specialist",
        "name": "iOS/Swift Specialist",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using strings for identifiers, keys, segues",
        "principles": [],
        "owns": [
          "ios-development",
          "swift-language",
          "swiftui",
          "uikit",
          "combine",
          "async-await-swift",
          "core-data",
          "app-store-guidelines",
          "ios-security"
        ],
        "does_not_own": [],
        "triggers": [
          "ios",
          "swift",
          "swiftui",
          "uikit",
          "xcode",
          "apple",
          "iphone",
          "ipad",
          "app store",
          "core data",
          "combine"
        ],
        "tags": [
          "ios",
          "swift",
          "swiftui",
          "uikit",
          "xcode",
          "apple",
          "mobile",
          "native",
          "combine",
          "core-data"
        ],
        "pairs_with": [
          "react-native-specialist",
          "ui-design",
          "test-architect",
          "devops",
          "backend",
          "security-analyst"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "kubernetes",
        "name": "Kubernetes & Container Orchestration",
        "version": "^5.x",
        "layer": 2,
        "description": "Pods without CPU/memory limits",
        "principles": [
          "Declarative over imperative - use manifests, not kubectl run",
          "Everything is a resource - learn the API model",
          "Labels and selectors are the glue",
          "Health checks are mandatory, not optional",
          "Resource limits prevent noisy neighbors",
          "Namespaces for isolation, not security",
          "Secrets are base64, not encrypted"
        ],
        "owns": [
          "kubernetes-manifests",
          "deployments",
          "services",
          "pods",
          "configmaps",
          "secrets",
          "ingress",
          "horizontal-pod-autoscaling",
          "kubernetes-networking",
          "helm-charts",
          "kustomize"
        ],
        "does_not_own": [
          "container-images -> docker",
          "ci-cd-pipelines -> devops",
          "cloud-infrastructure -> aws-services",
          "service-mesh -> microservices-patterns",
          "gitops -> devops"
        ],
        "triggers": [
          "kubernetes",
          "k8s",
          "kubectl",
          "deployment manifest",
          "helm chart",
          "kustomize",
          "pod",
          "service yaml",
          "ingress",
          "horizontal pod autoscaler",
          "hpa"
        ],
        "tags": [
          "kubernetes",
          "k8s",
          "containers",
          "orchestration",
          "devops",
          "cloud-native",
          "helm",
          "kustomize"
        ],
        "pairs_with": [
          "docker              # Container images",
          "devops              # CI/CD pipelines",
          "aws-services        # EKS",
          "backend             # App deployment",
          "postgres-wizard     # StatefulSets"
        ],
        "requires": [
          "docker              # Must understand containers first"
        ],
        "category": "development"
      },
      {
        "id": "kubernetes-deployment",
        "name": "Kubernetes Deployment",
        "version": "1.0.0",
        "layer": 1,
        "description": "Setting replicas in Deployment when using HorizontalPodAutoscaler",
        "principles": [],
        "owns": [
          "kubernetes-manifests",
          "deployments",
          "statefulsets",
          "services",
          "ingress",
          "configmaps",
          "secrets",
          "helm-charts",
          "resource-limits",
          "health-probes",
          "pod-debugging",
          "hpa-autoscaling",
          "rbac",
          "network-policies",
          "persistent-volumes"
        ],
        "does_not_own": [],
        "triggers": [
          "kubernetes",
          "k8s",
          "kubectl",
          "helm",
          "pod",
          "deployment",
          "service",
          "ingress",
          "configmap",
          "secret",
          "statefulset",
          "daemonset",
          "hpa",
          "pvc",
          "crashloopbackoff",
          "imagepullbackoff",
          "oomkilled",
          "liveness probe",
          "readiness probe"
        ],
        "tags": [
          "kubernetes",
          "k8s",
          "containers",
          "docker",
          "helm",
          "deployment",
          "devops",
          "cloud-native"
        ],
        "pairs_with": [
          "infrastructure-as-code",
          "devops",
          "observability-sre",
          "docker-containerization"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "logging-strategies",
        "name": "Logging Strategies",
        "version": "1.0.0",
        "layer": 1,
        "description": "Catching exceptions but not logging them",
        "principles": [],
        "owns": [
          "structured-logging",
          "log-levels",
          "correlation-ids",
          "request-tracing",
          "log-aggregation",
          "log-rotation",
          "sensitive-data-redaction",
          "contextual-logging",
          "performance-logging",
          "error-logging",
          "audit-logging",
          "log-sampling",
          "distributed-tracing"
        ],
        "does_not_own": [],
        "triggers": [
          "log",
          "logging",
          "logger",
          "debug",
          "trace",
          "audit",
          "structured log",
          "correlation id",
          "request id",
          "log level",
          "winston",
          "pino",
          "bunyan",
          "log4j"
        ],
        "tags": [
          "logging",
          "observability",
          "debugging",
          "monitoring",
          "tracing",
          "structured-logs",
          "correlation",
          "aggregation"
        ],
        "pairs_with": [
          "observability-sre",
          "backend",
          "security-hardening",
          "performance-optimization"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "mcp-developer",
        "name": "MCP Developer",
        "version": "1.0.0",
        "layer": 1,
        "description": "One tool that does many unrelated things via mode parameter",
        "principles": [],
        "owns": [
          "mcp-server-architecture",
          "mcp-tool-design",
          "mcp-resource-patterns",
          "mcp-prompt-templates",
          "mcp-transport-layer",
          "mcp-security",
          "mcp-client-integration",
          "claude-code-extensions"
        ],
        "does_not_own": [],
        "triggers": [
          "mcp server",
          "model context protocol",
          "claude code extension",
          "building ai tools",
          "tool definition",
          "mcp transport",
          "stdio transport",
          "sse transport",
          "resource provider",
          "prompt template"
        ],
        "tags": [
          "mcp",
          "model-context-protocol",
          "claude-code",
          "ai-tools",
          "llm-integration",
          "anthropic",
          "server",
          "protocol"
        ],
        "pairs_with": [
          "api-designer",
          "auth-specialist",
          "typescript-engineer",
          "security-engineer",
          "infra-architect",
          "llm-architect"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "mcp-product",
        "name": "MCP Product Design",
        "version": "1.0.0",
        "layer": 3,
        "description": "Requiring IDs or configuration before users get any value",
        "principles": [],
        "owns": [
          "MCP tool naming and design",
          "User experience for AI-assisted tools",
          "Error messages and feedback",
          "Onboarding and first-run experience",
          "Progressive complexity patterns",
          "Tool output formatting"
        ],
        "does_not_own": [
          "MCP protocol implementation details → mcp-cloudflare",
          "Specific tech stack patterns → relevant stack skills",
          "Database design → supabase-backend",
          "Authentication flows → nextjs-supabase-auth"
        ],
        "triggers": [
          "Designing new MCP tools",
          "Improving tool UX or DX",
          "Writing error messages",
          "Planning tool naming",
          "Discussing user onboarding",
          "Making tools \"sticky",
          "Vibe coder experience"
        ],
        "tags": [
          "mcp",
          "product",
          "ux",
          "dx",
          "vibe-coding",
          "onboarding",
          "developer-experience",
          "tool-design"
        ],
        "pairs_with": [
          "mcp-cloudflare",
          "typescript-strict"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "migration-specialist",
        "name": "Migration Specialist",
        "version": "1.0.0",
        "layer": 1,
        "description": "Migrations tested without production-scale data",
        "principles": [],
        "owns": [
          "schema-migrations",
          "data-migrations",
          "zero-downtime-deploys",
          "backward-compatibility",
          "rollback-strategies",
          "blue-green-deployments",
          "feature-flags",
          "migration-testing"
        ],
        "does_not_own": [],
        "triggers": [
          "migration",
          "schema change",
          "database migration",
          "zero downtime",
          "backward compatible",
          "rollback",
          "blue green",
          "data migration"
        ],
        "tags": [
          "migration",
          "schema",
          "database",
          "zero-downtime",
          "backward-compatible",
          "rollback",
          "blue-green",
          "feature-flag",
          "ai-memory"
        ],
        "pairs_with": [
          "postgres-wizard",
          "data-engineer",
          "infra-architect",
          "api-designer",
          "test-architect",
          "observability-sre"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "observability-sre",
        "name": "Observability SRE",
        "version": "1.0.0",
        "layer": 1,
        "description": "50 graphs nobody looks at",
        "principles": [],
        "owns": [
          "prometheus-metrics",
          "distributed-tracing",
          "alerting-strategy",
          "slo-design",
          "log-aggregation",
          "incident-response",
          "capacity-planning",
          "dashboards"
        ],
        "does_not_own": [],
        "triggers": [
          "observability",
          "monitoring",
          "prometheus",
          "grafana",
          "alerting",
          "slo",
          "sli",
          "metrics",
          "tracing",
          "logging",
          "on-call",
          "incident"
        ],
        "tags": [
          "observability",
          "prometheus",
          "grafana",
          "tracing",
          "jaeger",
          "alerting",
          "slo",
          "sli",
          "metrics",
          "logging",
          "sre",
          "ai-memory"
        ],
        "pairs_with": [
          "infra-architect",
          "performance-hunter",
          "postgres-wizard",
          "chaos-engineer",
          "event-architect",
          "api-designer"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "performance-hunter",
        "name": "Performance Hunter",
        "version": "1.0.0",
        "layer": 1,
        "description": "\"I think this is slow\" without measurement",
        "principles": [],
        "owns": [
          "profiling",
          "caching-strategies",
          "latency-optimization",
          "database-tuning",
          "async-patterns",
          "memory-profiling",
          "load-testing"
        ],
        "does_not_own": [],
        "triggers": [
          "performance",
          "latency",
          "slow query",
          "profiling",
          "caching",
          "optimization",
          "N+1",
          "connection pool",
          "p99"
        ],
        "tags": [
          "performance",
          "profiling",
          "caching",
          "latency",
          "optimization",
          "async",
          "database",
          "load-testing",
          "ai-memory"
        ],
        "pairs_with": [
          "vector-specialist",
          "graph-engineer",
          "temporal-craftsman",
          "event-architect",
          "ml-memory",
          "privacy-guardian"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "queue-workers",
        "name": "pg-boss",
        "version": "1.0.0",
        "layer": 1,
        "description": "Jobs that cause duplicate side effects on retry",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "development"
      },
      {
        "id": "privacy-guardian",
        "name": "Privacy Guardian",
        "version": "1.0.0",
        "layer": 1,
        "description": "Keeping all data forever without cleanup",
        "principles": [],
        "owns": [
          "differential-privacy",
          "encryption-at-rest",
          "privacy-preserving-ml",
          "pii-detection",
          "access-control",
          "audit-trails",
          "data-retention"
        ],
        "does_not_own": [],
        "triggers": [
          "privacy",
          "encryption",
          "differential privacy",
          "PII",
          "GDPR",
          "CCPA",
          "access control",
          "audit trail",
          "data retention"
        ],
        "tags": [
          "privacy",
          "security",
          "encryption",
          "differential-privacy",
          "gdpr",
          "ccpa",
          "pii",
          "opendp",
          "ai-memory"
        ],
        "pairs_with": [
          "ml-memory",
          "vector-specialist",
          "event-architect",
          "temporal-craftsman",
          "performance-hunter"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "prompt-engineer",
        "name": "Prompt Engineer",
        "version": "1.0.0",
        "layer": 2,
        "description": "Expecting specific format without specifying it",
        "principles": [],
        "owns": [
          "Prompt design and optimization",
          "System prompt architecture",
          "Context window management",
          "Output format specification",
          "Prompt testing and evaluation",
          "Few-shot example design"
        ],
        "does_not_own": [],
        "triggers": [
          "prompt engineering",
          "system prompt",
          "few-shot",
          "chain of thought",
          "prompt design",
          "LLM prompt",
          "instruction tuning",
          "prompt template",
          "output format"
        ],
        "tags": [
          "prompts",
          "llm",
          "gpt",
          "claude",
          "system-prompt",
          "few-shot",
          "chain-of-thought",
          "evaluation"
        ],
        "pairs_with": [
          "ai-agents-architect  # Agent prompts",
          "rag-engineer         # Context-aware prompts",
          "backend              # API integration",
          "product-manager      # Feature requirements"
        ],
        "requires": [
          "LLM fundamentals",
          "Understanding of tokenization",
          "Basic programming"
        ],
        "category": "development"
      },
      {
        "id": "python-craftsman",
        "name": "Python Craftsman",
        "version": "1.0.0",
        "layer": 1,
        "description": "Unpinned or loosely pinned dependencies",
        "principles": [],
        "owns": [
          "python-type-hints",
          "async-await-patterns",
          "python-packaging",
          "dependency-management",
          "code-organization",
          "python-performance",
          "pydantic-models",
          "testing-patterns"
        ],
        "does_not_own": [],
        "triggers": [
          "python development",
          "type hints",
          "async python",
          "pydantic models",
          "python packaging",
          "mypy errors",
          "python project structure",
          "dependency management"
        ],
        "tags": [
          "python",
          "type-hints",
          "async",
          "pydantic",
          "packaging",
          "uv",
          "poetry",
          "mypy",
          "ruff",
          "ai-memory"
        ],
        "pairs_with": [
          "api-designer",
          "test-architect",
          "data-engineer",
          "sdk-builder",
          "performance-hunter",
          "docs-engineer"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "qa-engineering",
        "name": "QA Engineering",
        "version": "1.0.0",
        "layer": 1,
        "description": "Tests that execute code but don't verify anything",
        "principles": [],
        "owns": [
          "test-strategy",
          "test-automation",
          "test-coverage",
          "regression-testing",
          "e2e-testing",
          "integration-testing",
          "performance-testing",
          "accessibility-testing",
          "mobile-testing",
          "cross-browser-testing",
          "test-infrastructure",
          "bug-reporting"
        ],
        "does_not_own": [],
        "triggers": [
          "QA",
          "quality assurance",
          "testing",
          "test automation",
          "e2e tests",
          "integration tests",
          "regression testing",
          "test coverage",
          "playwright",
          "cypress",
          "selenium",
          "test suite",
          "bug report",
          "test strategy",
          "flaky tests"
        ],
        "tags": [
          "testing",
          "QA",
          "automation",
          "e2e",
          "integration",
          "regression",
          "quality"
        ],
        "pairs_with": [
          "frontend",
          "backend",
          "devops",
          "cybersecurity"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "rag-engineer",
        "name": "RAG Engineer",
        "version": "1.0.0",
        "layer": 2,
        "description": "Cramming maximum context into prompt",
        "principles": [],
        "owns": [
          "Vector embeddings and similarity search",
          "Document chunking and preprocessing",
          "Retrieval pipeline design",
          "Semantic search implementation",
          "Context window optimization",
          "Hybrid search (keyword + semantic)"
        ],
        "does_not_own": [],
        "triggers": [
          "building RAG",
          "vector search",
          "embeddings",
          "semantic search",
          "document retrieval",
          "context retrieval",
          "knowledge base",
          "LLM with documents",
          "chunking strategy",
          "pinecone",
          "weaviate",
          "chromadb",
          "pgvector"
        ],
        "tags": [
          "rag",
          "embeddings",
          "vector-database",
          "retrieval",
          "semantic-search",
          "llm",
          "ai",
          "langchain",
          "llamaindex"
        ],
        "pairs_with": [
          "ai-agents-architect  # Agents use RAG for knowledge",
          "prompt-engineer      # Prompts consume retrieved context",
          "database-architect   # Vector store integration",
          "backend              # API and pipeline implementation"
        ],
        "requires": [
          "LLM fundamentals",
          "Understanding of embeddings",
          "Basic NLP concepts"
        ],
        "category": "development"
      },
      {
        "id": "react-native-specialist",
        "name": "React Native Specialist",
        "version": "1.0.0",
        "layer": 1,
        "description": "Leaving console.log in production builds",
        "principles": [],
        "owns": [
          "react-native-development",
          "expo-ecosystem",
          "native-modules",
          "mobile-navigation",
          "mobile-state-management",
          "mobile-performance",
          "app-store-deployment",
          "mobile-testing"
        ],
        "does_not_own": [],
        "triggers": [
          "react native",
          "expo",
          "mobile app",
          "ios app",
          "android app",
          "cross-platform",
          "native module",
          "react navigation",
          "mobile development"
        ],
        "tags": [
          "react-native",
          "expo",
          "mobile",
          "ios",
          "android",
          "cross-platform",
          "javascript",
          "typescript",
          "native-modules",
          "navigation"
        ],
        "pairs_with": [
          "frontend",
          "ios-swift-specialist",
          "test-architect",
          "devops",
          "ui-design",
          "performance-hunter"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "realtime-engineer",
        "name": "Realtime Engineer",
        "version": "1.0.0",
        "layer": 1,
        "description": "Reconnecting instantly after disconnect",
        "principles": [],
        "owns": [
          "websocket-architecture",
          "server-sent-events",
          "presence-systems",
          "live-cursors",
          "collaborative-editing",
          "pub-sub-patterns",
          "connection-management",
          "reconnection-strategies"
        ],
        "does_not_own": [],
        "triggers": [
          "websocket",
          "real-time updates",
          "live collaboration",
          "presence indicator",
          "online status",
          "live cursors",
          "multiplayer",
          "server-sent events",
          "push notifications",
          "collaborative editing"
        ],
        "tags": [
          "websocket",
          "sse",
          "realtime",
          "presence",
          "collaboration",
          "live-updates",
          "socket.io",
          "pusher",
          "ably",
          "supabase-realtime"
        ],
        "pairs_with": [
          "event-architect",
          "redis-specialist",
          "api-designer",
          "performance-hunter",
          "auth-specialist",
          "infra-architect"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "rust-craftsman",
        "name": "Rust Craftsman",
        "version": "1.0.0",
        "layer": 1,
        "description": "Returning Box<dyn Error> from all functions",
        "principles": [],
        "owns": [
          "rust-development",
          "ownership-borrowing",
          "memory-safety",
          "lifetimes",
          "async-rust",
          "unsafe-rust",
          "cargo-ecosystem",
          "rust-patterns",
          "zero-cost-abstractions",
          "rust-ffi"
        ],
        "does_not_own": [],
        "triggers": [
          "rust",
          "cargo",
          "ownership",
          "borrowing",
          "lifetimes",
          "rustc",
          "tokio",
          "async rust",
          "memory safety",
          "borrow checker",
          "zero-cost abstraction"
        ],
        "tags": [
          "rust",
          "systems-programming",
          "memory-safety",
          "ownership",
          "borrowing",
          "lifetimes",
          "cargo",
          "async",
          "tokio",
          "concurrency",
          "performance"
        ],
        "pairs_with": [
          "backend",
          "devops",
          "performance-hunter",
          "api-designer",
          "test-architect",
          "security-analyst"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "sdk-builder",
        "name": "SDK Builder",
        "version": "1.0.0",
        "layer": 1,
        "description": "Changing signatures or behavior without major bump",
        "principles": [],
        "owns": [
          "sdk-design",
          "client-libraries",
          "api-ergonomics",
          "sdk-versioning",
          "developer-experience",
          "type-generation",
          "error-handling",
          "retry-logic"
        ],
        "does_not_own": [],
        "triggers": [
          "sdk design",
          "client library",
          "api client",
          "developer experience",
          "sdk versioning",
          "type generation",
          "http client",
          "api wrapper"
        ],
        "tags": [
          "sdk",
          "client-library",
          "api-client",
          "developer-experience",
          "versioning",
          "type-safety",
          "http-client",
          "ai-memory"
        ],
        "pairs_with": [
          "api-designer",
          "python-craftsman",
          "docs-engineer",
          "test-architect",
          "code-reviewer",
          "performance-hunter"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "security",
        "name": "Security",
        "version": "1.0.0",
        "layer": 1,
        "description": "Relying on client-side validation or hiding for security",
        "principles": [
          "Security is not a feature, it's a property",
          "Defense in depth - multiple layers",
          "Least privilege - minimum access needed",
          "Never trust user input",
          "Fail secure - errors should deny access",
          "Secrets don't belong in code"
        ],
        "owns": [
          "owasp-top-10",
          "secure-coding",
          "input-validation",
          "output-encoding",
          "authentication-security",
          "authorization-security",
          "secrets-management",
          "csrf-protection",
          "xss-prevention",
          "sql-injection-prevention",
          "threat-modeling",
          "security-headers",
          "rate-limiting",
          "audit-logging"
        ],
        "does_not_own": [
          "infrastructure-security → devops",
          "network-security → platform-architecture",
          "authentication-flows → auth-patterns",
          "compliance → legal-compliance",
          "incident-response → incident-management"
        ],
        "triggers": [
          "security",
          "owasp",
          "xss",
          "sql injection",
          "csrf",
          "authentication",
          "authorization",
          "secrets",
          "api key",
          "vulnerability",
          "secure coding",
          "security headers",
          "rate limiting",
          "input validation",
          "sanitize",
          "escape"
        ],
        "tags": [
          "security",
          "owasp",
          "authentication",
          "authorization",
          "vulnerabilities",
          "secure-coding"
        ],
        "pairs_with": [
          "auth-patterns          # Authentication flows",
          "backend               # Server-side security",
          "devops                # Infrastructure security",
          "stripe-integration    # Payment security"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "security-hardening",
        "name": "Security Hardening",
        "version": "1.0.0",
        "layer": 1,
        "description": "Hiding all error details, even from developers",
        "principles": [],
        "owns": [
          "input-validation",
          "output-encoding",
          "sql-injection-prevention",
          "xss-prevention",
          "csrf-protection",
          "authentication-security",
          "authorization-patterns",
          "secret-management",
          "secure-headers",
          "dependency-security",
          "session-management",
          "cryptography-basics",
          "secure-file-handling",
          "rate-limiting",
          "security-logging"
        ],
        "does_not_own": [],
        "triggers": [
          "security",
          "secure",
          "vulnerability",
          "injection",
          "xss",
          "csrf",
          "authentication",
          "authorization",
          "owasp",
          "encryption",
          "secret",
          "password",
          "token",
          "sanitize",
          "validate",
          "escape",
          "encode",
          "harden"
        ],
        "tags": [
          "security",
          "owasp",
          "injection",
          "xss",
          "csrf",
          "authentication",
          "authorization",
          "encryption",
          "secrets",
          "hardening"
        ],
        "pairs_with": [
          "backend",
          "frontend",
          "api-design-architect",
          "ci-cd-pipeline",
          "database-schema-design"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "smart-contract-engineer",
        "name": "Smart Contract Engineer",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using ^0.8.0 instead of fixed version",
        "principles": [],
        "owns": [
          "solidity-development",
          "evm-internals",
          "contract-security",
          "gas-optimization",
          "upgradeable-contracts",
          "defi-primitives",
          "nft-contracts",
          "contract-testing"
        ],
        "does_not_own": [],
        "triggers": [
          "smart contract",
          "solidity",
          "ethereum",
          "evm",
          "contract",
          "web3",
          "gas optimization",
          "upgradeable contract",
          "reentrancy"
        ],
        "tags": [
          "solidity",
          "ethereum",
          "smart-contracts",
          "evm",
          "web3",
          "blockchain",
          "defi",
          "nft",
          "security",
          "gas"
        ],
        "pairs_with": [
          "defi-architect",
          "wallet-integration",
          "security-analyst",
          "test-architect",
          "backend",
          "frontend"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "state-management",
        "name": "State Management",
        "version": "1.0.0",
        "layer": 3,
        "description": "Storing computed values that can be derived from other state",
        "principles": [],
        "owns": [
          "Global state architecture decisions",
          "State library selection and setup",
          "Store structure and organization",
          "Action/reducer patterns",
          "Selector optimization",
          "State persistence strategies",
          "DevTools integration",
          "State synchronization patterns"
        ],
        "does_not_own": [
          "Server state/caching → react-query, SWR, RTK Query",
          "Form state → react-hook-form, formik",
          "URL state → router state management",
          "Component local state → useState/useReducer",
          "Backend state → database patterns"
        ],
        "triggers": [
          "set up state management",
          "redux vs zustand",
          "global state",
          "store architecture",
          "state not updating",
          "prop drilling problem",
          "share state between components",
          "Working with Redux, Zustand, MobX, Jotai, Recoil"
        ],
        "tags": [
          "state",
          "redux",
          "zustand",
          "mobx",
          "jotai",
          "recoil",
          "context",
          "frontend",
          "react"
        ],
        "pairs_with": [
          "frontend",
          "react-patterns",
          "performance-optimization",
          "testing-automation"
        ],
        "requires": [
          "React or similar component framework",
          "Understanding of component lifecycle"
        ],
        "category": "development"
      },
      {
        "id": "technical-debt-strategy",
        "name": "Technical Debt Strategy",
        "version": "1.0.0",
        "layer": 1,
        "description": "Maintain centralized tracking of all known technical debt",
        "principles": [
          "name: Debt is a tool, not a sin"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "development"
      },
      {
        "id": "test-architect",
        "name": "Test Architect",
        "version": "1.0.0",
        "layer": 1,
        "description": "Adding tests just to hit coverage number",
        "principles": [],
        "owns": [
          "test-strategy",
          "test-pyramid",
          "test-isolation",
          "property-testing",
          "contract-testing",
          "mutation-testing",
          "quality-gates",
          "ci-integration"
        ],
        "does_not_own": [],
        "triggers": [
          "testing",
          "test strategy",
          "unit test",
          "integration test",
          "e2e",
          "property testing",
          "test pyramid",
          "flaky test",
          "test coverage",
          "quality gate"
        ],
        "tags": [
          "testing",
          "pytest",
          "jest",
          "unit-testing",
          "integration-testing",
          "e2e",
          "property-testing",
          "tdd",
          "quality",
          "ai-memory"
        ],
        "pairs_with": [
          "api-designer",
          "performance-hunter",
          "code-reviewer",
          "observability-sre",
          "migration-specialist",
          "chaos-engineer"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "testing-automation",
        "name": "Testing Automation",
        "version": "1.0.0",
        "layer": 1,
        "description": "Chasing 100% coverage as a goal",
        "principles": [],
        "owns": [
          "unit-testing",
          "integration-testing",
          "e2e-testing",
          "test-automation",
          "testing-pyramid",
          "mocking-strategies",
          "test-fixtures",
          "test-coverage",
          "test-driven-development",
          "behavior-driven-development",
          "contract-testing",
          "snapshot-testing",
          "visual-regression",
          "load-testing"
        ],
        "does_not_own": [],
        "triggers": [
          "test",
          "testing",
          "unit test",
          "integration test",
          "e2e",
          "end to end",
          "jest",
          "vitest",
          "pytest",
          "playwright",
          "cypress",
          "mock",
          "stub",
          "fixture",
          "coverage",
          "tdd",
          "bdd",
          "flaky",
          "test automation"
        ],
        "tags": [
          "testing",
          "unit-tests",
          "integration-tests",
          "e2e",
          "tdd",
          "bdd",
          "jest",
          "pytest",
          "playwright",
          "cypress",
          "vitest"
        ],
        "pairs_with": [
          "backend",
          "frontend",
          "ci-cd-pipeline",
          "api-design-architect"
        ],
        "requires": [],
        "category": "development"
      },
      {
        "id": "wallet-integration",
        "name": "Wallet Integration Specialist",
        "version": "1.0.0",
        "layer": 2,
        "description": "Showing raw wallet/RPC errors to users",
        "principles": [],
        "owns": [
          "Wallet connection flows",
          "Transaction signing and submission",
          "Account and chain management",
          "Web3 frontend integration",
          "Wallet UX patterns",
          "Multi-chain wallet support"
        ],
        "does_not_own": [],
        "triggers": [
          "wallet integration",
          "connect wallet",
          "metamask",
          "wagmi",
          "rainbowkit",
          "walletconnect",
          "web3 frontend",
          "sign transaction",
          "dapp",
          "ethers.js",
          "viem"
        ],
        "tags": [
          "wallet",
          "web3",
          "metamask",
          "wagmi",
          "rainbowkit",
          "walletconnect",
          "ethereum",
          "dapp",
          "blockchain"
        ],
        "pairs_with": [
          "smart-contract-engineer  # Contract ABIs and interactions",
          "defi-architect           # DeFi protocol integration",
          "frontend                 # React/Vue integration",
          "security-analyst         # Transaction security review"
        ],
        "requires": [
          "JavaScript/TypeScript",
          "React or other frontend framework",
          "Basic blockchain concepts"
        ],
        "category": "development"
      },
      {
        "id": "websocket-realtime",
        "name": "WebSocket & Real-time",
        "version": "1.0.0",
        "layer": 3,
        "description": "Not handling connection drops and not implementing reconnection",
        "principles": [],
        "owns": [
          "WebSocket connection lifecycle",
          "Real-time message protocols",
          "Reconnection and heartbeat strategies",
          "Room/channel management",
          "Presence detection",
          "Real-time data synchronization",
          "Scaling WebSocket servers",
          "SSE implementation"
        ],
        "does_not_own": [
          "REST API design → api-design skill",
          "Database real-time triggers → database-schema-design",
          "Message queue architecture → queue-workers skill",
          "Video/audio streaming → specialized media skill",
          "Push notifications → mobile/notification skill"
        ],
        "triggers": [
          "implement websocket",
          "real-time updates",
          "live chat",
          "socket.io",
          "server-sent events",
          "live notifications",
          "collaborative editing",
          "presence indicators",
          "Working with ws, Socket.IO, Pusher, Ably"
        ],
        "tags": [
          "websocket",
          "realtime",
          "socket.io",
          "sse",
          "live",
          "streaming",
          "push",
          "collaboration"
        ],
        "pairs_with": [
          "backend",
          "state-management",
          "infrastructure-as-code",
          "security-hardening"
        ],
        "requires": [
          "Understanding of HTTP",
          "Node.js or similar runtime",
          "Basic networking concepts"
        ],
        "category": "development"
      }
    ]
  },
  {
    "id": "enterprise",
    "name": "Enterprise",
    "skills": [
      {
        "id": "compliance-automation",
        "name": "Compliance Automation",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use when implementing policy-as-code, continuous compliance monitoring, automated evidence collection, or audit-ready systems requiring SOC2/ISO/PCI/HIPAA compliance",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "enterprise"
      },
      {
        "id": "data-governance",
        "name": "Data Governance",
        "version": "1.0.0",
        "layer": 1,
        "description": "Technical management of data storage",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "enterprise"
      },
      {
        "id": "disaster-recovery",
        "name": "Disaster Recovery",
        "version": "1.0.0",
        "layer": 1,
        "description": "Full redundancy, traffic to both sites",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "enterprise"
      },
      {
        "id": "enterprise-architecture",
        "name": "Enterprise Architecture",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use when designing enterprise systems, applying TOGAF framework, creating capability maps, implementing domain-driven design, or planning technology transformations - covers ADM phases, architecture domains, and governance",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "enterprise"
      },
      {
        "id": "integration-patterns",
        "name": "Integration Patterns",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use when designing system integrations, implementing API gateways, event-driven architectures, ESB patterns, or hybrid cloud connectivity",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "enterprise"
      },
      {
        "id": "multi-tenancy",
        "name": "Multi-Tenancy",
        "version": "1.0.0",
        "layer": 1,
        "description": "Dedicated infrastructure per tenant",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "enterprise"
      }
    ]
  },
  {
    "id": "finance",
    "name": "Finance",
    "skills": [
      {
        "id": "algorithmic-trading",
        "name": "Algorithmic Trading",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use when building trading systems, backtesting strategies, implementing execution algorithms, or analyzing market microstructure - covers strategy development, risk management, and production deployment",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "finance"
      },
      {
        "id": "blockchain-defi",
        "name": "Blockchain DeFi",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use when building DeFi protocols, implementing AMMs, yield farming strategies, or integrating with Ethereum/L2s - covers smart contract patterns, liquidity pools, and security considerations",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "finance"
      },
      {
        "id": "derivatives-pricing",
        "name": "Derivatives Pricing",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use when pricing options, calculating Greeks, implementing exotic derivatives, or building pricing engines - covers Black-Scholes, binomial trees, Monte Carlo, and QuantLib integration",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "finance"
      },
      {
        "id": "fintech-integration",
        "name": "Fintech Integration",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use when integrating Plaid, Stripe, payment processors, or financial APIs - covers account linking, payment processing, KYC/AML compliance, and webhook handling",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "finance"
      },
      {
        "id": "portfolio-optimization",
        "name": "Portfolio Optimization",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use when constructing portfolios, implementing mean-variance optimization, factor models, risk parity, or Black-Litterman allocation - covers modern portfolio theory and practical enhancements",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "finance"
      },
      {
        "id": "risk-modeling",
        "name": "Risk Modeling",
        "version": "1.0.0",
        "layer": 1,
        "description": "Expected loss beyond VaR",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "finance"
      }
    ]
  },
  {
    "id": "frameworks",
    "name": "Frameworks",
    "skills": [
      {
        "id": "angular",
        "name": "Angular",
        "version": "^17.x",
        "layer": 2,
        "description": "Complex expressions or method calls in templates",
        "principles": [
          "Standalone components by default - NgModules when needed",
          "Signals for state, RxJS for async streams",
          "Smart containers, dumb presentational components",
          "OnPush change detection everywhere possible",
          "Strong typing with strict mode enabled",
          "Dependency injection over global state",
          "Reactive forms for complex forms, template-driven for simple"
        ],
        "owns": [
          "angular-components",
          "angular-routing",
          "angular-forms",
          "angular-http",
          "angular-di",
          "angular-signals",
          "angular-rxjs",
          "angular-testing",
          "angular-cli",
          "angular-ssr"
        ],
        "does_not_own": [
          "general-state-management -> ngrx",
          "backend-api-design -> backend",
          "css-frameworks -> tailwind-ui",
          "end-to-end-testing -> testing",
          "deployment -> devops"
        ],
        "triggers": [
          "angular",
          "angular component",
          "angular service",
          "angular routing",
          "angular forms",
          "rxjs",
          "ngrx",
          "angular signals",
          "standalone component",
          "angular ssr"
        ],
        "tags": [
          "angular",
          "typescript",
          "frontend",
          "spa",
          "enterprise",
          "rxjs",
          "signals",
          "standalone"
        ],
        "pairs_with": [
          "tailwind-ui          # Styling",
          "testing              # E2E with Playwright",
          "firebase             # Backend integration",
          "graphql-schema       # API layer"
        ],
        "requires": [],
        "category": "frameworks"
      },
      {
        "id": "go-services",
        "name": "Go Services",
        "version": "1.0.0",
        "layer": 1,
        "description": "Checking error but doing nothing with it",
        "principles": [
          "Simplicity is a feature - fight the urge to abstract",
          "The standard library is your friend - reach for it first",
          "Errors are values - handle them explicitly, never ignore",
          "Goroutines are cheap, but not free - know your limits",
          "Accept interfaces, return structs",
          "Make the zero value useful",
          "Clear is better than clever"
        ],
        "owns": [
          "go-services",
          "go-concurrency",
          "goroutines",
          "channels",
          "go-error-handling",
          "go-http-servers",
          "go-interfaces",
          "go-testing",
          "go-stdlib"
        ],
        "does_not_own": [
          "kubernetes-deployment → devops",
          "docker-containerization → devops",
          "grpc-protocols → api-design",
          "database-design → postgres-wizard",
          "observability-setup → devops"
        ],
        "triggers": [
          "golang",
          "go service",
          "go microservice",
          "goroutine",
          "channels",
          "go http",
          "go api",
          "go backend",
          "gin",
          "fiber",
          "chi router",
          "go concurrency"
        ],
        "tags": [
          "go",
          "golang",
          "microservices",
          "backend",
          "concurrency",
          "goroutines",
          "channels",
          "http",
          "api"
        ],
        "pairs_with": [
          "postgres-wizard      # Database integration",
          "devops               # Deployment and containers",
          "api-design           # API patterns",
          "backend              # General backend patterns"
        ],
        "requires": [],
        "category": "frameworks"
      },
      {
        "id": "nextjs-app-router",
        "name": "Next.js App Router",
        "version": "1.0.0",
        "layer": 1,
        "description": "Importing server-only modules (fs, db clients) in 'use client' files",
        "principles": [],
        "owns": [
          "app-router",
          "server-components",
          "client-components",
          "server-actions",
          "next-routing",
          "next-metadata",
          "next-caching"
        ],
        "does_not_own": [],
        "triggers": [
          "next.js app router",
          "server component",
          "client component",
          "use client",
          "use server",
          "server action",
          "next 13",
          "next 14",
          "next 15",
          "app directory"
        ],
        "tags": [
          "nextjs",
          "next",
          "react",
          "app-router",
          "rsc",
          "server-components",
          "ssr"
        ],
        "pairs_with": [
          "supabase-backend",
          "typescript-strict",
          "tailwind-ui",
          "react-patterns"
        ],
        "requires": [],
        "category": "frameworks"
      },
      {
        "id": "react-patterns",
        "name": "React Patterns",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using useState for values that could be derived or refs",
        "principles": [],
        "owns": [
          "react-hooks",
          "react-composition",
          "react-state",
          "react-context",
          "react-performance"
        ],
        "does_not_own": [],
        "triggers": [
          "react hook",
          "useEffect",
          "useState",
          "useCallback",
          "useMemo",
          "context",
          "component composition",
          "react performance",
          "re-render"
        ],
        "tags": [
          "react",
          "hooks",
          "components",
          "state",
          "context",
          "performance",
          "composition"
        ],
        "pairs_with": [
          "nextjs-app-router",
          "typescript-strict",
          "tailwind-ui"
        ],
        "requires": [],
        "category": "frameworks"
      },
      {
        "id": "supabase-backend",
        "name": "Supabase Backend",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using client-provided data in RLS decisions",
        "principles": [],
        "owns": [
          "supabase",
          "rls",
          "row-level-security",
          "postgres",
          "supabase-storage",
          "supabase-realtime"
        ],
        "does_not_own": [],
        "triggers": [
          "supabase",
          "row level security",
          "rls",
          "postgres",
          "database policy",
          "supabase storage",
          "supabase realtime"
        ],
        "tags": [
          "supabase",
          "postgres",
          "rls",
          "database",
          "backend",
          "storage",
          "realtime"
        ],
        "pairs_with": [
          "nextjs-app-router",
          "nextjs-supabase-auth",
          "typescript-strict"
        ],
        "requires": [],
        "category": "frameworks"
      },
      {
        "id": "svelte-kit",
        "name": "Svelte & SvelteKit",
        "version": "^2.x",
        "layer": 2,
        "description": "Using callbacks/events when assignment would work",
        "principles": [
          "Let the compiler do the work - minimal runtime",
          "Reactivity through assignment in Svelte 4, runes in Svelte 5",
          "$state for reactive state, $derived for computed values",
          "Forms with progressive enhancement via form actions",
          "Load data on the server when possible",
          "Components are the unit of reusability",
          "Simplicity over abstraction"
        ],
        "owns": [
          "svelte-components",
          "svelte-reactivity",
          "svelte-runes",
          "sveltekit-routing",
          "sveltekit-load-functions",
          "sveltekit-form-actions",
          "sveltekit-ssr",
          "svelte-stores",
          "svelte-transitions"
        ],
        "does_not_own": [
          "state-management-libraries -> frontend",
          "backend-api-design -> backend",
          "css-frameworks -> tailwind-ui",
          "deployment-infrastructure -> devops"
        ],
        "triggers": [
          "svelte",
          "sveltekit",
          "svelte component",
          "svelte store",
          "svelte runes",
          "$state",
          "$derived",
          "form actions",
          "load function",
          "+page.svelte"
        ],
        "tags": [
          "svelte",
          "sveltekit",
          "frontend",
          "ssr",
          "compiler",
          "runes",
          "reactivity",
          "forms"
        ],
        "pairs_with": [
          "tailwind-ui          # Styling",
          "testing              # Playwright for E2E",
          "firebase             # Backend integration",
          "backend              # API design"
        ],
        "requires": [],
        "category": "frameworks"
      },
      {
        "id": "sveltekit",
        "name": "SvelteKit",
        "version": "1.0.0",
        "layer": 1,
        "description": "Sequential await calls in load functions that could be parallel",
        "principles": [],
        "owns": [
          "sveltekit-routing",
          "svelte-components",
          "load-functions",
          "form-actions",
          "server-routes",
          "sveltekit-hooks",
          "sveltekit-adapters",
          "svelte-stores",
          "runes-system",
          "page-endpoints",
          "layout-system"
        ],
        "does_not_own": [],
        "triggers": [
          "sveltekit",
          "svelte kit",
          "svelte 5",
          "svelte5",
          "runes",
          "$state",
          "$derived",
          "$effect",
          "$props",
          "$bindable",
          "form actions",
          "+page.server",
          "+page.ts",
          "+layout",
          "+server",
          "load function",
          "svelte adapter",
          "adapter-node",
          "adapter-vercel",
          "hooks.server"
        ],
        "tags": [
          "sveltekit",
          "svelte",
          "svelte5",
          "ssr",
          "form-actions",
          "load-functions",
          "runes",
          "server-routes",
          "adapters",
          "vite"
        ],
        "pairs_with": [
          "supabase-backend",
          "tailwind-ui",
          "typescript-strict",
          "vercel-deployment"
        ],
        "requires": [],
        "category": "frameworks"
      },
      {
        "id": "tailwind-ui",
        "name": "Tailwind CSS UI",
        "version": "1.0.0",
        "layer": 1,
        "description": "Starting with desktop styles, using sm:hidden for mobile",
        "principles": [],
        "owns": [
          "tailwind",
          "tailwindcss",
          "utility-css",
          "responsive-design",
          "dark-mode"
        ],
        "does_not_own": [],
        "triggers": [
          "tailwind",
          "tailwindcss",
          "utility classes",
          "responsive design",
          "dark mode",
          "styling",
          "css classes"
        ],
        "tags": [
          "tailwind",
          "css",
          "styling",
          "ui",
          "responsive",
          "dark-mode",
          "components"
        ],
        "pairs_with": [
          "nextjs-app-router",
          "react-patterns"
        ],
        "requires": [],
        "category": "frameworks"
      },
      {
        "id": "typescript-strict",
        "name": "TypeScript Strict Mode",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using ! operator without certainty the value exists",
        "principles": [],
        "owns": [
          "typescript",
          "type-safety",
          "strict-mode",
          "generics",
          "type-inference"
        ],
        "does_not_own": [],
        "triggers": [
          "typescript",
          "type error",
          "strict mode",
          "generics",
          "type inference",
          "any type",
          "type assertion"
        ],
        "tags": [
          "typescript",
          "types",
          "strict",
          "generics",
          "type-safety",
          "inference"
        ],
        "pairs_with": [
          "nextjs-app-router",
          "react-patterns",
          "supabase-backend"
        ],
        "requires": [],
        "category": "frameworks"
      },
      {
        "id": "vue-nuxt",
        "name": "Vue & Nuxt",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using Options API for new Vue 3 components",
        "principles": [
          "Composition API first - Options API is legacy",
          "Reactivity is opt-in - use ref() and reactive() intentionally",
          "Composables over mixins - always",
          "Script setup is the default - less boilerplate wins",
          "Let Nuxt auto-import - don't fight the convention",
          "Single-file components are the unit of composition",
          "Keep templates readable - extract complex logic to composables"
        ],
        "owns": [
          "vue-3",
          "composition-api",
          "vue-reactivity",
          "nuxt-3",
          "pinia",
          "vue-router",
          "vue-composables",
          "vue-sfc",
          "vue-directives"
        ],
        "does_not_own": [
          "css-styling → tailwind-ui",
          "state-at-scale → backend",
          "server-deployment → devops",
          "testing-strategy → testing"
        ],
        "triggers": [
          "vue",
          "vue 3",
          "nuxt",
          "nuxt 3",
          "pinia",
          "composition api",
          "vue composable",
          "vue reactivity",
          "ref",
          "reactive",
          "vue router",
          "vite vue"
        ],
        "tags": [
          "vue",
          "vue3",
          "nuxt",
          "nuxt3",
          "composition-api",
          "pinia",
          "frontend",
          "javascript",
          "typescript",
          "reactive"
        ],
        "pairs_with": [
          "frontend            # General frontend patterns",
          "tailwind-ui         # Styling",
          "typescript-strict   # Type safety",
          "testing             # Component testing"
        ],
        "requires": [],
        "category": "frameworks"
      }
    ]
  },
  {
    "id": "hardware",
    "name": "Hardware",
    "skills": [
      {
        "id": "sensor-fusion",
        "name": "EKF on Highly Nonlinear Systems",
        "version": "1.0.0",
        "layer": 1,
        "description": "Optimal state estimator for linear systems with Gaussian noise",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "hardware"
      },
      {
        "id": "control-systems",
        "name": "Ignoring Actuator Saturation",
        "version": "1.0.0",
        "layer": 1,
        "description": "Classic proportional-integral-derivative control with anti-windup",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "hardware"
      },
      {
        "id": "motor-control",
        "name": "Ignoring Dead Time Effects",
        "version": "1.0.0",
        "layer": 1,
        "description": "Vector control for brushless motors",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "hardware"
      },
      {
        "id": "fpga-design",
        "name": "Multiple Drivers on Signal",
        "version": "1.0.0",
        "layer": 1,
        "description": "Two-flip-flop synchronizer for single-bit CDC",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "hardware"
      },
      {
        "id": "embedded-systems",
        "name": "Printf for Debugging Timing-Critical Code",
        "version": "1.0.0",
        "layer": 1,
        "description": "Separate hardware-specific code from application logic",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "hardware"
      },
      {
        "id": "ros2-robotics",
        "name": "QoS Mismatch Between Publisher and Subscriber",
        "version": "1.0.0",
        "layer": 1,
        "description": "Proper node structure with lifecycle management",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "hardware"
      }
    ]
  },
  {
    "id": "integration",
    "name": "Integration",
    "skills": [
      {
        "id": "bullmq-specialist",
        "name": "BullMQ Specialist",
        "version": "1.0.0",
        "layer": 1,
        "description": "Storing large data directly in job data",
        "principles": [
          "Jobs are fire-and-forget from the producer side - let the queue handle delivery",
          "Always set explicit job options - defaults rarely match your use case",
          "Idempotency is your responsibility - jobs may run more than once",
          "Backoff strategies prevent thundering herds - exponential beats linear",
          "Dead letter queues are not optional - failed jobs need a home",
          "Concurrency limits protect downstream services - start conservative",
          "Job data should be small - pass IDs, not payloads",
          "Graceful shutdown prevents orphaned jobs - handle SIGTERM properly"
        ],
        "owns": [
          "bullmq-queues",
          "job-scheduling",
          "delayed-jobs",
          "repeatable-jobs",
          "job-priorities",
          "rate-limiting-jobs",
          "job-events",
          "worker-patterns",
          "flow-producers",
          "job-dependencies"
        ],
        "does_not_own": [
          "redis-infrastructure -> redis-specialist",
          "serverless-queues -> upstash-qstash",
          "workflow-orchestration -> temporal-craftsman",
          "event-sourcing -> event-architect",
          "email-delivery -> email-systems"
        ],
        "triggers": [
          "bullmq",
          "bull queue",
          "redis queue",
          "background job",
          "job queue",
          "delayed job",
          "repeatable job",
          "worker process",
          "job scheduling",
          "async processing"
        ],
        "tags": [
          "bullmq",
          "bull",
          "redis",
          "queue",
          "background-jobs",
          "job-processing",
          "async",
          "workers",
          "scheduling",
          "delayed-jobs"
        ],
        "pairs_with": [
          "redis-specialist",
          "backend",
          "nextjs-app-router",
          "email-systems",
          "ai-workflow-automation",
          "performance-hunter"
        ],
        "requires": [],
        "category": "integration"
      },
      {
        "id": "email-systems",
        "name": "Email Systems",
        "version": "1.0.0",
        "layer": 1,
        "description": "Waiting for email to send before responding to user",
        "principles": [
          "name: Transactional vs Marketing separation"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "integration"
      },
      {
        "id": "inngest",
        "name": "Inngest Integration",
        "version": "1.0.0",
        "layer": 1,
        "description": "Doing all work in a single block without step boundaries",
        "principles": [
          "Events are the primitive - everything triggers from events, not queues",
          "Steps are your checkpoints - each step result is durably stored",
          "Sleep is not a hack - Inngest sleeps are real, not blocking threads",
          "Retries are automatic - but you control the policy",
          "Functions are just HTTP handlers - deploy anywhere that serves HTTP",
          "Concurrency is a first-class concern - protect downstream services",
          "Idempotency keys prevent duplicates - use them for critical operations",
          "Fan-out is built-in - one event can trigger many functions"
        ],
        "owns": [
          "inngest-functions",
          "event-driven-workflows",
          "step-functions",
          "serverless-background-jobs",
          "durable-sleep",
          "fan-out-patterns",
          "concurrency-control",
          "scheduled-functions"
        ],
        "does_not_own": [
          "redis-queues -> bullmq-specialist",
          "workflow-orchestration -> temporal-craftsman",
          "message-streaming -> event-architect",
          "infrastructure -> infra-architect"
        ],
        "triggers": [
          "inngest",
          "serverless background job",
          "event-driven workflow",
          "step function",
          "durable execution",
          "vercel background job",
          "scheduled function",
          "fan out"
        ],
        "tags": [
          "inngest",
          "serverless",
          "background-jobs",
          "event-driven",
          "workflows",
          "step-functions",
          "durable-execution",
          "vercel",
          "nextjs"
        ],
        "pairs_with": [
          "nextjs-app-router",
          "vercel-deployment",
          "supabase-backend",
          "email-systems",
          "ai-agents-architect",
          "stripe-integration"
        ],
        "requires": [],
        "category": "integration"
      },
      {
        "id": "nextjs-supabase-auth",
        "name": "Next.js + Supabase Auth",
        "version": "1.0.0",
        "layer": 2,
        "description": "Forgetting the callback route for OAuth",
        "principles": [],
        "owns": [
          "nextjs-auth",
          "supabase-auth-nextjs",
          "auth-middleware",
          "auth-callback"
        ],
        "does_not_own": [],
        "triggers": [
          "supabase auth next",
          "authentication next.js",
          "login supabase",
          "auth middleware",
          "protected route",
          "auth callback",
          "session management"
        ],
        "tags": [
          "authentication",
          "auth",
          "supabase",
          "nextjs",
          "middleware",
          "session"
        ],
        "pairs_with": [
          "nextjs-app-router",
          "supabase-backend"
        ],
        "requires": [
          "nextjs-app-router",
          "supabase-backend"
        ],
        "category": "integration"
      },
      {
        "id": "stripe-integration",
        "name": "Stripe Integration",
        "version": "1.0.0",
        "layer": 2,
        "description": "Assuming the API call succeeded means the operation completed",
        "principles": [
          "Webhooks are source of truth, not API responses",
          "Handle every edge case for money",
          "Idempotency keys on everything",
          "Test with real cards in test mode",
          "Never store card details yourself",
          "Logs everything for debugging payment issues"
        ],
        "owns": [
          "stripe-payments",
          "subscription-management",
          "billing-portal",
          "stripe-webhooks",
          "checkout-sessions",
          "payment-intents",
          "stripe-connect",
          "metered-billing",
          "dunning-management",
          "payment-failure-handling",
          "stripe-customer-sync",
          "pricing-tables"
        ],
        "does_not_own": [
          "pricing-strategy → product-strategy",
          "tax-calculation → finance-ops",
          "accounting → finance-ops",
          "fraud-detection → security",
          "user-authentication → auth-patterns"
        ],
        "triggers": [
          "stripe",
          "payments",
          "subscription",
          "billing",
          "checkout",
          "pricing",
          "metered billing",
          "stripe connect",
          "webhooks payment",
          "payment intent",
          "customer portal",
          "dunning",
          "failed payment",
          "refund"
        ],
        "tags": [
          "payments",
          "stripe",
          "billing",
          "subscriptions",
          "webhooks",
          "saas",
          "monetization"
        ],
        "pairs_with": [
          "nextjs-supabase-auth  # User auth",
          "supabase-backend      # Database for billing state",
          "webhook-patterns      # General webhook handling",
          "security              # PCI compliance"
        ],
        "requires": [
          "supabase-backend"
        ],
        "category": "integration"
      },
      {
        "id": "trigger-dev",
        "name": "Trigger.dev Integration",
        "version": "1.0.0",
        "layer": 1,
        "description": "Putting too much logic in a single task",
        "principles": [
          "Tasks are the building blocks - each task is independently retryable",
          "Runs are durable - state survives crashes and restarts",
          "Integrations are first-class - use built-in API wrappers for reliability",
          "Logs are your debugging lifeline - log liberally in tasks",
          "Concurrency protects your resources - always set limits",
          "Delays and schedules are built-in - no external cron needed",
          "AI-ready by design - long-running AI tasks just work",
          "Local development matches production - use the CLI"
        ],
        "owns": [
          "trigger-dev-tasks",
          "ai-background-jobs",
          "integration-tasks",
          "scheduled-triggers",
          "webhook-handlers",
          "long-running-tasks",
          "task-queues",
          "batch-processing"
        ],
        "does_not_own": [
          "redis-queues -> bullmq-specialist",
          "pure-event-driven -> inngest",
          "workflow-orchestration -> temporal-craftsman",
          "infrastructure -> infra-architect"
        ],
        "triggers": [
          "trigger.dev",
          "trigger dev",
          "background task",
          "ai background job",
          "long running task",
          "integration task",
          "scheduled task"
        ],
        "tags": [
          "trigger-dev",
          "background-jobs",
          "ai-workflows",
          "typescript",
          "integrations",
          "async",
          "tasks",
          "serverless"
        ],
        "pairs_with": [
          "nextjs-app-router",
          "vercel-deployment",
          "ai-agents-architect",
          "llm-architect",
          "email-systems",
          "stripe-integration"
        ],
        "requires": [],
        "category": "integration"
      },
      {
        "id": "upstash-qstash",
        "name": "Upstash QStash",
        "version": "1.0.0",
        "layer": 1,
        "description": "Processing QStash messages without verifying signatures",
        "principles": [
          "HTTP is the interface - if it speaks HTTPS, it speaks QStash",
          "Endpoints must be public - QStash calls your URLs from the cloud",
          "Verify signatures always - never trust unverified webhooks",
          "Schedules are fire-and-forget - QStash handles the cron",
          "Retries are built-in - but configure them for your use case",
          "Delays are free - schedule seconds to days in the future",
          "Callbacks complete the loop - know when delivery succeeds or fails",
          "Deduplication prevents double-processing - use message IDs"
        ],
        "owns": [
          "qstash-messaging",
          "scheduled-http-calls",
          "serverless-cron",
          "webhook-delivery",
          "message-deduplication",
          "callback-handling",
          "delay-scheduling",
          "url-groups"
        ],
        "does_not_own": [
          "complex-workflows -> inngest",
          "redis-queues -> bullmq-specialist",
          "event-sourcing -> event-architect",
          "workflow-orchestration -> temporal-craftsman"
        ],
        "triggers": [
          "qstash",
          "upstash queue",
          "serverless cron",
          "scheduled http",
          "message queue serverless",
          "vercel cron",
          "delayed message"
        ],
        "tags": [
          "qstash",
          "upstash",
          "serverless",
          "message-queue",
          "scheduling",
          "cron",
          "webhooks",
          "http-messaging"
        ],
        "pairs_with": [
          "vercel-deployment",
          "nextjs-app-router",
          "redis-specialist",
          "email-systems",
          "supabase-backend",
          "cloudflare-workers"
        ],
        "requires": [],
        "category": "integration"
      },
      {
        "id": "vercel-deployment",
        "name": "Vercel Deployment",
        "version": "1.0.0",
        "layer": 2,
        "description": "Serverless functions over 50MB",
        "principles": [],
        "owns": [
          "vercel",
          "deployment",
          "edge-functions",
          "serverless",
          "environment-variables"
        ],
        "does_not_own": [],
        "triggers": [
          "vercel",
          "deploy",
          "deployment",
          "hosting",
          "production",
          "environment variables",
          "edge function",
          "serverless function"
        ],
        "tags": [
          "vercel",
          "deployment",
          "hosting",
          "serverless",
          "edge",
          "ci-cd",
          "environment"
        ],
        "pairs_with": [
          "nextjs-app-router",
          "supabase-backend"
        ],
        "requires": [
          "nextjs-app-router"
        ],
        "category": "integration"
      }
    ]
  },
  {
    "id": "integrations",
    "name": "Integrations",
    "skills": [
      {
        "id": "aws-serverless",
        "name": "AWS Serverless",
        "version": "1.0.0",
        "layer": 1,
        "description": "Don't put all code in one function",
        "principles": [
          "Right-size memory and timeout (measure before optimizing)",
          "Minimize cold starts for latency-sensitive workloads",
          "Use SnapStart for Java/.NET functions",
          "Prefer HTTP API over REST API for simple use cases",
          "Design for failure with DLQs and retries",
          "Keep deployment packages small",
          "Use environment variables for configuration",
          "Implement structured logging with correlation IDs"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [
          "aws",
          "lambda",
          "serverless",
          "api-gateway",
          "dynamodb"
        ],
        "pairs_with": [],
        "requires": [],
        "category": "integrations"
      },
      {
        "id": "azure-functions",
        "name": "Azure Functions",
        "version": "1.0.0",
        "layer": 1,
        "description": "Modern .NET execution model with process isolation",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "azure function",
          "azure functions",
          "durable functions",
          "azure serverless",
          "function app"
        ],
        "tags": "[azure, serverless, functions, durable-functions, cloud]",
        "pairs_with": [],
        "requires": [],
        "category": "integrations"
      },
      {
        "id": "slack-bot-builder",
        "name": "Bolt App Foundation Pattern",
        "version": "1.0.0",
        "layer": 1,
        "description": "The Bolt framework is Slack's recommended approach for building apps.\r\n    It handles authentication, event routing, request verification, and\r\n    HTTP request processing so you can focus on app logic.\r\n\n    Key benefits:\r\n    - Event handling in a few lines of code\r\n    - Security checks and payload validation built-in\r\n    - Organized, consistent patterns\r\n    - Works for experiments and production\r\n\n    Available in: Python, JavaScript (Node.js), Java\r\n  when_to_use:\r\n    - \"Starting any new Slack app\"\r\n    - \"Migrating from legacy Slack APIs\"\r\n    - \"Building production Slack integrations\"\r\n  implementation: |\r\n\n    from slack_bolt import App\r\n    from slack_bolt.adapter.socket_mode import SocketModeHandler\r\n    import os\r\n\n\n    app = App(\r\n        token=os.environ[\"SLACK_BOT_TOKEN\"],\r\n        signing_secret=os.environ[\"SLACK_SIGNING_SECRET\"]\r\n    )\r\n\n\n    @app.message(\"hello\")\r\n    def handle_hello(message, say):\r\n        \"\"\"Respond to messages containing 'hello'.\"\"\"\r\n        user = message[\"user\"]\r\n        say(f\"Hey there <@{user}>!\")\r\n\n\n    @app.command(\"/ticket\")\r\n    def handle_ticket_command(ack, body, client):\r\n        \"\"\"Handle /ticket slash command.\"\"\"\r\n\n        ack()\r\n\n\n        client.views_open(\r\n            trigger_id=body[\"trigger_id\"],\r\n            view={\r\n                \"type\": \"modal\",\r\n                \"callback_id\": \"ticket_modal\",\r\n                \"title\": {\"type\": \"plain_text\", \"text\": \"Create Ticket\"},\r\n                \"submit\": {\"type\": \"plain_text\", \"text\": \"Submit\"},\r\n                \"blocks\": [\r\n                    {\r\n                        \"type\": \"input\",\r\n                        \"block_id\": \"title_block\",\r\n                        \"element\": {\r\n                            \"type\": \"plain_text_input\",\r\n                            \"action_id\": \"title_input\"\r\n                        },\r\n                        \"label\": {\"type\": \"plain_text\", \"text\": \"Title\"}\r\n                    },\r\n                    {\r\n                        \"type\": \"input\",\r\n                        \"block_id\": \"desc_block\",\r\n                        \"element\": {\r\n                            \"type\": \"plain_text_input\",\r\n                            \"multiline\": True,\r\n                            \"action_id\": \"desc_input\"\r\n                        },\r\n                        \"label\": {\"type\": \"plain_text\", \"text\": \"Description\"}\r\n                    },\r\n                    {\r\n                        \"type\": \"input\",\r\n                        \"block_id\": \"priority_block\",\r\n                        \"element\": {\r\n                            \"type\": \"static_select\",\r\n                            \"action_id\": \"priority_select\",\r\n                            \"options\": [\r\n                                {\"text\": {\"type\": \"plain_text\", \"text\": \"Low\"}, \"value\": \"low\"},\r\n                                {\"text\": {\"type\": \"plain_text\", \"text\": \"Medium\"}, \"value\": \"medium\"},\r\n                                {\"text\": {\"type\": \"plain_text\", \"text\": \"High\"}, \"value\": \"high\"}\r\n                            ]\r\n                        },\r\n                        \"label\": {\"type\": \"plain_text\", \"text\": \"Priority\"}\r\n                    }\r\n                ]\r\n            }\r\n        )\r\n\n\n    @app.view(\"ticket_modal\")\r\n    def handle_ticket_submission(ack, body, client, view):\r\n        \"\"\"Handle ticket modal submission.\"\"\"\r\n        ack()\r\n\n\n        values = view[\"state\"][\"values\"]\r\n        title = values[\"title_block\"][\"title_input\"][\"value\"]\r\n        desc = values[\"desc_block\"][\"desc_input\"][\"value\"]\r\n        priority = values[\"priority_block\"][\"priority_select\"][\"selected_option\"][\"value\"]\r\n        user_id = body[\"user\"][\"id\"]\r\n\n\n        ticket_id = create_ticket(title, desc, priority, user_id)\r\n\n\n        client.chat_postMessage(\r\n            channel=user_id,\r\n            text=f\"Ticket #{ticket_id} created: {title}\"\r\n        )\r\n\n\n    @app.action(\"approve_button\")\r\n    def handle_approval(ack, body, client):\r\n        \"\"\"Handle approval button click.\"\"\"\r\n        ack()\r\n\n\n        user = body[\"user\"][\"id\"]\r\n        action_value = body[\"actions\"][0][\"value\"]\r\n\n\n\n        client.chat_update(\r\n            channel=body[\"channel\"][\"id\"],\r\n            ts=body[\"message\"][\"ts\"],\r\n            text=f\"Approved by <@{user}>\",\r\n            blocks=[]  # Remove interactive blocks\r\n        )\r\n\n\n    @app.event(\"app_home_opened\")\r\n    def update_home_tab(client, event):\r\n        \"\"\"Update the Home tab when user opens it.\"\"\"\r\n        client.views_publish(\r\n            user_id=event[\"user\"],\r\n            view={\r\n                \"type\": \"home\",\r\n                \"blocks\": [\r\n                    {\r\n                        \"type\": \"section\",\r\n                        \"text\": {\r\n                            \"type\": \"mrkdwn\",\r\n                            \"text\": \"*Welcome to the Ticket Bot!*\"\r\n                        }\r\n                    },\r\n                    {\r\n                        \"type\": \"actions\",\r\n                        \"elements\": [\r\n                            {\r\n                                \"type\": \"button\",\r\n                                \"text\": {\"type\": \"plain_text\", \"text\": \"Create Ticket\"},\r\n                                \"action_id\": \"create_ticket_button\"\r\n                            }\r\n                        ]\r\n                    }\r\n                ]\r\n            }\r\n        )\r\n\n\n    if __name__ == \"__main__\":\r\n        handler = SocketModeHandler(app, os.environ[\"SLACK_APP_TOKEN\"])\r\n        handler.start()\r\n\n\n\n\n\n\n\n\n\n\n\n  anti_patterns:\r\n    - \"Not acknowledging requests within 3 seconds\"\r\n    - \"Blocking operations in the ack handler\"\r\n    - \"Hardcoding tokens in source code\"\r\n    - \"Not using Socket Mode for development\"\r\n\n- id: block-kit-pattern\r\n  name: Block Kit UI Pattern\r\n  description: |\r\n    Block Kit is Slack's UI framework for building rich, interactive messages.\r\n    Compose messages using blocks (sections, actions, inputs) and elements\r\n    (buttons, menus, text inputs).\r\n\n    Limits:\r\n    - Up to 50 blocks per message\r\n    - Up to 100 blocks in modals/Home tabs\r\n    - Block text limited to 3000 characters\r\n\n    Use Block Kit Builder to prototype: https://app.slack.com/block-kit-builder\r\n  when_to_use:\r\n    - \"Building rich message layouts\"\r\n    - \"Adding interactive components to messages\"\r\n    - \"Creating forms in modals\"\r\n    - \"Building Home tab experiences\"\r\n  implementation: |\r\n    from slack_bolt import App\r\n    import os\r\n\n    app = App(token=os.environ[\"SLACK_BOT_TOKEN\"])\r\n\n    def build_notification_blocks(incident: dict) -> list:\r\n        \"\"\"Build Block Kit blocks for incident notification.\"\"\"\r\n        severity_emoji = {\r\n            \"critical\": \":red_circle:\",\r\n            \"high\": \":large_orange_circle:\",\r\n            \"medium\": \":large_yellow_circle:\",\r\n            \"low\": \":white_circle:\"\r\n        }\r\n\n        return [\r\n\n            {\r\n                \"type\": \"header\",\r\n                \"text\": {\r\n                    \"type\": \"plain_text\",\r\n                    \"text\": f\"{severity_emoji.get(incident['severity'], '')} Incident Alert\"\r\n                }\r\n            },\r\n\n            {\r\n                \"type\": \"section\",\r\n                \"fields\": [\r\n                    {\r\n                        \"type\": \"mrkdwn\",\r\n                        \"text\": f\"*Incident:*\\n{incident['title']}\"\r\n                    },\r\n                    {\r\n                        \"type\": \"mrkdwn\",\r\n                        \"text\": f\"*Severity:*\\n{incident['severity'].upper()}\"\r\n                    },\r\n                    {\r\n                        \"type\": \"mrkdwn\",\r\n                        \"text\": f\"*Service:*\\n{incident['service']}\"\r\n                    },\r\n                    {\r\n                        \"type\": \"mrkdwn\",\r\n                        \"text\": f\"*Reported:*\\n<!date^{incident['timestamp']}^{date_short} {time}|{incident['timestamp']}>\"\r\n                    }\r\n                ]\r\n            },\r\n\n            {\r\n                \"type\": \"section\",\r\n                \"text\": {\r\n                    \"type\": \"mrkdwn\",\r\n                    \"text\": f\"*Description:*\\n{incident['description'][:2000]}\"\r\n                }\r\n            },\r\n\n            {\"type\": \"divider\"},\r\n\n            {\r\n                \"type\": \"actions\",\r\n                \"block_id\": f\"incident_actions_{incident['id']}\",\r\n                \"elements\": [\r\n                    {\r\n                        \"type\": \"button\",\r\n                        \"text\": {\"type\": \"plain_text\", \"text\": \"Acknowledge\"},\r\n                        \"style\": \"primary\",\r\n                        \"action_id\": \"acknowledge_incident\",\r\n                        \"value\": incident['id']\r\n                    },\r\n                    {\r\n                        \"type\": \"button\",\r\n                        \"text\": {\"type\": \"plain_text\", \"text\": \"Resolve\"},\r\n                        \"style\": \"danger\",\r\n                        \"action_id\": \"resolve_incident\",\r\n                        \"value\": incident['id'],\r\n                        \"confirm\": {\r\n                            \"title\": {\"type\": \"plain_text\", \"text\": \"Resolve Incident?\"},\r\n                            \"text\": {\"type\": \"mrkdwn\", \"text\": \"Are you sure this incident is resolved?\"},\r\n                            \"confirm\": {\"type\": \"plain_text\", \"text\": \"Yes, Resolve\"},\r\n                            \"deny\": {\"type\": \"plain_text\", \"text\": \"Cancel\"}\r\n                        }\r\n                    },\r\n                    {\r\n                        \"type\": \"button\",\r\n                        \"text\": {\"type\": \"plain_text\", \"text\": \"View Details\"},\r\n                        \"action_id\": \"view_incident\",\r\n                        \"value\": incident['id'],\r\n                        \"url\": f\"https://incidents.example.com/{incident['id']}\"\r\n                    }\r\n                ]\r\n            },\r\n\n            {\r\n                \"type\": \"context\",\r\n                \"elements\": [\r\n                    {\r\n                        \"type\": \"mrkdwn\",\r\n                        \"text\": f\"Incident ID: {incident['id']} | <https://runbook.example.com/{incident['service']}|View Runbook>\"\r\n                    }\r\n                ]\r\n            }\r\n        ]\r\n\n    def send_incident_notification(channel: str, incident: dict):\r\n        \"\"\"Send incident notification with Block Kit.\"\"\"\r\n        blocks = build_notification_blocks(incident)\r\n\n        app.client.chat_postMessage(\r\n            channel=channel,\r\n            text=f\"Incident: {incident['title']}\",  # Fallback for notifications\r\n            blocks=blocks\r\n        )\r\n\n\n    @app.action(\"acknowledge_incident\")\r\n    def handle_acknowledge(ack, body, client):\r\n        \"\"\"Handle incident acknowledgment.\"\"\"\r\n        ack()\r\n\n        incident_id = body[\"actions\"][0][\"value\"]\r\n        user = body[\"user\"][\"id\"]\r\n\n\n        acknowledge_incident(incident_id, user)\r\n\n\n        original_blocks = body[\"message\"][\"blocks\"]\r\n\n\n        original_blocks[-1][\"elements\"].append({\r\n            \"type\": \"mrkdwn\",\r\n            \"text\": f\":white_check_mark: Acknowledged by <@{user}>\"\r\n        })\r\n\n\n        action_block = next(b for b in original_blocks if b.get(\"block_id\", \"\").startswith(\"incident_actions\"))\r\n        action_block[\"elements\"] = [e for e in action_block[\"elements\"] if e[\"action_id\"] != \"acknowledge_incident\"]\r\n\n        client.chat_update(\r\n            channel=body[\"channel\"][\"id\"],\r\n            ts=body[\"message\"][\"ts\"],\r\n            blocks=original_blocks\r\n        )\r\n\n\n    def build_user_selector_blocks():\r\n        \"\"\"Build blocks with user selector.\"\"\"\r\n        return [\r\n            {\r\n                \"type\": \"section\",\r\n                \"text\": {\"type\": \"mrkdwn\", \"text\": \"Assign this task:\"},\r\n                \"accessory\": {\r\n                    \"type\": \"users_select\",\r\n                    \"action_id\": \"assign_user\",\r\n                    \"placeholder\": {\"type\": \"plain_text\", \"text\": \"Select assignee\"}\r\n                }\r\n            }\r\n        ]\r\n\n\n    def build_task_blocks(task: dict):\r\n        \"\"\"Build task blocks with overflow menu.\"\"\"\r\n        return [\r\n            {\r\n                \"type\": \"section\",\r\n                \"text\": {\"type\": \"mrkdwn\", \"text\": f\"*{task['title']}*\"},\r\n                \"accessory\": {\r\n                    \"type\": \"overflow\",\r\n                    \"action_id\": \"task_overflow\",\r\n                    \"options\": [\r\n                        {\r\n                            \"text\": {\"type\": \"plain_text\", \"text\": \"Edit\"},\r\n                            \"value\": f\"edit_{task['id']}\"\r\n                        },\r\n                        {\r\n                            \"text\": {\"type\": \"plain_text\", \"text\": \"Delete\"},\r\n                            \"value\": f\"delete_{task['id']}\"\r\n                        },\r\n                        {\r\n                            \"text\": {\"type\": \"plain_text\", \"text\": \"Share\"},\r\n                            \"value\": f\"share_{task['id']}\"\r\n                        }\r\n                    ]\r\n                }\r\n            }\r\n        ]\r\n  anti_patterns:\r\n    - \"Exceeding 50 blocks per message\"\r\n    - \"Not providing fallback text for accessibility\"\r\n    - \"Hardcoding action_ids (use dynamic IDs when needed)\"\r\n    - \"Not handling button clicks idempotently\"\r\n\n- id: oauth-installation-pattern\r\n  name: OAuth Installation Pattern\r\n  description: |\r\n    Enable users to install your app in their workspaces via OAuth 2.0.\r\n    Bolt handles most of the OAuth flow, but you need to configure it\r\n    and store tokens securely.\r\n\n    Key OAuth concepts:\r\n    - Scopes define permissions (request minimum needed)\r\n    - Tokens are workspace-specific\r\n    - Installation data must be stored persistently\r\n    - Users can add scopes later (additive)\r\n\n    70% of users abandon installation when confronted with excessive\r\n    permission requests - request only what you need!\r\n  when_to_use:\r\n    - \"Distributing app to multiple workspaces\"\r\n    - \"Building public Slack apps\"\r\n    - \"Enterprise-grade integrations\"\r\n  implementation: |\r\n    from slack_bolt import App\r\n    from slack_bolt.oauth.oauth_settings import OAuthSettings\r\n    from slack_sdk.oauth.installation_store import FileInstallationStore\r\n    from slack_sdk.oauth.state_store import FileOAuthStateStore\r\n    import os\r\n\n\n\n\n    class DatabaseInstallationStore:\r\n        \"\"\"Store installation data in your database.\"\"\"\r\n\n        async def save(self, installation):\r\n            \"\"\"Save installation when user completes OAuth.\"\"\"\r\n            await db.installations.upsert({\r\n                \"team_id\": installation.team_id,\r\n                \"enterprise_id\": installation.enterprise_id,\r\n                \"bot_token\": encrypt(installation.bot_token),\r\n                \"bot_user_id\": installation.bot_user_id,\r\n                \"bot_scopes\": installation.bot_scopes,\r\n                \"user_id\": installation.user_id,\r\n                \"installed_at\": installation.installed_at\r\n            })\r\n\n        async def find_installation(self, *, enterprise_id, team_id, user_id=None, is_enterprise_install=False):\r\n            \"\"\"Find installation for a workspace.\"\"\"\r\n            record = await db.installations.find_one({\r\n                \"team_id\": team_id,\r\n                \"enterprise_id\": enterprise_id\r\n            })\r\n\n            if record:\r\n                return Installation(\r\n                    bot_token=decrypt(record[\"bot_token\"]),\r\n\n                )\r\n            return None\r\n\n\n    app = App(\r\n        signing_secret=os.environ[\"SLACK_SIGNING_SECRET\"],\r\n        oauth_settings=OAuthSettings(\r\n            client_id=os.environ[\"SLACK_CLIENT_ID\"],\r\n            client_secret=os.environ[\"SLACK_CLIENT_SECRET\"],\r\n            scopes=[\r\n                \"channels:history\",\r\n                \"channels:read\",\r\n                \"chat:write\",\r\n                \"commands\",\r\n                \"users:read\"\r\n            ],\r\n            user_scopes=[],  # User token scopes if needed\r\n            installation_store=DatabaseInstallationStore(),\r\n            state_store=FileOAuthStateStore(expiration_seconds=600)\r\n        )\r\n    )\r\n\n\n\n\n\n\n    from flask import Flask, request\r\n    from slack_bolt.adapter.flask import SlackRequestHandler\r\n\n    flask_app = Flask(__name__)\r\n    handler = SlackRequestHandler(app)\r\n\n    @flask_app.route(\"/slack/install\", methods=[\"GET\"])\r\n    def install():\r\n        return handler.handle(request)\r\n\n    @flask_app.route(\"/slack/oauth_redirect\", methods=[\"GET\"])\r\n    def oauth_redirect():\r\n        return handler.handle(request)\r\n\n    @flask_app.route(\"/slack/events\", methods=[\"POST\"])\r\n    def slack_events():\r\n        return handler.handle(request)\r\n\n\n    @app.oauth_success\r\n    def handle_oauth_success(args):\r\n        \"\"\"Called when OAuth completes successfully.\"\"\"\r\n        installation = args[\"installation\"]\r\n\n\n        app.client.chat_postMessage(\r\n            token=installation.bot_token,\r\n            channel=installation.user_id,\r\n            text=\"Thanks for installing! Type /help to get started.\"\r\n        )\r\n\n        return \"Installation successful! You can close this window.\"\r\n\n    @app.oauth_failure\r\n    def handle_oauth_failure(args):\r\n        \"\"\"Called when OAuth fails.\"\"\"\r\n        error = args.get(\"error\", \"Unknown error\")\r\n        return f\"Installation failed: {error}\"\r\n\n\n    def request_additional_scopes(team_id: str, new_scopes: list):\r\n        \"\"\"\r\n        Generate URL for user to add scopes.\r\n        Note: Existing tokens retain old scopes.\r\n        User must re-authorize for new scopes.\r\n        \"\"\"\r\n        base_url = \"https://slack.com/oauth/v2/authorize\"\r\n        params = {\r\n            \"client_id\": os.environ[\"SLACK_CLIENT_ID\"],\r\n            \"scope\": \",\".join(new_scopes),\r\n            \"team\": team_id\r\n        }\r\n        return f\"{base_url}?{urlencode(params)}\"\r\n  anti_patterns:\r\n    - \"Requesting unnecessary scopes upfront\"\r\n    - \"Storing tokens in plain text\"\r\n    - \"Not validating OAuth state parameter (CSRF risk)\"\r\n    - \"Assuming tokens have new scopes after config change\"\r\n\n- id: socket-mode-pattern\r\n  name: Socket Mode Pattern\r\n  description: |\r\n    Socket Mode allows your app to receive events via WebSocket instead\r\n    of public HTTP endpoints. Perfect for development and apps behind\r\n    firewalls.\r\n\n    Benefits:\r\n    - No public URL needed\r\n    - Works behind corporate firewalls\r\n    - Simpler local development\r\n    - Real-time bidirectional communication\r\n\n    Limitation: Not recommended for high-volume production apps.\r\n  when_to_use:\r\n    - \"Local development\"\r\n    - \"Apps behind corporate firewalls\"\r\n    - \"Internal tools with security constraints\"\r\n    - \"Prototyping and testing\"\r\n  implementation: |\r\n    from slack_bolt import App\r\n    from slack_bolt.adapter.socket_mode import SocketModeHandler\r\n    import os\r\n\n\n\n\n\n    app = App(token=os.environ[\"SLACK_BOT_TOKEN\"])\r\n\n    @app.message(\"hello\")\r\n    def handle_hello(message, say):\r\n        say(f\"Hey <@{message['user']}>!\")\r\n\n    @app.command(\"/status\")\r\n    def handle_status(ack, say):\r\n        ack()\r\n        say(\"All systems operational!\")\r\n\n    @app.event(\"app_mention\")\r\n    def handle_mention(event, say):\r\n        say(f\"You mentioned me, <@{event['user']}>!\")\r\n\n    if __name__ == \"__main__\":\r\n\n        handler = SocketModeHandler(\r\n            app,\r\n            os.environ[\"SLACK_APP_TOKEN\"]  # xapp-... token\r\n        )\r\n\n        print(\"Starting Socket Mode...\")\r\n        handler.start()\r\n\n\n    from slack_bolt.async_app import AsyncApp\r\n    from slack_bolt.adapter.socket_mode.async_handler import AsyncSocketModeHandler\r\n    import asyncio\r\n\n    async_app = AsyncApp(token=os.environ[\"SLACK_BOT_TOKEN\"])\r\n\n    @async_app.message(\"hello\")\r\n    async def handle_hello_async(message, say):\r\n        await say(f\"Hey <@{message['user']}>!\")\r\n\n    async def main():\r\n        handler = AsyncSocketModeHandler(async_app, os.environ[\"SLACK_APP_TOKEN\"])\r\n        await handler.start_async()\r\n\n    if __name__ == \"__main__\":\r\n        asyncio.run(main())\r\n  anti_patterns:\r\n    - \"Using Socket Mode for high-volume production apps\"\r\n    - \"Not handling WebSocket disconnections\"\r\n    - \"Forgetting to create app-level token\"\r\n    - \"Using bot token instead of app token\"\r\n\n- id: workflow-step-pattern\r\n  name: Workflow Builder Step Pattern\r\n  description: |\r\n    Extend Slack's Workflow Builder with custom steps powered by your app.\r\n    Users can include your custom steps in their no-code workflows.\r\n\n    Workflow steps can:\r\n    - Collect input from users\r\n    - Execute custom logic\r\n    - Output data for subsequent steps\r\n  when_to_use:\r\n    - \"Integrating with Workflow Builder\"\r\n    - \"Enabling non-technical users to use your features\"\r\n    - \"Building reusable automation components\"\r\n  implementation: |\r\n    from slack_bolt import App\r\n    from slack_bolt.workflows.step import WorkflowStep\r\n    import os\r\n\n    app = App(\r\n        token=os.environ[\"SLACK_BOT_TOKEN\"],\r\n        signing_secret=os.environ[\"SLACK_SIGNING_SECRET\"]\r\n    )\r\n\n\n    def edit(ack, step, configure):\r\n        \"\"\"Called when user adds/edits the step in Workflow Builder.\"\"\"\r\n        ack()\r\n\n\n        blocks = [\r\n            {\r\n                \"type\": \"input\",\r\n                \"block_id\": \"ticket_type\",\r\n                \"element\": {\r\n                    \"type\": \"static_select\",\r\n                    \"action_id\": \"type_select\",\r\n                    \"options\": [\r\n                        {\"text\": {\"type\": \"plain_text\", \"text\": \"Bug\"}, \"value\": \"bug\"},\r\n                        {\"text\": {\"type\": \"plain_text\", \"text\": \"Feature\"}, \"value\": \"feature\"},\r\n                        {\"text\": {\"type\": \"plain_text\", \"text\": \"Task\"}, \"value\": \"task\"}\r\n                    ]\r\n                },\r\n                \"label\": {\"type\": \"plain_text\", \"text\": \"Ticket Type\"}\r\n            },\r\n            {\r\n                \"type\": \"input\",\r\n                \"block_id\": \"title_input\",\r\n                \"element\": {\r\n                    \"type\": \"plain_text_input\",\r\n                    \"action_id\": \"title\"\r\n                },\r\n                \"label\": {\"type\": \"plain_text\", \"text\": \"Title\"}\r\n            },\r\n            {\r\n                \"type\": \"input\",\r\n                \"block_id\": \"assignee_input\",\r\n                \"element\": {\r\n                    \"type\": \"users_select\",\r\n                    \"action_id\": \"assignee\"\r\n                },\r\n                \"label\": {\"type\": \"plain_text\", \"text\": \"Assignee\"}\r\n            }\r\n        ]\r\n\n        configure(blocks=blocks)\r\n\n    def save(ack, view, update):\r\n        \"\"\"Called when user saves step configuration.\"\"\"\r\n        ack()\r\n\n        values = view[\"state\"][\"values\"]\r\n\n\n        inputs = {\r\n            \"ticket_type\": {\r\n                \"value\": values[\"ticket_type\"][\"type_select\"][\"selected_option\"][\"value\"]\r\n            },\r\n            \"title\": {\r\n                \"value\": values[\"title_input\"][\"title\"][\"value\"]\r\n            },\r\n            \"assignee\": {\r\n                \"value\": values[\"assignee_input\"][\"assignee\"][\"selected_user\"]\r\n            }\r\n        }\r\n\n\n        outputs = [\r\n            {\r\n                \"name\": \"ticket_id\",\r\n                \"type\": \"text\",\r\n                \"label\": \"Created Ticket ID\"\r\n            },\r\n            {\r\n                \"name\": \"ticket_url\",\r\n                \"type\": \"text\",\r\n                \"label\": \"Ticket URL\"\r\n            }\r\n        ]\r\n\n        update(inputs=inputs, outputs=outputs)\r\n\n    def execute(step, complete, fail):\r\n        \"\"\"Called when the step runs in a workflow.\"\"\"\r\n        inputs = step[\"inputs\"]\r\n\n        try:\r\n\n            ticket_type = inputs[\"ticket_type\"][\"value\"]\r\n            title = inputs[\"title\"][\"value\"]\r\n            assignee = inputs[\"assignee\"][\"value\"]\r\n\n\n            ticket = create_ticket(\r\n                type=ticket_type,\r\n                title=title,\r\n                assignee=assignee\r\n            )\r\n\n\n            complete(outputs={\r\n                \"ticket_id\": ticket[\"id\"],\r\n                \"ticket_url\": ticket[\"url\"]\r\n            })\r\n\n        except Exception as e:\r\n            fail(error={\"message\": str(e)})\r\n\n\n    create_ticket_step = WorkflowStep(\r\n        callback_id=\"create_ticket_step\",\r\n        edit=edit,\r\n        save=save,\r\n        execute=execute\r\n    )\r\n\n    app.step(create_ticket_step)\r\n  anti_patterns:\r\n    - \"Not calling complete() or fail() in execute\"\r\n    - \"Long-running operations without progress updates\"\r\n    - \"Not validating inputs in execute\"\r\n    - \"Exposing sensitive data in outputs\"",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "slack bot",
          "slack app",
          "bolt framework",
          "block kit",
          "slash command",
          "slack webhook",
          "slack workflow",
          "slack interactive",
          "slack oauth"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "integrations"
      },
      {
        "id": "discord-bot-architect",
        "name": "Discord Bot Architect",
        "version": "1.0.0",
        "layer": 1,
        "description": "Don't parse message content for commands",
        "principles": [
          "Slash commands over message parsing (Message Content Intent deprecated)",
          "Acknowledge interactions within 3 seconds, always",
          "Request only required intents (minimize privileged intents)",
          "Handle rate limits gracefully with exponential backoff",
          "Plan for sharding from the start (required at 2500+ guilds)",
          "Use components (buttons, selects, modals) for rich UX",
          "Test with guild commands first, deploy global when ready"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [
          "discord",
          "bots",
          "slash-commands",
          "interactions",
          "real-time"
        ],
        "pairs_with": [],
        "requires": [],
        "category": "integrations"
      },
      {
        "id": "firebase",
        "name": "Firebase",
        "version": "^5.x",
        "layer": 2,
        "description": "Leaving default rules or using allow all",
        "principles": [
          "Design data for queries, not relationships",
          "Security rules are mandatory, not optional",
          "Denormalize aggressively - duplication is cheap, joins are expensive",
          "Batch writes and transactions for consistency",
          "Use offline persistence wisely - it's not free",
          "Cloud Functions for what clients shouldn't do",
          "Environment-based config, never hardcode keys in client"
        ],
        "owns": [
          "firebase-auth",
          "firestore",
          "firebase-realtime-database",
          "firebase-cloud-functions",
          "firebase-storage",
          "firebase-hosting",
          "firebase-security-rules",
          "firebase-admin-sdk",
          "firebase-emulators"
        ],
        "does_not_own": [
          "general-backend-architecture -> backend",
          "payment-processing -> stripe",
          "email-sending -> email",
          "advanced-auth-flows -> authentication-oauth",
          "kubernetes-deployment -> devops"
        ],
        "triggers": [
          "firebase",
          "firestore",
          "firebase auth",
          "cloud functions",
          "firebase storage",
          "realtime database",
          "firebase hosting",
          "firebase emulator",
          "security rules",
          "firebase admin"
        ],
        "tags": [
          "firebase",
          "firestore",
          "cloud-functions",
          "serverless",
          "backend",
          "realtime",
          "authentication",
          "google-cloud"
        ],
        "pairs_with": [
          "nextjs-app-router    # SSR with Firebase",
          "react-patterns       # Client-side Firebase",
          "authentication-oauth # Complex auth flows",
          "stripe              # Payments integration"
        ],
        "requires": [],
        "category": "integrations"
      },
      {
        "id": "gcp-cloud-run",
        "name": "GCP Cloud Run",
        "version": "1.0.0",
        "layer": 1,
        "description": "Running CPU-bound code with high concurrency",
        "principles": [
          "Cloud Run for containers, Functions for simple event handlers",
          "Optimize for cold starts with startup CPU boost and min instances",
          "Set concurrency based on workload (start with 8, adjust)",
          "Memory includes /tmp filesystem - plan accordingly",
          "Use VPC Connector only when needed (adds latency)",
          "Containers should start fast and be stateless",
          "Handle signals gracefully for clean shutdown"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [
          "gcp",
          "cloud-run",
          "serverless",
          "containers",
          "pubsub"
        ],
        "pairs_with": [],
        "requires": [],
        "category": "integrations"
      },
      {
        "id": "graphql",
        "name": "GraphQL",
        "version": "^3.x",
        "layer": 2,
        "description": "Fetching related data without batching",
        "principles": [
          "Schema-first design - the schema is the contract",
          "Prevent N+1 queries with DataLoader",
          "Limit query depth and complexity",
          "Use fragments for reusable selections",
          "Mutations should be specific, not generic update operations",
          "Errors are data - use union types for expected failures",
          "Nullability is meaningful - design it intentionally"
        ],
        "owns": [
          "graphql-schema-design",
          "graphql-resolvers",
          "graphql-federation",
          "graphql-subscriptions",
          "graphql-dataloader",
          "graphql-codegen",
          "apollo-server",
          "apollo-client",
          "urql"
        ],
        "does_not_own": [
          "database-queries -> postgres-wizard",
          "authentication -> authentication-oauth",
          "rest-api-design -> backend",
          "websocket-infrastructure -> backend"
        ],
        "triggers": [
          "graphql",
          "graphql schema",
          "graphql resolver",
          "apollo server",
          "apollo client",
          "graphql federation",
          "dataloader",
          "graphql codegen",
          "graphql query",
          "graphql mutation"
        ],
        "tags": [
          "graphql",
          "api",
          "apollo",
          "schema",
          "resolvers",
          "dataloader",
          "federation",
          "typescript"
        ],
        "pairs_with": [
          "backend              # Server implementation",
          "postgres-wizard      # Database layer",
          "nextjs-app-router    # Client integration",
          "react-patterns       # Client state"
        ],
        "requires": [],
        "category": "integrations"
      },
      {
        "id": "hubspot-integration",
        "name": "HubSpot Integration",
        "version": "1.0.0",
        "layer": 1,
        "description": "Secure authentication for public apps",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "hubspot",
          "hubspot api",
          "hubspot crm",
          "hubspot integration",
          "contacts api"
        ],
        "tags": "[hubspot, crm, marketing, sales, api]",
        "pairs_with": [],
        "requires": [],
        "category": "integrations"
      },
      {
        "id": "clerk-auth",
        "name": "Next.js App Router Setup",
        "version": "1.0.0",
        "layer": 1,
        "description": "Complete Clerk setup for Next.js 14/15 App Router.\r\n\n    Includes ClerkProvider, environment variables, and basic\r\n    sign-in/sign-up components.\r\n\n    Key components:\r\n    - ClerkProvider: Wraps app for auth context\r\n    - <SignIn />, <SignUp />: Pre-built auth forms\r\n    - <UserButton />: User menu with session management\r\n\n  code_example: |\r\n\n    NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_test_...\r\n    CLERK_SECRET_KEY=sk_test_...\r\n    NEXT_PUBLIC_CLERK_SIGN_IN_URL=/sign-in\r\n    NEXT_PUBLIC_CLERK_SIGN_UP_URL=/sign-up\r\n    NEXT_PUBLIC_CLERK_AFTER_SIGN_IN_URL=/dashboard\r\n    NEXT_PUBLIC_CLERK_AFTER_SIGN_UP_URL=/onboarding\r\n\n    // app/layout.tsx\r\n    import { ClerkProvider } from '@clerk/nextjs';\r\n\n    export default function RootLayout({\r\n      children,\r\n    }: {\r\n      children: React.ReactNode;\r\n    }) {\r\n      return (\r\n        <ClerkProvider>\r\n          <html lang=\"en\">\r\n            <body>{children}</body>\r\n          </html>\r\n        </ClerkProvider>\r\n      );\r\n    }\r\n\n    // app/sign-in/[[...sign-in]]/page.tsx\r\n    import { SignIn } from '@clerk/nextjs';\r\n\n    export default function SignInPage() {\r\n      return (\r\n        <div className=\"flex justify-center items-center min-h-screen\">\r\n          <SignIn />\r\n        </div>\r\n      );\r\n    }\r\n\n    // app/sign-up/[[...sign-up]]/page.tsx\r\n    import { SignUp } from '@clerk/nextjs';\r\n\n    export default function SignUpPage() {\r\n      return (\r\n        <div className=\"flex justify-center items-center min-h-screen\">\r\n          <SignUp />\r\n        </div>\r\n      );\r\n    }\r\n\n    // components/Header.tsx\r\n    import { SignedIn, SignedOut, SignInButton, UserButton } from '@clerk/nextjs';\r\n\n    export function Header() {\r\n      return (\r\n        <header className=\"flex justify-between p-4\">\r\n          <h1>My App</h1>\r\n          <SignedOut>\r\n            <SignInButton />\r\n          </SignedOut>\r\n          <SignedIn>\r\n            <UserButton afterSignOutUrl=\"/\" />\r\n          </SignedIn>\r\n        </header>\r\n      );\r\n    }\r\n\n  anti_patterns:\r\n    - pattern: \"ClerkProvider inside page component\"\r\n      why: \"Provider must wrap entire app in root layout\"\r\n      fix: \"Move ClerkProvider to app/layout.tsx\"\r\n\n    - pattern: \"Using auth() without middleware\"\r\n      why: \"auth() requires clerkMiddleware to be configured\"\r\n      fix: \"Set up middleware.ts with clerkMiddleware\"\r\n\n  references:\r\n    - \"https://clerk.com/docs/nextjs/getting-started/quickstart\"\r\n\n- id: middleware-protection\r\n  name: Middleware Route Protection\r\n  description: |\r\n    Protect routes using clerkMiddleware and createRouteMatcher.\r\n\n    Best practices:\r\n    - Single middleware.ts file at project root\r\n    - Use createRouteMatcher for route groups\r\n    - auth.protect() for explicit protection\r\n    - Centralize all auth logic in middleware\r\n\n  code_example: |\r\n    // middleware.ts\r\n    import { clerkMiddleware, createRouteMatcher } from '@clerk/nextjs/server';\r\n\n    // Define protected route patterns\r\n    const isProtectedRoute = createRouteMatcher([\r\n      '/dashboard(.*)',\r\n      '/settings(.*)',\r\n      '/api/private(.*)',\r\n    ]);\r\n\n    // Define public routes (optional, for clarity)\r\n    const isPublicRoute = createRouteMatcher([\r\n      '/',\r\n      '/sign-in(.*)',\r\n      '/sign-up(.*)',\r\n      '/api/webhooks(.*)',\r\n    ]);\r\n\n    export default clerkMiddleware(async (auth, req) => {\r\n      // Protect matched routes\r\n      if (isProtectedRoute(req)) {\r\n        await auth.protect();\r\n      }\r\n    });\r\n\n    export const config = {\r\n      matcher: [\r\n        // Match all routes except static files\r\n        '/((?!_next|[^?]*\\\\.(?:html?|css|js(?!on)|jpe?g|webp|png|gif|svg|ttf|woff2?|ico|csv|docx?|xlsx?|zip|webmanifest)).*)',\r\n        // Always run for API routes\r\n        '/(api|trpc)(.*)',\r\n      ],\r\n    };\r\n\n    // Advanced: Role-based protection\r\n    export default clerkMiddleware(async (auth, req) => {\r\n      if (isProtectedRoute(req)) {\r\n        await auth.protect();\r\n      }\r\n\n      // Admin routes require admin role\r\n      if (req.nextUrl.pathname.startsWith('/admin')) {\r\n        await auth.protect({\r\n          role: 'org:admin',\r\n        });\r\n      }\r\n\n      // Premium routes require premium permission\r\n      if (req.nextUrl.pathname.startsWith('/premium')) {\r\n        await auth.protect({\r\n          permission: 'org:premium:access',\r\n        });\r\n      }\r\n    });\r\n\n  anti_patterns:\r\n    - pattern: \"Multiple middleware.ts files\"\r\n      why: \"Causes conflicts and redirect loops\"\r\n      fix: \"Use single middleware.ts with route matchers\"\r\n\n    - pattern: \"Manual redirects in components\"\r\n      why: \"Double redirects, missed routes\"\r\n      fix: \"Handle all redirects in middleware\"\r\n\n    - pattern: \"Missing matcher config\"\r\n      why: \"Middleware won't run on all routes\"\r\n      fix: \"Add comprehensive matcher pattern\"\r\n\n  references:\r\n    - \"https://clerk.com/docs/reference/nextjs/clerk-middleware\"\r\n\n- id: server-component-auth\r\n  name: Server Component Authentication\r\n  description: |\r\n    Access auth state in Server Components using auth() and currentUser().\r\n\n    Key functions:\r\n    - auth(): Returns userId, sessionId, orgId, claims\r\n    - currentUser(): Returns full User object\r\n    - Both require clerkMiddleware to be configured\r\n\n  code_example: |\r\n    // app/dashboard/page.tsx (Server Component)\r\n    import { auth, currentUser } from '@clerk/nextjs/server';\r\n    import { redirect } from 'next/navigation';\r\n\n    export default async function DashboardPage() {\r\n      const { userId } = await auth();\r\n\n      if (!userId) {\r\n        redirect('/sign-in');\r\n      }\r\n\n      // Full user data (counts toward rate limits)\r\n      const user = await currentUser();\r\n\n      return (\r\n        <div>\r\n          <h1>Welcome, {user?.firstName}!</h1>\r\n          <p>Email: {user?.emailAddresses[0]?.emailAddress}</p>\r\n        </div>\r\n      );\r\n    }\r\n\n    // Using auth() for quick checks\r\n    export default async function ProtectedLayout({\r\n      children,\r\n    }: {\r\n      children: React.ReactNode;\r\n    }) {\r\n      const { userId, orgId, orgRole } = await auth();\r\n\n      if (!userId) {\r\n        redirect('/sign-in');\r\n      }\r\n\n      // Check organization access\r\n      if (!orgId) {\r\n        redirect('/select-org');\r\n      }\r\n\n      return (\r\n        <div>\r\n          <p>Organization Role: {orgRole}</p>\r\n          {children}\r\n        </div>\r\n      );\r\n    }\r\n\n    // Server Action with auth check\r\n    // app/actions/posts.ts\r\n    'use server';\r\n    import { auth } from '@clerk/nextjs/server';\r\n\n    export async function createPost(formData: FormData) {\r\n      const { userId } = await auth();\r\n\n      if (!userId) {\r\n        throw new Error('Unauthorized');\r\n      }\r\n\n      const title = formData.get('title') as string;\r\n\n      // Create post with userId\r\n      const post = await prisma.post.create({\r\n        data: {\r\n          title,\r\n          authorId: userId,\r\n        },\r\n      });\r\n\n      return post;\r\n    }\r\n\n  anti_patterns:\r\n    - pattern: \"Not awaiting auth()\"\r\n      why: \"auth() is async in App Router\"\r\n      fix: \"Use await auth() or const { userId } = await auth()\"\r\n\n    - pattern: \"Using currentUser() for simple checks\"\r\n      why: \"Counts toward rate limits, slower than auth()\"\r\n      fix: \"Use auth() for userId checks, currentUser() for user data\"\r\n\n  references:\r\n    - \"https://clerk.com/docs/references/nextjs/auth\"\r\n\n- id: client-component-hooks\r\n  name: Client Component Hooks\r\n  description: |\r\n    Access auth state in Client Components using hooks.\r\n\n    Key hooks:\r\n    - useUser(): User object and loading state\r\n    - useAuth(): Auth state, signOut, etc.\r\n    - useSession(): Session object\r\n    - useOrganization(): Current organization\r\n\n  code_example: |\r\n    // components/UserProfile.tsx\r\n    'use client';\r\n    import { useUser, useAuth } from '@clerk/nextjs';\r\n\n    export function UserProfile() {\r\n      const { user, isLoaded, isSignedIn } = useUser();\r\n      const { signOut } = useAuth();\r\n\n      if (!isLoaded) {\r\n        return <div>Loading...</div>;\r\n      }\r\n\n      if (!isSignedIn) {\r\n        return <div>Not signed in</div>;\r\n      }\r\n\n      return (\r\n        <div>\r\n          <img src={user.imageUrl} alt={user.fullName ?? ''} />\r\n          <h2>{user.fullName}</h2>\r\n          <p>{user.emailAddresses[0]?.emailAddress}</p>\r\n          <button onClick={() => signOut()}>Sign Out</button>\r\n        </div>\r\n      );\r\n    }\r\n\n    // Organization context\r\n    'use client';\r\n    import { useOrganization, useOrganizationList } from '@clerk/nextjs';\r\n\n    export function OrgSwitcher() {\r\n      const { organization, membership } = useOrganization();\r\n      const { setActive, userMemberships } = useOrganizationList({\r\n        userMemberships: { infinite: true },\r\n      });\r\n\n      if (!organization) {\r\n        return <p>No organization selected</p>;\r\n      }\r\n\n      return (\r\n        <div>\r\n          <p>Current: {organization.name}</p>\r\n          <p>Role: {membership?.role}</p>\r\n\n          <select\r\n            onChange={(e) => setActive?.({ organization: e.target.value })}\r\n            value={organization.id}\r\n          >\r\n            {userMemberships.data?.map((mem) => (\r\n              <option key={mem.organization.id} value={mem.organization.id}>\r\n                {mem.organization.name}\r\n              </option>\r\n            ))}\r\n          </select>\r\n        </div>\r\n      );\r\n    }\r\n\n    // Protected client component\r\n    'use client';\r\n    import { useAuth } from '@clerk/nextjs';\r\n    import { useRouter } from 'next/navigation';\r\n    import { useEffect } from 'react';\r\n\n    export function ProtectedContent() {\r\n      const { isLoaded, userId } = useAuth();\r\n      const router = useRouter();\r\n\n      useEffect(() => {\r\n        if (isLoaded && !userId) {\r\n          router.push('/sign-in');\r\n        }\r\n      }, [isLoaded, userId, router]);\r\n\n      if (!isLoaded || !userId) {\r\n        return <div>Loading...</div>;\r\n      }\r\n\n      return <div>Protected content here</div>;\r\n    }\r\n\n  anti_patterns:\r\n    - pattern: \"Not checking isLoaded\"\r\n      why: \"Auth state undefined during hydration\"\r\n      fix: \"Always check isLoaded before accessing user/auth state\"\r\n\n    - pattern: \"Using hooks in Server Components\"\r\n      why: \"Hooks only work in Client Components\"\r\n      fix: \"Use auth() and currentUser() in Server Components\"\r\n\n  references:\r\n    - \"https://clerk.com/docs/references/react/use-user\"\r\n\n- id: organizations-multi-tenancy\r\n  name: Organizations and Multi-Tenancy\r\n  description: |\r\n    Implement B2B multi-tenancy with Clerk Organizations.\r\n\n    Features:\r\n    - Multiple orgs per user\r\n    - Roles and permissions\r\n    - Organization-scoped data\r\n    - Enterprise SSO per organization\r\n\n  code_example: |\r\n    // Organization creation UI\r\n    // app/create-org/page.tsx\r\n    import { CreateOrganization } from '@clerk/nextjs';\r\n\n    export default function CreateOrgPage() {\r\n      return (\r\n        <div className=\"flex justify-center\">\r\n          <CreateOrganization afterCreateOrganizationUrl=\"/dashboard\" />\r\n        </div>\r\n      );\r\n    }\r\n\n    // Organization profile and management\r\n    // app/org-settings/page.tsx\r\n    import { OrganizationProfile } from '@clerk/nextjs';\r\n\n    export default function OrgSettingsPage() {\r\n      return <OrganizationProfile />;\r\n    }\r\n\n    // Organization switcher in header\r\n    // components/Header.tsx\r\n    import { OrganizationSwitcher, UserButton } from '@clerk/nextjs';\r\n\n    export function Header() {\r\n      return (\r\n        <header className=\"flex justify-between p-4\">\r\n          <OrganizationSwitcher\r\n            hidePersonal\r\n            afterCreateOrganizationUrl=\"/dashboard\"\r\n            afterSelectOrganizationUrl=\"/dashboard\"\r\n          />\r\n          <UserButton />\r\n        </header>\r\n      );\r\n    }\r\n\n    // Org-scoped data access\r\n    // app/dashboard/page.tsx\r\n    import { auth } from '@clerk/nextjs/server';\r\n    import { prisma } from '@/lib/prisma';\r\n\n    export default async function DashboardPage() {\r\n      const { orgId } = await auth();\r\n\n      if (!orgId) {\r\n        redirect('/select-org');\r\n      }\r\n\n      // Fetch org-scoped data\r\n      const projects = await prisma.project.findMany({\r\n        where: { organizationId: orgId },\r\n      });\r\n\n      return (\r\n        <div>\r\n          <h1>Projects</h1>\r\n          {projects.map((p) => (\r\n            <div key={p.id}>{p.name}</div>\r\n          ))}\r\n        </div>\r\n      );\r\n    }\r\n\n    // Role-based UI\r\n    'use client';\r\n    import { useOrganization, Protect } from '@clerk/nextjs';\r\n\n    export function AdminPanel() {\r\n      const { membership } = useOrganization();\r\n\n      // Using Protect component\r\n      return (\r\n        <Protect role=\"org:admin\" fallback={<p>Admin access required</p>}>\r\n          <div>Admin content here</div>\r\n        </Protect>\r\n      );\r\n\n      // Or manual check\r\n      if (membership?.role !== 'org:admin') {\r\n        return <p>Admin access required</p>;\r\n      }\r\n\n      return <div>Admin content here</div>;\r\n    }\r\n\n  anti_patterns:\r\n    - pattern: \"Not scoping data by orgId\"\r\n      why: \"Data leaks between organizations\"\r\n      fix: \"Always filter queries by orgId from auth()\"\r\n\n    - pattern: \"Hardcoding role strings\"\r\n      why: \"Typos cause access issues\"\r\n      fix: \"Define role constants or use TypeScript enums\"\r\n\n  references:\r\n    - \"https://clerk.com/docs/guides/organizations\"\r\n    - \"https://clerk.com/articles/multi-tenancy-in-react-applications-guide\"\r\n\n- id: webhook-user-sync\r\n  name: Webhook User Sync\r\n  description: |\r\n    Sync Clerk users to your database using webhooks.\r\n\n    Key webhooks:\r\n    - user.created: New user signed up\r\n    - user.updated: User profile changed\r\n    - user.deleted: User deleted account\r\n\n    Uses svix for signature verification.\r\n\n  code_example: |\r\n    // app/api/webhooks/clerk/route.ts\r\n    import { Webhook } from 'svix';\r\n    import { headers } from 'next/headers';\r\n    import { WebhookEvent } from '@clerk/nextjs/server';\r\n    import { prisma } from '@/lib/prisma';\r\n\n    export async function POST(req: Request) {\r\n      const WEBHOOK_SECRET = process.env.CLERK_WEBHOOK_SECRET;\r\n\n      if (!WEBHOOK_SECRET) {\r\n        throw new Error('Missing CLERK_WEBHOOK_SECRET');\r\n      }\r\n\n      // Get headers\r\n      const headerPayload = await headers();\r\n      const svix_id = headerPayload.get('svix-id');\r\n      const svix_timestamp = headerPayload.get('svix-timestamp');\r\n      const svix_signature = headerPayload.get('svix-signature');\r\n\n      if (!svix_id || !svix_timestamp || !svix_signature) {\r\n        return new Response('Missing svix headers', { status: 400 });\r\n      }\r\n\n      // Get body\r\n      const payload = await req.json();\r\n      const body = JSON.stringify(payload);\r\n\n      // Verify webhook\r\n      const wh = new Webhook(WEBHOOK_SECRET);\r\n      let evt: WebhookEvent;\r\n\n      try {\r\n        evt = wh.verify(body, {\r\n          'svix-id': svix_id,\r\n          'svix-timestamp': svix_timestamp,\r\n          'svix-signature': svix_signature,\r\n        }) as WebhookEvent;\r\n      } catch (err) {\r\n        console.error('Webhook verification failed:', err);\r\n        return new Response('Verification failed', { status: 400 });\r\n      }\r\n\n      // Handle events\r\n      const eventType = evt.type;\r\n\n      if (eventType === 'user.created') {\r\n        const { id, email_addresses, first_name, last_name, image_url } = evt.data;\r\n\n        await prisma.user.create({\r\n          data: {\r\n            clerkId: id,\r\n            email: email_addresses[0]?.email_address,\r\n            firstName: first_name,\r\n            lastName: last_name,\r\n            imageUrl: image_url,\r\n          },\r\n        });\r\n      }\r\n\n      if (eventType === 'user.updated') {\r\n        const { id, email_addresses, first_name, last_name, image_url } = evt.data;\r\n\n        await prisma.user.update({\r\n          where: { clerkId: id },\r\n          data: {\r\n            email: email_addresses[0]?.email_address,\r\n            firstName: first_name,\r\n            lastName: last_name,\r\n            imageUrl: image_url,\r\n          },\r\n        });\r\n      }\r\n\n      if (eventType === 'user.deleted') {\r\n        const { id } = evt.data;\r\n\n        await prisma.user.delete({\r\n          where: { clerkId: id! },\r\n        });\r\n      }\r\n\n      return new Response('Webhook processed', { status: 200 });\r\n    }\r\n\n    // Prisma schema\r\n    // prisma/schema.prisma\r\n    model User {\r\n      id        String   @id @default(cuid())\r\n      clerkId   String   @unique\r\n      email     String   @unique\r\n      firstName String?\r\n      lastName  String?\r\n      imageUrl  String?\r\n      createdAt DateTime @default(now())\r\n      updatedAt DateTime @updatedAt\r\n\n      posts     Post[]\r\n      @@index([clerkId])\r\n    }\r\n\n  anti_patterns:\r\n    - pattern: \"Not verifying webhook signature\"\r\n      why: \"Anyone can hit your endpoint with fake data\"\r\n      fix: \"Always verify with svix\"\r\n\n    - pattern: \"Blocking middleware for webhook routes\"\r\n      why: \"Webhooks come from Clerk, not authenticated users\"\r\n      fix: \"Add /api/webhooks(.*)' to public routes\"\r\n\n    - pattern: \"Not handling race conditions\"\r\n      why: \"user.created might arrive after user.updated\"\r\n      fix: \"Use upsert instead of create, handle missing records\"\r\n\n  references:\r\n    - \"https://clerk.com/docs/webhooks/sync-data\"\r\n    - \"https://clerk.com/articles/how-to-sync-clerk-user-data-to-your-database\"\r\n\n- id: api-route-protection\r\n  name: API Route Protection\r\n  description: |\r\n    Protect API routes using auth() from Clerk.\r\n\n    Route Handlers in App Router use auth() for authentication.\r\n    Middleware provides initial protection, auth() provides in-handler verification.\r\n\n  code_example: |\r\n    // app/api/projects/route.ts\r\n    import { auth } from '@clerk/nextjs/server';\r\n    import { prisma } from '@/lib/prisma';\r\n    import { NextResponse } from 'next/server';\r\n\n    export async function GET() {\r\n      const { userId, orgId } = await auth();\r\n\n      if (!userId) {\r\n        return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });\r\n      }\r\n\n      // User's personal projects or org projects\r\n      const projects = await prisma.project.findMany({\r\n        where: orgId\r\n          ? { organizationId: orgId }\r\n          : { userId, organizationId: null },\r\n      });\r\n\n      return NextResponse.json(projects);\r\n    }\r\n\n    export async function POST(req: Request) {\r\n      const { userId, orgId } = await auth();\r\n\n      if (!userId) {\r\n        return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });\r\n      }\r\n\n      const body = await req.json();\r\n\n      const project = await prisma.project.create({\r\n        data: {\r\n          name: body.name,\r\n          userId,\r\n          organizationId: orgId ?? null,\r\n        },\r\n      });\r\n\n      return NextResponse.json(project, { status: 201 });\r\n    }\r\n\n    // Protected with role check\r\n    // app/api/admin/users/route.ts\r\n    export async function GET() {\r\n      const { userId, orgRole } = await auth();\r\n\n      if (!userId) {\r\n        return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });\r\n      }\r\n\n      if (orgRole !== 'org:admin') {\r\n        return NextResponse.json({ error: 'Forbidden' }, { status: 403 });\r\n      }\r\n\n      // Admin-only logic\r\n      const users = await prisma.user.findMany();\r\n      return NextResponse.json(users);\r\n    }\r\n\n    // Using getAuth in older patterns (not recommended)\r\n    // For backwards compatibility only\r\n    import { getAuth } from '@clerk/nextjs/server';\r\n\n    export async function GET(req: Request) {\r\n      const { userId } = getAuth(req);\r\n      // ...\r\n    }\r\n\n  anti_patterns:\r\n    - pattern: \"Trusting middleware alone\"\r\n      why: \"Middleware can be bypassed (CVE-2025-29927)\"\r\n      fix: \"Always verify auth in route handler too\"\r\n\n    - pattern: \"Not checking orgId for multi-tenant\"\r\n      why: \"Users might access other org's data\"\r\n      fix: \"Always filter by orgId from auth()\"\r\n\n  references:\r\n    - \"https://clerk.com/docs/guides/protecting-pages\"",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "adding authentication",
          "clerk auth",
          "user authentication",
          "sign in",
          "sign up",
          "user management",
          "multi-tenancy",
          "organizations",
          "sso",
          "single sign-on"
        ],
        "tags": [
          "clerk",
          "authentication",
          "auth",
          "user-management",
          "multi-tenancy",
          "organizations",
          "sso",
          "oauth"
        ],
        "pairs_with": [],
        "requires": [],
        "category": "integrations"
      },
      {
        "id": "plaid-fintech",
        "name": "Plaid Fintech",
        "version": "1.0.0",
        "layer": 1,
        "description": "Access tokens grant full account access and must be encrypted",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "plaid",
          "bank account linking",
          "bank connection",
          "ach",
          "account aggregation",
          "bank transactions",
          "open banking",
          "fintech",
          "identity verification banking"
        ],
        "tags": [
          "plaid",
          "fintech",
          "banking",
          "payments",
          "ach",
          "transactions",
          "identity"
        ],
        "pairs_with": [],
        "requires": [],
        "category": "integrations"
      },
      {
        "id": "neon-postgres",
        "name": "Prisma with Neon Connection",
        "version": "1.0.0",
        "layer": 1,
        "description": "Configure Prisma for Neon with connection pooling.\r\n\n    Use two connection strings:\r\n    - DATABASE_URL: Pooled connection for Prisma Client\r\n    - DIRECT_URL: Direct connection for Prisma Migrate\r\n\n    The pooled connection uses PgBouncer for up to 10K connections.\r\n    Direct connection required for migrations (DDL operations).\r\n\n  code_example: |\r\n\n\n    DATABASE_URL=\"postgres://user:password@ep-xxx-pooler.us-east-2.aws.neon.tech/neondb?sslmode=require\"\r\n\n    DIRECT_URL=\"postgres://user:password@ep-xxx.us-east-2.aws.neon.tech/neondb?sslmode=require\"\r\n\n    // prisma/schema.prisma\r\n    generator client {\r\n      provider = \"prisma-client-js\"\r\n    }\r\n\n    datasource db {\r\n      provider  = \"postgresql\"\r\n      url       = env(\"DATABASE_URL\")\r\n      directUrl = env(\"DIRECT_URL\")\r\n    }\r\n\n    model User {\r\n      id        String   @id @default(cuid())\r\n      email     String   @unique\r\n      name      String?\r\n      createdAt DateTime @default(now())\r\n      updatedAt DateTime @updatedAt\r\n    }\r\n\n    // lib/prisma.ts\r\n    import { PrismaClient } from '@prisma/client';\r\n\n    const globalForPrisma = globalThis as unknown as {\r\n      prisma: PrismaClient | undefined;\r\n    };\r\n\n    export const prisma = globalForPrisma.prisma ?? new PrismaClient({\r\n      log: process.env.NODE_ENV === 'development'\r\n        ? ['query', 'error', 'warn']\r\n        : ['error'],\r\n    });\r\n\n    if (process.env.NODE_ENV !== 'production') {\r\n      globalForPrisma.prisma = prisma;\r\n    }\r\n\n    // Run migrations\r\n    // Uses DIRECT_URL automatically\r\n    npx prisma migrate dev\r\n    npx prisma migrate deploy\r\n\n  anti_patterns:\r\n    - pattern: \"Using pooled connection for migrations\"\r\n      why: \"DDL operations fail through PgBouncer\"\r\n      fix: \"Set directUrl in schema.prisma\"\r\n\n    - pattern: \"Not using connection pooling\"\r\n      why: \"Serverless functions exhaust connection limits\"\r\n      fix: \"Use -pooler endpoint in DATABASE_URL\"\r\n\n  references:\r\n    - \"https://neon.com/docs/guides/prisma\"\r\n    - \"https://www.prisma.io/docs/orm/overview/databases/neon\"\r\n\n- id: drizzle-serverless-driver\r\n  name: Drizzle with Neon Serverless Driver\r\n  description: |\r\n    Use Drizzle ORM with Neon's serverless HTTP driver for\r\n    edge/serverless environments.\r\n\n    Two driver options:\r\n    - neon-http: Single queries over HTTP (fastest for one-off queries)\r\n    - neon-serverless: WebSocket for transactions and sessions\r\n\n  code_example: |\r\n\n    npm install drizzle-orm @neondatabase/serverless\r\n    npm install -D drizzle-kit\r\n\n    // lib/db/schema.ts\r\n    import { pgTable, serial, text, timestamp } from 'drizzle-orm/pg-core';\r\n\n    export const users = pgTable('users', {\r\n      id: serial('id').primaryKey(),\r\n      email: text('email').notNull().unique(),\r\n      name: text('name'),\r\n      createdAt: timestamp('created_at').defaultNow().notNull(),\r\n      updatedAt: timestamp('updated_at').defaultNow().notNull(),\r\n    });\r\n\n    // lib/db/index.ts (for serverless - HTTP driver)\r\n    import { neon } from '@neondatabase/serverless';\r\n    import { drizzle } from 'drizzle-orm/neon-http';\r\n    import * as schema from './schema';\r\n\n    const sql = neon(process.env.DATABASE_URL!);\r\n    export const db = drizzle(sql, { schema });\r\n\n    // Usage in API route\r\n    import { db } from '@/lib/db';\r\n    import { users } from '@/lib/db/schema';\r\n\n    export async function GET() {\r\n      const allUsers = await db.select().from(users);\r\n      return Response.json(allUsers);\r\n    }\r\n\n    // lib/db/index.ts (for WebSocket - transactions)\r\n    import { Pool } from '@neondatabase/serverless';\r\n    import { drizzle } from 'drizzle-orm/neon-serverless';\r\n    import * as schema from './schema';\r\n\n    const pool = new Pool({ connectionString: process.env.DATABASE_URL });\r\n    export const db = drizzle(pool, { schema });\r\n\n    // With transactions\r\n    await db.transaction(async (tx) => {\r\n      await tx.insert(users).values({ email: 'test@example.com' });\r\n      await tx.update(users).set({ name: 'Updated' });\r\n    });\r\n\n    // drizzle.config.ts\r\n    import { defineConfig } from 'drizzle-kit';\r\n\n    export default defineConfig({\r\n      schema: './lib/db/schema.ts',\r\n      out: './drizzle',\r\n      dialect: 'postgresql',\r\n      dbCredentials: {\r\n        url: process.env.DATABASE_URL!,\r\n      },\r\n    });\r\n\n    // Run migrations\r\n    npx drizzle-kit generate\r\n    npx drizzle-kit migrate\r\n\n  anti_patterns:\r\n    - pattern: \"Using pg driver in serverless\"\r\n      why: \"TCP connections don't work in all edge environments\"\r\n      fix: \"Use @neondatabase/serverless driver\"\r\n\n    - pattern: \"HTTP driver for transactions\"\r\n      why: \"HTTP driver doesn't support transactions\"\r\n      fix: \"Use WebSocket driver (Pool) for transactions\"\r\n\n  references:\r\n    - \"https://neon.com/docs/guides/drizzle\"\r\n    - \"https://orm.drizzle.team/docs/connect-neon\"\r\n\n- id: connection-pooling\r\n  name: Connection Pooling with PgBouncer\r\n  description: |\r\n    Neon provides built-in connection pooling via PgBouncer.\r\n\n    Key limits:\r\n    - Up to 10,000 concurrent connections to pooler\r\n    - Connections still consume underlying Postgres connections\r\n    - 7 connections reserved for Neon superuser\r\n\n    Use pooled endpoint for application, direct for migrations.\r\n\n  code_example: |\r\n\n\n\n\n    postgres://user:pass@ep-cool-name-pooler.us-east-2.aws.neon.tech/neondb\r\n\n\n\n    postgres://user:pass@ep-cool-name.us-east-2.aws.neon.tech/neondb\r\n\n    // Prisma with pooling\r\n    // prisma/schema.prisma\r\n    datasource db {\r\n      provider  = \"postgresql\"\r\n      url       = env(\"DATABASE_URL\")      // Pooled\r\n      directUrl = env(\"DIRECT_URL\")        // Direct\r\n    }\r\n\n    // Connection pool settings for high-traffic\r\n    // lib/prisma.ts\r\n    import { PrismaClient } from '@prisma/client';\r\n\n    export const prisma = new PrismaClient({\r\n      datasources: {\r\n        db: {\r\n          url: process.env.DATABASE_URL,\r\n        },\r\n      },\r\n      // Connection pool settings\r\n      // Adjust based on compute size\r\n    });\r\n\n    // For Drizzle with connection pool\r\n    import { Pool } from '@neondatabase/serverless';\r\n\n    const pool = new Pool({\r\n      connectionString: process.env.DATABASE_URL,\r\n      max: 10,  // Max connections in local pool\r\n      idleTimeoutMillis: 30000,\r\n      connectionTimeoutMillis: 10000,\r\n    });\r\n\n    // Compute size connection limits\r\n    // 0.25 CU: 112 connections (105 available after reserved)\r\n    // 0.5 CU: 225 connections\r\n    // 1 CU: 450 connections\r\n    // 2 CU: 901 connections\r\n    // 4 CU: 1802 connections\r\n    // 8 CU: 3604 connections\r\n\n  anti_patterns:\r\n    - pattern: \"Opening new connection per request\"\r\n      why: \"Exhausts connection limits quickly\"\r\n      fix: \"Use connection pooling, reuse connections\"\r\n\n    - pattern: \"High max pool size in serverless\"\r\n      why: \"Many function instances = many pools = many connections\"\r\n      fix: \"Keep local pool size low (5-10), rely on PgBouncer\"\r\n\n  references:\r\n    - \"https://neon.com/docs/connect/connection-pooling\"\r\n\n- id: database-branching\r\n  name: Database Branching for Development\r\n  description: |\r\n    Create instant copies of your database for development,\r\n    testing, and preview environments.\r\n\n    Branches share underlying storage (copy-on-write),\r\n    making them instant and cost-effective.\r\n\n  code_example: |\r\n\n    neon branches create --name feature/new-feature --parent main\r\n\n\n    neon branches create --name debug/yesterday \\\r\n      --parent main \\\r\n      --timestamp \"2024-01-15T10:00:00Z\"\r\n\n\n    neon branches list\r\n\n\n    neon connection-string feature/new-feature\r\n\n\n    neon branches delete feature/new-feature\r\n\n    // In CI/CD (GitHub Actions)\r\n    // .github/workflows/preview.yml\r\n    name: Preview Environment\r\n    on:\r\n      pull_request:\r\n        types: [opened, synchronize]\r\n\n    jobs:\r\n      create-branch:\r\n        runs-on: ubuntu-latest\r\n        steps:\r\n          - uses: neondatabase/create-branch-action@v5\r\n            id: create-branch\r\n            with:\r\n              project_id: ${{ secrets.NEON_PROJECT_ID }}\r\n              branch_name: preview/pr-${{ github.event.pull_request.number }}\r\n              api_key: ${{ secrets.NEON_API_KEY }}\r\n              username: ${{ secrets.NEON_ROLE_NAME }}\r\n\n          - name: Run migrations\r\n            env:\r\n              DATABASE_URL: ${{ steps.create-branch.outputs.db_url_with_pooler }}\r\n            run: npx prisma migrate deploy\r\n\n          - name: Deploy to Vercel\r\n            env:\r\n              DATABASE_URL: ${{ steps.create-branch.outputs.db_url_with_pooler }}\r\n            run: vercel deploy --prebuilt\r\n\n    // Cleanup on PR close\r\n    on:\r\n      pull_request:\r\n        types: [closed]\r\n\n    jobs:\r\n      delete-branch:\r\n        runs-on: ubuntu-latest\r\n        steps:\r\n          - uses: neondatabase/delete-branch-action@v3\r\n            with:\r\n              project_id: ${{ secrets.NEON_PROJECT_ID }}\r\n              branch: preview/pr-${{ github.event.pull_request.number }}\r\n              api_key: ${{ secrets.NEON_API_KEY }}\r\n\n  anti_patterns:\r\n    - pattern: \"Sharing production database for development\"\r\n      why: \"Risk of data corruption, no isolation\"\r\n      fix: \"Create development branches from production\"\r\n\n    - pattern: \"Not cleaning up old branches\"\r\n      why: \"Accumulates storage and clutter\"\r\n      fix: \"Auto-delete branches on PR close\"\r\n\n  references:\r\n    - \"https://neon.com/blog/branching-with-preview-environments\"\r\n    - \"https://github.com/neondatabase/create-branch-action\"\r\n\n- id: vercel-integration\r\n  name: Vercel Preview Environment Integration\r\n  description: |\r\n    Automatically create database branches for Vercel preview\r\n    deployments. Each PR gets its own isolated database.\r\n\n    Two integration options:\r\n    - Vercel-Managed: Billing in Vercel, auto-setup\r\n    - Neon-Managed: Billing in Neon, more control\r\n\n  code_example: |\r\n\n\n\n\n\n\n\n\n\n\n\n\n    // vercel.json - Add migration to build\r\n    {\r\n      \"buildCommand\": \"prisma migrate deploy && next build\",\r\n      \"framework\": \"nextjs\"\r\n    }\r\n\n    // Or in package.json\r\n    {\r\n      \"scripts\": {\r\n        \"vercel-build\": \"prisma generate && prisma migrate deploy && next build\"\r\n      }\r\n    }\r\n\n    // Environment variables injected by integration\r\n    // DATABASE_URL - Pooled connection for preview branch\r\n    // DATABASE_URL_UNPOOLED - Direct connection for migrations\r\n    // PGHOST, PGUSER, PGDATABASE, PGPASSWORD - Individual vars\r\n\n    // Prisma schema for Vercel integration\r\n    datasource db {\r\n      provider  = \"postgresql\"\r\n      url       = env(\"DATABASE_URL\")\r\n      directUrl = env(\"DATABASE_URL_UNPOOLED\")  // Vercel variable\r\n    }\r\n\n    // For Drizzle in Next.js on Vercel\r\n    import { neon } from '@neondatabase/serverless';\r\n    import { drizzle } from 'drizzle-orm/neon-http';\r\n\n    // Use pooled URL for queries\r\n    const sql = neon(process.env.DATABASE_URL!);\r\n    export const db = drizzle(sql);\r\n\n  anti_patterns:\r\n    - pattern: \"Same database for all previews\"\r\n      why: \"Previews interfere with each other\"\r\n      fix: \"Enable branch-per-preview in integration\"\r\n\n    - pattern: \"Not running migrations on preview\"\r\n      why: \"Schema mismatch between code and database\"\r\n      fix: \"Add migrate command to build step\"\r\n\n  references:\r\n    - \"https://neon.com/docs/guides/vercel-managed-integration\"\r\n    - \"https://neon.com/docs/guides/neon-managed-vercel-integration\"\r\n\n- id: autoscaling-cold-starts\r\n  name: Autoscaling and Cold Start Management\r\n  description: |\r\n    Neon autoscales compute resources and scales to zero.\r\n\n    Cold start latency: 500ms - few seconds when waking from idle.\r\n    Production recommendation: Disable scale-to-zero, set minimum compute.\r\n\n  code_example: |\r\n\n\n\n\n\n    // Handle cold starts in application\r\n    // lib/db-with-retry.ts\r\n    import { prisma } from './prisma';\r\n\n    const MAX_RETRIES = 3;\r\n    const RETRY_DELAY = 1000;\r\n\n    export async function queryWithRetry<T>(\r\n      query: () => Promise<T>\r\n    ): Promise<T> {\r\n      let lastError: Error | undefined;\r\n\n      for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {\r\n        try {\r\n          return await query();\r\n        } catch (error) {\r\n          lastError = error as Error;\r\n\n          // Retry on connection errors (cold start)\r\n          if (error.code === 'P1001' || error.code === 'P1002') {\r\n            console.log(`Retry attempt ${attempt}/${MAX_RETRIES}`);\r\n            await new Promise(r => setTimeout(r, RETRY_DELAY * attempt));\r\n            continue;\r\n          }\r\n\n          throw error;\r\n        }\r\n      }\r\n\n      throw lastError;\r\n    }\r\n\n    // Usage\r\n    const users = await queryWithRetry(() =>\r\n      prisma.user.findMany()\r\n    );\r\n\n    // Reduce cold start latency with SSL direct negotiation\r\n\n    postgres://user:pass@ep-xxx-pooler.aws.neon.tech/db?sslmode=require&sslnegotiation=direct\r\n\n    // Keep-alive for long-running apps\r\n    // lib/db-keepalive.ts\r\n    import { prisma } from './prisma';\r\n\n    // Ping database every 4 minutes to prevent suspend\r\n    const KEEPALIVE_INTERVAL = 4 * 60 * 1000;\r\n\n    if (process.env.NEON_KEEPALIVE === 'true') {\r\n      setInterval(async () => {\r\n        try {\r\n          await prisma.$queryRaw`SELECT 1`;\r\n        } catch (error) {\r\n          console.error('Keepalive failed:', error);\r\n        }\r\n      }, KEEPALIVE_INTERVAL);\r\n    }\r\n\n    // Compute sizing recommendations\r\n    // Development: 0.25 CU, scale-to-zero enabled\r\n    // Staging: 0.5 CU, scale-to-zero enabled\r\n    // Production: 1+ CU, scale-to-zero DISABLED\r\n    // High-traffic: 2-4 CU minimum, autoscaling enabled\r\n\n  anti_patterns:\r\n    - pattern: \"Scale-to-zero in production\"\r\n      why: \"Cold starts add 500ms+ latency to first request\"\r\n      fix: \"Disable scale-to-zero for production branch\"\r\n\n    - pattern: \"No retry logic for cold starts\"\r\n      why: \"First connection after idle may timeout\"\r\n      fix: \"Add retry with exponential backoff\"\r\n\n  references:\r\n    - \"https://neon.com/blog/scaling-serverless-postgres\"\r\n    - \"https://neon.com/docs/connect/connection-latency\"",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "neon database",
          "serverless postgres",
          "database branching",
          "neon postgres",
          "postgres serverless",
          "connection pooling",
          "preview environments",
          "database per preview"
        ],
        "tags": [
          "neon",
          "postgres",
          "serverless",
          "database",
          "branching",
          "prisma",
          "drizzle",
          "connection-pooling"
        ],
        "pairs_with": [],
        "requires": [],
        "category": "integrations"
      },
      {
        "id": "algolia-search",
        "name": "React InstantSearch with Hooks",
        "version": "1.0.0",
        "layer": 1,
        "description": "Modern React InstantSearch setup using hooks for type-ahead search.\r\n\n    Uses react-instantsearch-hooks-web package with algoliasearch client.\r\n    Widgets are components that can be customized with classnames.\r\n\n    Key hooks:\r\n    - useSearchBox: Search input handling\r\n    - useHits: Access search results\r\n    - useRefinementList: Facet filtering\r\n    - usePagination: Result pagination\r\n    - useInstantSearch: Full state access\r\n\n  code_example: |\r\n    // lib/algolia.ts\r\n    import algoliasearch from 'algoliasearch/lite';\r\n\n    export const searchClient = algoliasearch(\r\n      process.env.NEXT_PUBLIC_ALGOLIA_APP_ID!,\r\n      process.env.NEXT_PUBLIC_ALGOLIA_SEARCH_KEY!  // Search-only key!\r\n    );\r\n\n    export const INDEX_NAME = 'products';\r\n\n    // components/Search.tsx\r\n    'use client';\r\n    import { InstantSearch, SearchBox, Hits, Configure } from 'react-instantsearch';\r\n    import { searchClient, INDEX_NAME } from '@/lib/algolia';\r\n\n    function Hit({ hit }: { hit: ProductHit }) {\r\n      return (\r\n        <article>\r\n          <h3>{hit.name}</h3>\r\n          <p>{hit.description}</p>\r\n          <span>${hit.price}</span>\r\n        </article>\r\n      );\r\n    }\r\n\n    export function ProductSearch() {\r\n      return (\r\n        <InstantSearch searchClient={searchClient} indexName={INDEX_NAME}>\r\n          <Configure hitsPerPage={20} />\r\n          <SearchBox\r\n            placeholder=\"Search products...\"\r\n            classNames={{\r\n              root: 'relative',\r\n              input: 'w-full px-4 py-2 border rounded',\r\n            }}\r\n          />\r\n          <Hits hitComponent={Hit} />\r\n        </InstantSearch>\r\n      );\r\n    }\r\n\n    // Custom hook usage\r\n    import { useSearchBox, useHits, useInstantSearch } from 'react-instantsearch';\r\n\n    function CustomSearch() {\r\n      const { query, refine } = useSearchBox();\r\n      const { hits } = useHits<ProductHit>();\r\n      const { status } = useInstantSearch();\r\n\n      return (\r\n        <div>\r\n          <input\r\n            value={query}\r\n            onChange={(e) => refine(e.target.value)}\r\n            placeholder=\"Search...\"\r\n          />\r\n          {status === 'loading' && <p>Loading...</p>}\r\n          <ul>\r\n            {hits.map((hit) => (\r\n              <li key={hit.objectID}>{hit.name}</li>\r\n            ))}\r\n          </ul>\r\n        </div>\r\n      );\r\n    }\r\n\n  anti_patterns:\r\n    - pattern: \"Using Admin API key in frontend code\"\r\n      why: \"Admin key exposes full index control including deletion\"\r\n      fix: \"Use search-only API key with restrictions\"\r\n\n    - pattern: \"Not using /lite client for frontend\"\r\n      why: \"Full client includes unnecessary code for search\"\r\n      fix: \"Import from algoliasearch/lite for smaller bundle\"\r\n\n  references:\r\n    - \"https://www.algolia.com/doc/api-reference/widgets/react\"\r\n    - \"https://www.algolia.com/doc/libraries/javascript/v5/methods/search/\"\r\n\n- id: nextjs-ssr-search\r\n  name: Next.js Server-Side Rendering\r\n  description: |\r\n    SSR integration for Next.js with react-instantsearch-nextjs package.\r\n\n    Use <InstantSearchNext> instead of <InstantSearch> for SSR.\r\n    Supports both Pages Router and App Router (experimental).\r\n\n    Key considerations:\r\n    - Set dynamic = 'force-dynamic' for fresh results\r\n    - Handle URL synchronization with routing prop\r\n    - Use getServerState for initial state\r\n\n  code_example: |\r\n    // app/search/page.tsx\r\n    import { InstantSearchNext } from 'react-instantsearch-nextjs';\r\n    import { searchClient, INDEX_NAME } from '@/lib/algolia';\r\n    import { SearchBox, Hits, RefinementList } from 'react-instantsearch';\r\n\n    // Force dynamic rendering for fresh search results\r\n    export const dynamic = 'force-dynamic';\r\n\n    export default function SearchPage() {\r\n      return (\r\n        <InstantSearchNext\r\n          searchClient={searchClient}\r\n          indexName={INDEX_NAME}\r\n          routing={{\r\n            router: {\r\n              cleanUrlOnDispose: false,\r\n            },\r\n          }}\r\n        >\r\n          <div className=\"flex gap-8\">\r\n            <aside className=\"w-64\">\r\n              <h3>Categories</h3>\r\n              <RefinementList attribute=\"category\" />\r\n              <h3>Brand</h3>\r\n              <RefinementList attribute=\"brand\" />\r\n            </aside>\r\n            <main className=\"flex-1\">\r\n              <SearchBox placeholder=\"Search products...\" />\r\n              <Hits hitComponent={ProductHit} />\r\n            </main>\r\n          </div>\r\n        </InstantSearchNext>\r\n      );\r\n    }\r\n\n    // For custom routing (URL synchronization)\r\n    import { history } from 'instantsearch.js/es/lib/routers';\r\n    import { simple } from 'instantsearch.js/es/lib/stateMappings';\r\n\n    <InstantSearchNext\r\n      searchClient={searchClient}\r\n      indexName={INDEX_NAME}\r\n      routing={{\r\n        router: history({\r\n          getLocation: () =>\r\n            typeof window === 'undefined'\r\n              ? new URL(url) as unknown as Location\r\n              : window.location,\r\n        }),\r\n        stateMapping: simple(),\r\n      }}\r\n    >\r\n      {/* widgets */}\r\n    </InstantSearchNext>\r\n\n  anti_patterns:\r\n    - pattern: \"Using InstantSearch component for Next.js SSR\"\r\n      why: \"Regular component doesn't support server-side rendering\"\r\n      fix: \"Use InstantSearchNext from react-instantsearch-nextjs\"\r\n\n    - pattern: \"Static rendering for search pages\"\r\n      why: \"Search results must be fresh for each request\"\r\n      fix: \"Set export const dynamic = 'force-dynamic'\"\r\n\n  references:\r\n    - \"https://www.npmjs.com/package/react-instantsearch-nextjs\"\r\n    - \"https://www.algolia.com/developers/code-exchange/instantsearch-and-next-js-starter\"\r\n\n- id: indexing-strategies\r\n  name: Data Synchronization and Indexing\r\n  description: |\r\n    Indexing strategies for keeping Algolia in sync with your data.\r\n\n    Three main approaches:\r\n    1. Full Reindexing - Replace entire index (expensive)\r\n    2. Full Record Updates - Replace individual records\r\n    3. Partial Updates - Update specific attributes only\r\n\n    Best practices:\r\n    - Batch records (ideal: 10MB, 1K-10K records per batch)\r\n    - Use incremental updates when possible\r\n    - partialUpdateObjects for attribute-only changes\r\n    - Avoid deleteBy (computationally expensive)\r\n\n  code_example: |\r\n    // lib/algolia-admin.ts (SERVER ONLY)\r\n    import algoliasearch from 'algoliasearch';\r\n\n    // Admin client - NEVER expose to frontend\r\n    const adminClient = algoliasearch(\r\n      process.env.ALGOLIA_APP_ID!,\r\n      process.env.ALGOLIA_ADMIN_KEY!  // Admin key for indexing\r\n    );\r\n\n    const index = adminClient.initIndex('products');\r\n\n    // Batch indexing (recommended approach)\r\n    export async function indexProducts(products: Product[]) {\r\n      const records = products.map((p) => ({\r\n        objectID: p.id,  // Required unique identifier\r\n        name: p.name,\r\n        description: p.description,\r\n        price: p.price,\r\n        category: p.category,\r\n        inStock: p.inventory > 0,\r\n        createdAt: p.createdAt.getTime(),  // Use timestamps for sorting\r\n      }));\r\n\n      // Batch in chunks of ~1000-5000 records\r\n      const BATCH_SIZE = 1000;\r\n      for (let i = 0; i < records.length; i += BATCH_SIZE) {\r\n        const batch = records.slice(i, i + BATCH_SIZE);\r\n        await index.saveObjects(batch);\r\n      }\r\n    }\r\n\n    // Partial update - update only specific fields\r\n    export async function updateProductPrice(productId: string, price: number) {\r\n      await index.partialUpdateObject({\r\n        objectID: productId,\r\n        price,\r\n        updatedAt: Date.now(),\r\n      });\r\n    }\r\n\n    // Partial update with operations\r\n    export async function incrementViewCount(productId: string) {\r\n      await index.partialUpdateObject({\r\n        objectID: productId,\r\n        viewCount: {\r\n          _operation: 'Increment',\r\n          value: 1,\r\n        },\r\n      });\r\n    }\r\n\n    // Delete records (prefer this over deleteBy)\r\n    export async function deleteProducts(productIds: string[]) {\r\n      await index.deleteObjects(productIds);\r\n    }\r\n\n    // Full reindex with zero-downtime (atomic swap)\r\n    export async function fullReindex(products: Product[]) {\r\n      const tempIndex = adminClient.initIndex('products_temp');\r\n\n      // Index to temp index\r\n      await tempIndex.saveObjects(\r\n        products.map((p) => ({\r\n          objectID: p.id,\r\n          ...p,\r\n        }))\r\n      );\r\n\n      // Copy settings from main index\r\n      await adminClient.copyIndex('products', 'products_temp', {\r\n        scope: ['settings', 'synonyms', 'rules'],\r\n      });\r\n\n      // Atomic swap\r\n      await adminClient.moveIndex('products_temp', 'products');\r\n    }\r\n\n  anti_patterns:\r\n    - pattern: \"Using deleteBy for bulk deletions\"\r\n      why: \"deleteBy is computationally expensive and rate limited\"\r\n      fix: \"Use deleteObjects with array of objectIDs\"\r\n\n    - pattern: \"Indexing one record at a time\"\r\n      why: \"Creates indexing queue, slows down process\"\r\n      fix: \"Batch records in groups of 1K-10K\"\r\n\n    - pattern: \"Full reindex for small changes\"\r\n      why: \"Wastes operations, slower than incremental\"\r\n      fix: \"Use partialUpdateObject for attribute changes\"\r\n\n  references:\r\n    - \"https://www.algolia.com/doc/guides/sending-and-managing-data/send-and-update-your-data/in-depth/the-different-synchronization-strategies\"\r\n    - \"https://www.algolia.com/blog/engineering/search-indexing-best-practices-for-top-performance-with-code-samples\"\r\n\n- id: api-key-security\r\n  name: API Key Security and Restrictions\r\n  description: |\r\n    Secure API key configuration for Algolia.\r\n\n    Key types:\r\n    - Admin API Key: Full control (indexing, settings, deletion)\r\n    - Search-Only API Key: Safe for frontend\r\n    - Secured API Keys: Generated from base key with restrictions\r\n\n    Restrictions available:\r\n    - Indices: Limit accessible indices\r\n    - Rate limit: Limit API calls per hour per IP\r\n    - Validity: Set expiration time\r\n    - HTTP referrers: Restrict to specific URLs\r\n    - Query parameters: Enforce search parameters\r\n\n  code_example: |\r\n    // NEVER do this - admin key in frontend\r\n    // const client = algoliasearch(appId, ADMIN_KEY);  // WRONG!\r\n\n    // Correct: Use search-only key in frontend\r\n    const searchClient = algoliasearch(\r\n      process.env.NEXT_PUBLIC_ALGOLIA_APP_ID!,\r\n      process.env.NEXT_PUBLIC_ALGOLIA_SEARCH_KEY!\r\n    );\r\n\n    // Server-side: Generate secured API key\r\n    // lib/algolia-secured-key.ts\r\n    import algoliasearch from 'algoliasearch';\r\n\n    const adminClient = algoliasearch(\r\n      process.env.ALGOLIA_APP_ID!,\r\n      process.env.ALGOLIA_ADMIN_KEY!\r\n    );\r\n\n    // Generate user-specific secured key\r\n    export function generateSecuredKey(userId: string) {\r\n      const searchKey = process.env.ALGOLIA_SEARCH_KEY!;\r\n\n      return adminClient.generateSecuredApiKey(searchKey, {\r\n        // User can only see their own data\r\n        filters: `userId:${userId}`,\r\n        // Key expires in 1 hour\r\n        validUntil: Math.floor(Date.now() / 1000) + 3600,\r\n        // Restrict to specific index\r\n        restrictIndices: ['user_documents'],\r\n      });\r\n    }\r\n\n    // Rate-limited key for public APIs\r\n    export async function createRateLimitedKey() {\r\n      const { key } = await adminClient.addApiKey({\r\n        acl: ['search'],\r\n        indexes: ['products'],\r\n        description: 'Public search with rate limit',\r\n        maxQueriesPerIPPerHour: 1000,\r\n        referers: ['https://mysite.com/*'],\r\n        validity: 0,  // Never expires\r\n      });\r\n\n      return key;\r\n    }\r\n\n    // API endpoint to get user's secured key\r\n    // app/api/search-key/route.ts\r\n    import { auth } from '@/lib/auth';\r\n    import { generateSecuredKey } from '@/lib/algolia-secured-key';\r\n\n    export async function GET() {\r\n      const session = await auth();\r\n      if (!session?.user) {\r\n        return Response.json({ error: 'Unauthorized' }, { status: 401 });\r\n      }\r\n\n      const securedKey = generateSecuredKey(session.user.id);\r\n\n      return Response.json({ key: securedKey });\r\n    }\r\n\n  anti_patterns:\r\n    - pattern: \"Hardcoding Admin API key in client code\"\r\n      why: \"Exposes full index control to attackers\"\r\n      fix: \"Use search-only key with restrictions\"\r\n\n    - pattern: \"Using same key for all users\"\r\n      why: \"Can't restrict data access per user\"\r\n      fix: \"Generate secured API keys with user filters\"\r\n\n    - pattern: \"No rate limiting on public search\"\r\n      why: \"Bots can exhaust your search quota\"\r\n      fix: \"Set maxQueriesPerIPPerHour on API key\"\r\n\n  references:\r\n    - \"https://www.algolia.com/doc/guides/security/api-keys\"\r\n    - \"https://support.algolia.com/hc/en-us/articles/14339249272977-What-are-the-best-practices-to-manage-Algolia-API-keys-in-my-code-and-protect-them\"\r\n\n- id: custom-ranking-relevance\r\n  name: Custom Ranking and Relevance Tuning\r\n  description: |\r\n    Configure searchable attributes and custom ranking for relevance.\r\n\n    Searchable attributes (order matters):\r\n    1. Most important fields first (title, name)\r\n    2. Secondary fields next (description, tags)\r\n    3. Exclude non-searchable fields (image_url, id)\r\n\n    Custom ranking:\r\n    - Add business metrics (popularity, rating, date)\r\n    - Use desc() for descending, asc() for ascending\r\n\n  code_example: |\r\n    // scripts/configure-index.ts\r\n    import algoliasearch from 'algoliasearch';\r\n\n    const adminClient = algoliasearch(\r\n      process.env.ALGOLIA_APP_ID!,\r\n      process.env.ALGOLIA_ADMIN_KEY!\r\n    );\r\n\n    const index = adminClient.initIndex('products');\r\n\n    async function configureIndex() {\r\n      await index.setSettings({\r\n        // Searchable attributes in order of importance\r\n        searchableAttributes: [\r\n          'name',              // Most important\r\n          'brand',\r\n          'category',\r\n          'description',       // Least important\r\n        ],\r\n\n        // Attributes for faceting/filtering\r\n        attributesForFaceting: [\r\n          'category',\r\n          'brand',\r\n          'filterOnly(inStock)',  // Filter only, not displayed\r\n          'searchable(tags)',     // Searchable facet\r\n        ],\r\n\n        // Custom ranking (after text relevance)\r\n        customRanking: [\r\n          'desc(popularity)',     // Most popular first\r\n          'desc(rating)',         // Then by rating\r\n          'desc(createdAt)',      // Then by recency\r\n        ],\r\n\n        // Typo tolerance\r\n        typoTolerance: true,\r\n        minWordSizefor1Typo: 4,\r\n        minWordSizefor2Typos: 8,\r\n\n        // Query settings\r\n        queryLanguages: ['en'],\r\n        removeStopWords: ['en'],\r\n\n        // Highlighting\r\n        attributesToHighlight: ['name', 'description'],\r\n        highlightPreTag: '<mark>',\r\n        highlightPostTag: '</mark>',\r\n\n        // Pagination\r\n        hitsPerPage: 20,\r\n        paginationLimitedTo: 1000,\r\n\n        // Distinct (deduplication)\r\n        attributeForDistinct: 'productFamily',\r\n        distinct: true,\r\n      });\r\n\n      // Add synonyms\r\n      await index.saveSynonyms([\r\n        {\r\n          objectID: 'phone-mobile',\r\n          type: 'synonym',\r\n          synonyms: ['phone', 'mobile', 'cell', 'smartphone'],\r\n        },\r\n        {\r\n          objectID: 'laptop-notebook',\r\n          type: 'oneWaySynonym',\r\n          input: 'laptop',\r\n          synonyms: ['notebook', 'portable computer'],\r\n        },\r\n      ]);\r\n\n      // Add rules (query-based customization)\r\n      await index.saveRules([\r\n        {\r\n          objectID: 'boost-sale-items',\r\n          condition: {\r\n            anchoring: 'contains',\r\n            pattern: 'sale',\r\n          },\r\n          consequence: {\r\n            params: {\r\n              filters: 'onSale:true',\r\n              optionalFilters: ['featured:true'],\r\n            },\r\n          },\r\n        },\r\n      ]);\r\n\n      console.log('Index configured successfully');\r\n    }\r\n\n    configureIndex();\r\n\n  anti_patterns:\r\n    - pattern: \"Searching all attributes equally\"\r\n      why: \"Reduces relevance, matches in descriptions rank same as titles\"\r\n      fix: \"Order searchableAttributes by importance\"\r\n\n    - pattern: \"No custom ranking\"\r\n      why: \"Relies only on text matching, ignores business value\"\r\n      fix: \"Add popularity, rating, or recency to customRanking\"\r\n\n    - pattern: \"Indexing raw dates as strings\"\r\n      why: \"Can't sort by date correctly\"\r\n      fix: \"Use timestamps (getTime()) for date sorting\"\r\n\n  references:\r\n    - \"https://www.algolia.com/doc/guides/managing-results/relevance-overview\"\r\n    - \"https://www.algolia.com/doc/guides/managing-results/must-do/custom-ranking\"\r\n\n- id: faceted-search\r\n  name: Faceted Search and Filtering\r\n  description: |\r\n    Implement faceted navigation with refinement lists, range sliders,\r\n    and hierarchical menus.\r\n\n    Widget types:\r\n    - RefinementList: Multi-select checkboxes\r\n    - Menu: Single-select list\r\n    - HierarchicalMenu: Nested categories\r\n    - RangeInput/RangeSlider: Numeric ranges\r\n    - ToggleRefinement: Boolean filters\r\n\n  code_example: |\r\n    'use client';\r\n    import {\r\n      InstantSearch,\r\n      SearchBox,\r\n      Hits,\r\n      RefinementList,\r\n      HierarchicalMenu,\r\n      RangeInput,\r\n      ToggleRefinement,\r\n      ClearRefinements,\r\n      CurrentRefinements,\r\n      Stats,\r\n      SortBy,\r\n    } from 'react-instantsearch';\r\n    import { searchClient, INDEX_NAME } from '@/lib/algolia';\r\n\n    export function ProductSearch() {\r\n      return (\r\n        <InstantSearch searchClient={searchClient} indexName={INDEX_NAME}>\r\n          <div className=\"flex gap-8\">\r\n            {/* Filters Sidebar */}\r\n            <aside className=\"w-64 space-y-6\">\r\n              <ClearRefinements />\r\n              <CurrentRefinements />\r\n\n              {/* Category hierarchy */}\r\n              <div>\r\n                <h3 className=\"font-semibold mb-2\">Categories</h3>\r\n                <HierarchicalMenu\r\n                  attributes={[\r\n                    'categories.lvl0',\r\n                    'categories.lvl1',\r\n                    'categories.lvl2',\r\n                  ]}\r\n                  limit={10}\r\n                  showMore\r\n                />\r\n              </div>\r\n\n              {/* Brand filter */}\r\n              <div>\r\n                <h3 className=\"font-semibold mb-2\">Brand</h3>\r\n                <RefinementList\r\n                  attribute=\"brand\"\r\n                  searchable\r\n                  searchablePlaceholder=\"Search brands...\"\r\n                  showMore\r\n                  limit={5}\r\n                  showMoreLimit={20}\r\n                />\r\n              </div>\r\n\n              {/* Price range */}\r\n              <div>\r\n                <h3 className=\"font-semibold mb-2\">Price</h3>\r\n                <RangeInput\r\n                  attribute=\"price\"\r\n                  precision={0}\r\n                  classNames={{\r\n                    input: 'w-20 px-2 py-1 border rounded',\r\n                  }}\r\n                />\r\n              </div>\r\n\n              {/* In stock toggle */}\r\n              <ToggleRefinement\r\n                attribute=\"inStock\"\r\n                label=\"In Stock Only\"\r\n                on={true}\r\n              />\r\n\n              {/* Rating filter */}\r\n              <div>\r\n                <h3 className=\"font-semibold mb-2\">Rating</h3>\r\n                <RefinementList\r\n                  attribute=\"rating\"\r\n                  transformItems={(items) =>\r\n                    items.map((item) => ({\r\n                      ...item,\r\n                      label: '★'.repeat(Number(item.label)),\r\n                    }))\r\n                  }\r\n                />\r\n              </div>\r\n            </aside>\r\n\n            {/* Results */}\r\n            <main className=\"flex-1\">\r\n              <div className=\"flex justify-between items-center mb-4\">\r\n                <SearchBox placeholder=\"Search products...\" />\r\n                <SortBy\r\n                  items={[\r\n                    { label: 'Relevance', value: 'products' },\r\n                    { label: 'Price (Low to High)', value: 'products_price_asc' },\r\n                    { label: 'Price (High to Low)', value: 'products_price_desc' },\r\n                    { label: 'Rating', value: 'products_rating_desc' },\r\n                  ]}\r\n                />\r\n              </div>\r\n              <Stats />\r\n              <Hits hitComponent={ProductHit} />\r\n            </main>\r\n          </div>\r\n        </InstantSearch>\r\n      );\r\n    }\r\n\n    // For sorting, create replica indices\r\n    // products_price_asc: customRanking: ['asc(price)']\r\n    // products_price_desc: customRanking: ['desc(price)']\r\n    // products_rating_desc: customRanking: ['desc(rating)']\r\n\n  anti_patterns:\r\n    - pattern: \"Faceting on non-faceted attributes\"\r\n      why: \"Must declare attributesForFaceting in settings\"\r\n      fix: \"Add attributes to attributesForFaceting array\"\r\n\n    - pattern: \"Not using filterOnly() for hidden filters\"\r\n      why: \"Wastes facet computation on non-displayed attributes\"\r\n      fix: \"Use filterOnly(attribute) for filters you won't show\"\r\n\n  references:\r\n    - \"https://www.algolia.com/doc/guides/managing-results/refine-results/faceting\"\r\n    - \"https://www.algolia.com/doc/api-reference/widgets/refinement-list/react\"\r\n\n- id: autocomplete-suggestions\r\n  name: Query Suggestions and Autocomplete\r\n  description: |\r\n    Implement autocomplete with query suggestions and instant results.\r\n\n    Uses @algolia/autocomplete-js for standalone autocomplete or\r\n    integrate with InstantSearch using SearchBox.\r\n\n    Query Suggestions require a separate index generated by Algolia.\r\n\n  code_example: |\r\n    // Standalone Autocomplete\r\n    // components/Autocomplete.tsx\r\n    'use client';\r\n    import { autocomplete, getAlgoliaResults } from '@algolia/autocomplete-js';\r\n    import algoliasearch from 'algoliasearch/lite';\r\n    import { useEffect, useRef } from 'react';\r\n    import '@algolia/autocomplete-theme-classic';\r\n\n    const searchClient = algoliasearch(\r\n      process.env.NEXT_PUBLIC_ALGOLIA_APP_ID!,\r\n      process.env.NEXT_PUBLIC_ALGOLIA_SEARCH_KEY!\r\n    );\r\n\n    export function Autocomplete() {\r\n      const containerRef = useRef<HTMLDivElement>(null);\r\n\n      useEffect(() => {\r\n        if (!containerRef.current) return;\r\n\n        const search = autocomplete({\r\n          container: containerRef.current,\r\n          placeholder: 'Search for products',\r\n          openOnFocus: true,\r\n          getSources({ query }) {\r\n            if (!query) return [];\r\n\n            return [\r\n              // Query suggestions\r\n              {\r\n                sourceId: 'suggestions',\r\n                getItems() {\r\n                  return getAlgoliaResults({\r\n                    searchClient,\r\n                    queries: [\r\n                      {\r\n                        indexName: 'products_query_suggestions',\r\n                        query,\r\n                        params: { hitsPerPage: 5 },\r\n                      },\r\n                    ],\r\n                  });\r\n                },\r\n                templates: {\r\n                  header() {\r\n                    return 'Suggestions';\r\n                  },\r\n                  item({ item, html }) {\r\n                    return html`<span>${item.query}</span>`;\r\n                  },\r\n                },\r\n              },\r\n              // Instant results\r\n              {\r\n                sourceId: 'products',\r\n                getItems() {\r\n                  return getAlgoliaResults({\r\n                    searchClient,\r\n                    queries: [\r\n                      {\r\n                        indexName: 'products',\r\n                        query,\r\n                        params: { hitsPerPage: 8 },\r\n                      },\r\n                    ],\r\n                  });\r\n                },\r\n                templates: {\r\n                  header() {\r\n                    return 'Products';\r\n                  },\r\n                  item({ item, html }) {\r\n                    return html`\r\n                      <a href=\"/products/${item.objectID}\">\r\n                        <img src=\"${item.image}\" alt=\"${item.name}\" />\r\n                        <span>${item.name}</span>\r\n                        <span>$${item.price}</span>\r\n                      </a>\r\n                    `;\r\n                  },\r\n                },\r\n                onSelect({ item, setQuery, refresh }) {\r\n                  // Navigate on selection\r\n                  window.location.href = `/products/${item.objectID}`;\r\n                },\r\n              },\r\n            ];\r\n          },\r\n        });\r\n\n        return () => search.destroy();\r\n      }, []);\r\n\n      return <div ref={containerRef} />;\r\n    }\r\n\n    // Combined with InstantSearch\r\n    import { connectSearchBox } from 'react-instantsearch';\r\n    import { autocomplete } from '@algolia/autocomplete-js';\r\n\n    // Or use built-in Autocomplete widget\r\n    import { Autocomplete as AlgoliaAutocomplete } from 'react-instantsearch';\r\n\n    export function SearchWithAutocomplete() {\r\n      return (\r\n        <InstantSearch searchClient={searchClient} indexName=\"products\">\r\n          <AlgoliaAutocomplete\r\n            placeholder=\"Search products...\"\r\n            detachedMediaQuery=\"(max-width: 768px)\"\r\n          />\r\n          <Hits hitComponent={ProductHit} />\r\n        </InstantSearch>\r\n      );\r\n    }\r\n\n  anti_patterns:\r\n    - pattern: \"Creating autocomplete without debouncing\"\r\n      why: \"Every keystroke triggers search, wastes operations\"\r\n      fix: \"Algolia autocomplete handles debouncing automatically\"\r\n\n    - pattern: \"Not using Query Suggestions index\"\r\n      why: \"Missing search analytics for popular queries\"\r\n      fix: \"Enable Query Suggestions in Algolia dashboard\"\r\n\n  references:\r\n    - \"https://www.algolia.com/doc/ui-libraries/autocomplete/introduction/what-is-autocomplete\"\r\n    - \"https://www.algolia.com/doc/guides/building-search-ui/ui-and-ux-patterns/query-suggestions/how-to/optimizing-query-suggestions-relevance/js\"",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "adding search to",
          "algolia",
          "instantsearch",
          "search api",
          "search functionality",
          "typeahead",
          "autocomplete search",
          "faceted search",
          "search index",
          "search as you type"
        ],
        "tags": [
          "algolia",
          "search",
          "instantsearch",
          "indexing",
          "relevance",
          "faceted-search",
          "autocomplete"
        ],
        "pairs_with": [],
        "requires": [],
        "category": "integrations"
      },
      {
        "id": "salesforce-development",
        "name": "Salesforce Development",
        "version": "1.0.0",
        "layer": 1,
        "description": "Queries in loops hit the 100 SOQL limit instantly with bulk data",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "salesforce",
          "sfdc",
          "apex",
          "lwc",
          "lightning web components",
          "sfdx",
          "scratch org",
          "visualforce",
          "soql",
          "governor limits",
          "connected app"
        ],
        "tags": [
          "salesforce",
          "lwc",
          "apex",
          "crm",
          "platform",
          "sfdx",
          "lightning"
        ],
        "pairs_with": [],
        "requires": [],
        "category": "integrations"
      },
      {
        "id": "segment-cdp",
        "name": "Segment CDP",
        "version": "1.0.0",
        "layer": 1,
        "description": "Event names with dynamic values pollute tracking",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "segment",
          "analytics.js",
          "customer data platform",
          "cdp",
          "tracking plan",
          "event tracking",
          "identify track page",
          "data routing"
        ],
        "tags": [
          "segment",
          "cdp",
          "analytics",
          "tracking",
          "data-pipeline",
          "customer-data"
        ],
        "pairs_with": [],
        "requires": [],
        "category": "integrations"
      },
      {
        "id": "shopify-apps",
        "name": "Shopify Apps",
        "version": "1.0.0",
        "layer": 1,
        "description": "Modern Shopify app template with React Router",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "shopify app",
          "shopify",
          "embedded app",
          "polaris",
          "app bridge",
          "shopify webhook"
        ],
        "tags": "[shopify, ecommerce, apps, embedded-apps, polaris, app-bridge]",
        "pairs_with": [],
        "requires": [],
        "category": "integrations"
      },
      {
        "id": "twilio-communications",
        "name": "SMS Sending Pattern",
        "version": "1.0.0",
        "layer": 1,
        "description": "Basic pattern for sending SMS messages with Twilio.\r\n    Handles the fundamentals: phone number formatting, message delivery,\r\n    and delivery status callbacks.\r\n\n    Key considerations:\r\n    - Phone numbers must be in E.164 format (+1234567890)\r\n    - Default rate limit: 80 messages per second (MPS)\r\n    - Messages over 160 characters are split (and cost more)\r\n    - Carrier filtering can block messages (especially to US numbers)\r\n  when_to_use:\r\n    - \"Sending notifications to users\"\r\n    - \"Transactional messages (order confirmations, shipping)\"\r\n    - \"Alerts and reminders\"\r\n  implementation: |\r\n    from twilio.rest import Client\r\n    from twilio.base.exceptions import TwilioRestException\r\n    import os\r\n    import re\r\n\n    class TwilioSMS:\r\n        \"\"\"\r\n        SMS sending with proper error handling and validation.\r\n        \"\"\"\r\n\n        def __init__(self):\r\n            self.client = Client(\r\n                os.environ[\"TWILIO_ACCOUNT_SID\"],\r\n                os.environ[\"TWILIO_AUTH_TOKEN\"]\r\n            )\r\n            self.from_number = os.environ[\"TWILIO_PHONE_NUMBER\"]\r\n\n        def validate_e164(self, phone: str) -> bool:\r\n            \"\"\"Validate phone number is in E.164 format.\"\"\"\r\n            pattern = r'^\\+[1-9]\\d{1,14}$'\r\n            return bool(re.match(pattern, phone))\r\n\n        def send_sms(\r\n            self,\r\n            to: str,\r\n            body: str,\r\n            status_callback: str = None\r\n        ) -> dict:\r\n            \"\"\"\r\n            Send an SMS message.\r\n\n            Args:\r\n                to: Recipient phone number in E.164 format\r\n                body: Message text (160 chars = 1 segment)\r\n                status_callback: URL for delivery status webhooks\r\n\n            Returns:\r\n                Message SID and status\r\n            \"\"\"\r\n\n            if not self.validate_e164(to):\r\n                return {\r\n                    \"success\": False,\r\n                    \"error\": \"Phone number must be in E.164 format (+1234567890)\"\r\n                }\r\n\n\n            segment_count = (len(body) + 159) // 160\r\n            if segment_count > 1:\r\n                print(f\"Warning: Message will be sent as {segment_count} segments\")\r\n\n            try:\r\n                message = self.client.messages.create(\r\n                    to=to,\r\n                    from_=self.from_number,\r\n                    body=body,\r\n                    status_callback=status_callback\r\n                )\r\n\n                return {\r\n                    \"success\": True,\r\n                    \"message_sid\": message.sid,\r\n                    \"status\": message.status,\r\n                    \"segments\": segment_count\r\n                }\r\n\n            except TwilioRestException as e:\r\n                return self._handle_error(e)\r\n\n        def _handle_error(self, error: TwilioRestException) -> dict:\r\n            \"\"\"Handle Twilio-specific errors.\"\"\"\r\n            error_handlers = {\r\n                21610: \"Recipient has opted out. They must reply START.\",\r\n                21614: \"Invalid 'To' phone number format.\",\r\n                21211: \"'From' phone number is not valid.\",\r\n                30003: \"Phone is unreachable (off, airplane mode, no signal).\",\r\n                30005: \"Unknown destination (invalid number or landline).\",\r\n                30006: \"Landline or unreachable carrier.\",\r\n                30429: \"Rate limit exceeded. Implement exponential backoff.\",\r\n            }\r\n\n            return {\r\n                \"success\": False,\r\n                \"error_code\": error.code,\r\n                \"error\": error_handlers.get(error.code, error.msg),\r\n                \"details\": str(error)\r\n            }\r\n\n\n    sms = TwilioSMS()\r\n    result = sms.send_sms(\r\n        to=\"+14155551234\",\r\n        body=\"Your order #1234 has shipped!\",\r\n        status_callback=\"https://your-app.com/webhooks/twilio/status\"\r\n    )\r\n  anti_patterns:\r\n    - \"Not validating E.164 format before sending\"\r\n    - \"Hardcoding Twilio credentials in code\"\r\n    - \"Ignoring delivery status callbacks\"\r\n    - \"Not handling the opted-out (21610) error\"\r\n\n- id: twilio-verify-pattern\r\n  name: Twilio Verify Pattern (2FA/OTP)\r\n  description: |\r\n    Use Twilio Verify for phone number verification and 2FA.\r\n    Handles code generation, delivery, rate limiting, and fraud prevention.\r\n\n    Key benefits over DIY OTP:\r\n    - Twilio manages code generation and expiration\r\n    - Built-in fraud prevention (saved customers $82M+ blocking 747M attempts)\r\n    - Handles rate limiting automatically\r\n    - Multi-channel: SMS, Voice, Email, Push, WhatsApp\r\n\n    Google found SMS 2FA blocks \"100% of automated bots, 96% of bulk\r\n    phishing attacks, and 76% of targeted attacks.\"\r\n  when_to_use:\r\n    - \"User phone number verification at signup\"\r\n    - \"Two-factor authentication (2FA)\"\r\n    - \"Password reset verification\"\r\n    - \"High-value transaction confirmation\"\r\n  implementation: |\r\n    from twilio.rest import Client\r\n    from twilio.base.exceptions import TwilioRestException\r\n    import os\r\n    from enum import Enum\r\n    from typing import Optional\r\n\n    class VerifyChannel(Enum):\r\n        SMS = \"sms\"\r\n        CALL = \"call\"\r\n        EMAIL = \"email\"\r\n        WHATSAPP = \"whatsapp\"\r\n\n    class TwilioVerify:\r\n        \"\"\"\r\n        Phone verification with Twilio Verify.\r\n        Never store OTP codes - Twilio handles it.\r\n        \"\"\"\r\n\n        def __init__(self, verify_service_sid: str = None):\r\n            self.client = Client(\r\n                os.environ[\"TWILIO_ACCOUNT_SID\"],\r\n                os.environ[\"TWILIO_AUTH_TOKEN\"]\r\n            )\r\n\n            self.service_sid = verify_service_sid or os.environ[\"TWILIO_VERIFY_SID\"]\r\n\n        def send_verification(\r\n            self,\r\n            to: str,\r\n            channel: VerifyChannel = VerifyChannel.SMS,\r\n            locale: str = \"en\"\r\n        ) -> dict:\r\n            \"\"\"\r\n            Send verification code to phone/email.\r\n\n            Args:\r\n                to: Phone number (E.164) or email\r\n                channel: SMS, call, email, or whatsapp\r\n                locale: Language code for message\r\n\n            Returns:\r\n                Verification status\r\n            \"\"\"\r\n            try:\r\n                verification = self.client.verify \\\r\n                    .v2 \\\r\n                    .services(self.service_sid) \\\r\n                    .verifications \\\r\n                    .create(\r\n                        to=to,\r\n                        channel=channel.value,\r\n                        locale=locale\r\n                    )\r\n\n                return {\r\n                    \"success\": True,\r\n                    \"status\": verification.status,  # \"pending\"\r\n                    \"channel\": channel.value,\r\n                    \"valid\": verification.valid\r\n                }\r\n\n            except TwilioRestException as e:\r\n                return self._handle_verify_error(e)\r\n\n        def check_verification(self, to: str, code: str) -> dict:\r\n            \"\"\"\r\n            Check if verification code is correct.\r\n\n            Args:\r\n                to: Phone number or email that received code\r\n                code: The code entered by user\r\n\n            Returns:\r\n                Verification result\r\n            \"\"\"\r\n            try:\r\n                check = self.client.verify \\\r\n                    .v2 \\\r\n                    .services(self.service_sid) \\\r\n                    .verification_checks \\\r\n                    .create(\r\n                        to=to,\r\n                        code=code\r\n                    )\r\n\n                return {\r\n                    \"success\": True,\r\n                    \"valid\": check.status == \"approved\",\r\n                    \"status\": check.status  # \"approved\" or \"pending\"\r\n                }\r\n\n            except TwilioRestException as e:\r\n\n                return {\r\n                    \"success\": False,\r\n                    \"valid\": False,\r\n                    \"error\": str(e)\r\n                }\r\n\n        def _handle_verify_error(self, error: TwilioRestException) -> dict:\r\n            \"\"\"Handle Verify-specific errors.\"\"\"\r\n            error_handlers = {\r\n                60200: \"Invalid phone number format\",\r\n                60203: \"Max send attempts reached for this number\",\r\n                60205: \"Service not found - check VERIFY_SID\",\r\n                60223: \"Failed to create verification - carrier rejected\",\r\n            }\r\n\n            return {\r\n                \"success\": False,\r\n                \"error_code\": error.code,\r\n                \"error\": error_handlers.get(error.code, error.msg)\r\n            }\r\n\n\n    verify = TwilioVerify()\r\n\n\n    result = verify.send_verification(\"+14155551234\", VerifyChannel.SMS)\r\n    if result[\"success\"]:\r\n        print(\"Code sent! Check your phone.\")\r\n\n\n    code = \"123456\"  # From user input\r\n    check = verify.check_verification(\"+14155551234\", code)\r\n\n    if check[\"valid\"]:\r\n        print(\"Phone verified! Create account.\")\r\n    else:\r\n        print(\"Invalid code. Try again.\")\r\n\n\n    async def verify_with_fallback(phone: str, max_attempts: int = 3):\r\n        \"\"\"Verify with voice fallback if SMS fails.\"\"\"\r\n        for attempt in range(max_attempts):\r\n            channel = VerifyChannel.SMS if attempt == 0 else VerifyChannel.CALL\r\n            result = verify.send_verification(phone, channel)\r\n\n            if result[\"success\"]:\r\n                return result\r\n\n\n            if channel == VerifyChannel.SMS:\r\n                await asyncio.sleep(30)\r\n                continue\r\n\n        return {\"success\": False, \"error\": \"All verification attempts failed\"}\r\n  anti_patterns:\r\n    - \"Storing OTP codes in your database (Twilio handles this)\"\r\n    - \"Not implementing rate limiting on your verify endpoint\"\r\n    - \"Using same-code retries (let Verify generate new codes)\"\r\n    - \"No fallback channel when SMS fails\"\r\n\n- id: twiml-ivr-pattern\r\n  name: TwiML IVR Pattern\r\n  description: |\r\n    Build Interactive Voice Response (IVR) systems using TwiML.\r\n    TwiML (Twilio Markup Language) is XML that tells Twilio what to do\r\n    when receiving calls.\r\n\n    Core TwiML verbs:\r\n    - <Say>: Text-to-speech\r\n    - <Play>: Play audio file\r\n    - <Gather>: Collect keypad/speech input\r\n    - <Dial>: Connect to another number\r\n    - <Record>: Record caller's voice\r\n    - <Redirect>: Move to another TwiML endpoint\r\n\n    Key insight: Twilio makes HTTP request to your webhook, you return\r\n    TwiML, Twilio executes it. Stateless, so use URL params or sessions.\r\n  when_to_use:\r\n    - \"Phone menu systems (press 1 for sales...)\"\r\n    - \"Automated customer support\"\r\n    - \"Appointment reminders with confirmation\"\r\n    - \"Voicemail systems\"\r\n  implementation: |\r\n    from flask import Flask, request, Response\r\n    from twilio.twiml.voice_response import VoiceResponse, Gather\r\n    from twilio.request_validator import RequestValidator\r\n    import os\r\n\n    app = Flask(__name__)\r\n\n    def validate_twilio_request(f):\r\n        \"\"\"Decorator to validate requests are from Twilio.\"\"\"\r\n        def wrapper(*args, **kwargs):\r\n            validator = RequestValidator(os.environ[\"TWILIO_AUTH_TOKEN\"])\r\n\n\n            url = request.url\r\n            params = request.form.to_dict()\r\n            signature = request.headers.get(\"X-Twilio-Signature\", \"\")\r\n\n            if not validator.validate(url, params, signature):\r\n                return \"Invalid request\", 403\r\n\n            return f(*args, **kwargs)\r\n        wrapper.__name__ = f.__name__\r\n        return wrapper\r\n\n    @app.route(\"/voice/incoming\", methods=[\"POST\"])\r\n    @validate_twilio_request\r\n    def incoming_call():\r\n        \"\"\"Handle incoming call with IVR menu.\"\"\"\r\n        response = VoiceResponse()\r\n\n\n        gather = Gather(\r\n            num_digits=1,\r\n            action=\"/voice/menu-selection\",\r\n            method=\"POST\",\r\n            timeout=5\r\n        )\r\n        gather.say(\r\n            \"Welcome to Acme Corp. \"\r\n            \"Press 1 for sales. \"\r\n            \"Press 2 for support. \"\r\n            \"Press 3 to leave a message.\"\r\n        )\r\n        response.append(gather)\r\n\n\n        response.redirect(\"/voice/incoming\")\r\n\n        return Response(str(response), mimetype=\"text/xml\")\r\n\n    @app.route(\"/voice/menu-selection\", methods=[\"POST\"])\r\n    @validate_twilio_request\r\n    def menu_selection():\r\n        \"\"\"Route based on menu selection.\"\"\"\r\n        response = VoiceResponse()\r\n        digit = request.form.get(\"Digits\", \"\")\r\n\n        if digit == \"1\":\r\n\n            response.say(\"Connecting you to sales.\")\r\n            response.dial(os.environ[\"SALES_PHONE\"])\r\n\n        elif digit == \"2\":\r\n\n            response.say(\"Connecting you to support.\")\r\n            response.dial(os.environ[\"SUPPORT_PHONE\"])\r\n\n        elif digit == \"3\":\r\n\n            response.say(\"Please leave a message after the beep.\")\r\n            response.record(\r\n                action=\"/voice/voicemail-saved\",\r\n                max_length=120,\r\n                transcribe=True,\r\n                transcribe_callback=\"/voice/transcription\"\r\n            )\r\n\n        else:\r\n            response.say(\"Invalid selection.\")\r\n            response.redirect(\"/voice/incoming\")\r\n\n        return Response(str(response), mimetype=\"text/xml\")\r\n\n    @app.route(\"/voice/voicemail-saved\", methods=[\"POST\"])\r\n    @validate_twilio_request\r\n    def voicemail_saved():\r\n        \"\"\"Handle saved voicemail.\"\"\"\r\n        response = VoiceResponse()\r\n\n        recording_url = request.form.get(\"RecordingUrl\")\r\n        recording_sid = request.form.get(\"RecordingSid\")\r\n\n\n        print(f\"Voicemail saved: {recording_url}\")\r\n\n        response.say(\"Thank you. Goodbye.\")\r\n        response.hangup()\r\n\n        return Response(str(response), mimetype=\"text/xml\")\r\n\n    @app.route(\"/voice/transcription\", methods=[\"POST\"])\r\n    @validate_twilio_request\r\n    def transcription_callback():\r\n        \"\"\"Handle voicemail transcription.\"\"\"\r\n        transcription = request.form.get(\"TranscriptionText\")\r\n        recording_sid = request.form.get(\"RecordingSid\")\r\n\n\n        print(f\"Transcription: {transcription}\")\r\n\n        return \"\", 200\r\n\n\n    from twilio.rest import Client\r\n\n    def make_outbound_call(to: str, message: str):\r\n        \"\"\"Make outbound call with custom TwiML.\"\"\"\r\n        client = Client(\r\n            os.environ[\"TWILIO_ACCOUNT_SID\"],\r\n            os.environ[\"TWILIO_AUTH_TOKEN\"]\r\n        )\r\n\n\n        call = client.calls.create(\r\n            to=to,\r\n            from_=os.environ[\"TWILIO_PHONE_NUMBER\"],\r\n            url=\"https://your-app.com/voice/outbound-message\",\r\n            status_callback=\"https://your-app.com/voice/status\"\r\n        )\r\n\n        return call.sid\r\n\n    if __name__ == \"__main__\":\r\n        app.run(debug=True)\r\n  anti_patterns:\r\n    - \"Not validating X-Twilio-Signature (security risk)\"\r\n    - \"Returning non-XML responses to Twilio\"\r\n    - \"Not handling timeout/no-input cases\"\r\n    - \"Hardcoding phone numbers in TwiML\"\r\n\n- id: whatsapp-business-pattern\r\n  name: WhatsApp Business API Pattern\r\n  description: |\r\n    Send and receive WhatsApp messages via Twilio API.\r\n    Uses the same Twilio Messages API as SMS with minor changes.\r\n\n    Key WhatsApp rules:\r\n    - 24-hour session window: Can only reply within 24 hours of user message\r\n    - Template messages: Pre-approved templates for outside session window\r\n    - Opt-in required: Users must explicitly consent to receive messages\r\n    - Rate limit: 80 MPS default (up to 400 with approval)\r\n    - Character limits: Non-template 1024 chars, templates ~550 chars\r\n  when_to_use:\r\n    - \"Customer support with rich media\"\r\n    - \"Order notifications with buttons\"\r\n    - \"Marketing messages (with templates)\"\r\n    - \"Interactive flows (booking, surveys)\"\r\n  implementation: |\r\n    from twilio.rest import Client\r\n    from twilio.base.exceptions import TwilioRestException\r\n    import os\r\n    from datetime import datetime, timedelta\r\n    from typing import Optional\r\n\n    class TwilioWhatsApp:\r\n        \"\"\"\r\n        WhatsApp Business API via Twilio.\r\n        Handles session windows and template messages.\r\n        \"\"\"\r\n\n        def __init__(self):\r\n            self.client = Client(\r\n                os.environ[\"TWILIO_ACCOUNT_SID\"],\r\n                os.environ[\"TWILIO_AUTH_TOKEN\"]\r\n            )\r\n\n            self.from_number = os.environ[\"TWILIO_WHATSAPP_NUMBER\"]\r\n\n        def send_message(\r\n            self,\r\n            to: str,\r\n            body: str,\r\n            media_url: Optional[str] = None\r\n        ) -> dict:\r\n            \"\"\"\r\n            Send WhatsApp message within 24-hour session.\r\n\n            Args:\r\n                to: Recipient number (E.164, without whatsapp: prefix)\r\n                body: Message text (max 1024 chars for non-template)\r\n                media_url: Optional image/document URL\r\n\n            Returns:\r\n                Message result\r\n            \"\"\"\r\n\n            to_whatsapp = f\"whatsapp:{to}\"\r\n            from_whatsapp = f\"whatsapp:{self.from_number}\"\r\n\n            try:\r\n                message_params = {\r\n                    \"to\": to_whatsapp,\r\n                    \"from_\": from_whatsapp,\r\n                    \"body\": body\r\n                }\r\n\n                if media_url:\r\n                    message_params[\"media_url\"] = [media_url]\r\n\n                message = self.client.messages.create(**message_params)\r\n\n                return {\r\n                    \"success\": True,\r\n                    \"message_sid\": message.sid,\r\n                    \"status\": message.status\r\n                }\r\n\n            except TwilioRestException as e:\r\n                return self._handle_whatsapp_error(e)\r\n\n        def send_template_message(\r\n            self,\r\n            to: str,\r\n            content_sid: str,\r\n            content_variables: dict\r\n        ) -> dict:\r\n            \"\"\"\r\n            Send pre-approved template message.\r\n            Use this for messages outside 24-hour window.\r\n\n            Content templates must be approved by WhatsApp first.\r\n            Create them in Twilio Console > Content Template Builder.\r\n            \"\"\"\r\n            to_whatsapp = f\"whatsapp:{to}\"\r\n            from_whatsapp = f\"whatsapp:{self.from_number}\"\r\n\n            try:\r\n                message = self.client.messages.create(\r\n                    to=to_whatsapp,\r\n                    from_=from_whatsapp,\r\n                    content_sid=content_sid,\r\n                    content_variables=content_variables\r\n                )\r\n\n                return {\r\n                    \"success\": True,\r\n                    \"message_sid\": message.sid,\r\n                    \"template\": True\r\n                }\r\n\n            except TwilioRestException as e:\r\n                return self._handle_whatsapp_error(e)\r\n\n        def _handle_whatsapp_error(self, error: TwilioRestException) -> dict:\r\n            \"\"\"Handle WhatsApp-specific errors.\"\"\"\r\n            error_handlers = {\r\n                63016: \"Outside 24-hour window. Use template message.\",\r\n                63018: \"Template not approved or doesn't exist.\",\r\n                63025: \"Too many template messages sent to this user.\",\r\n                63038: \"Rate limit exceeded for WhatsApp.\",\r\n            }\r\n\n            return {\r\n                \"success\": False,\r\n                \"error_code\": error.code,\r\n                \"error\": error_handlers.get(error.code, error.msg)\r\n            }\r\n\n\n    from flask import Flask, request\r\n\n    app = Flask(__name__)\r\n\n    @app.route(\"/webhooks/whatsapp\", methods=[\"POST\"])\r\n    def whatsapp_webhook():\r\n        \"\"\"Handle incoming WhatsApp messages.\"\"\"\r\n        from_number = request.form.get(\"From\", \"\").replace(\"whatsapp:\", \"\")\r\n        body = request.form.get(\"Body\", \"\")\r\n        media_url = request.form.get(\"MediaUrl0\")  # First attachment\r\n\n\n        session_start = datetime.now()\r\n        session_expires = session_start + timedelta(hours=24)\r\n\n\n\n\n\n        response = process_whatsapp_message(from_number, body, media_url)\r\n\n\n        whatsapp = TwilioWhatsApp()\r\n        whatsapp.send_message(from_number, response)\r\n\n        return \"\", 200\r\n\n    def process_whatsapp_message(phone: str, text: str, media: str) -> str:\r\n        \"\"\"Process incoming message and generate response.\"\"\"\r\n        text_lower = text.lower()\r\n\n        if \"order status\" in text_lower:\r\n            return \"Your order #1234 is out for delivery!\"\r\n        elif \"support\" in text_lower:\r\n            return \"A support agent will contact you shortly.\"\r\n        else:\r\n            return \"Thanks for your message! Reply with 'order status' or 'support'.\"\r\n\n\n    def send_typing_indicator(to: str):\r\n        \"\"\"Let user know you're typing.\"\"\"\r\n\n        pass\r\n  anti_patterns:\r\n    - \"Sending non-template messages outside 24-hour window\"\r\n    - \"Not tracking session windows per user\"\r\n    - \"Exceeding 1024 char limit for session messages\"\r\n    - \"Not handling template rejection errors\"\r\n\n- id: webhook-handler-pattern\r\n  name: Webhook Handler Pattern\r\n  description: |\r\n    Handle Twilio webhooks for delivery status, incoming messages,\r\n    and call events. Critical: always validate X-Twilio-Signature.\r\n\n    Twilio sends webhooks for:\r\n    - Message status updates (queued → sent → delivered/failed)\r\n    - Incoming SMS/WhatsApp messages\r\n    - Call events (initiated, ringing, answered, completed)\r\n    - Recording/transcription ready\r\n  when_to_use:\r\n    - \"Tracking message delivery status\"\r\n    - \"Receiving incoming messages\"\r\n    - \"Call analytics and logging\"\r\n    - \"Voicemail transcription processing\"\r\n  implementation: |\r\n    from flask import Flask, request, abort\r\n    from twilio.request_validator import RequestValidator\r\n    from functools import wraps\r\n    import os\r\n    import logging\r\n\n    app = Flask(__name__)\r\n    logger = logging.getLogger(__name__)\r\n\n    def validate_twilio_signature(f):\r\n        \"\"\"\r\n        Validate that request came from Twilio.\r\n        CRITICAL: Always use this for webhook endpoints.\r\n        \"\"\"\r\n        @wraps(f)\r\n        def wrapper(*args, **kwargs):\r\n            validator = RequestValidator(os.environ[\"TWILIO_AUTH_TOKEN\"])\r\n\n\n            url = request.url\r\n\n\n            params = request.form.to_dict()\r\n\n\n            signature = request.headers.get(\"X-Twilio-Signature\", \"\")\r\n\n            if not validator.validate(url, params, signature):\r\n                logger.warning(f\"Invalid Twilio signature from {request.remote_addr}\")\r\n                abort(403)\r\n\n            return f(*args, **kwargs)\r\n        return wrapper\r\n\n    @app.route(\"/webhooks/twilio/sms/status\", methods=[\"POST\"])\r\n    @validate_twilio_signature\r\n    def sms_status_callback():\r\n        \"\"\"\r\n        Handle SMS delivery status updates.\r\n\n        Status progression: queued → sending → sent → delivered\r\n        Or: queued → sending → undelivered/failed\r\n        \"\"\"\r\n        message_sid = request.form.get(\"MessageSid\")\r\n        status = request.form.get(\"MessageStatus\")\r\n        error_code = request.form.get(\"ErrorCode\")\r\n        error_message = request.form.get(\"ErrorMessage\")\r\n\n        logger.info(f\"SMS {message_sid}: {status}\")\r\n\n        if status == \"delivered\":\r\n\n            update_message_status(message_sid, \"delivered\")\r\n\n        elif status == \"undelivered\":\r\n\n            logger.error(f\"SMS failed: {error_code} - {error_message}\")\r\n            handle_failed_message(message_sid, error_code, error_message)\r\n\n        elif status == \"failed\":\r\n\n            logger.error(f\"SMS send failed: {error_code}\")\r\n            handle_failed_message(message_sid, error_code, error_message)\r\n\n        return \"\", 200\r\n\n    @app.route(\"/webhooks/twilio/sms/incoming\", methods=[\"POST\"])\r\n    @validate_twilio_signature\r\n    def incoming_sms():\r\n        \"\"\"\r\n        Handle incoming SMS messages.\r\n        \"\"\"\r\n        from_number = request.form.get(\"From\")\r\n        to_number = request.form.get(\"To\")\r\n        body = request.form.get(\"Body\")\r\n        num_media = int(request.form.get(\"NumMedia\", 0))\r\n\n\n        media_urls = []\r\n        for i in range(num_media):\r\n            media_urls.append(request.form.get(f\"MediaUrl{i}\"))\r\n\n\n        if body.strip().upper() in [\"STOP\", \"UNSUBSCRIBE\", \"CANCEL\"]:\r\n            handle_opt_out(from_number)\r\n            return \"\", 200\r\n\n\n        if body.strip().upper() in [\"START\", \"SUBSCRIBE\"]:\r\n            handle_opt_in(from_number)\r\n            return \"\", 200\r\n\n\n        process_incoming_sms(from_number, body, media_urls)\r\n\n        return \"\", 200\r\n\n    @app.route(\"/webhooks/twilio/voice/status\", methods=[\"POST\"])\r\n    @validate_twilio_signature\r\n    def voice_status_callback():\r\n        \"\"\"Handle call status updates.\"\"\"\r\n        call_sid = request.form.get(\"CallSid\")\r\n        status = request.form.get(\"CallStatus\")\r\n        duration = request.form.get(\"CallDuration\")\r\n        direction = request.form.get(\"Direction\")\r\n\n\n\n        logger.info(f\"Call {call_sid}: {status} ({duration}s)\")\r\n\n        if status == \"completed\":\r\n\n            log_call_completion(call_sid, duration)\r\n\n        elif status in [\"busy\", \"no-answer\", \"canceled\", \"failed\"]:\r\n\n            handle_failed_call(call_sid, status)\r\n\n        return \"\", 200\r\n\n\n    def update_message_status(message_sid: str, status: str):\r\n        \"\"\"Update message status in database.\"\"\"\r\n        pass\r\n\n    def handle_failed_message(message_sid: str, error_code: str, error_msg: str):\r\n        \"\"\"Handle failed message delivery.\"\"\"\r\n\n        pass\r\n\n    def handle_opt_out(phone: str):\r\n        \"\"\"Handle user opting out of messages.\"\"\"\r\n\n\n        pass\r\n\n    def handle_opt_in(phone: str):\r\n        \"\"\"Handle user opting back in.\"\"\"\r\n        pass\r\n\n    def process_incoming_sms(from_phone: str, body: str, media: list):\r\n        \"\"\"Process incoming SMS message.\"\"\"\r\n        pass\r\n\n    def log_call_completion(call_sid: str, duration: str):\r\n        \"\"\"Log completed call.\"\"\"\r\n        pass\r\n\n    def handle_failed_call(call_sid: str, status: str):\r\n        \"\"\"Handle call that didn't connect.\"\"\"\r\n        pass\r\n  anti_patterns:\r\n    - \"Not validating X-Twilio-Signature\"\r\n    - \"Exposing webhook URLs without authentication\"\r\n    - \"Not handling opt-out keywords (STOP)\"\r\n    - \"Blocking webhook response (should be fast)\"\r\n\n- id: rate-limit-retry-pattern\r\n  name: Rate Limit and Retry Pattern\r\n  description: |\r\n    Handle Twilio rate limits and implement proper retry logic.\r\n\n    Default limits:\r\n    - SMS: 80 messages per second (MPS)\r\n    - Voice: Varies by number type and region\r\n    - API calls: 100 requests per second\r\n\n    Error codes:\r\n    - 20429: Voice API rate limit\r\n    - 30429: Messaging API rate limit\r\n  when_to_use:\r\n    - \"High-volume messaging applications\"\r\n    - \"Bulk SMS campaigns\"\r\n    - \"Automated calling systems\"\r\n  implementation: |\r\n    import time\r\n    import random\r\n    from functools import wraps\r\n    from twilio.base.exceptions import TwilioRestException\r\n    import logging\r\n\n    logger = logging.getLogger(__name__)\r\n\n    def exponential_backoff_retry(\r\n        max_retries: int = 5,\r\n        base_delay: float = 1.0,\r\n        max_delay: float = 60.0,\r\n        rate_limit_codes: list = [20429, 30429]\r\n    ):\r\n        \"\"\"\r\n        Decorator for exponential backoff retry on rate limits.\r\n\n        Uses jitter to prevent thundering herd.\r\n        \"\"\"\r\n        def decorator(func):\r\n            @wraps(func)\r\n            def wrapper(*args, **kwargs):\r\n                last_exception = None\r\n\n                for attempt in range(max_retries + 1):\r\n                    try:\r\n                        return func(*args, **kwargs)\r\n\n                    except TwilioRestException as e:\r\n                        last_exception = e\r\n\n\n                        if e.code not in rate_limit_codes:\r\n                            raise\r\n\n                        if attempt == max_retries:\r\n                            logger.error(f\"Max retries exceeded: {e}\")\r\n                            raise\r\n\n\n                        delay = min(\r\n                            base_delay * (2 ** attempt) + random.uniform(0, 1),\r\n                            max_delay\r\n                        )\r\n\n                        logger.warning(\r\n                            f\"Rate limited (attempt {attempt + 1}/{max_retries}). \"\r\n                            f\"Retrying in {delay:.1f}s\"\r\n                        )\r\n                        time.sleep(delay)\r\n\n                raise last_exception\r\n\n            return wrapper\r\n        return decorator\r\n\n\n    from twilio.rest import Client\r\n\n    client = Client(account_sid, auth_token)\r\n\n    @exponential_backoff_retry(max_retries=5)\r\n    def send_sms(to: str, body: str):\r\n        return client.messages.create(\r\n            to=to,\r\n            from_=from_number,\r\n            body=body\r\n        )\r\n\n\n    import asyncio\r\n    from asyncio import Semaphore\r\n\n    class RateLimitedSender:\r\n        \"\"\"\r\n        Send messages with built-in rate limiting.\r\n        Stays under Twilio's 80 MPS limit.\r\n        \"\"\"\r\n\n        def __init__(self, client, from_number: str, mps: int = 50):\r\n            self.client = client\r\n            self.from_number = from_number\r\n            self.mps = mps\r\n            self.semaphore = Semaphore(mps)\r\n\n        async def send_bulk(self, messages: list[dict]) -> list[dict]:\r\n            \"\"\"\r\n            Send messages with rate limiting.\r\n\n            Args:\r\n                messages: List of {\"to\": \"+1...\", \"body\": \"...\"}\r\n\n            Returns:\r\n                Results for each message\r\n            \"\"\"\r\n            tasks = [\r\n                self._send_with_limit(msg[\"to\"], msg[\"body\"])\r\n                for msg in messages\r\n            ]\r\n\n            return await asyncio.gather(*tasks, return_exceptions=True)\r\n\n        async def _send_with_limit(self, to: str, body: str):\r\n            \"\"\"Send single message with semaphore-based rate limit.\"\"\"\r\n            async with self.semaphore:\r\n                try:\r\n\n                    loop = asyncio.get_event_loop()\r\n                    result = await loop.run_in_executor(\r\n                        None,\r\n                        lambda: self.client.messages.create(\r\n                            to=to,\r\n                            from_=self.from_number,\r\n                            body=body\r\n                        )\r\n                    )\r\n                    return {\"success\": True, \"sid\": result.sid, \"to\": to}\r\n\n                except TwilioRestException as e:\r\n                    return {\"success\": False, \"error\": str(e), \"to\": to}\r\n\n                finally:\r\n\n                    await asyncio.sleep(1 / self.mps)\r\n\n\n    async def send_campaign():\r\n        sender = RateLimitedSender(client, from_number, mps=50)\r\n\n        messages = [\r\n            {\"to\": \"+14155551234\", \"body\": \"Hello!\"},\r\n            {\"to\": \"+14155555678\", \"body\": \"Hello!\"},\r\n\n        ]\r\n\n        results = await sender.send_bulk(messages)\r\n\n        successful = sum(1 for r in results if r.get(\"success\"))\r\n        print(f\"Sent {successful}/{len(messages)} messages\")\r\n  anti_patterns:\r\n    - \"Retrying immediately without backoff\"\r\n    - \"No jitter causing thundering herd\"\r\n    - \"Retrying non-rate-limit errors\"\r\n    - \"Exceeding Twilio's MPS limit\"",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "twilio",
          "send SMS",
          "text message",
          "voice call",
          "phone verification",
          "2FA SMS",
          "WhatsApp API",
          "programmable messaging",
          "IVR system",
          "TwiML",
          "phone number verification"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "integrations"
      }
    ]
  },
  {
    "id": "legal",
    "name": "Legal",
    "skills": [
      {
        "id": "contract-analysis",
        "name": "Contract Analysis",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use when reviewing contracts, extracting key terms, identifying risks, or building contract analysis tools - covers NLP approaches, clause identification, and risk scoring",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "legal"
      },
      {
        "id": "export-control",
        "name": "Export Control Compliance",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use when implementing ITAR/EAR compliance, ECCN classification, party screening, technology control plans, or deemed exports - covers US export control regulations",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "Sharing controlled technology",
          "Training on controlled items",
          "Employment access"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "legal"
      },
      {
        "id": "gdpr-privacy",
        "name": "GDPR Privacy Compliance",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use when implementing GDPR compliance, handling data subject requests, conducting DPIAs, managing consent, or responding to data breaches - covers all key GDPR requirements",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "legal"
      },
      {
        "id": "patent-drafting",
        "name": "Patent Drafting",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use when drafting patent applications, writing claims, analyzing prior art, or responding to office actions - covers USPTO practice, claim strategies, and specification requirements",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "legal"
      },
      {
        "id": "sox-compliance",
        "name": "SOX Compliance",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use when implementing Sarbanes-Oxley compliance, internal controls, audit trails, segregation of duties, or continuous monitoring - covers COSO framework and IT general controls",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "legal"
      }
    ]
  },
  {
    "id": "marketing",
    "name": "Marketing",
    "skills": [
      {
        "id": "ad-copywriting",
        "name": "Ad Copywriting",
        "version": "1.0.0",
        "layer": 2,
        "description": "Not giving reason to click right now",
        "principles": [
          "Headlines do 80% of the work—obsess over them",
          "Features are what it does; benefits are why they care",
          "One message per ad. Not two. One.",
          "The CTA is not optional—every ad needs a next step",
          "Write to one person, not a demographic",
          "Test assumptions. Data beats opinion.",
          "Good copy is good UX—clarity over cleverness"
        ],
        "owns": [
          "headline-writing",
          "ad-body-copy",
          "cta-optimization",
          "value-proposition-copy",
          "benefit-focused-writing",
          "direct-response-copy",
          "platform-specific-ad-copy",
          "ad-variation-generation",
          "performance-copy-testing"
        ],
        "does_not_own": [
          "ad-strategy → ai-ad-creative",
          "visual-creative → ai-image-generation",
          "brand-voice → branding",
          "long-form-content → copywriting"
        ],
        "triggers": [
          "ad copy",
          "headline",
          "ad text",
          "CTA",
          "call to action",
          "Facebook ad",
          "Google ad",
          "ad variations",
          "direct response",
          "performance copy",
          "primary text",
          "ad headline"
        ],
        "tags": [
          "ad-copy",
          "headlines",
          "direct-response",
          "performance",
          "conversion",
          "cta",
          "advertising"
        ],
        "pairs_with": [
          "ai-ad-creative            # Strategy and creative",
          "ai-image-generation       # Visual pairing",
          "copywriting               # Brand voice foundation",
          "brand-storytelling        # Narrative foundation",
          "ai-creative-director      # Campaign orchestration"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "ai-ad-creative",
        "name": "AI Ad Creative",
        "version": "1.0.0",
        "layer": 2,
        "description": "Creating generic ads without platform consideration",
        "principles": [
          "Conversion beats beauty—ugly ads that work beat beautiful ads that don't",
          "AI enables hypothesis volume—test more, learn faster",
          "Creative fatigue is real—refresh frequency matters",
          "The hook happens in 3 seconds or not at all",
          "Platform context changes everything—native beats generic",
          "Data informs, doesn't decide—creative intuition still matters",
          "Scale testing, not scale spending",
          "Winners emerge from volume—generate many, test widely"
        ],
        "owns": [
          "ai-ad-generation",
          "creative-testing-at-scale",
          "dynamic-creative-optimization",
          "performance-creative-strategy",
          "ad-variation-systems",
          "creative-fatigue-management",
          "platform-specific-ads",
          "ai-ugc-ads",
          "ai-product-ads",
          "conversion-creative"
        ],
        "does_not_own": [
          "media-buying → marketing",
          "campaign-strategy → marketing",
          "organic-creative → creative-communications",
          "brand-creative → branding"
        ],
        "triggers": [
          "AI ads",
          "ad creative",
          "performance creative",
          "ad generation",
          "creative testing",
          "ad variants",
          "DCO",
          "dynamic creative",
          "Meta ads",
          "Google ads",
          "ad fatigue",
          "conversion creative"
        ],
        "tags": [
          "advertising",
          "performance-marketing",
          "creative-testing",
          "ai-ads",
          "conversion",
          "paid-media",
          "scale"
        ],
        "pairs_with": [
          "ai-image-generation       # Static ads",
          "ai-video-generation       # Video ads",
          "digital-humans            # UGC-style ads",
          "marketing                 # Distribution",
          "ai-creative-director      # Orchestration",
          "ai-localization           # Multi-market"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "ai-audio-production",
        "name": "AI Audio Production",
        "version": "1.0.0",
        "layer": 1,
        "description": "Publishing AI audio without listening critically",
        "principles": [
          "AI is an instrument, not a replacement for musicality",
          "Reference tracks are your most powerful tool",
          "Iteration is cheap—generate many, select ruthlessly",
          "Rights matter—understand licensing before using",
          "Human curation makes AI audio feel intentional",
          "Sound design is 50% of video's emotional impact",
          "AI audio + human editing = professional quality",
          "The uncanny valley exists in audio too—listen critically"
        ],
        "owns": [
          "ai-music-generation",
          "ai-sound-effects",
          "ai-audio-enhancement",
          "ai-audio-mixing",
          "ai-stem-separation",
          "soundtrack-creation",
          "jingle-generation",
          "podcast-audio",
          "ai-audio-mastering",
          "background-music",
          "audio-branding"
        ],
        "does_not_own": [
          "human-voiceover → voiceover",
          "video-editing → video-production",
          "music-licensing → creative-communications",
          "live-recording → creative-communications"
        ],
        "triggers": [
          "AI music",
          "generate music",
          "Suno",
          "Udio",
          "AI audio",
          "AI sound",
          "generate soundtrack",
          "background music",
          "sound effects",
          "audio generation",
          "jingle",
          "AI score",
          "stem separation"
        ],
        "tags": [
          "ai-audio",
          "music",
          "suno",
          "udio",
          "sound-effects",
          "soundtrack",
          "generation",
          "audio-branding",
          "production"
        ],
        "pairs_with": [
          "voiceover                    # Voice elements",
          "ai-video-generation          # Video soundtracks",
          "video-production             # Traditional video",
          "explainer-videos             # Educational content",
          "ai-creative-director         # Orchestration",
          "prompt-engineering-creative  # Prompt optimization"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "ai-content-analytics",
        "name": "AI Content Analytics",
        "version": "1.0.0",
        "layer": 2,
        "description": "Comparing AI content to different time periods or conditions",
        "principles": [
          "Measure outcomes, not outputs - conversion beats word count",
          "Attribution is complex but required - track the full journey",
          "AI variations enable A/B testing at unprecedented scale",
          "Speed-to-insight compounds - automate measurement from day one",
          "Qualitative feedback prevents AI optimization into local maxima",
          "Cost-per-quality is the meta-metric for AI content ROI",
          "Human baseline comparison matters more than AI vs AI",
          "Long-term brand impact trumps short-term engagement spikes"
        ],
        "owns": [
          "ai-content-performance-tracking",
          "ai-human-content-comparison",
          "ai-variation-ab-testing",
          "ai-content-attribution",
          "ai-content-roi-calculation",
          "ai-content-quality-metrics",
          "ai-content-velocity-tracking",
          "ai-model-performance-monitoring",
          "ai-content-iteration-cycles",
          "ai-cost-per-conversion",
          "ai-content-dashboard-design",
          "ai-prompt-performance-analytics"
        ],
        "does_not_own": [
          "general-analytics → analytics",
          "content-strategy → content-strategy",
          "copywriting-execution → copywriting",
          "ai-content-generation → ai-creative-director",
          "brand-measurement → brand-positioning",
          "paid-advertising-analytics → marketing"
        ],
        "triggers": [
          "ai content performance",
          "ai content analytics",
          "measure ai content",
          "ai content roi",
          "ai vs human content",
          "ai content attribution",
          "ai content testing",
          "ai variation testing",
          "ai content dashboard",
          "ai content metrics",
          "prompt performance",
          "ai content conversion",
          "ai content quality score",
          "content velocity",
          "ai content efficiency"
        ],
        "tags": [
          "ai-content",
          "analytics",
          "measurement",
          "attribution",
          "roi",
          "ab-testing",
          "performance",
          "optimization",
          "data-driven",
          "content-analytics"
        ],
        "pairs_with": [
          "content-strategy      # AI content planning",
          "ai-creative-director  # AI content creation",
          "marketing             # Campaign integration",
          "analytics             # Infrastructure layer",
          "growth-strategy       # Optimization loops"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "ai-content-qa",
        "name": "AI Content Quality Assurance",
        "version": "1.0.0",
        "layer": 2,
        "description": "Holding content to impossible standards",
        "principles": [
          "Fresh eyes find what tired eyes miss—don't QA your own work",
          "Checklists beat judgment for repeatable quality",
          "One error in public > ten caught in review",
          "QA is not gatekeeping—it's collaborative quality building",
          "Speed of QA should match speed of production",
          "Document patterns, not just problems",
          "QA exists to make creators successful, not to catch them failing"
        ],
        "owns": [
          "content-review",
          "quality-checklists",
          "brand-compliance-checking",
          "fact-verification",
          "platform-compliance-review",
          "copy-editing",
          "consistency-checking",
          "performance-readiness-review",
          "ai-output-validation"
        ],
        "does_not_own": [
          "content-creation → copywriting",
          "brand-guidelines → branding",
          "strategy-review → content-strategy",
          "creative-direction → ai-creative-director"
        ],
        "triggers": [
          "review content",
          "QA",
          "quality check",
          "proofread",
          "check copy",
          "content review",
          "brand compliance",
          "verify content",
          "fact check",
          "review before publish",
          "content approval",
          "final review"
        ],
        "tags": [
          "qa",
          "content-review",
          "quality-assurance",
          "brand-compliance",
          "proofreading",
          "content-quality",
          "review"
        ],
        "pairs_with": [
          "copywriting               # Reviews copy output",
          "ad-copywriting            # Reviews ad copy",
          "video-scriptwriting       # Reviews scripts",
          "brand-storytelling        # Verifies story consistency",
          "ai-creative-director      # Coordinates review process",
          "content-strategy          # Aligns with strategy"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "ai-creative-director",
        "name": "AI Creative Director",
        "version": "1.0.0",
        "layer": 3,
        "description": "Using only one AI tool for everything",
        "principles": [
          "Vision first, tools second",
          "Consistency is harder than creation—prioritize it",
          "Every AI tool has strengths—compose an orchestra, not a solo",
          "Human creative judgment directs AI creative capability",
          "Scale amplifies both brilliance and mistakes—QA everything",
          "The brief is even more important when AI executes it",
          "Document workflows—repeatability is leverage",
          "AI speed enables iteration—use it for creative exploration"
        ],
        "owns": [
          "ai-creative-orchestration",
          "multi-tool-workflows",
          "ai-production-pipelines",
          "ai-campaign-production",
          "ai-creative-quality-control",
          "ai-asset-consistency",
          "ai-creative-systems",
          "ai-production-scaling",
          "tool-selection-strategy",
          "ai-creative-team-direction"
        ],
        "does_not_own": [
          "individual-tool-execution → respective tools",
          "creative-strategy → creative-strategy",
          "brand-strategy → branding",
          "marketing-strategy → marketing"
        ],
        "triggers": [
          "AI creative director",
          "orchestrate AI",
          "AI campaign",
          "multi-tool",
          "AI workflow",
          "AI pipeline",
          "coordinate AI",
          "AI production",
          "AI creative system",
          "full AI production",
          "AI at scale"
        ],
        "tags": [
          "orchestration",
          "creative-direction",
          "ai-production",
          "workflow",
          "pipeline",
          "multi-tool",
          "scale",
          "quality-control"
        ],
        "pairs_with": [
          "ai-video-generation       # Video production",
          "ai-image-generation       # Image production",
          "ai-audio-production       # Audio production",
          "digital-humans            # Avatar production",
          "ai-visual-effects         # Post-production",
          "prompt-engineering-creative # Prompt strategy"
        ],
        "requires": [
          "prompt-engineering-creative"
        ],
        "category": "marketing"
      },
      {
        "id": "ai-image-generation",
        "name": "AI Image Generation",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using prompts from others without knowing why they work",
        "principles": [
          "The prompt is 20% of the image; the model choice is 40%; iteration is 40%",
          "Specificity beats vagueness—details create believability",
          "Style words are worth a thousand descriptions",
          "Reference images trump text descriptions",
          "Every model has a personality—learn to speak its language",
          "Good prompting is good communication: clear, specific, unambiguous",
          "Generate many, select ruthlessly, refine winners",
          "Negative prompts are as important as positive prompts"
        ],
        "owns": [
          "text-to-image",
          "image-to-image",
          "ai-concept-art",
          "ai-product-photography",
          "ai-marketing-visuals",
          "ai-social-media-images",
          "ai-illustration",
          "style-transfer",
          "ai-photo-manipulation",
          "consistent-character-generation",
          "brand-consistent-imagery",
          "batch-generation"
        ],
        "does_not_own": [
          "ai-video-generation → ai-video-generation",
          "traditional-photography → creative-communications",
          "ui-design → ui-design",
          "prompt-strategy → prompt-engineering-creative",
          "motion-graphics → motion-graphics"
        ],
        "triggers": [
          "AI image",
          "generate image",
          "Midjourney",
          "DALL-E",
          "Flux",
          "Stable Diffusion",
          "Imagen",
          "text to image",
          "AI art",
          "AI photo",
          "AI illustration",
          "AI visual",
          "AI graphics",
          "generate picture"
        ],
        "tags": [
          "ai-image",
          "midjourney",
          "dall-e",
          "flux",
          "stable-diffusion",
          "imagen",
          "generation",
          "text-to-image",
          "visual",
          "art"
        ],
        "pairs_with": [
          "prompt-engineering-creative  # Prompt mastery",
          "ai-video-generation          # Seed frames",
          "ai-visual-effects            # Enhancement",
          "motion-graphics              # Animate images",
          "creative-communications      # Creative direction",
          "ai-creative-director         # Orchestration"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "ai-localization",
        "name": "AI Localization",
        "version": "1.0.0",
        "layer": 2,
        "description": "Not checking local regulatory requirements",
        "principles": [
          "Localization is not translation—it's cultural adaptation",
          "AI enables speed, humans ensure cultural accuracy",
          "Some things translate, some must be recreated",
          "Local context beats global template",
          "Test assumptions—cultural intuition can be wrong",
          "Legal requirements vary by market—know them",
          "Visual localization is as important as text",
          "Voice and tone differ across cultures"
        ],
        "owns": [
          "ai-translation",
          "cultural-adaptation",
          "multi-language-content",
          "voice-localization",
          "visual-localization",
          "global-content-strategy",
          "market-adaptation",
          "localization-workflows",
          "terminology-management",
          "transcreation"
        ],
        "does_not_own": [
          "content-creation → content-strategy",
          "video-production → video-production",
          "marketing-strategy → marketing",
          "legal-compliance → (external)"
        ],
        "triggers": [
          "localize",
          "localization",
          "translate",
          "translation",
          "multi-language",
          "international",
          "global",
          "multilingual",
          "market adaptation",
          "cultural adaptation",
          "other languages",
          "different countries"
        ],
        "tags": [
          "localization",
          "translation",
          "international",
          "global",
          "multilingual",
          "cultural-adaptation",
          "ai-dubbing"
        ],
        "pairs_with": [
          "ai-video-generation       # Video localization",
          "digital-humans            # Voice localization",
          "ai-audio-production       # Audio localization",
          "voiceover                 # Voice recording",
          "ai-creative-director      # Orchestration",
          "marketing                 # Market strategy"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "ai-trend-alchemy",
        "name": "AI Trend Alchemy",
        "version": "1.0.0",
        "layer": 2,
        "description": "Viewing trend-catching as competition with other brands",
        "principles": [
          "Early signal > late certainty",
          "Not all trends are worth catching—selectivity matters",
          "AI speed enables trend surfing; AI generation enables instant content",
          "The best trend content feels inevitable, not opportunistic",
          "Prediction without execution is just interesting data",
          "Some trends are worth creating, not just catching",
          "Cultural sensitivity scales with trend velocity"
        ],
        "owns": [
          "trend-detection",
          "trend-prediction",
          "trend-content-generation",
          "viral-mechanics",
          "cultural-signal-reading",
          "trend-timing",
          "trend-creation",
          "memetic-engineering",
          "zeitgeist-capture"
        ],
        "does_not_own": [
          "content-creation → respective tools",
          "social-media-management → marketing",
          "data-science → analytics",
          "brand-strategy → branding"
        ],
        "triggers": [
          "trend",
          "trending",
          "viral",
          "predict",
          "emerging",
          "what's next",
          "cultural moment",
          "before it peaks",
          "early signal",
          "catch the wave",
          "trend prediction",
          "going viral"
        ],
        "tags": [
          "trend",
          "prediction",
          "viral",
          "cultural",
          "emerging",
          "timing",
          "alchemy",
          "detection"
        ],
        "pairs_with": [
          "real-time-content         # Rapid execution",
          "ai-image-generation       # Visual content",
          "ai-video-generation       # Video content",
          "viral-marketing           # Viral mechanics",
          "content-strategy          # Planning",
          "ai-creative-director      # Orchestration"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "ai-video-generation",
        "name": "AI Video Generation",
        "version": "1.0.0",
        "layer": 1,
        "description": "Trying to generate long videos in single pass",
        "principles": [
          "AI video is a new medium, not a cheaper replacement",
          "The prompt is your screenplay, your director, and your DP",
          "Consistency is the hardest problem—solve it systematically",
          "Iterate in seconds, not days",
          "Know each model's strengths—Veo3 for realism, Runway for style",
          "Human review is still essential—AI hallucinates confidently",
          "Combine AI generation with traditional editing for best results",
          "Motion is information—every movement must mean something"
        ],
        "owns": [
          "ai-video-prompting",
          "text-to-video",
          "image-to-video",
          "video-to-video",
          "ai-b-roll-generation",
          "ai-product-visualization",
          "impossible-camera-work",
          "ai-video-consistency",
          "multi-model-workflows",
          "ai-video-upscaling",
          "temporal-coherence",
          "ai-scene-generation"
        ],
        "does_not_own": [
          "traditional-video-production → video-production",
          "ai-image-generation → ai-image-generation",
          "motion-graphics → motion-graphics",
          "voiceover → voiceover",
          "prompt-strategy → prompt-engineering-creative"
        ],
        "triggers": [
          "AI video",
          "generate video",
          "Veo3",
          "Veo 3",
          "Runway",
          "Sora",
          "Kling",
          "Pika",
          "Luma",
          "text to video",
          "image to video",
          "video generation",
          "AI footage",
          "neural video",
          "synthetic video",
          "impossible shot"
        ],
        "tags": [
          "ai-video",
          "veo3",
          "runway",
          "sora",
          "kling",
          "pika",
          "generation",
          "text-to-video",
          "neural",
          "synthesis"
        ],
        "pairs_with": [
          "prompt-engineering-creative  # Prompt mastery",
          "ai-image-generation          # Starting frames",
          "ai-visual-effects            # Enhancement",
          "video-production             # Hybrid workflows",
          "ai-creative-director         # Orchestration",
          "digital-humans               # AI presenters"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "ai-visual-effects",
        "name": "AI Visual Effects",
        "version": "1.0.0",
        "layer": 1,
        "description": "Believing one tool solves everything",
        "principles": [
          "AI generation is step one; enhancement is where polish happens",
          "Upscaling is not magic—garbage in, slightly better garbage out",
          "Compositing is about selling the integration",
          "Color consistency makes disparate elements feel unified",
          "AI tools augment traditional skills, not replace them",
          "Iteration is cheap—try many approaches",
          "The uncanny valley is often fixed in post"
        ],
        "owns": [
          "ai-upscaling",
          "ai-compositing",
          "ai-rotoscoping",
          "ai-color-grading",
          "ai-restoration",
          "ai-inpainting",
          "ai-outpainting",
          "ai-background-removal",
          "ai-object-removal",
          "ai-style-transfer",
          "comfyui-workflows",
          "ai-post-production"
        ],
        "does_not_own": [
          "ai-video-generation → ai-video-generation",
          "ai-image-generation → ai-image-generation",
          "traditional-vfx → creative-communications",
          "motion-graphics → motion-graphics"
        ],
        "triggers": [
          "AI visual effects",
          "VFX",
          "upscale",
          "upscaling",
          "composite",
          "rotoscope",
          "background removal",
          "color grade",
          "inpaint",
          "outpaint",
          "style transfer",
          "enhance",
          "ComfyUI",
          "post-production AI"
        ],
        "tags": [
          "vfx",
          "visual-effects",
          "compositing",
          "upscaling",
          "post-production",
          "comfyui",
          "enhancement",
          "color-grading"
        ],
        "pairs_with": [
          "ai-video-generation       # Source content",
          "ai-image-generation       # Source content",
          "video-production          # Traditional footage",
          "motion-graphics           # Animation elements",
          "ai-creative-director      # Orchestration"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "ai-workflow-automation",
        "name": "AI Workflow Automation",
        "version": "1.0.0",
        "layer": 3,
        "description": "Automation locks out human intervention",
        "principles": [
          "Automation amplifies both excellence and errors—build quality gates first",
          "Brand voice consistency is harder at scale—systematize it early",
          "Human-in-the-loop where judgment matters, automation everywhere else",
          "Cost runaway is real—build monitoring and limits from day one",
          "Every workflow should be versioned, documented, and improvable",
          "Start with one channel, perfect it, then scale—don't automate chaos",
          "Approval bottlenecks kill automation—design parallel approval flows",
          "The best automation feels invisible to end users, obvious to operators"
        ],
        "owns": [
          "ai-content-pipeline-architecture",
          "workflow-automation-design",
          "approval-workflow-systems",
          "multi-channel-distribution-automation",
          "quality-gate-implementation",
          "cost-tracking-and-limits",
          "ai-tool-orchestration",
          "brand-voice-consistency-systems",
          "human-in-the-loop-design",
          "workflow-monitoring-and-alerts"
        ],
        "does_not_own": [
          "content-strategy → content-strategy",
          "individual-ai-tools → respective tool skills",
          "brand-guidelines → branding",
          "platform-specific-tactics → marketing"
        ],
        "triggers": [
          "AI workflow",
          "automate content",
          "content automation",
          "workflow automation",
          "AI pipeline",
          "automated marketing",
          "content distribution automation",
          "approval workflow",
          "scale content production",
          "AI orchestration"
        ],
        "tags": [
          "automation",
          "workflow",
          "ai-orchestration",
          "content-pipeline",
          "approval-workflow",
          "multi-channel",
          "quality-gates",
          "cost-control"
        ],
        "pairs_with": [
          "copywriting               # Content that gets automated",
          "ai-creative-director      # Coordinates AI production",
          "marketing                 # Distribution strategy",
          "content-strategy          # What to automate",
          "ai-content-qa             # Quality assurance layer"
        ],
        "requires": [
          "content-strategy"
        ],
        "category": "marketing"
      },
      {
        "id": "ai-world-building",
        "name": "AI World Building",
        "version": "1.0.0",
        "layer": 2,
        "description": "Building world around one AI tool's capabilities",
        "principles": [
          "Consistency is the hardest problem—solve it systematically",
          "A world is defined by what it excludes as much as what it includes",
          "Characters need rules, not just appearances",
          "Environments are characters too",
          "Style guides are code—they generate infinite assets",
          "Every element must feel like it belongs to the same universe",
          "AI enables scale; design enables coherence"
        ],
        "owns": [
          "brand-universe-creation",
          "consistent-character-design",
          "ai-environment-design",
          "visual-language-systems",
          "style-guide-as-code",
          "character-model-sheets",
          "world-bible-creation",
          "ai-asset-coherence",
          "universe-expansion"
        ],
        "does_not_own": [
          "brand-strategy → branding",
          "individual-asset-creation → ai-image-generation",
          "character-animation → motion-graphics",
          "narrative-development → content-strategy"
        ],
        "triggers": [
          "world building",
          "brand world",
          "universe",
          "consistent character",
          "character design",
          "visual language",
          "brand universe",
          "style bible",
          "world bible",
          "coherent assets",
          "character sheet",
          "environment design"
        ],
        "tags": [
          "world-building",
          "universe",
          "character-design",
          "consistency",
          "visual-language",
          "brand-world",
          "style-guide"
        ],
        "pairs_with": [
          "ai-image-generation       # Asset creation",
          "ai-video-generation       # World in motion",
          "synthetic-influencers     # Characters that live",
          "ai-creative-director      # Orchestration",
          "branding                  # Brand strategy"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "ai-brand-kit",
        "name": "ai-brand-kit",
        "version": "1.0.0",
        "layer": 1,
        "description": "Build comprehensive AI-native brand asset systems that maintain consistency\r\nacross all AI-generated content. Train AI tools on brand guidelines, create\r\nreusable prompt libraries, and manage visual/voice assets at scale.",
        "principles": [
          "principle: Brand is encoded in prompts, not just documents"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "when: Need to define brand positioning before building AI assets"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "blog-writing",
        "name": "Blog Writing",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using phrases that scream \"a robot wrote this",
        "principles": [
          "The first sentence's only job is to make you read the second",
          "Write like you're explaining to a smart friend over coffee",
          "Every section must earn its place or get cut",
          "Specificity is the soul of credibility",
          "Make the complex feel inevitable, not dumbed down",
          "Stories beat statistics, but stories with statistics are unstoppable",
          "The best posts teach the reader to see differently",
          "Write the post you wish existed when you needed it",
          "Voice is HOW you write, not WHAT you claim - never fabricate experiences",
          "Authority comes from knowledge depth, not fictional personal stories"
        ],
        "owns": [
          "blog-posts",
          "long-form-articles",
          "technical-explainers",
          "thought-leadership-pieces",
          "educational-content",
          "how-to-guides",
          "opinion-pieces",
          "industry-analysis",
          "trend-pieces",
          "listicles-with-depth",
          "case-studies",
          "tutorials",
          "newsletters"
        ],
        "does_not_own": [
          "short-form-copy → copywriting",
          "content-planning → content-strategy",
          "landing-pages → copywriting",
          "social-media-posts → marketing",
          "email-sequences → copywriting",
          "brand-voice-guidelines → branding",
          "SEO-keyword-research → seo"
        ],
        "triggers": [
          "write a blog post",
          "blog post about",
          "write an article",
          "create content about",
          "explain this topic",
          "write about",
          "long-form content",
          "thought leadership",
          "technical blog",
          "how-to article",
          "tutorial post",
          "educational content",
          "industry analysis",
          "opinion piece",
          "newsletter content",
          "make this engaging",
          "write for developers",
          "explain like"
        ],
        "tags": [
          "writing",
          "blog",
          "content",
          "articles",
          "long-form",
          "storytelling",
          "technical-writing",
          "thought-leadership",
          "educational",
          "tutorials",
          "explainers",
          "engagement"
        ],
        "pairs_with": [
          "content-strategy   # What to write about",
          "copywriting        # Headlines and CTAs",
          "seo               # Optimization",
          "branding          # Voice consistency",
          "marketing         # Distribution"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "brand-storytelling",
        "name": "Brand Storytelling",
        "version": "1.0.0",
        "layer": 2,
        "description": "Narratives where nothing is at risk",
        "principles": [
          "Every brand has a story—your job is to find it, not invent it",
          "Story is the vehicle; emotion is the cargo",
          "Consistency of narrative beats consistency of visual",
          "The hero is the customer, never the brand",
          "Conflict drives story; transformation resolves it",
          "Show, don't tell—especially in visual media",
          "A story without stakes is just information"
        ],
        "owns": [
          "brand-narrative-development",
          "story-arc-design",
          "hero-journey-framework",
          "emotional-storytelling",
          "origin-story-creation",
          "customer-story-mining",
          "narrative-consistency",
          "story-adaptation",
          "transmedia-storytelling"
        ],
        "does_not_own": [
          "brand-strategy → branding",
          "copywriting-execution → copywriting",
          "video-production → ai-video-generation",
          "content-calendar → content-strategy"
        ],
        "triggers": [
          "story",
          "storytelling",
          "narrative",
          "brand story",
          "origin story",
          "hero journey",
          "emotional connection",
          "customer story",
          "testimonial",
          "case study",
          "brand film",
          "about us"
        ],
        "tags": [
          "storytelling",
          "narrative",
          "brand-story",
          "emotional",
          "hero-journey",
          "content"
        ],
        "pairs_with": [
          "video-scriptwriting       # Stories need scripts",
          "copywriting               # Written execution",
          "ai-video-generation       # Visual storytelling",
          "content-strategy          # Story distribution",
          "branding                  # Strategic foundation",
          "ai-creative-director      # Orchestration"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "content-strategy",
        "name": "Content Strategy",
        "version": "1.0.0",
        "layer": 2,
        "description": "Publishing helpful content but not guiding readers to next step",
        "principles": [
          "Answer the questions your audience is actually asking",
          "Distribution is as important as creation",
          "Quality beats quantity, but consistency beats quality",
          "Every piece of content needs a job to do",
          "Write for humans, optimize for search",
          "The best content teaches something valuable",
          "Repurpose everything worth creating"
        ],
        "owns": [
          "content-planning",
          "editorial-calendar",
          "content-pillars",
          "topic-clusters",
          "content-formats",
          "content-distribution",
          "content-measurement",
          "content-auditing",
          "content-repurposing",
          "audience-development",
          "SEO-content-strategy",
          "content-governance"
        ],
        "does_not_own": [
          "copywriting → copywriting",
          "visual-design → ui-design",
          "brand-voice → branding",
          "marketing-campaigns → marketing",
          "social-media-management → marketing",
          "video-production → creative-strategy"
        ],
        "triggers": [
          "content strategy",
          "content plan",
          "editorial calendar",
          "blog strategy",
          "content marketing",
          "topic clusters",
          "pillar content",
          "content audit",
          "content calendar",
          "SEO content",
          "content distribution",
          "content funnel",
          "thought leadership",
          "content engine",
          "content topics",
          "what to write"
        ],
        "tags": [
          "content",
          "strategy",
          "editorial",
          "SEO",
          "blog",
          "planning",
          "distribution",
          "measurement"
        ],
        "pairs_with": [
          "marketing          # Content distribution",
          "copywriting        # Content execution",
          "analytics          # Content measurement",
          "growth-strategy    # Content for growth",
          "brand-positioning  # Voice and positioning"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "copywriting",
        "name": "Copywriting",
        "version": "1.0.0",
        "layer": 1,
        "description": "Generic buttons like \"Submit\" or \"Click Here",
        "principles": [
          "Write to one person, not to everyone",
          "Benefits first, features second",
          "Clear beats clever every time",
          "Every word must earn its place",
          "The headline is 80% of the work",
          "Good copy is a conversation, not a broadcast",
          "You're not writing about you—you're writing about them"
        ],
        "owns": [
          "headlines",
          "body-copy",
          "email-copy",
          "ad-copy",
          "landing-page-copy",
          "product-copy",
          "UX-writing",
          "taglines",
          "CTAs",
          "value-propositions",
          "feature-descriptions",
          "error-messages"
        ],
        "does_not_own": [
          "brand-voice → branding",
          "content-strategy → content-strategy",
          "blog-content → content-strategy",
          "visual-design → ui-design",
          "creative-direction → creative-strategy"
        ],
        "triggers": [
          "copywriting",
          "write copy",
          "headlines",
          "taglines",
          "email copy",
          "ad copy",
          "landing page copy",
          "product copy",
          "UX writing",
          "CTAs",
          "value proposition",
          "microcopy",
          "sales copy",
          "conversion copy"
        ],
        "tags": [
          "writing",
          "copy",
          "headlines",
          "conversion",
          "persuasion",
          "messaging",
          "UX-writing",
          "emails"
        ],
        "pairs_with": [
          "branding           # Voice and tone",
          "creative-strategy  # Campaign concepts",
          "marketing          # Distribution context",
          "ui-design          # Visual integration",
          "content-strategy   # Content ecosystem"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "creative-communications",
        "name": "Creative Communications",
        "version": "1.0.0",
        "layer": 1,
        "description": "Giving subjective opinions instead of brief-aligned direction",
        "principles": [
          "The brief is the contract—unclear briefs produce unclear work",
          "Creative without strategy is art; creative with strategy is advertising",
          "Every asset must answer: who is this for, what do we want them to do, why should they care",
          "Consistency beats novelty—brand recognition compounds",
          "Feedback must be specific and actionable, not just 'make it pop'",
          "Channel dictates format—what works on Instagram dies in email",
          "Ship beats perfect—creative is never done, only due"
        ],
        "owns": [
          "creative-briefs",
          "creative-production",
          "asset-creation",
          "creative-feedback",
          "creative-adaptation",
          "visual-storytelling",
          "video-production",
          "motion-graphics",
          "photography-direction",
          "creative-operations"
        ],
        "does_not_own": [
          "brand-strategy → brand-positioning",
          "campaign-strategy → marketing",
          "copywriting → copywriting",
          "ui-design → ui-design",
          "brand-identity → branding"
        ],
        "triggers": [
          "creative",
          "creative brief",
          "assets",
          "video",
          "motion",
          "animation",
          "creative production",
          "photoshoot",
          "visual content",
          "creative review",
          "ad creative",
          "creative feedback"
        ],
        "tags": [
          "creative",
          "production",
          "video",
          "motion",
          "assets",
          "briefs",
          "feedback",
          "visual-content"
        ],
        "pairs_with": [
          "branding           # Brand guidelines",
          "marketing          # Campaign creative",
          "copywriting        # Words + visuals",
          "content-strategy   # Content calendar",
          "ui-design          # Digital assets",
          "creative-strategy  # Creative direction"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "digital-humans",
        "name": "Digital Humans",
        "version": "1.0.0",
        "layer": 1,
        "description": "Choosing avatar without considering audience perception",
        "principles": [
          "Transparency first—never deceive audiences about AI nature",
          "Quality > Quantity—uncanny valley destroys trust",
          "Match avatar to use case—enterprise needs different than casual",
          "Lip sync quality is the first thing people notice",
          "Voice quality is the second thing people notice",
          "Body language and micro-expressions create believability",
          "Script quality matters even more when AI presents it",
          "Cultural sensitivity applies to avatar selection too"
        ],
        "owns": [
          "ai-avatar-creation",
          "digital-presenter-production",
          "ai-spokesperson-videos",
          "personalized-video-at-scale",
          "multilingual-ai-video",
          "ai-training-videos",
          "synthetic-media-production",
          "avatar-consistency",
          "ai-video-personalization",
          "virtual-presenter-direction"
        ],
        "does_not_own": [
          "human-presenter-production → video-production",
          "voiceover → voiceover",
          "script-writing → copywriting",
          "ai-video-generation → ai-video-generation"
        ],
        "triggers": [
          "digital human",
          "AI avatar",
          "AI presenter",
          "HeyGen",
          "Synthesia",
          "D-ID",
          "Tavus",
          "synthetic",
          "talking head AI",
          "AI spokesperson",
          "personalized video",
          "video at scale",
          "multilingual video",
          "AI actor"
        ],
        "tags": [
          "digital-humans",
          "avatar",
          "ai-presenter",
          "synthesia",
          "heygen",
          "d-id",
          "synthetic-media",
          "personalization",
          "multilingual"
        ],
        "pairs_with": [
          "voiceover                    # Voice quality",
          "copywriting                  # Scripts",
          "ai-video-generation          # Background generation",
          "video-production             # Hybrid productions",
          "ai-creative-director         # Orchestration",
          "ai-localization              # Multi-language"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "explainer-videos",
        "name": "Explainer Videos",
        "version": "1.0.0",
        "layer": 1,
        "description": "Creating a great explainer but not telling viewers what to do next",
        "principles": [
          "If you can't explain it simply, you don't understand it well enough",
          "One video, one message, one action",
          "Show, don't tell—then tell while showing",
          "The curse of knowledge is the enemy of clarity",
          "Every second of complexity is a viewer lost",
          "Analogies are your most powerful tool",
          "The problem matters more than the solution"
        ],
        "owns": [
          "explainer-strategy",
          "concept-simplification",
          "visual-metaphors",
          "explainer-scripting",
          "storyboarding-for-explainers",
          "educational-video",
          "product-demos",
          "how-it-works-videos",
          "onboarding-videos",
          "training-videos",
          "whiteboard-videos"
        ],
        "does_not_own": [
          "motion-graphics-execution → motion-graphics",
          "voiceover-recording → voiceover",
          "live-action-production → video-production",
          "copywriting → copywriting",
          "marketing-strategy → marketing"
        ],
        "triggers": [
          "explainer",
          "explainer video",
          "how it works",
          "product demo",
          "onboarding video",
          "training video",
          "educational video",
          "whiteboard",
          "animated explainer",
          "explain this",
          "simplify",
          "concept video",
          "SaaS video"
        ],
        "tags": [
          "explainer",
          "video",
          "animation",
          "educational",
          "product",
          "demo",
          "onboarding",
          "SaaS"
        ],
        "pairs_with": [
          "motion-graphics          # Animation execution",
          "voiceover                # Narration",
          "video-production         # Live action elements",
          "copywriting              # Script writing",
          "product-management       # Product knowledge",
          "marketing                # Distribution"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "marketing",
        "name": "Marketing",
        "version": "1.0.0",
        "layer": 2,
        "description": "Running marketing without input from sales, product, and customer success",
        "principles": [
          "Permission is more valuable than interruption",
          "Marketing is not a department - it's everyone's job",
          "What gets measured gets managed",
          "Consistency beats intensity",
          "The best marketing feels like helping",
          "Your competition is not who you think it is",
          "Distribution is as important as creation"
        ],
        "owns": [
          "go-to-market-strategy",
          "channel-strategy",
          "campaign-planning",
          "demand-generation",
          "brand-marketing",
          "performance-marketing",
          "marketing-automation",
          "lead-generation",
          "customer-acquisition",
          "marketing-analytics",
          "market-positioning",
          "competitive-intelligence"
        ],
        "does_not_own": [
          "brand-identity → branding",
          "copywriting → copywriting",
          "product-decisions → product-strategy",
          "sales-process → sales",
          "content-creation → content-strategy",
          "creative-execution → creative-strategy"
        ],
        "triggers": [
          "marketing",
          "campaign",
          "go-to-market",
          "gtm",
          "launch",
          "promotion",
          "advertising",
          "ads",
          "acquisition",
          "demand gen",
          "lead gen",
          "channel",
          "funnel",
          "conversion",
          "cac",
          "customer acquisition",
          "reach",
          "awareness",
          "consideration"
        ],
        "tags": [
          "marketing",
          "advertising",
          "acquisition",
          "campaigns",
          "gtm",
          "demand-generation",
          "analytics",
          "channels"
        ],
        "pairs_with": [
          "growth-strategy      # Acquisition strategy",
          "content-strategy     # Content execution",
          "brand-positioning    # Positioning alignment",
          "analytics            # Performance measurement",
          "copywriting          # Message execution"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "marketing-fundamentals",
        "name": "Marketing Fundamentals",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using competitor tactics without understanding context",
        "principles": [
          "name: Positioning First"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "marketing strategy",
          "positioning",
          "messaging",
          "customer acquisition",
          "growth channels",
          "brand",
          "go-to-market"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "motion-graphics",
        "name": "Motion Graphics",
        "version": "1.0.0",
        "layer": 1,
        "description": "Delivering unoptimized files that slow down playback",
        "principles": [
          "Every movement must have purpose",
          "Timing and spacing are more important than complexity",
          "Less is more—restraint shows mastery",
          "Motion should guide the eye, not distract it",
          "The 12 principles of animation still apply",
          "Style follows message, not trends",
          "Smooth in, smooth out—easing matters"
        ],
        "owns": [
          "motion-design",
          "animation-principles",
          "kinetic-typography",
          "logo-animation",
          "lower-thirds",
          "title-sequences",
          "transitions",
          "icon-animation",
          "character-animation-simple",
          "data-visualization-animated",
          "UI-animation",
          "loading-animations",
          "social-media-animations"
        ],
        "does_not_own": [
          "3D-animation → 3D-design",
          "video-editing → video-production",
          "static-design → ui-design",
          "copywriting → copywriting",
          "voiceover → voiceover"
        ],
        "triggers": [
          "motion graphics",
          "animation",
          "animate",
          "motion design",
          "kinetic",
          "logo animation",
          "title sequence",
          "lower thirds",
          "animated",
          "after effects",
          "lottie",
          "transitions",
          "motion"
        ],
        "tags": [
          "motion",
          "graphics",
          "animation",
          "after-effects",
          "lottie",
          "kinetic",
          "typography",
          "design"
        ],
        "pairs_with": [
          "video-production        # Video content",
          "explainer-videos        # Educational animation",
          "ui-design               # Product animations",
          "creative-communications # Creative direction",
          "voiceover               # Audio sync"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "prompt-engineering-creative",
        "name": "Prompt Engineering for Creatives",
        "version": "1.0.0",
        "layer": 1,
        "description": "Expecting perfect results from first prompt",
        "principles": [
          "Every model has a personality—learn to speak its language",
          "Specificity beats vagueness, but brevity beats verbosity",
          "Reference examples are worth a thousand words",
          "Iteration is cheap—hypothesis testing is the method",
          "Negative prompts are as important as positive prompts",
          "Build libraries, not one-off prompts",
          "What you don't say matters as much as what you do",
          "The prompt is a conversation, not a command"
        ],
        "owns": [
          "prompt-architecture",
          "prompt-optimization",
          "prompt-libraries",
          "model-specific-prompting",
          "multi-modal-prompting",
          "prompt-debugging",
          "prompt-iteration",
          "negative-prompting",
          "style-encoding",
          "prompt-templates",
          "few-shot-prompting",
          "chain-of-thought-creative"
        ],
        "does_not_own": [
          "image-generation-execution → ai-image-generation",
          "video-generation-execution → ai-video-generation",
          "audio-generation-execution → ai-audio-production",
          "LLM-prompting → (separate skill)"
        ],
        "triggers": [
          "prompt",
          "prompting",
          "prompt engineering",
          "better prompts",
          "prompt optimization",
          "how to prompt",
          "prompt strategy",
          "prompt library",
          "prompt template",
          "make AI understand"
        ],
        "tags": [
          "prompt-engineering",
          "prompting",
          "meta-skill",
          "ai-creative",
          "foundational",
          "optimization",
          "iteration"
        ],
        "pairs_with": [
          "ai-image-generation       # Image prompts",
          "ai-video-generation       # Video prompts",
          "ai-audio-production       # Audio prompts",
          "digital-humans            # Avatar prompts",
          "ai-creative-director      # Campaign prompts"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "real-time-content",
        "name": "Real-Time Content",
        "version": "1.0.0",
        "layer": 2,
        "description": "Copying how competitors responded to trend",
        "principles": [
          "Speed beats perfection when moments matter",
          "Relevance has a half-life—capture moments fast",
          "Reactive + authentic > reactive + forced",
          "Not every trend deserves your brand's attention",
          "Real-time requires pre-built systems, not improvisation",
          "Cultural sensitivity is still critical, even at speed",
          "The best real-time content feels effortless"
        ],
        "owns": [
          "trend-response-content",
          "event-based-marketing",
          "newsjacking",
          "cultural-moment-content",
          "meme-marketing",
          "rapid-content-production",
          "real-time-social",
          "moment-marketing"
        ],
        "does_not_own": [
          "trend-prediction → ai-trend-alchemy",
          "content-strategy → content-strategy",
          "social-media-management → marketing",
          "brand-voice → branding"
        ],
        "triggers": [
          "real-time",
          "trending",
          "moment",
          "reactive",
          "newsjacking",
          "current event",
          "meme",
          "viral moment",
          "rapid",
          "respond to",
          "capitalize on",
          "trending topic"
        ],
        "tags": [
          "real-time",
          "trending",
          "reactive",
          "rapid",
          "moment-marketing",
          "newsjacking",
          "speed"
        ],
        "pairs_with": [
          "ai-image-generation       # Rapid visuals",
          "ai-video-generation       # Quick video",
          "ai-trend-alchemy          # Trend detection",
          "marketing                 # Distribution",
          "copywriting               # Messaging",
          "ai-creative-director      # When orchestration needed"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "seo",
        "name": "SEO",
        "version": "1.0.0",
        "layer": 1,
        "description": "Constantly changing strategy based on every Google update",
        "principles": [
          "name: Solve Real Problems"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "seo",
          "search engine optimization",
          "organic traffic",
          "google ranking",
          "keyword research",
          "backlinks",
          "content strategy",
          "search visibility"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "synthetic-influencers",
        "name": "Synthetic Influencers",
        "version": "1.0.0",
        "layer": 2,
        "description": "Influencer that never grows or changes",
        "principles": [
          "Transparency is non-negotiable—audiences must know it's synthetic",
          "Personality consistency matters more than visual perfection",
          "A synthetic influencer needs a reason to exist",
          "Community building is still human work",
          "The persona serves the brand, not the other way around",
          "Controversy immunity is a feature, not a bug",
          "Content velocity is the synthetic advantage"
        ],
        "owns": [
          "synthetic-persona-creation",
          "ai-influencer-strategy",
          "virtual-brand-ambassador",
          "ai-persona-voice",
          "synthetic-content-strategy",
          "ai-influencer-management",
          "virtual-spokesperson",
          "ai-personality-design",
          "synthetic-media-ethics"
        ],
        "does_not_own": [
          "visual-generation → ai-image-generation",
          "video-production → digital-humans",
          "human-influencer-management → marketing",
          "community-management → marketing"
        ],
        "triggers": [
          "synthetic influencer",
          "AI influencer",
          "virtual influencer",
          "AI persona",
          "brand ambassador AI",
          "digital influencer",
          "virtual spokesperson",
          "AI character",
          "Lil Miquela",
          "virtual model",
          "AI personality"
        ],
        "tags": [
          "synthetic",
          "influencer",
          "virtual",
          "AI-persona",
          "brand-ambassador",
          "digital-character",
          "social-media"
        ],
        "pairs_with": [
          "ai-world-building         # Character universe",
          "digital-humans            # Video production",
          "ai-image-generation       # Visual content",
          "content-strategy          # Content planning",
          "marketing                 # Distribution",
          "copywriting               # Voice and messaging"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "video-directing",
        "name": "Video Directing",
        "version": "1.0.0",
        "layer": 1,
        "description": "Accepting AI generations without directorial judgment",
        "principles": [
          "The camera is your audience's eye—what you show them is what they experience",
          "Every shot must earn its place in the sequence",
          "Emotion first, exposition second—make them feel, then help them understand",
          "The best special effect is a great performance",
          "Constraints breed creativity—limitations are gifts",
          "The cut is where the magic happens—editing is directing's second act",
          "Know the rules deeply so you can break them meaningfully",
          "A director is a storyteller who happens to use cameras"
        ],
        "owns": [
          "shot-composition",
          "camera-movement",
          "visual-storytelling",
          "scene-blocking",
          "talent-direction",
          "emotional-pacing",
          "storyboarding",
          "pre-visualization",
          "cinematic-language",
          "shot-sequencing",
          "visual-rhythm",
          "establishing-shots",
          "coverage-strategy",
          "performance-direction",
          "visual-metaphor",
          "cinematic-tension"
        ],
        "does_not_own": [
          "video-editing → video-production",
          "color-grading → video-production",
          "sound-design → ai-audio-production",
          "motion-graphics → motion-graphics",
          "visual-effects → ai-visual-effects",
          "script-writing → video-scriptwriting",
          "casting → talent-management"
        ],
        "triggers": [
          "direct",
          "directing",
          "director",
          "shot",
          "camera angle",
          "camera movement",
          "cinematic",
          "scene",
          "blocking",
          "coverage",
          "composition",
          "visual storytelling",
          "like Spielberg",
          "like Cameron",
          "like Nolan",
          "like Tarantino",
          "like Scorsese",
          "film style",
          "movie style"
        ],
        "tags": [
          "directing",
          "cinematography",
          "camera",
          "shot-composition",
          "storytelling",
          "film",
          "cinematic",
          "visual-language",
          "blocking",
          "spielberg",
          "cameron",
          "nolan",
          "tarantino",
          "scorsese"
        ],
        "pairs_with": [
          "video-production           # Technical execution",
          "video-scriptwriting        # Story foundation",
          "ai-video-generation        # AI footage creation",
          "ai-creative-director       # Overall creative vision",
          "motion-graphics            # Animated elements",
          "ai-visual-effects          # Post-production enhancement",
          "ai-audio-production        # Sound and music"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "video-production",
        "name": "Video Production",
        "version": "1.0.0",
        "layer": 1,
        "description": "Creating one video and resizing for all platforms",
        "principles": [
          "Pre-production prevents post-production problems",
          "Story first, technology second",
          "Every second must earn its place",
          "Audio is half the video experience",
          "The best shot is the one that tells the story",
          "B-roll is storytelling, not decoration",
          "Good enough shipped beats perfect never finished"
        ],
        "owns": [
          "video-strategy",
          "video-scripting",
          "storyboarding",
          "shot-lists",
          "video-shooting",
          "video-editing",
          "color-grading",
          "sound-design",
          "video-formatting",
          "video-optimization",
          "talking-head-videos",
          "product-videos",
          "testimonial-videos",
          "brand-videos",
          "social-video-content"
        ],
        "does_not_own": [
          "motion-graphics → motion-graphics",
          "explainer-videos → explainer-videos",
          "voiceover → voiceover",
          "copywriting → copywriting",
          "creative-strategy → creative-strategy",
          "marketing-strategy → marketing"
        ],
        "triggers": [
          "video",
          "video production",
          "film",
          "shoot",
          "footage",
          "editing",
          "product video",
          "testimonial",
          "talking head",
          "brand video",
          "social video",
          "youtube",
          "video content",
          "b-roll",
          "color grade"
        ],
        "tags": [
          "video",
          "production",
          "editing",
          "filming",
          "content",
          "youtube",
          "social",
          "brand"
        ],
        "pairs_with": [
          "creative-communications  # Creative direction",
          "copywriting              # Scripts and messaging",
          "marketing                # Distribution",
          "motion-graphics          # Animated elements",
          "voiceover                # Narration",
          "explainer-videos         # Educational content"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "video-scriptwriting",
        "name": "Video Scriptwriting",
        "version": "1.0.0",
        "layer": 2,
        "description": "Video that doesn't ask viewer to do anything",
        "principles": [
          "Write for the eye first, then the ear",
          "The first 3 seconds are everything",
          "Every frame should communicate something",
          "If you can't see it, don't write it",
          "Dialogue is a last resort, not a first choice",
          "Time is the most limited resource—respect it",
          "Scripts are blueprints, not literature"
        ],
        "owns": [
          "video-script-structure",
          "commercial-scriptwriting",
          "social-video-scripts",
          "long-form-video-scripts",
          "script-formatting",
          "shot-description",
          "dialogue-writing",
          "video-hooks",
          "call-to-action-design"
        ],
        "does_not_own": [
          "video-production → ai-video-generation",
          "story-development → brand-storytelling",
          "voiceover-recording → ai-audio-production",
          "advertising-strategy → ai-ad-creative"
        ],
        "triggers": [
          "script",
          "video script",
          "commercial script",
          "ad script",
          "TikTok script",
          "YouTube script",
          "explainer video",
          "brand film",
          "promo video",
          "video ad",
          "screenplay",
          "storyboard"
        ],
        "tags": [
          "script",
          "video",
          "commercial",
          "social-video",
          "storytelling",
          "visual",
          "production"
        ],
        "pairs_with": [
          "brand-storytelling       # Story foundation",
          "ai-video-generation      # Production",
          "ai-audio-production      # Voice/music",
          "ai-ad-creative           # Ad strategy",
          "digital-humans           # Talking head scripts",
          "copywriting              # Written elements"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "viral-marketing",
        "name": "Viral Marketing",
        "version": "1.0.0",
        "layer": 1,
        "description": "Tracking shares and impressions without measuring actual conversion",
        "principles": [
          "People share what makes them look good",
          "Virality is a product feature, not a marketing campaign",
          "The best referral is when the product doesn't work without sharing",
          "Remove friction from sharing like it's a conversion funnel",
          "Incentives amplify, they don't create—you can't bribe people to share crap",
          "K-factor > 1 changes everything; K-factor < 1 is just paid acquisition with extra steps",
          "Viral content has emotional resonance—logical content doesn't spread"
        ],
        "owns": [
          "viral-loops",
          "referral-programs",
          "share-mechanics",
          "word-of-mouth",
          "social-proof",
          "network-effects",
          "invite-systems",
          "k-factor-optimization",
          "viral-content",
          "growth-hacking"
        ],
        "does_not_own": [
          "paid-acquisition → marketing",
          "content-creation → content-strategy",
          "social-media-management → marketing",
          "product-market-fit → product-strategy",
          "brand-building → branding"
        ],
        "triggers": [
          "viral",
          "referral",
          "invite",
          "share",
          "word of mouth",
          "k-factor",
          "network effect",
          "growth loop",
          "spread",
          "organic growth",
          "tell a friend",
          "refer"
        ],
        "tags": [
          "viral",
          "referral",
          "growth",
          "sharing",
          "word-of-mouth",
          "network-effects",
          "organic",
          "loops"
        ],
        "pairs_with": [
          "growth-strategy    # Growth frameworks",
          "product-management # Feature design",
          "marketing          # Campaign coordination",
          "analytics          # Measurement",
          "frontend           # Share UI implementation",
          "copywriting        # Share messaging"
        ],
        "requires": [],
        "category": "marketing"
      },
      {
        "id": "voiceover",
        "name": "Voiceover",
        "version": "1.0.0",
        "layer": 1,
        "description": "Using AI-generated voice without human quality check",
        "principles": [
          "The voice must match the message, brand, and audience",
          "Pacing controls emotion—slow for gravity, fast for energy",
          "Natural beats perfect every time",
          "Audio quality is non-negotiable",
          "Direction is as important as talent",
          "The script determines 80% of voiceover success",
          "AI is a tool, not a replacement for performance"
        ],
        "owns": [
          "voice-casting",
          "voiceover-direction",
          "script-optimization-for-voice",
          "audio-recording",
          "voice-editing",
          "ai-voice-generation",
          "voice-pacing",
          "voice-tone",
          "narration-style",
          "commercial-voiceover",
          "corporate-narration",
          "character-voice"
        ],
        "does_not_own": [
          "video-editing → video-production",
          "music-composition → creative-communications",
          "script-writing → copywriting",
          "sound-effects → video-production",
          "animation → motion-graphics"
        ],
        "triggers": [
          "voiceover",
          "voice over",
          "VO",
          "narration",
          "narrator",
          "voice recording",
          "voice talent",
          "voice actor",
          "AI voice",
          "text to speech",
          "audio narration",
          "voice direction"
        ],
        "tags": [
          "voiceover",
          "audio",
          "narration",
          "voice",
          "recording",
          "AI-voice",
          "talent",
          "direction"
        ],
        "pairs_with": [
          "video-production       # Video content",
          "explainer-videos       # Educational content",
          "motion-graphics        # Animated content",
          "copywriting            # Script source",
          "creative-communications # Creative direction"
        ],
        "requires": [],
        "category": "marketing"
      }
    ]
  },
  {
    "id": "mind",
    "name": "Mind",
    "skills": [
      {
        "id": "code-quality",
        "name": "Code Quality",
        "version": "1.0.0",
        "layer": 1,
        "description": "Creating abstractions before understanding the pattern",
        "principles": [],
        "owns": [
          "code-readability",
          "naming-conventions",
          "function-design",
          "solid-principles",
          "code-organization",
          "code-review",
          "technical-excellence",
          "maintainability"
        ],
        "does_not_own": [],
        "triggers": [
          "code quality",
          "clean code",
          "readability",
          "naming",
          "SOLID",
          "refactor",
          "code review",
          "best practices",
          "maintainable",
          "how should I structure"
        ],
        "tags": [
          "clean-code",
          "solid",
          "readability",
          "maintainability",
          "code-review",
          "naming",
          "functions",
          "principles"
        ],
        "pairs_with": [
          "refactoring-guide",
          "test-strategist",
          "debugging-master",
          "system-designer",
          "tech-debt-manager"
        ],
        "requires": [],
        "category": "mind"
      },
      {
        "id": "debugging-master",
        "name": "Debugging Master",
        "version": "1.0.0",
        "layer": 1,
        "description": "Looking for evidence that supports your theory",
        "principles": [],
        "owns": [
          "debugging-methodology",
          "root-cause-analysis",
          "hypothesis-testing",
          "bug-isolation",
          "minimal-reproduction",
          "binary-search-debugging",
          "production-debugging",
          "postmortem-analysis"
        ],
        "does_not_own": [],
        "triggers": [
          "bug",
          "debugging",
          "not working",
          "broken",
          "investigate",
          "root cause",
          "why is this happening",
          "figure out",
          "troubleshoot",
          "doesn't work",
          "unexpected behavior"
        ],
        "tags": [
          "debugging",
          "root-cause",
          "hypothesis",
          "scientific-method",
          "troubleshooting",
          "bug-hunting",
          "investigation",
          "problem-solving"
        ],
        "pairs_with": [
          "incident-responder",
          "test-strategist",
          "performance-thinker",
          "code-quality",
          "system-designer"
        ],
        "requires": [],
        "category": "mind"
      },
      {
        "id": "decision-maker",
        "name": "Decision Maker",
        "version": "1.0.0",
        "layer": 1,
        "description": "Endless research and discussion, never deciding",
        "principles": [],
        "owns": [
          "technical-decisions",
          "trade-off-analysis",
          "reversibility-assessment",
          "architecture-decision-records",
          "second-order-thinking",
          "decision-documentation",
          "stakeholder-alignment",
          "risk-assessment"
        ],
        "does_not_own": [],
        "triggers": [
          "should we",
          "which is better",
          "trade-off",
          "decision",
          "choose between",
          "versus",
          "pros and cons",
          "what if we",
          "is it worth",
          "evaluate options"
        ],
        "tags": [
          "decisions",
          "trade-offs",
          "architecture",
          "adr",
          "reversibility",
          "strategy",
          "planning",
          "risk"
        ],
        "pairs_with": [
          "system-designer",
          "tech-debt-manager",
          "code-quality",
          "performance-thinker",
          "debugging-master"
        ],
        "requires": [],
        "category": "mind"
      },
      {
        "id": "incident-responder",
        "name": "Incident Responder",
        "version": "1.0.0",
        "layer": 1,
        "description": "One person trying to solve everything alone",
        "principles": [],
        "owns": [
          "incident-response",
          "on-call",
          "outage-handling",
          "post-mortem",
          "war-room",
          "severity-classification",
          "incident-communication"
        ],
        "does_not_own": [],
        "triggers": [
          "incident",
          "outage",
          "production issue",
          "site down",
          "on-call",
          "post-mortem",
          "war room",
          "severity",
          "pages",
          "alerts",
          "rollback"
        ],
        "tags": [
          "incident",
          "outage",
          "on-call",
          "post-mortem",
          "production",
          "reliability",
          "SRE",
          "communication"
        ],
        "pairs_with": [
          "debugging-master",
          "performance-thinker",
          "system-designer",
          "decision-maker",
          "tech-debt-manager"
        ],
        "requires": [],
        "category": "mind"
      },
      {
        "id": "performance-thinker",
        "name": "Performance Thinker",
        "version": "1.0.0",
        "layer": 1,
        "description": "Optimizing before measuring or before it matters",
        "principles": [],
        "owns": [
          "performance-optimization",
          "profiling",
          "benchmarking",
          "caching-strategy",
          "complexity-analysis",
          "query-optimization",
          "memory-management",
          "latency-throughput"
        ],
        "does_not_own": [],
        "triggers": [
          "slow",
          "performance",
          "optimize",
          "profiling",
          "benchmark",
          "latency",
          "throughput",
          "cache",
          "n+1",
          "bottleneck",
          "memory leak",
          "too slow",
          "speed up",
          "response time"
        ],
        "tags": [
          "performance",
          "optimization",
          "profiling",
          "caching",
          "latency",
          "throughput",
          "big-o",
          "benchmarking"
        ],
        "pairs_with": [
          "system-designer",
          "debugging-master",
          "test-strategist",
          "code-quality",
          "refactoring-guide"
        ],
        "requires": [],
        "category": "mind"
      },
      {
        "id": "refactoring-guide",
        "name": "Refactoring Guide",
        "version": "1.0.0",
        "layer": 1,
        "description": "Throwing away working code to rewrite from scratch",
        "principles": [],
        "owns": [
          "refactoring-strategy",
          "code-smells",
          "legacy-code",
          "incremental-improvement",
          "strangler-pattern",
          "characterization-tests",
          "safe-transformation"
        ],
        "does_not_own": [],
        "triggers": [
          "refactor",
          "refactoring",
          "clean up",
          "legacy code",
          "code smell",
          "improve this",
          "restructure",
          "technical debt",
          "rewrite",
          "extract",
          "inline",
          "rename",
          "move method"
        ],
        "tags": [
          "refactoring",
          "legacy-code",
          "code-smells",
          "transformation",
          "incremental",
          "technical-debt",
          "clean-code"
        ],
        "pairs_with": [
          "code-quality",
          "test-strategist",
          "debugging-master",
          "tech-debt-manager",
          "system-designer"
        ],
        "requires": [],
        "category": "mind"
      },
      {
        "id": "system-designer",
        "name": "System Designer",
        "version": "1.0.0",
        "layer": 1,
        "description": "System without recognizable architecture",
        "principles": [],
        "owns": [
          "system-architecture",
          "scalability-patterns",
          "reliability-engineering",
          "distributed-systems",
          "api-design",
          "data-modeling",
          "component-decomposition",
          "architecture-documentation"
        ],
        "does_not_own": [],
        "triggers": [
          "system design",
          "architecture",
          "scalability",
          "how should we structure",
          "distributed",
          "microservices",
          "monolith",
          "high availability",
          "design the system",
          "component diagram"
        ],
        "tags": [
          "architecture",
          "system-design",
          "scalability",
          "reliability",
          "distributed",
          "api",
          "modeling",
          "c4"
        ],
        "pairs_with": [
          "decision-maker",
          "performance-thinker",
          "tech-debt-manager",
          "code-quality",
          "incident-responder"
        ],
        "requires": [],
        "category": "mind"
      },
      {
        "id": "tech-debt-manager",
        "name": "Tech Debt Manager",
        "version": "1.0.0",
        "layer": 1,
        "description": "Pretending debt doesn't exist or isn't growing",
        "principles": [],
        "owns": [
          "tech-debt-strategy",
          "debt-prioritization",
          "debt-communication",
          "debt-tracking",
          "interest-calculation",
          "legacy-management"
        ],
        "does_not_own": [],
        "triggers": [
          "tech debt",
          "technical debt",
          "legacy code",
          "should we fix",
          "cleanup backlog",
          "maintenance",
          "when to refactor",
          "debt prioritization",
          "shortcuts"
        ],
        "tags": [
          "tech-debt",
          "technical-debt",
          "legacy",
          "maintenance",
          "prioritization",
          "stakeholder-communication"
        ],
        "pairs_with": [
          "refactoring-guide",
          "code-quality",
          "decision-maker",
          "system-designer",
          "performance-thinker"
        ],
        "requires": [],
        "category": "mind"
      },
      {
        "id": "technical-writer",
        "name": "Technical Writer",
        "version": "1.0.0",
        "layer": 1,
        "description": "Writing docs at the end of a project",
        "principles": [],
        "owns": [
          "technical-documentation",
          "api-documentation",
          "readme-writing",
          "code-comments",
          "architecture-docs",
          "user-guides",
          "documentation-maintenance",
          "knowledge-transfer"
        ],
        "does_not_own": [],
        "triggers": [
          "documentation",
          "document",
          "README",
          "API docs",
          "comments",
          "explain",
          "write docs",
          "architecture doc",
          "ADR",
          "user guide",
          "tutorial",
          "onboarding"
        ],
        "tags": [
          "documentation",
          "writing",
          "communication",
          "knowledge-transfer",
          "API",
          "README",
          "comments",
          "architecture",
          "onboarding"
        ],
        "pairs_with": [
          "system-designer",
          "code-quality",
          "refactoring-guide",
          "decision-maker",
          "test-strategist"
        ],
        "requires": [],
        "category": "mind"
      },
      {
        "id": "test-strategist",
        "name": "Test Strategist",
        "version": "1.0.0",
        "layer": 1,
        "description": "Test that passes but doesn't test what it claims",
        "principles": [],
        "owns": [
          "test-strategy",
          "unit-testing",
          "integration-testing",
          "e2e-testing",
          "test-design",
          "test-pyramid",
          "tdd-methodology",
          "test-coverage"
        ],
        "does_not_own": [],
        "triggers": [
          "test",
          "testing",
          "unit test",
          "integration test",
          "e2e",
          "TDD",
          "test coverage",
          "how to test",
          "should I test",
          "test pyramid",
          "flaky test"
        ],
        "tags": [
          "testing",
          "tdd",
          "unit-tests",
          "integration",
          "e2e",
          "test-pyramid",
          "coverage",
          "quality"
        ],
        "pairs_with": [
          "debugging-master",
          "code-quality",
          "refactoring-guide",
          "performance-thinker",
          "system-designer"
        ],
        "requires": [],
        "category": "mind"
      }
    ]
  },
  {
    "id": "product",
    "name": "Product",
    "skills": [
      {
        "id": "a-b-testing",
        "name": "A/B Testing",
        "version": "1.0.0",
        "layer": 1,
        "description": "Running experiments with vague goals like \"see what performs better",
        "principles": [
          "Every experiment must have a hypothesis before it starts",
          "Sample size isn't negotiable—underpowered tests are worse than no test",
          "Negative results are results—they save you from bad ideas",
          "Test one thing at a time or you learn nothing",
          "Statistical significance is necessary but not sufficient",
          "Practical significance matters more than p-values",
          "Trust the data even when it surprises you"
        ],
        "owns": [
          "experiment-design",
          "statistical-testing",
          "feature-flags",
          "hypothesis-formation",
          "sample-size-calculation",
          "experiment-analysis",
          "variant-design",
          "test-duration",
          "guardrail-metrics",
          "experiment-culture"
        ],
        "does_not_own": [
          "event-tracking → analytics",
          "personalization-at-scale → machine-learning",
          "marketing-attribution → marketing",
          "full-stack-feature-development → frontend/backend",
          "user-research-interviews → ux-design"
        ],
        "triggers": [
          "a/b test",
          "experiment",
          "hypothesis",
          "statistical significance",
          "sample size",
          "feature flag",
          "variant",
          "control",
          "treatment",
          "p-value",
          "conversion rate",
          "test winner",
          "split test"
        ],
        "tags": [
          "experimentation",
          "testing",
          "statistics",
          "feature-flags",
          "hypothesis",
          "growth",
          "optimization",
          "learning",
          "validation"
        ],
        "pairs_with": [
          "analytics          # Measurement and tracking",
          "product-management # Prioritization and roadmap",
          "frontend           # UI variant implementation",
          "growth-strategy    # Growth experimentation",
          "ux-design          # User behavior insights",
          "marketing          # Marketing experiments"
        ],
        "requires": [],
        "category": "product"
      },
      {
        "id": "analytics",
        "name": "Analytics",
        "version": "1.0.0",
        "layer": 1,
        "description": "Tracking metrics that look good but don't drive decisions",
        "principles": [
          "Every metric should drive a decision",
          "Measure outcomes, not just activities",
          "If you're not acting on it, stop measuring it",
          "Correlation is not causation",
          "Track events, derive metrics",
          "Simple dashboards beat comprehensive dashboards",
          "Data quality > data quantity"
        ],
        "owns": [
          "event-tracking",
          "metrics-design",
          "dashboards",
          "user-analytics",
          "funnel-analysis",
          "cohort-analysis",
          "retention-metrics",
          "product-analytics",
          "data-visualization",
          "reporting"
        ],
        "does_not_own": [
          "a-b-testing → a-b-testing",
          "marketing-attribution → marketing",
          "infrastructure-monitoring → devops",
          "business-intelligence → growth-strategy",
          "data-engineering → backend"
        ],
        "triggers": [
          "analytics",
          "metrics",
          "tracking",
          "dashboard",
          "funnel",
          "cohort",
          "retention",
          "events",
          "KPI",
          "measure",
          "data",
          "insights",
          "conversion",
          "engagement"
        ],
        "tags": [
          "analytics",
          "metrics",
          "data",
          "dashboards",
          "tracking",
          "funnels",
          "cohorts",
          "KPIs",
          "insights"
        ],
        "pairs_with": [
          "product-management  # Product metrics",
          "growth-strategy     # Growth metrics",
          "marketing           # Marketing analytics",
          "a-b-testing         # Experiment analysis",
          "frontend            # Implementation",
          "backend             # Data pipeline"
        ],
        "requires": [],
        "category": "product"
      },
      {
        "id": "customer-success",
        "name": "Customer Success",
        "version": "1.0.0",
        "layer": 1,
        "description": "Long list of tasks with no clear path to value",
        "principles": [
          "name: Time to value is everything"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "product"
      },
      {
        "id": "product-management",
        "name": "Product Management",
        "version": "1.0.0",
        "layer": 2,
        "description": "Shipping features without validating they solve user problems",
        "principles": [
          "Outcomes over output—shipping features isn't success, solving problems is",
          "Fall in love with the problem, not the solution",
          "The best product decision is the one you don't have to make",
          "Conviction comes from evidence, not opinion",
          "Two-way doors can be walked through quickly; one-way doors need deliberation",
          "Say no to 1000 things to say yes to the right thing",
          "Stakeholder alignment is a prerequisite, not a nice-to-have"
        ],
        "owns": [
          "product-roadmap",
          "feature-prioritization",
          "requirements-definition",
          "user-stories",
          "acceptance-criteria",
          "stakeholder-alignment",
          "sprint-planning",
          "product-discovery",
          "competitive-analysis",
          "feature-specification",
          "release-planning",
          "product-metrics",
          "user-feedback-synthesis"
        ],
        "does_not_own": [
          "product-strategy → product-strategy",
          "UI-design → ui-design",
          "UX-research → ux-design",
          "engineering-estimates → frontend, backend",
          "go-to-market → marketing",
          "pricing-decisions → growth-strategy",
          "brand-decisions → brand-positioning"
        ],
        "triggers": [
          "product management",
          "product roadmap",
          "feature prioritization",
          "user stories",
          "acceptance criteria",
          "PRD",
          "product requirements",
          "sprint planning",
          "backlog",
          "product discovery",
          "feature spec",
          "product metrics",
          "OKRs",
          "release planning",
          "stakeholder alignment",
          "product decision"
        ],
        "tags": [
          "product",
          "roadmap",
          "prioritization",
          "requirements",
          "discovery",
          "execution",
          "stakeholders",
          "metrics"
        ],
        "pairs_with": [
          "product-strategy    # Vision alignment",
          "ux-design          # User research",
          "frontend           # Implementation",
          "backend            # Technical feasibility",
          "growth-strategy    # Business outcomes",
          "marketing          # Launch coordination"
        ],
        "requires": [],
        "category": "product"
      }
    ]
  },
  {
    "id": "science",
    "name": "Science",
    "skills": [
      {
        "id": "statistical-analysis",
        "name": "Dichotomizing Continuous Variables",
        "version": "1.0.0",
        "layer": 1,
        "description": "Converting continuous variables to categories",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "science"
      },
      {
        "id": "data-reproducibility",
        "name": "Hardcoded File Paths",
        "version": "1.0.0",
        "layer": 1,
        "description": "Ensure exact environment reproduction",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "science"
      },
      {
        "id": "experimental-design",
        "name": "One-Factor-at-a-Time (OFAT)",
        "version": "1.0.0",
        "layer": 1,
        "description": "Test multiple factors efficiently",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "science"
      },
      {
        "id": "scientific-method",
        "name": "P-Hacking (Data Dredging)",
        "version": "1.0.0",
        "layer": 1,
        "description": "Searching for significant results through multiple analyses",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "science"
      }
    ]
  },
  {
    "id": "simulation",
    "name": "Simulation",
    "skills": [
      {
        "id": "agent-based-modeling",
        "name": "Agent-Based Modeling",
        "version": "1.0.0",
        "layer": 1,
        "description": "Core agent design with state, perception, and action",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "agent-based",
          "multi-agent",
          "emergent behavior",
          "swarm simulation",
          "social simulation",
          "crowd modeling",
          "population dynamics",
          "individual-based"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "simulation"
      },
      {
        "id": "digital-twin",
        "name": "Digital Twin Development",
        "version": "1.0.0",
        "layer": 1,
        "description": "Core digital twin system structure",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "digital twin",
          "virtual model",
          "real-time synchronization",
          "physical-virtual coupling",
          "predictive maintenance",
          "asset modeling",
          "system replica",
          "live simulation"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "simulation"
      },
      {
        "id": "discrete-event-simulation",
        "name": "Discrete Event Simulation",
        "version": "1.0.0",
        "layer": 1,
        "description": "Core event-driven simulation engine",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "discrete event",
          "DES simulation",
          "queuing system",
          "queue model",
          "manufacturing simulation",
          "process simulation",
          "SimPy",
          "event-driven simulation"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "simulation"
      },
      {
        "id": "monte-carlo",
        "name": "Monte Carlo Simulation",
        "version": "1.0.0",
        "layer": 1,
        "description": "Fundamental Monte Carlo estimation",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "monte carlo",
          "random sampling",
          "uncertainty quantification",
          "risk analysis",
          "stochastic simulation",
          "MCMC",
          "variance reduction",
          "probabilistic"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "simulation"
      },
      {
        "id": "physics-simulation",
        "name": "Objects Pass Through Each Other",
        "version": "1.0.0",
        "layer": 1,
        "description": "ODE solvers for physical systems",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "simulation"
      }
    ]
  },
  {
    "id": "space",
    "name": "Space",
    "skills": [
      {
        "id": "ground-station-ops",
        "name": "Ground Station Operations",
        "version": "1.0.0",
        "layer": 1,
        "description": "Tracks satellite, receives/transmits RF",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "ground station",
          "satellite contact",
          "pass prediction",
          "AOS",
          "LOS",
          "telemetry",
          "commanding",
          "uplink",
          "downlink",
          "antenna tracking",
          "link budget",
          "G/T",
          "EIRP"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "space"
      },
      {
        "id": "mission-planning",
        "name": "Guiana Space Centre",
        "version": "1.0.0",
        "layer": 1,
        "description": "Electric propulsion spiral transfers",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "mission design",
          "launch window",
          "trajectory optimization",
          "mission timeline",
          "mass budget",
          "propellant budget",
          "mission phases",
          "porkchop plot",
          "C3",
          "gravity assist",
          "low thrust",
          "mission architecture",
          "LEO",
          "GEO",
          "interplanetary"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "space"
      },
      {
        "id": "orbital-mechanics",
        "name": "Orbital Mechanics",
        "version": "1.0.0",
        "layer": 1,
        "description": "Use planetary flyby to change velocity direction/magnitude",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "orbit",
          "trajectory",
          "maneuver",
          "delta-v",
          "Hohmann",
          "Keplerian",
          "perturbation",
          "J2",
          "TLE",
          "orbital elements",
          "semi-major axis",
          "eccentricity",
          "inclination",
          "RAAN",
          "spacecraft propagation",
          "Lambert solver",
          "interplanetary"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "space"
      },
      {
        "id": "space-data-processing",
        "name": "Space Data Processing",
        "version": "1.0.0",
        "layer": 1,
        "description": "Machine learning for land cover and change detection",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "satellite imagery",
          "remote sensing",
          "Earth observation",
          "optical imagery",
          "hyperspectral",
          "SAR",
          "InSAR",
          "NDVI",
          "atmospheric correction",
          "radiometric calibration",
          "land cover classification",
          "change detection",
          "pan-sharpening",
          "spectral unmixing"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "space"
      },
      {
        "id": "spacecraft-systems",
        "name": "Spacecraft Systems",
        "version": "1.0.0",
        "layer": 1,
        "description": "Electrical Power System (EPS)",
        "principles": [],
        "owns": [],
        "does_not_own": [],
        "triggers": [
          "spacecraft",
          "satellite",
          "ADCS",
          "attitude control",
          "reaction wheel",
          "star tracker",
          "solar array",
          "battery",
          "thermal control",
          "radiator",
          "MLI",
          "propulsion",
          "thruster",
          "communications",
          "link budget",
          "C&DH",
          "subsystem"
        ],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "space"
      }
    ]
  },
  {
    "id": "startup",
    "name": "Startup",
    "skills": [
      {
        "id": "burn-rate-management",
        "name": "Burn Rate Management",
        "version": "1.0.0",
        "layer": 3,
        "description": "Assuming revenue will materialize or fundraising will work out",
        "principles": [
          "Cash is oxygen",
          "Default alive or default dead - know which you are",
          "Every hire is a bet",
          "Revenue solves all problems",
          "18 months runway minimum before fundraising",
          "Cut once, cut deep"
        ],
        "owns": [
          "runway-calculation",
          "burn-rate-optimization",
          "default-alive-analysis",
          "cash-management",
          "fundraising-timing",
          "cost-cutting-decisions",
          "headcount-planning",
          "zero-based-budgeting",
          "financial-modeling-startup",
          "bridge-financing"
        ],
        "does_not_own": [
          "fundraising-pitch → fundraising-strategy",
          "unit-economics → business-model",
          "pricing-strategy → product-strategy",
          "accounting → finance-ops",
          "legal-entities → legal-compliance"
        ],
        "triggers": [
          "burn rate",
          "runway",
          "default alive",
          "default dead",
          "how much money",
          "when to raise",
          "cutting costs",
          "layoffs",
          "cash management",
          "should we hire",
          "running out of money",
          "bridge round",
          "extend runway",
          "ramen profitable"
        ],
        "tags": [
          "finance",
          "runway",
          "cash",
          "burn",
          "survival",
          "fundraising",
          "startup"
        ],
        "pairs_with": [
          "yc-playbook          # YC context",
          "founder-mode         # Making hard decisions",
          "fundraising-strategy # When to raise",
          "hiring-engineering   # Headcount decisions"
        ],
        "requires": [],
        "category": "startup"
      },
      {
        "id": "founder-mode",
        "name": "Founder Mode",
        "version": "1.0.0",
        "layer": 3,
        "description": "Hiring expensive execs and stepping back because \"that's what you do at scale",
        "principles": [
          "Stay close to the work",
          "Skip levels when necessary",
          "Details matter at every scale",
          "Hire people who can handle founder mode",
          "Delegate outcomes, not understanding",
          "Trust but verify, always"
        ],
        "owns": [
          "founder-involvement",
          "delegation-decisions",
          "direct-engagement",
          "operational-cadence",
          "decision-making-authority",
          "skip-level-communication",
          "founder-time-allocation",
          "strategic-deep-dives"
        ],
        "does_not_own": [
          "team-structure → hiring-engineering",
          "company-culture → culture-building",
          "management-training → people-ops",
          "process-design → operations",
          "strategic-planning → product-strategy"
        ],
        "triggers": [
          "founder mode",
          "should i delegate",
          "staying close to work",
          "micromanagement",
          "when to step back",
          "professional ceo",
          "manager vs founder",
          "skip level",
          "how involved should i be",
          "letting go of control",
          "scaling as founder",
          "founder burnout"
        ],
        "tags": [
          "founder",
          "leadership",
          "delegation",
          "management",
          "scaling",
          "operational"
        ],
        "pairs_with": [
          "yc-playbook          # The broader context",
          "burn-rate-management # Resources to protect",
          "hiring-engineering   # Building the team",
          "product-strategy     # What to focus on"
        ],
        "requires": [],
        "category": "startup"
      },
      {
        "id": "yc-playbook",
        "name": "YC Playbook",
        "version": "1.0.0",
        "layer": 3,
        "description": "Building in secret, waiting for perfect launch, avoiding user feedback",
        "principles": [
          "Make something people want",
          "Launch now",
          "Talk to users",
          "Do things that don't scale",
          "It's better to have 100 users who love you than 1M who kinda like you",
          "Build something you yourself want",
          "Growth solves all problems"
        ],
        "owns": [
          "yc-application",
          "demo-day-prep",
          "batch-dynamics",
          "investor-updates",
          "yc-network-leverage",
          "office-hours-protocol",
          "launch-strategy",
          "user-obsession",
          "yc-metrics",
          "post-batch-strategy"
        ],
        "does_not_own": [
          "fundraising-mechanics → fundraising-strategy",
          "product-vision → product-strategy",
          "team-building → hiring-engineering",
          "technical-architecture → backend",
          "growth-tactics → growth-strategy",
          "brand-building → brand-positioning"
        ],
        "triggers": [
          "yc",
          "y combinator",
          "demo day",
          "batch",
          "investor update",
          "office hours",
          "launch now",
          "talk to users",
          "do things that don't scale",
          "make something people want",
          "startup school",
          "yc application",
          "series a prep",
          "post-yc"
        ],
        "tags": [
          "yc",
          "startup",
          "accelerator",
          "demo-day",
          "fundraising",
          "launch",
          "users",
          "growth"
        ],
        "pairs_with": [
          "founder-mode           # How to stay in control",
          "burn-rate-management   # Don't die",
          "product-strategy       # What to build",
          "growth-strategy        # How to grow",
          "fundraising-strategy   # Raising money"
        ],
        "requires": [],
        "category": "startup"
      }
    ]
  },
  {
    "id": "strategy",
    "name": "Strategy",
    "skills": [
      {
        "id": "brand-positioning",
        "name": "Brand Positioning",
        "version": "1.0.0",
        "layer": 3,
        "description": "Positioning based on what founders think is important vs customer perception",
        "principles": [
          "Positioning happens in the mind of the customer, not in the product",
          "It's better to be first in a category than to be better",
          "If you can't be first, create a new category where you can be first",
          "The most powerful concept in marketing is owning a word in the mind",
          "A brand is a promise. Keep it or die.",
          "Differentiation that doesn't matter is meaningless"
        ],
        "owns": [
          "brand-strategy",
          "market-positioning",
          "category-design",
          "brand-architecture",
          "competitive-positioning",
          "brand-values",
          "brand-personality",
          "brand-promise",
          "positioning-statement",
          "value-proposition-articulation",
          "brand-differentiation",
          "brand-naming-strategy",
          "tagline-development",
          "brand-manifesto",
          "brand-platform"
        ],
        "does_not_own": [
          "product-features → product-strategy",
          "growth-tactics → growth-strategy",
          "visual-identity → branding",
          "logo-design → ui-design",
          "marketing-campaigns → marketing",
          "ad-creative → creative-strategy",
          "copy-writing → copywriting",
          "content-creation → content-strategy",
          "pricing-strategy → product-strategy"
        ],
        "triggers": [
          "brand positioning",
          "positioning statement",
          "brand strategy",
          "category design",
          "competitive positioning",
          "how should we position",
          "brand differentiation",
          "value proposition",
          "what makes us different",
          "brand platform",
          "brand values",
          "brand personality",
          "brand promise",
          "brand manifesto",
          "tagline",
          "unique selling proposition",
          "usp",
          "category creation",
          "own a word",
          "mind share"
        ],
        "tags": [
          "brand",
          "positioning",
          "strategy",
          "differentiation",
          "category",
          "competitive",
          "values",
          "identity"
        ],
        "pairs_with": [
          "product-strategy     # Product truth enables brand promise",
          "growth-strategy      # Growth amplifies brand reach",
          "copywriting         # Copy expresses brand voice",
          "marketing           # Marketing activates brand position",
          "branding           # Visual identity embodies positioning",
          "creative-strategy   # Creative expresses brand platform"
        ],
        "requires": [],
        "category": "strategy"
      },
      {
        "id": "creative-strategy",
        "name": "Creative Strategy",
        "version": "1.0.0",
        "layer": 2,
        "description": "Creating work that makes internal stakeholders happy vs resonating with audience",
        "principles": [
          "Strategy before creativity, insight before execution",
          "The idea should be explainable in one sentence",
          "Distinctive beats different",
          "Emotion drives action, not information",
          "Great creative makes the audience feel something",
          "Constraints are creative catalysts",
          "Simple ideas executed brilliantly beat complex ideas"
        ],
        "owns": [
          "campaign-concepts",
          "creative-briefs",
          "visual-direction",
          "art-direction",
          "creative-storytelling",
          "campaign-messaging",
          "creative-production",
          "video-strategy",
          "photography-direction",
          "motion-design-direction",
          "brand-campaigns",
          "launch-creative"
        ],
        "does_not_own": [
          "brand-identity → branding",
          "copywriting → copywriting",
          "UI-design → ui-design",
          "brand-strategy → brand-positioning",
          "media-buying → marketing",
          "content-planning → content-strategy"
        ],
        "triggers": [
          "creative strategy",
          "campaign concept",
          "creative direction",
          "art direction",
          "video production",
          "photo shoot",
          "brand campaign",
          "advertising",
          "ad creative",
          "visual identity",
          "campaign idea",
          "creative brief",
          "storyboard",
          "motion design",
          "commercial",
          "brand video"
        ],
        "tags": [
          "creative",
          "campaigns",
          "art-direction",
          "video",
          "advertising",
          "visual",
          "storytelling",
          "production"
        ],
        "pairs_with": [
          "brand-positioning    # Strategy alignment",
          "marketing           # Campaign distribution",
          "copywriting         # Message execution",
          "branding            # Visual identity",
          "content-strategy    # Content execution"
        ],
        "requires": [],
        "category": "strategy"
      },
      {
        "id": "early-stage-hustle",
        "name": "Early Stage Hustle",
        "version": "1.0.0",
        "layer": 1,
        "description": "Physically help users start using your product on the spot",
        "principles": [
          "name: Do things that don't scale"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "strategy"
      },
      {
        "id": "founder-character",
        "name": "Founder Character",
        "version": "1.0.0",
        "layer": 1,
        "description": "When blocked, find a way around. Problems are puzzles, not walls.",
        "principles": [
          "name: Relentlessly resourceful"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "strategy"
      },
      {
        "id": "founder-operating-system",
        "name": "Founder Operating System",
        "version": "1.0.0",
        "layer": 1,
        "description": "Block long uninterrupted periods for deep work, batch meetings separately",
        "principles": [
          "name: Maker schedule vs manager schedule"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "strategy"
      },
      {
        "id": "fundraising-strategy",
        "name": "Fundraising Strategy",
        "version": "1.0.0",
        "layer": 2,
        "description": "Treating fundraising as the goal",
        "principles": [
          "Raise when you don't need to, not when you're desperate",
          "Dilution matters - 10% less ownership compounds over decades",
          "Money is commodity - value-add investors are rare",
          "Raise for 18-24 months runway, not longer",
          "Fundraising is a process, not a lottery",
          "Investors aren't just capital - they're partners for 10 years"
        ],
        "owns": [
          "fundraising-strategy",
          "investor-relations",
          "pitch-deck",
          "term-sheet",
          "valuation",
          "cap-table",
          "dilution",
          "venture-capital",
          "angel-investment",
          "seed-funding",
          "series-a"
        ],
        "does_not_own": [
          "financial-modeling → data-skills",
          "legal-structure → operations",
          "investor-updates → founder-operating-system",
          "growth-metrics → growth-strategy"
        ],
        "triggers": [
          "fundraising",
          "raising money",
          "pitch deck",
          "investors",
          "term sheet",
          "valuation",
          "dilution",
          "series A",
          "seed round",
          "pre-seed",
          "runway",
          "cap table",
          "VC",
          "venture capital"
        ],
        "tags": [
          "fundraising",
          "investors",
          "venture-capital",
          "pitch-deck",
          "term-sheet",
          "valuation",
          "dilution",
          "seed",
          "series-a",
          "cap-table"
        ],
        "pairs_with": [
          "growth-strategy       # Metrics for fundraising",
          "moat-building         # Story for investors",
          "hiring-strategy       # Use of funds",
          "founder-operating-system # Investor management"
        ],
        "requires": [],
        "category": "strategy"
      },
      {
        "id": "go-to-market",
        "name": "Go-to-Market Strategy",
        "version": "1.0.0",
        "layer": 2,
        "description": "Assuming a great product doesn't need distribution",
        "principles": [
          "Distribution is as important as product - both are solved problems",
          "Pick one GTM motion and execute it well before adding another",
          "Your first GTM motion should match founder DNA and customer expectations",
          "Channels exhaust - what works now won't work forever",
          "Early customers are different from scale customers - plan the transition",
          "Paid acquisition only works after organic proves the product works"
        ],
        "owns": [
          "go-to-market",
          "gtm-strategy",
          "launch-strategy",
          "product-led-growth",
          "sales-led-growth",
          "community-led-growth",
          "channel-strategy",
          "market-entry",
          "customer-acquisition",
          "launch-sequencing",
          "distribution-strategy"
        ],
        "does_not_own": [
          "growth-loops → growth-strategy",
          "viral-mechanics → growth-strategy",
          "brand-building → brand-positioning",
          "pricing-decisions → pricing-strategy",
          "product-direction → product-strategy"
        ],
        "triggers": [
          "go to market",
          "GTM",
          "launch strategy",
          "how to get customers",
          "sales vs product-led",
          "channel strategy",
          "market entry",
          "customer acquisition",
          "distribution strategy",
          "product launch",
          "getting first customers",
          "sales motion",
          "bottoms up",
          "top down sales"
        ],
        "tags": [
          "go-to-market",
          "gtm",
          "launch",
          "product-led-growth",
          "sales",
          "channels",
          "customer-acquisition",
          "distribution",
          "marketing"
        ],
        "pairs_with": [
          "product-strategy      # What you're launching",
          "pricing-strategy      # How you're charging",
          "growth-strategy       # Growth loops and retention",
          "brand-positioning     # How you're positioning",
          "hiring-strategy       # Sales/marketing hires"
        ],
        "requires": [],
        "category": "strategy"
      },
      {
        "id": "growth-strategy",
        "name": "Growth Strategy",
        "version": "1.0.0",
        "layer": 3,
        "description": "Assuming what works for competitors will work for you",
        "principles": [
          "Growth follows product-market fit, never precedes it",
          "Retention is the foundation; acquisition without retention is a leaky bucket",
          "The best growth is product-driven, not marketing-driven",
          "Compound effects beat linear efforts",
          "Every growth channel eventually saturates",
          "Network effects are the ultimate moat"
        ],
        "owns": [
          "growth-strategy",
          "growth-modeling",
          "acquisition-strategy",
          "retention-strategy",
          "activation-optimization",
          "viral-loops",
          "network-effects",
          "growth-loops",
          "channel-strategy",
          "unit-economics",
          "ltv-cac-optimization",
          "growth-experimentation-strategy",
          "referral-systems",
          "growth-flywheels"
        ],
        "does_not_own": [
          "product-vision → product-strategy",
          "brand-identity → brand-positioning",
          "marketing-campaigns → marketing",
          "viral-content → viral-marketing",
          "analytics-implementation → analytics",
          "ab-testing-execution → a-b-testing",
          "landing-page-design → landing-page-design",
          "copywriting → copywriting",
          "paid-advertising → marketing"
        ],
        "triggers": [
          "growth strategy",
          "how do we grow",
          "acquisition strategy",
          "retention strategy",
          "viral growth",
          "network effects",
          "growth loops",
          "product-led growth",
          "plg",
          "ltv cac",
          "unit economics",
          "growth model",
          "flywheel",
          "compound growth",
          "channel strategy",
          "referral program",
          "activation rate",
          "magic moment",
          "aha moment",
          "growth experimentation"
        ],
        "tags": [
          "growth",
          "strategy",
          "acquisition",
          "retention",
          "viral",
          "network-effects",
          "plg",
          "loops",
          "experimentation"
        ],
        "pairs_with": [
          "product-strategy     # Growth requires product-market fit",
          "brand-positioning    # Brand accelerates organic growth",
          "marketing           # Marketing executes growth strategy",
          "analytics           # Analytics measures growth",
          "a-b-testing         # Testing validates growth hypotheses",
          "viral-marketing     # Viral executes growth loops"
        ],
        "requires": [],
        "category": "strategy"
      },
      {
        "id": "hiring-strategy",
        "name": "Hiring Strategy",
        "version": "1.0.0",
        "layer": 2,
        "description": "Hiring senior to avoid learning",
        "principles": [
          "Hire for the next 18 months, not the next 5 years",
          "Wrong hire costs 6+ months - the cost is time, not money",
          "A-players hire A-players, B-players hire C-players",
          "Culture is defined by early hires, not by posters",
          "Startups can't compete on cash - compete on mission and equity",
          "Speed matters but desperation kills - don't hire to fill a hole"
        ],
        "owns": [
          "hiring-strategy",
          "team-building",
          "compensation",
          "equity-allocation",
          "role-definition",
          "interview-process",
          "candidate-assessment",
          "hiring-sequence",
          "first-hires",
          "offer-negotiation"
        ],
        "does_not_own": [
          "organization-design → operations",
          "performance-management → operations",
          "company-culture → founder-operating-system",
          "leadership-development → founder-character"
        ],
        "triggers": [
          "hiring",
          "first hire",
          "when to hire",
          "who to hire",
          "compensation",
          "equity",
          "salary",
          "recruiting",
          "interview process",
          "offer negotiation",
          "team building",
          "engineer hire",
          "sales hire",
          "founding team"
        ],
        "tags": [
          "hiring",
          "team",
          "compensation",
          "equity",
          "recruiting",
          "interviews",
          "offers",
          "startups",
          "founding-team"
        ],
        "pairs_with": [
          "fundraising-strategy     # Capital enables hiring",
          "go-to-market             # GTM hires",
          "product-strategy         # Product hires",
          "founder-operating-system # Culture and leadership"
        ],
        "requires": [],
        "category": "strategy"
      },
      {
        "id": "idea-maze",
        "name": "Idea Maze Navigation",
        "version": "1.0.0",
        "layer": 1,
        "description": "Picking ideas based on what's currently hot or funded",
        "principles": [
          "name: Live in the future, notice what is missing"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "strategy"
      },
      {
        "id": "moat-building",
        "name": "Moat Building",
        "version": "1.0.0",
        "layer": 2,
        "description": "Believing product quality alone is defensible",
        "principles": [
          "A great product is not a moat - it's a starting point",
          "The best moats compound over time - they get stronger, not weaker",
          "Moats protect margins, not just market share",
          "If you can't articulate your moat, you probably don't have one",
          "Some businesses are structurally incapable of moats - know which",
          "Network effects are the strongest moat, but hardest to build"
        ],
        "owns": [
          "competitive-advantage",
          "moat-building",
          "defensibility",
          "network-effects",
          "switching-costs",
          "brand-moat",
          "scale-economies",
          "data-moat",
          "platform-moat",
          "regulatory-moat",
          "counter-positioning"
        ],
        "does_not_own": [
          "product-strategy → product-strategy",
          "growth-tactics → growth-strategy",
          "brand-identity → brand-positioning",
          "pricing-power → pricing-strategy"
        ],
        "triggers": [
          "moat",
          "defensibility",
          "competitive advantage",
          "network effects",
          "switching costs",
          "barrier to entry",
          "unfair advantage",
          "protect from competition",
          "sustainable advantage",
          "winner take all",
          "flywheel",
          "lock-in"
        ],
        "tags": [
          "moat",
          "defensibility",
          "strategy",
          "network-effects",
          "switching-costs",
          "competitive-advantage",
          "seven-powers"
        ],
        "pairs_with": [
          "product-strategy      # Moat follows product-market fit",
          "growth-strategy       # Growth can build or depend on moat",
          "pricing-strategy      # Pricing power indicates moat strength",
          "platform-strategy     # Platforms are moat-building machines"
        ],
        "requires": [],
        "category": "strategy"
      },
      {
        "id": "pivot-patterns",
        "name": "Pivot Patterns",
        "version": "1.0.0",
        "layer": 1,
        "description": "Pivot based on accumulated evidence and user insights, not frustration",
        "principles": [
          "name: Pivot from learning, not frustration"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "strategy"
      },
      {
        "id": "pricing-strategy",
        "name": "Pricing Strategy",
        "version": "1.0.0",
        "layer": 2,
        "description": "Competing primarily on price",
        "principles": [
          "Price on value delivered, not cost incurred",
          "You're probably underpriced - most startups are",
          "Pricing is positioning - price signals quality",
          "Simple pricing converts better than clever pricing",
          "The goal is to capture a fair share of value created, not all of it",
          "Pricing is never 'done' - it evolves with your product and market"
        ],
        "owns": [
          "pricing-models",
          "pricing-strategy",
          "monetization",
          "pricing-psychology",
          "price-optimization",
          "value-based-pricing",
          "freemium-strategy",
          "usage-based-pricing",
          "enterprise-pricing",
          "pricing-experimentation",
          "discount-strategy",
          "packaging",
          "price-localization"
        ],
        "does_not_own": [
          "revenue-operations → growth-strategy",
          "sales-process → go-to-market",
          "financial-modeling → burn-rate-management",
          "market-sizing → product-strategy"
        ],
        "triggers": [
          "pricing",
          "how much to charge",
          "pricing model",
          "freemium",
          "free trial",
          "pricing tiers",
          "enterprise pricing",
          "usage-based",
          "per seat",
          "discount",
          "monetization",
          "when to charge",
          "price increase",
          "packaging",
          "value pricing"
        ],
        "tags": [
          "pricing",
          "monetization",
          "strategy",
          "revenue",
          "value",
          "freemium",
          "enterprise",
          "SaaS"
        ],
        "pairs_with": [
          "product-strategy      # Pricing reflects product positioning",
          "growth-strategy       # Pricing affects acquisition and retention",
          "go-to-market         # Pricing determines sales motion",
          "moat-building        # Pricing power is a moat indicator"
        ],
        "requires": [
          "product-strategy     # Need product clarity before pricing"
        ],
        "category": "strategy"
      },
      {
        "id": "product-strategy",
        "name": "Product Strategy",
        "version": "1.0.0",
        "layer": 3,
        "description": "Prioritizing features for your most vocal/engaged users",
        "principles": [
          "Fall in love with the problem, not the solution",
          "The best products are painkillers, not vitamins",
          "If you're not embarrassed by v1, you launched too late",
          "Strategy is what you say no to",
          "Products are not built, they are discovered"
        ],
        "owns": [
          "product-vision",
          "product-market-fit",
          "competitive-positioning",
          "value-proposition",
          "problem-definition",
          "customer-discovery",
          "product-principles",
          "success-metrics-definition",
          "go-to-market-strategy",
          "product-differentiation",
          "mvp-definition",
          "product-prioritization-frameworks"
        ],
        "does_not_own": [
          "brand-identity → brand-positioning",
          "growth-tactics → growth-strategy",
          "user-interface-design → ui-design",
          "user-experience-flows → ux-design",
          "technical-architecture → backend",
          "marketing-campaigns → marketing",
          "copy-and-messaging → copywriting",
          "analytics-implementation → analytics",
          "feature-specifications → product-management"
        ],
        "triggers": [
          "what should we build",
          "product strategy",
          "product vision",
          "product-market fit",
          "pmf",
          "value proposition",
          "competitive advantage",
          "market positioning",
          "customer discovery",
          "jobs to be done",
          "jtbd",
          "problem worth solving",
          "mvp scope",
          "product differentiation",
          "why will this win",
          "product principles",
          "what makes this different",
          "market opportunity"
        ],
        "tags": [
          "product",
          "strategy",
          "vision",
          "pmf",
          "positioning",
          "discovery",
          "validation",
          "prioritization"
        ],
        "pairs_with": [
          "brand-positioning    # Brand amplifies product truth",
          "growth-strategy      # Growth follows product-market fit",
          "ux-design           # UX realizes product vision",
          "marketing           # Marketing communicates value prop",
          "product-management  # PM executes strategy"
        ],
        "requires": [],
        "category": "strategy"
      },
      {
        "id": "taste-and-craft",
        "name": "Taste and Craft",
        "version": "1.0.0",
        "layer": 1,
        "description": "Study great work systematically to develop taste over time",
        "principles": [
          "name: Taste is learned, not innate"
        ],
        "owns": [],
        "does_not_own": [],
        "triggers": [],
        "tags": [],
        "pairs_with": [],
        "requires": [],
        "category": "strategy"
      }
    ]
  }
]